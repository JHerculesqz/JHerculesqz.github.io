<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>妙木山</title><link>https://jherculesqz.github.io/</link><description>Recent content on 妙木山</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 26 Feb 2024 10:00:59 +0800</lastBuildDate><atom:link href="https://jherculesqz.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>关于</title><link>https://jherculesqz.github.io/about/</link><pubDate>Thu, 05 Aug 2021 13:01:37 +0800</pubDate><guid>https://jherculesqz.github.io/about/</guid><description>&lt;h1 id="关于博客">关于博客&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>独立&lt;/strong>：一直在写技术博客，从微信公众号、头条号、SegmentFault、掘金、简书一路折腾过来，还是希望有一个自己独立的空间。&lt;/li>
&lt;li>&lt;strong>坚持&lt;/strong>：随着年龄增长，逐渐欲说还休，还是文字更有韵味，希望自己能坚持写下去。&lt;/li>
&lt;li>&lt;strong>浪漫&lt;/strong>：按照&lt;a href="https://archiveprogram.github.com">Archive Program&lt;/a>计划的愿景，我的博客会在&amp;rdquo; GitHub北极代码库&amp;quot;中保存千年。想想1000年以后，我的后代们能读到我这个中二祖先的文字，还是一件挺浪漫的事儿。&lt;/li>
&lt;li>&lt;strong>感谢&lt;/strong>：感谢GitHub Pages、Hugo、Jane提供的技术支持。&lt;/li>
&lt;li>&lt;strong>妙木山&lt;/strong>：妙木山是修炼仙术的地方，作为火影的死忠粉，&amp;ldquo;妙木山&amp;quot;无比适合这个博客的定位——修炼、探索。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/about/MiaoMu.png" alt="MiaoMu">&lt;/p>
&lt;h1 id="关于我">关于我&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>行业&lt;/strong>：软件行业16年，无法用语言表达对编程的喜爱——举个栗子吧：有段时间喜欢在酒吧里写代码，同去的小伙伴无聊地陌陌上约人，自我介绍就是&amp;quot;A+吧台，旁边有个写代码的沙雕&amp;rdquo;。&lt;/li>
&lt;li>&lt;strong>技术方向&lt;/strong>：近几年痴迷语言和编译器技术，还有点痴迷计算机图形学。
&lt;ul>
&lt;li>&lt;strong>编程语言&lt;/strong>：目前工作Java和JavaScript用的最多，但我最喜欢C#——PHP是最好的语言，行了吧！&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>哲学&lt;/strong>：不知何时，开始期待理解生命的意义。东一本西一本的书拿来乱翻，也没找到答案。不过，也不是全无收获——能模模糊糊地体会诗词的意境、能回味出毛选的奇妙、能敬畏金刚经的高深……继续求索吧……&lt;/li>
&lt;li>&lt;strong>兴趣&lt;/strong>：年轻的时候，喜欢轮滑、滑板、快乐肥仔水。现在，喜欢滑雪、乒乓球、茶(特指正山小种)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/about/Me.png" alt="Me">&lt;/p></description></item><item><title>【chatGPT】学习笔记41-多模态-Sora浅析</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-sora%E6%B5%85%E6%9E%90/</link><pubDate>Mon, 26 Feb 2024 10:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-sora%E6%B5%85%E6%9E%90/</guid><description>&lt;p>Sora自2024年2月16日发布以来，持续霸屏、热度不断。从OpenAI官网上的演示视频看，效果也是相当震撼。&lt;/p>
&lt;p>本篇基于OpenAI发布的技术报告对Sora的技术特点和原理进行解读。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-Sora%E6%B5%85%E6%9E%90/image-20240226144755598.png" alt="image-20240226144755598">&lt;/p>
&lt;h1 id="1sora是什么">1.Sora是什么？&lt;/h1>
&lt;p>Sora是一个文生视频的AI模型，可以根据文本信息生成真实且富有想象力的视频内容。主要特点：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>以自然语言为输入(提示词)，生成符合提示词描述的视频&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>可生成1分钟内容连贯的视频，视频尺寸/分辨率可调整，目前只有Sora做到&lt;/strong>。其它模型只能生成4秒以内、256x256固定尺寸的视频。&lt;/li>
&lt;li>&lt;strong>真实世界的模拟器&lt;/strong>，不仅理解物理实体(如人、猫、狗、&amp;hellip;)，还懂得物理规律(如光照、碰撞、粒子、&amp;hellip;)。&lt;/li>
&lt;/ul>
&lt;p>Sora出道即颠峰，让一众顶级文生视频模型望尘莫及。我们来直观感受下Sora生成的视频的震撼效果：&lt;/p>
&lt;p>提示词如下：&lt;/p>
&lt;blockquote>
&lt;p>Several giant wooly mammoths approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large furry mammal with beautiful photography, depth of field.&lt;/p>
&lt;/blockquote>
&lt;p>视频如下：&lt;/p>
&lt;iframe src="//player.bilibili.com/player.html?aid=1301071173&amp;bvid=BV1zu4m1c7gg&amp;cid=1452188766&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;h1 id="2sora原理浅析和技术优势">2.Sora原理浅析和技术优势&lt;/h1>
&lt;p>OpenAI没有公开Sora的模型细节，本文后续分析依据OpenAI的&amp;quot;Technic Report&amp;quot;推测所得。&lt;/p>
&lt;h2 id="21sora是否采用了新的模型架构技术">2.1.Sora是否采用了新的模型架构&amp;amp;技术？&lt;/h2>
&lt;p>答案是没有。&lt;/p>
&lt;p>文生视频可能涉及的模型架构如下：&lt;/p>
&lt;ul>
&lt;li>RRN (循环神经网络)&lt;/li>
&lt;li>GAN (生成式对抗网络)&lt;/li>
&lt;li>自回归Transformer&lt;/li>
&lt;li>Diffusion (扩散模型)&lt;/li>
&lt;/ul>
&lt;p>Sora采用的是：&lt;/p>
&lt;ul>
&lt;li>自回归Transformer&lt;/li>
&lt;li>Diffusion (扩散模型)&lt;/li>
&lt;/ul>
&lt;h2 id="22sora对现有模型架构技术的创新">2.2.Sora对现有模型架构&amp;amp;技术的创新&lt;/h2>
&lt;p>Sora架构是结合了Diffusion扩散模型和Transformer架构的创新设计。&lt;/p>
&lt;h3 id="1用transformer架构学习视频特征">(1)用Transformer架构，学习视频特征&lt;/h3>
&lt;p>灵感来自于Tranformer架构在GPT中的成功应用，OpenAI把自然语言的特征表示方法引入到了视频处理中：&lt;/p>
&lt;ul>
&lt;li>通过编码器，把视频的每一帧转换为有时序的向量，若干帧形成了&lt;strong>向量矩阵&lt;/strong>，Sora称之为&lt;strong>Turning visual data into patches&lt;/strong>。(大语言模型是把文字转换成一个个token，Sora则是把视频转换成一个个patch。)&lt;/li>
&lt;li>与大语言模型中token线性序列不同，由patch组成的高维向量矩阵包含了时序、分辨率、高宽比等丰富信息。&lt;/li>
&lt;li>和大语言模型一样(文本信息压缩网络)，Sora模型本质是一个视频压缩网络&lt;strong>Video compression network&lt;/strong>，使用该视频压缩网络把高维向量矩阵压缩成单维向量序列。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-Sora%E6%B5%85%E6%9E%90/image-20240223161152675.png" alt="image-20240223161152675">&lt;/p>
&lt;h3 id="2用结合了transformer的diffusion模型学习还原视频的特征">(2)用结合了Transformer的Diffusion模型，学习还原视频的特征&lt;/h3>
&lt;h4 id="--什么是扩散模型diffusion-model">- 什么是扩散模型Diffusion Model&lt;/h4>
&lt;p>Diffusion Model的基本原理是将原始图片逐渐加入噪声(Noise)，让原本清晰的图片逐渐变成全是噪声的状态。&lt;/p>
&lt;p>Diffusion Model主要有两个过程：前向处理和反向处理。图解如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>前向处理&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>AI训练过程中的1次噪声扩散&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-Sora%E6%B5%85%E6%9E%90/image-20240226131740185.png" alt="image-20240226131740185">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>AI训练过程中，进行N次噪声扩散&lt;/p>
&lt;ul>
&lt;li>进行N次噪声扩散，将图片变成全是噪点的图像&lt;/li>
&lt;li>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-Sora%E6%B5%85%E6%9E%90/image-20240226132019285.png" alt="image-20240226132019285">&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>后向处理&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>AI训练过程中，进行N次噪声降噪，变成清晰图片&lt;/li>
&lt;li>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-Sora%E6%B5%85%E6%9E%90/image-20240226132143014.png" alt="image-20240226132143014">&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>经过如上扩散处理，我们得到了&lt;strong>噪声与图像的关系。&lt;/strong>&lt;/p>
&lt;p>利用transformer模型，既可以理解噪声的特性向量，也可以理解自然语言的特征向量，那么就可以建立&lt;strong>噪声与提示词的关系&lt;/strong>。基于这种机制，模型就能够根据提示词来生成图片了。图片是视频的一帧，文生视频也可以用同样的原理来生成。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-Sora%E6%B5%85%E6%9E%90/image-20240227084715255.png" alt="image-20240227084715255">&lt;/p>
&lt;h4 id="--sora的diffusion-transformer模型">- Sora的Diffusion Transformer模型&lt;/h4>
&lt;p>在Diffusion Model的基础上，引入Transformer技术方法：&lt;/p>
&lt;ul>
&lt;li>通过编码器，将每一帧噪声转换为向量，若干帧形成了&lt;strong>噪声向量矩阵&lt;/strong>，Sora称之为&lt;strong>Noisy patches&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-Sora%E6%B5%85%E6%9E%90/image-20240226104456184.png" alt="image-20240226104456184">&lt;/p>
&lt;ul>
&lt;li>Sora的创新点：&lt;strong>一次性生成&lt;/strong>Noise Vector Cude，用以保证帧与帧之间的逻辑关系。从而生成时间和空间更流畅、更连贯的视频。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-Sora%E6%B5%85%E6%9E%90/image-20240226104436506.png" alt="image-20240226104436506">&lt;/p>
&lt;h2 id="23sora的技术优势">2.3.Sora的技术优势&lt;/h2>
&lt;p>虽然OpenAI没有公布Sora模型的训练细节，但即使公布了，其他厂家可能也很难复制或追赶。&lt;/p>
&lt;h3 id="1sora的video-compression-network依托于强大的算力">(1)Sora的Video compression network依托于强大的算力&lt;/h3>
&lt;p>模型成功的一个重要因素是海量的训练数据，训练需要消耗大量算力。Sora采用高维向量矩阵模式的视频处理方式，意味着更大算力消耗。中信证券曾简单估算，一个6~8秒的视频（约60帧）需要约6万个Patches，如果去噪步数是20的话，相当于要生成120万个Tokens，这是相当大的计算量。那么Sora生成1分钟视频需要的算力可想而知。&lt;/p>
&lt;p>同一个提示词，算力越高，生成视频效果越好。Sora给出基础算力、4倍算力、32倍算力下的效果展示：&lt;/p>
&lt;iframe src="//player.bilibili.com/player.html?bvid=BV1uC411s7y9&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;iframe src="//player.bilibili.com/player.html?bvid=BV1ey421q72G&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;h3 id="2gpt4加速孵化多模态大模型多模态大模型反哺llm">(2)GPT4加速孵化多模态大模型，多模态大模型反哺LLM&lt;/h3>
&lt;ul>
&lt;li>遥遥领先的自然语言理解能力：
&lt;ul>
&lt;li>文生视频模型的训练离不开大量带有文字标注的视频，OpenAI基于GPT4专门训练一个高度描述性的字幕模型，使用它来为训练数据集中的所有视频生成文本字幕。这样进行训练极大的保证了文本保真度以及视频的整体质量。&lt;/li>
&lt;li>同时，GPT优秀的文本扩展能力，可以丰富用户输入的提示词，让文本描述更丰富、更细致，从而生成丰富、细腻的视频。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-Sora%E6%B5%85%E6%9E%90/image-20240226141517838.png" alt="image-20240226141517838">&lt;/p>
&lt;h1 id="3sora有哪些创意玩法">3.Sora有哪些创意玩法&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>Animating DALL·E images&lt;/strong>：图生视频
&lt;ul>
&lt;li>左边是图片和提示词，右边是生成的视频&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?bvid=BV1pZ421y7RF&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>&lt;strong>Extending generated videos&lt;/strong>：视频续写
&lt;ul>
&lt;li>基于原视频，向前或向后续写新的视频&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?bvid=BV1oK42187Kc&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>&lt;strong>Video-to-video editing&lt;/strong>：编辑视频
&lt;ul>
&lt;li>左边是原视频，右边是根据提示词修改的视频&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?bvid=BV1Vu4m1w7QY&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>&lt;strong>Connecting videos&lt;/strong>：连接视频
&lt;ul>
&lt;li>通过左侧视频和右侧视频，生成中间过渡视频&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?bvid=BV19w4m1f7dr&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>&lt;strong>Image generation capabilities&lt;/strong>：生成高质量图片
&lt;ul>
&lt;li>生成各种尺寸的图片，分辨率最高可达 2048x2048&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B041-%E5%A4%9A%E6%A8%A1%E6%80%81-Sora%E6%B5%85%E6%9E%90/image-20240226173623135.png" alt="image-20240226173623135">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>卓越的仿真能力&lt;/strong>：生成现实世界仿真视频&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>3D consistency&lt;/strong>：空间一致性&lt;/p>
&lt;ul>
&lt;li>模拟摄像机镜头旋转和运行，画面中的人和场景元素在三维空间中也一致的移动。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?bvid=BV11K421t75e&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>&lt;strong>Long-range coherence and object permanence&lt;/strong>：时间一致性
&lt;ul>
&lt;li>Sora能够有效地为短期和长期依赖关系建模。例如，模型可以保存人物、动物和物体，即使它们被遮挡或离开了框架(下左视频)。同样，可以基于单个样本生成同一角色的多个镜头，并在整个视频中保持其外观(下右视频)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?bvid=BV1Av421k7vD&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>&lt;strong>Interacting with the world&lt;/strong>：模拟真实世界的动作和结果
&lt;ul>
&lt;li>随着画笔的移动，画面中增加了花瓣；人吃汉堡，汉堡留下咬痕。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?bvid=BV1vF4m157Hm&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;h1 id="4sora对视频相关领域的影响">4.Sora对视频相关领域的影响&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>内容创作与媒体行业&lt;/strong>：&lt;/p>
&lt;p>在内容创作领域，Sora将缩短创作周期，降低制作成本。&lt;/p>
&lt;p>导演、视频编辑等岗位将直面Sora的影响。&lt;/p>
&lt;p>抖音类短视频App是否会面临挑战？&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>教育和培训：&lt;/strong>
教育工作者可以利用Sora创建生动的教学材料，提高课程互动性和学习效果。
但Sora仍然面临垂域微调的难题——我们尝试生成一个排序算法的Demo，得到的视频不尽如人意。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>营销和广告&lt;/strong>
广告设计师和品牌经理可以通过Sora来快速生成视频广告内容。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>游戏开发与动画制作&lt;/strong>
游戏设计师和动画制作人员可能会使用Sora快速原型制作和动画创建。
这不仅能够加快项目开发速度，还能使得复杂场景的测试和迭代变得更为高效。
不过，这也可能引发对传统动画和建模技艺的重新评估。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>上下游基础设施：&lt;/strong>
上游厂商：AI服务器、AI芯片、通信行业、云厂商。
下游应用：大量的短/中/长视频应用和服务需求。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="5参考">5.参考&lt;/h1>
&lt;blockquote>
&lt;p>&lt;a href="https://openai.com/research/video-generation-models-as-world-simulators">https://openai.com/research/video-generation-models-as-world-simulators&lt;/a>&lt;/p>
&lt;/blockquote></description></item><item><title>【chatGPT】学习笔记40-LLM应用-如何构建RAG数据集</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B040-llm%E5%BA%94%E7%94%A8-%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BArag%E6%95%B0%E6%8D%AE%E9%9B%86/</link><pubDate>Mon, 05 Feb 2024 10:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B040-llm%E5%BA%94%E7%94%A8-%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BArag%E6%95%B0%E6%8D%AE%E9%9B%86/</guid><description>&lt;p>2023年是基础大模型的爆发元年，专家预测2024年将是AI应用的爆发元年。&lt;/p>
&lt;p>因此，本专栏希望通过一系列文章，和大家探讨AI应用的规划、落地、实践等问题：&lt;/p>
&lt;blockquote>
&lt;p>如何在千行百业寻找AI应用的落地点？如何用AI为客户带来真实的价值？&lt;/p>
&lt;p>如何开发高质量AI应用？如何评估和控制AI应用的开发成本？&lt;/p>
&lt;/blockquote>
&lt;p>RAG是目前AI应用落地的主要技术领域，本文首先来探讨RAG相关的产品实践。&lt;/p>
&lt;h1 id="1开发ai应用前我们应该考虑什么">1.开发AI应用前，我们应该考虑什么？&lt;/h1>
&lt;h2 id="1我们真的需要ai应用吗">(1)我们真的需要AI应用吗？&lt;/h2>
&lt;p>相信大家有一种感觉：AI很强大，但问及AI解决什么具体的行业问题？又无从回答。&lt;/p>
&lt;p>这是一个产品规划问题：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>行业痛点&lt;/strong>：我的行业领域有什么Gap点？&lt;/li>
&lt;li>&lt;strong>业务设计&lt;/strong>：AI能解决这些Gap点吗？&lt;/li>
&lt;li>&lt;strong>价值呈现&lt;/strong>：这些问题解决后能给客户带来什么价值？&lt;/li>
&lt;/ul>
&lt;p>我们不能叶公好龙式地迷失在AI浪潮中，还是要落脚于&lt;strong>解决客户痛点、呈现产品价值&lt;/strong>。&lt;/p>
&lt;p>以&lt;strong>Khan Academy&lt;/strong>在AI赋能教育的实践为例：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Khan Academy是一家具备全球影响力的在线教育平台，愿景是为提供&lt;strong>普惠教育&lt;/strong>(为无法享受基础教育的学生提供覆盖学科广泛、内容专业的在线课程。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>行业痛点&lt;/strong>：Khan Academy的普惠教育理想，意味着既要&lt;strong>高教学质量、千人千面&lt;/strong>，又要&lt;strong>控制教学成本&lt;/strong>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>业务设计&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>怎么学&lt;/strong>：通过AI对不同学生的画像，自动化(成本)、专业化(高质量)、针对性(千人千面)地给出学习地图。&lt;/li>
&lt;li>&lt;strong>学什么&lt;/strong>：通过AI自主挖掘发现学习资源，自动化(成本)、针对性(千人千面)地为学生推荐学习资源。&lt;/li>
&lt;li>&lt;strong>监督引导&lt;/strong>：通过AI，自动化(成本)、有耐心(高质量)地监督与调整学生进度及学习习惯。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>价值呈现&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>自主学习、个性化学习是普惠教育的基石。&lt;/li>
&lt;li>&lt;strong>AI从教学质量和成本上使得自主学习、个性化学习成为了可能&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B040-LLM%E5%BA%94%E7%94%A8-%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BARAG%E6%95%B0%E6%8D%AE%E9%9B%86/image-20240206095448606.png" alt="image-20240206095448606">&lt;/p>
&lt;h2 id="2解决问题的手段只有锤子吗">(2)解决问题的手段只有锤子吗？&lt;/h2>
&lt;p>AI智能问答是一把锤子(也是目前国内AI应用的主要形态)，但它只是AI能力的很小一部分。&lt;/p>
&lt;p>为了更好地选择合适的AI能力解决客户问题，我们需要理解AI能力的全集。&lt;/p>
&lt;p>AI能力可以分为&lt;strong>基础能力&lt;/strong>和&lt;strong>综合能力&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>基础能力&lt;/strong>：AI的听说读写能力，这些能力可以让AI将&amp;quot;文字&amp;rdquo;、&amp;ldquo;语音&amp;rdquo;、&amp;ldquo;图像及视频&amp;quot;进行相互转换。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B040-LLM%E5%BA%94%E7%94%A8-%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BARAG%E6%95%B0%E6%8D%AE%E9%9B%86/image-20240203083813459.png" alt="image-20240203083813459">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>综合能力&lt;/strong>：综合能力依托于AI基础能力，进而解决客户的业务问题。
&lt;ul>
&lt;li>&lt;strong>RAG能力&lt;/strong>：AI可以通过外挂形式，进行垂域知识问答。&lt;/li>
&lt;li>&lt;strong>ReAct能力&lt;/strong>：可以发挥AI具备的一定的推理能力，分解任务，自动执行。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B040-LLM%E5%BA%94%E7%94%A8-%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BARAG%E6%95%B0%E6%8D%AE%E9%9B%86/image-20240206101931437.png" alt="image-20240206101931437">&lt;/p>
&lt;p>面向不同类型的客户问题，我们选择的AI能力不同：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>检索类问题适合采用RAG&lt;/strong>。
&lt;ul>
&lt;li>如：了解工作流程、学习专业知识等检索类客户问题，适合使用AI的RAG综合能力。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>任务执行类问题适合采用ReAct&lt;/strong>。
&lt;ul>
&lt;li>如：挖掘海量互联网学习资源、根据学生学习情况监督调整学习计划等任务执行类问题，适合采用ReAct综合能力。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="2如何构建rag数据集">2.如何构建RAG数据集？&lt;/h1>
&lt;p>在确定采用RAG技术解决客户问题后，构建高质量的RAG数据集是RAG成功的关键(否则就是&amp;quot;垃圾进，垃圾出&amp;quot;的结果)。&lt;/p>
&lt;p>我们接下来讨论如何构建高质量RAG数据集。&lt;/p>
&lt;h2 id="21问题分类">2.1.问题分类&lt;/h2>
&lt;p>在制作数据集前，要理清垂域中的&lt;strong>垂域用户问题&lt;/strong>和&lt;strong>垂域知识&lt;/strong>的&lt;strong>特点&lt;/strong>。&lt;/p>
&lt;p>垂域用户问题有如下特点：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>高频问题易识别&lt;/strong>: 常见问题和重复性问题出现的频率较高，垂域专家清楚高频问题是什么。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>针对性强&amp;amp;辨识度高&lt;/strong>：通常针对特定的知识进行提问，问题描述包含垂域专业术语，不闲聊。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>兼具广度和深度&lt;/strong>：可能是问结构纲领级的问题，也可能是针对某个具体细节的问题。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>垂域知识有以下特点：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>独特性&lt;/strong>：垂域知识有其独特的知识体系和术语，需要具备一定的专业背景和知识储备才能理解和应用。&lt;/li>
&lt;li>&lt;strong>结构明确&lt;/strong>：垂域知识通常有明确的结构和层次，各层知识间不存在重复和二义性。垂域知识更新很快，但知识结构变化相对小。&lt;/li>
&lt;/ul>
&lt;p>基于以上特点，可以将垂域用户向AI提问的&lt;strong>问题类型分为2类&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>高频问题&lt;/strong>：适合采用FAQ问答技术，一则可使&lt;strong>答案准确可控&lt;/strong>，二则减少AI的资源消耗。&lt;/li>
&lt;li>&lt;strong>知识问答&lt;/strong>：适合采用文档问答技术，一则文档所覆盖的垂域知识深度与广度兼备，二则构建成本相对较低。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B040-LLM%E5%BA%94%E7%94%A8-%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BARAG%E6%95%B0%E6%8D%AE%E9%9B%86/image-20240206103355976.png" alt="image-20240206103355976">&lt;/p>
&lt;h2 id="22faq问答数据集构建">2.2.FAQ问答数据集构建&lt;/h2>
&lt;h3 id="1关注构建成本">(1)关注构建成本&lt;/h3>
&lt;p>FAQ问答数据数据集构建时，可能存在一种误区：&lt;strong>问题不够加问题&lt;/strong>？&lt;/p>
&lt;ul>
&lt;li>问题不是不够，而是AI的理解能力有限，无法理解同一个问题五花八门的表达形式。&lt;/li>
&lt;li>问题不够加问题，本质就是穷举问题表达形式，但自然语言的表达形式穷举成本极高甚至不可穷举，因此会导致数据集构建成本不可承受。&lt;/li>
&lt;/ul>
&lt;p>如果上述方法行不通，则说明我们需要：用&lt;strong>有限的问答对&lt;/strong>覆盖&lt;strong>多样的问题表达形式&lt;/strong>，进而才能控制FAQ数据集的构建成本。&lt;/p>
&lt;p>如下是我们的工程实践：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>从知识的覆盖度上构建问答对，而不是从问题的表达多样性上构建问答对——这样&lt;strong>问答对的数量就是有限的&lt;/strong>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>覆盖多样的问题表达形式，可以采用关键词、扩展问等技巧。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>这个过程必须投入业务专家，根据上述两点工程实践进行把关和输出，业务专家需要保证。&lt;/p>
&lt;ul>
&lt;li>每个问题要保证&lt;strong>语义唯一性&lt;/strong>。&lt;/li>
&lt;li>所有问题构成的语义集合要保证&lt;strong>业务覆盖性&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;h3 id="2关注关键词提取">(2)关注关键词提取&lt;/h3>
&lt;p>关于前文提到的关键词技巧，也存在一个误区：直接将问题中的主谓宾作为关键词。&lt;/p>
&lt;ul>
&lt;li>这里举个例子：&lt;code>Java&lt;/code>是&amp;quot;如何提高Java的调试与定位能力？&amp;ldquo;这个问题的关键词吗？&lt;/li>
&lt;li>显然，从自然语言角度&lt;code>Java&lt;/code>是关键词，但从业务角度&lt;code>Java&lt;/code>不是关键词。
&lt;ul>
&lt;li>因为用户对Java领域的常见问题，都会带有Java这个单词。&lt;/li>
&lt;li>如果将Java作为本问题的关键词，那么所有的垂域问题都会被AI认为与本问题有关。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>我们的实践经验是：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>每个关键词必须具备&lt;strong>独特性&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>上述例子中，&lt;code>Java&lt;/code>没有独特性，失去了特征，而&lt;code>调试与定位能力&lt;/code>作为这个问题的关键词更为合适，因其具有独特性。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>关键词集合必须具备&lt;strong>丰富性&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>从业务角度，&amp;ldquo;调试与定位能力&amp;rdquo;，也有&amp;quot;调试定位&amp;rdquo;、&amp;ldquo;调试与定位&amp;quot;这种&lt;strong>惯用语&lt;/strong>，因此关键词集合可以丰富为[&amp;ldquo;调试与定位能力&amp;rdquo;, &amp;ldquo;调试与定位&amp;rdquo;, &amp;ldquo;调试定位&amp;rdquo;]。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="23文档问答数据集构建">2.3.文档问答数据集构建&lt;/h2>
&lt;h3 id="1关注文档质量">(1)关注文档质量&lt;/h3>
&lt;p>文档问答是AI对垂域文档进行学习理解(向量化)。这个过程类似老师(AI工程师)教小孩(AI)学习一本教材(垂域文档)。&lt;/p>
&lt;p>需要充分理解AI的特点(&lt;strong>因材施教&lt;/strong>)，设计出AI更容易理解垂域文档(&lt;strong>好教材&lt;/strong>)，是构建文档问答数据集的关键技术。&lt;/p>
&lt;p>构建垂域文档，有如下实践：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>知识组织形式&lt;/strong>会影响召回率：
&lt;ul>
&lt;li>通过实测和尝试，将垂域知识构建为树状结构，比较易于当前国内LLM理解和学习。&lt;/li>
&lt;li>不要在垂域知识树的节点之间产生关联关系形成有向图，可以通过搬移树节点的形式用线性的形式表达知识节点的关系。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B040-LLM%E5%BA%94%E7%94%A8-%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BARAG%E6%95%B0%E6%8D%AE%E9%9B%86/image-20240206113907749.png" alt="image-20240206113907749">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>每个知识块节点的&lt;strong>粒度适中&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>知识块不宜过大&lt;/strong>：将整个垂域文档设计为一个知识块，会导致问啥问题都返回这个知识块。&lt;/li>
&lt;li>&lt;strong>知识块不宜过小&lt;/strong>：将垂域文档设计为一句话一个知识块，会导致知识点太碎，知识点之间存在复杂的逻辑关联，远超出现有LLM的推理能力。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>每个知识块节点内容&lt;strong>避免重复&lt;/strong>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个知识块节点内容&lt;strong>避免矛盾&lt;/strong>。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="24ai辅助构建数据集">2.4.AI辅助构建数据集&lt;/h2>
&lt;p>前述FAQ数据集构建、文档问答数据集构建的过程，都可以采用AI、自动化工具等方式辅助构建。&lt;/p>
&lt;p>我们会在后续文章中分享AI辅助构建数据集的工程方法与实践。&lt;/p>
&lt;p>但，无论采用怎样的数据集构建过程，还是要关注数据集的内容本身，是否满足上述工程实践的要求和原则。&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>构建RAG数据集，需要考虑一系列实践方法，建立标注规范，确保数据的质量和有效性。具体实践经验如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>AI应用的规划与设计：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>要用产品规划方法进行业务设计，落脚于&lt;strong>解决客户痛点、呈现产品价值&lt;/strong>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>要选择合适的AI能力解决业务问题，可用的AI能力包括&lt;strong>基础能力(听说读写)&lt;strong>和&lt;/strong>综合能力(RAG、ReAct)&lt;/strong>。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>构建RAG数据集方法：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>问题分类：&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>高频问题&lt;/strong>：适合采用FAQ问答技术，一则可使&lt;strong>答案准确可控&lt;/strong>，二则减少AI的资源消耗。&lt;/li>
&lt;li>&lt;strong>知识问答&lt;/strong>：适合采用文档问答技术，一则文档所覆盖的垂域知识深度与广度兼备，二则构建成本相对较低。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>FAQ问答数据集构建方法：
&lt;ul>
&lt;li>每个问题要保证&lt;strong>语义唯一性&lt;/strong>。&lt;/li>
&lt;li>所有问题构成的语义集合要保证&lt;strong>业务覆盖性&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>文档问答数据集构建方法：
&lt;ul>
&lt;li>&lt;strong>知识组织形式&lt;/strong>会影响召回率：将垂域知识构建为树状结构，可以通过搬移树节点的形式用线性的形式表达知识节点的关系。&lt;/li>
&lt;li>每个知识块节点的&lt;strong>粒度适中&lt;/strong>：知识块不宜过大，也不宜过小。&lt;/li>
&lt;li>每个知识块节点内容&lt;strong>避免重复&lt;/strong>。&lt;/li>
&lt;li>每个知识块节点内容&lt;strong>避免矛盾&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>可采用AI辅助构建数据集，但关键还是&lt;strong>要关注数据集的内容本身符合上述工程实践的要求和原则&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记39-LangChain解读-LCEL语言之领域功能(5)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD5/</link><pubDate>Thu, 01 Feb 2024 10:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD5/</guid><description>&lt;p>在LLM应用程序中，不可避免的会存在大量可知或不可知的故障点，比如模型API调用异常、链组合集成的问题、自定义的组件运行出错等。如果针对这些情况准备了fallback备用方法，就可以让程序更稳健。&lt;/p>
&lt;p>本篇我们来看下在LCEL中如何实现&amp;quot;fallback&amp;rdquo;。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(5)/image-20240202010923281.png" alt="image-20240202010923281">&lt;/p>
&lt;h1 id="1-lcel的fallback方法">1. LCEL的Fallback方法&lt;/h1>
&lt;p>LCEL在runnable中定义了fallback方法&lt;code>withfallback&lt;/code>，runnable组件及其组成的链都可以直接使用这个方法。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>功能简介&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>当调用方出现异常，则执行fallback中预置的备用方法。&lt;/li>
&lt;li>通常用于预防LLM API错误，也可用于其它runnable组件，或者工作链。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>使用语法&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>withfallbacks&lt;/code>的第一个参数是&lt;strong>备用方法&lt;/strong>，放在方括号&lt;code>[]&lt;/code>中。&lt;/li>
&lt;li>第二个参数&lt;code>exceptions_to_handle&lt;/code>为可选，用于&lt;strong>指定要处理的错误&lt;/strong>——当发生这些错误时才执行备用方法。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nv">chain&lt;/span> &lt;span class="o">=&lt;/span> runnable对象.withfallback&lt;span class="o">(&lt;/span>
&lt;span class="o">[&lt;/span>备用方法&lt;span class="o">]&lt;/span>,
&lt;span class="nv">exceptions_to_handle&lt;/span>&lt;span class="o">=(&lt;/span>KeyboardInterrupt, ...,&lt;span class="o">)&lt;/span>
&lt;span class="o">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;h1 id="2快速上手">2.快速上手&lt;/h1>
&lt;p>以智能客服场景为例，模拟LLM模型发生异常的情况，使用fallback来预防这些错误，提升用户体验。&lt;/p>
&lt;h2 id="step1-构建故障链">STEP1: 构建故障链&lt;/h2>
&lt;ul>
&lt;li>构造一个工作链，专门负责回答物流问题。通过设置不存在的模型来模拟模型故障。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(5)/image-20240202003427497.png" alt="image-20240202003427497">&lt;/p>
&lt;ul>
&lt;li>运行链，返回关于模型的错误信息。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(5)/image-20240202003628125.png" alt="image-20240202003628125">&lt;/p>
&lt;h2 id="step2-构建备用链">STEP2: 构建备用链&lt;/h2>
&lt;ul>
&lt;li>构建默认回复链，该链使用正常模型。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(5)/image-20240202003914611.png" alt="image-20240202003914611">&lt;/p>
&lt;h2 id="step3-构建fallback链">STEP3: 构建Fallback链&lt;/h2>
&lt;ul>
&lt;li>使用&lt;code>with_fallbacks&lt;/code>方法，构造工作链service_chain，把默认回复链作为物流链的后备方法。&lt;/li>
&lt;li>运行具有fallback能力service_chain，顺利得到回复。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(5)/image-20240202003948900.png" alt="image-20240202003948900">&lt;/p>
&lt;ul>
&lt;li>除了上述基础用法，我们还可以指定fallback服务于特殊的异常类型。如下示例中，指定故障链一旦发生了KeyboardInterrupt异常，才执行备用链。&lt;/li>
&lt;li>具体如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(5)/image-20240202004341255.png" alt="image-20240202004341255">&lt;/p>
&lt;h2 id="step4-构建fallback链自定义备用方法">STEP4: 构建Fallback链：自定义备用方法&lt;/h2>
&lt;ul>
&lt;li>假设LLM模型全部失效，把默认回复链的模型也改成无效的模型。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(5)/image-20240202005006014.png" alt="image-20240202005006014">&lt;/p>
&lt;ul>
&lt;li>自定义一个备用方法，来兜底保证给用户及时回复。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(5)/image-20240202005208000.png" alt="image-20240202005208000">&lt;/p>
&lt;ul>
&lt;li>构造新的工作链new_service_chain，把兜底回复作为后备方法。&lt;/li>
&lt;li>运行链，顺利得到回复。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B039-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(5)/image-20240202005233635.png" alt="image-20240202005233635">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本篇介绍了LCEL的fallback方法&lt;code>withfallbacks&lt;/code>，可以有效解决LLM API、模型输出不佳以及其他集成问题带来的问题。&lt;/p>
&lt;p>关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>&lt;code>withfallbacks&lt;/code>方法&lt;/strong>：&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LCEL在runnable中定义了fallback方法&lt;code>withfallbacks&lt;/code>，runnable组件及其组成的链都可以直接使用这个方法。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>withfallbacks&lt;/code>的第一个参数是&lt;strong>备用方法&lt;/strong>，第二个参数&lt;code>exceptions_to_handle&lt;/code>为可选，用于&lt;strong>指定要处理的错误&lt;/strong>——当发生这些错误时才执行备用方法。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用上述方法，构建了一个具有fallback机制的客服问答工作链。模拟LLM模型发生异常时，通过预置的后备方法及时回复用户消息。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>参考文档：翻译的LangChain官方文档&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记38-LangChain解读-LCEL语言之领域功能(4)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B038-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD4/</link><pubDate>Sun, 21 Jan 2024 10:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B038-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD4/</guid><description>&lt;p>langchain基础的链包括三个组件：提示词、LLM模型、输出解析器，但实际LLM应用开发会复杂很多，可能需要更多组件。&lt;/p>
&lt;p>本篇我们介绍LCEL提供的几个常用方法，可以帮助开发者构建自定义runnable组件，进而组合成功能更强大的链。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B038-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(4)/image-20240120130624759.png" alt="">&lt;/p>
&lt;h1 id="1-lcel组件构建方法">1. LCEL组件构建方法&lt;/h1>
&lt;p>LCEL在Runnable协议中定义了如下方法，帮助开发者灵活构建runnable组件：&lt;/p>
&lt;ul>
&lt;li>RunnablePassthrough&lt;/li>
&lt;li>RunnableLambda&lt;/li>
&lt;li>RunnableBranch&lt;/li>
&lt;/ul>
&lt;h2 id="1runnablepassthrough">(1)RunnablePassthrough:&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>功能简介&lt;/strong>：&lt;/p>
&lt;p>透传用户输入。通常与一个键组成键值对，用于构造下一个组件的输入。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>使用语法&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>如下示例，prompt组件需要的输入是以topic为键的字典，但实际用户输入是字符串&amp;quot;袋鼠&amp;rdquo;。&lt;/li>
&lt;li>利用&lt;code>RunnablePassthrough&lt;/code>透传用户输入，并与topic组成键值对，构造了promt所需的输入。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nv">prompt&lt;/span> &lt;span class="o">=&lt;/span> ChatPromptTemplate.from_template&lt;span class="o">(&lt;/span>&lt;span class="s2">&amp;#34;请讲一个关于{topic}的笑话。&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="nv">output_parser&lt;/span> &lt;span class="o">=&lt;/span> StrOutputParser&lt;span class="o">()&lt;/span>
&lt;span class="nv">model&lt;/span> &lt;span class="o">=&lt;/span> ChatOpenAI&lt;span class="o">()&lt;/span>
&lt;span class="nv">chain&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>&lt;span class="s2">&amp;#34;topic&amp;#34;&lt;/span>: RunnablePassthrough&lt;span class="o">()}&lt;/span> &lt;span class="p">|&lt;/span> prompt&lt;span class="p">|&lt;/span> model &lt;span class="p">|&lt;/span> output_parser
chain.invoke&lt;span class="o">(&lt;/span>&lt;span class="s2">&amp;#34;袋鼠&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;h2 id="2runnablelambda">(2)RunnableLambda:&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>功能简介&lt;/strong>：&lt;/p>
&lt;p>&lt;code>RunnableLambda&lt;/code>可以把自定义函数转换成Runnable对象，以便在组件中使用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>使用语法&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>如下示例，自定义函数my_function，然后通过RunnableLambda(my_function)转换为runnable组件。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">def my_function&lt;span class="o">()&lt;/span>
...
&lt;span class="k">return&lt;/span> xxxx
&lt;span class="nv">chain&lt;/span> &lt;span class="o">=&lt;/span> RunnableLambda&lt;span class="o">(&lt;/span>my_function&lt;span class="o">)&lt;/span> &lt;span class="p">|&lt;/span> 其它组件&lt;span class="p">|&lt;/span> ...
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;h2 id="3runnablebranch">(3)RunnableBranch&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>功能简介&lt;/strong>：&lt;/p>
&lt;p>类似路由功能，可以根据条件选择要运行的分支，即当条件满足时，则执行该分支。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>使用语法&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>如下示例，&lt;code>RunnableBranch&lt;/code>的参数是&amp;quot;条件、分支&amp;quot;对 + 默认分支。&lt;/li>
&lt;li>当某个条件满足时，则执行对应分支；如果条件都不满足，则执行默认分支。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nv">branch&lt;/span> &lt;span class="o">=&lt;/span> RunnableBranch&lt;span class="o">(&lt;/span>
&lt;span class="o">(&lt;/span>条件1, 分支1&lt;span class="o">)&lt;/span>,
...,
&lt;span class="o">(&lt;/span>条件n, 分支n&lt;span class="o">)&lt;/span>,
默认分支,
&lt;span class="o">)&lt;/span>
&lt;span class="nv">chain&lt;/span> &lt;span class="o">=&lt;/span> branch &lt;span class="p">|&lt;/span> 其它组件&lt;span class="p">|&lt;/span> ...
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;h1 id="2快速上手">2.快速上手&lt;/h1>
&lt;p>以智能客服场景为例，我们使用上述三个方法来组成一个相对复杂的工作链：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>利用LLM判断问题类别、感情色彩&lt;/p>
&lt;/li>
&lt;li>
&lt;p>自定义函数对LLM输出结果格式化，以便后续组件使用&lt;/p>
&lt;/li>
&lt;li>
&lt;p>根据问题类别，构造不同的客服分支，组建客服路由链&lt;/p>
&lt;/li>
&lt;li>
&lt;p>组成完整工作链，根据问题类别回答问题&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="step1-构建问题分类链">STEP1: 构建问题分类链&lt;/h2>
&lt;ul>
&lt;li>构建问题分类链topic_chain，任务是判断问题属于&amp;quot;产品质量&amp;rdquo; or &amp;ldquo;物流&amp;rdquo;，情绪是&amp;quot;积极&amp;rdquo;、&amp;ldquo;消极&amp;rdquo; or &amp;ldquo;中立&amp;rdquo;。&lt;/li>
&lt;li>使用&lt;code>RunnablePassthrough&lt;/code>透传用户问题，并与&amp;quot;question&amp;quot;组成键值对，作为prompt组件的输入。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B038-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(4)/image-20240120115926742.png" alt="">&lt;/p>
&lt;h2 id="step2-自定义runnable组件格式化输出结果">STEP2: 自定义Runnable组件：格式化输出结果&lt;/h2>
&lt;ul>
&lt;li>LangChain自带的输出解析器&lt;code>StrOutputParser&lt;/code>输出的是字符串，但我们下个组件的输入要求是字典。所以自己写个函数format_func，把字符串转成字典格式。&lt;/li>
&lt;li>使用&lt;code>RunnableLambda&lt;/code>把自定义函数format_func转换成runnable，并作为组件加入到工作链service_chain中。&lt;/li>
&lt;li>使用相同的用户问题调用工作链service_chain，输出结果为字典。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B038-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(4)/image-20240120121343812.png" alt="">&lt;/p>
&lt;h2 id="step3-构建路由链由3个分支链组成物流产品和默认">STEP3: 构建路由链：由3个分支链组成(物流、产品和默认)&lt;/h2>
&lt;ul>
&lt;li>先创建3个分支链，用于回答产品质量、物流等不同类别的问题。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B038-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(4)/image-20240120122633665.png" alt="">&lt;/p>
&lt;ul>
&lt;li>利用&lt;code>RunnableBranch&lt;/code>构造客服路由链anwser_routing_chain：
&lt;ul>
&lt;li>当用户问题类别为产品质量时，走产品客服链prod_response&lt;/li>
&lt;li>当用户问题类别为物流时，走物流客服链logistic_response链&lt;/li>
&lt;li>当用户问题类别不是上面两类时，走默认链general_response&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B038-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(4)/image-20240120123827219.png" alt="">&lt;/p>
&lt;h2 id="step4-组成完整工作链">STEP4: 组成完整工作链&lt;/h2>
&lt;ul>
&lt;li>现在，把工作链service_chain增加客服路由组件，组成完整工作链。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B038-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(4)/image-20240120124737826.png" alt="">&lt;/p>
&lt;ul>
&lt;li>使用不同的问题来测试，不同类别的问题都得到了对应领域客服的回复。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B038-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(4)/image-20240120124807112.png" alt="">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本篇介绍了LCEL提供的几种常用方法，可以帮助开发者灵活构建自己的Runnable组件，以支撑开发复杂的LLM应用。&lt;/p>
&lt;p>关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>RunnablePassthrough: 透传用户输入。通常与一个键组成键值对，用于构造下一个组件的输入。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RunnableLambda: 把自定义函数转换成Runnable对象，以便在组件中使用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RunnableBranch: 类似路由功能，可以根据条件选择要运行的分支，即当条件满足时，则执行该分支。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>使用上述方法，构建了一个客服问答工作链，自动判断用户问题类别并路由到对应领域的客服。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>参考文档：翻译的LangChain官方文档&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记37-LangChain解读-LCEL语言之领域功能(3)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B037-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD3/</link><pubDate>Mon, 08 Jan 2024 10:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B037-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD3/</guid><description>&lt;p>LCEL 可以轻松的构建复杂的链，并灵活调用它们，是因为LCEL基于&lt;code>Runnable&lt;/code>协议封装了一系列组合方法和调用接口。&lt;/p>
&lt;p>之前我们介绍了LCEL的核心调用接口&lt;code>invoke/ainvoke&lt;/code>、&lt;code>stream/astream&lt;/code>、&lt;code>batch/abatch&lt;/code>，本篇开始我们来学习LCEL的组合方法。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B037-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(3)/image-20240105205805572.png" alt="">&lt;/p>
&lt;h1 id="1-lcel的组合原语">1. LCEL的组合原语&lt;/h1>
&lt;p>LCEL的主要组合原语有两种：**RunnableSequence(串行组合)**和 &lt;strong>RunnableParallel( 并行组合)&lt;/strong>。&lt;/p>
&lt;h2 id="1runnablesequence-串行组合">(1)RunnableSequence: 串行组合&lt;/h2>
&lt;p>&lt;strong>方法简介&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>RunnableSequence可以将多个链组成一个串行工作流，各链串行执行。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个链的输出是下个链的输入，最后一个链的输出就是该整个工作流的输出。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>组合语法&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>RunnableSequence的原始调用语法如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nv">RunnableSequence对象&lt;/span> &lt;span class="o">=&lt;/span> RunnableSequence&lt;span class="o">(&lt;/span>&lt;span class="nv">first&lt;/span>&lt;span class="o">=&lt;/span>组件1, &lt;span class="nv">middle&lt;/span>&lt;span class="o">=[&lt;/span>组件2, 组件3, ...&lt;span class="o">]&lt;/span>, &lt;span class="nv">last&lt;/span>&lt;span class="o">=&lt;/span>组件n&lt;span class="o">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>RunnableSequence在构建串行工作流的示例如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nv">串行工作流对象&lt;/span> &lt;span class="o">=&lt;/span> RunnableSequence&lt;span class="o">(&lt;/span>&lt;span class="nv">first&lt;/span>&lt;span class="o">=&lt;/span>chain1, &lt;span class="nv">middle&lt;/span>&lt;span class="o">=[&lt;/span>chain2, chain3, ...&lt;span class="o">]&lt;/span>, &lt;span class="nv">last&lt;/span>&lt;span class="o">=&lt;/span>chainn&lt;span class="o">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>LCEL实现了用管道符&lt;code>|&lt;/code>来做串行组合的连接符。我们之前的案例都是在用这种方式来做串行组合。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nv">串行工作流对象&lt;/span> &lt;span class="o">=&lt;/span> chain1 &lt;span class="p">|&lt;/span> chain2 &lt;span class="p">|&lt;/span> ... &lt;span class="p">|&lt;/span> chainn&lt;span class="o">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;h2 id="2runnableparallel-并行组合">(2)RunnableParallel: 并行组合&lt;/h2>
&lt;p>&lt;strong>方法简介&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>RunnableParallel可以把多个链组成并行工作流，各链并行执行。&lt;/li>
&lt;li>各链的输入是相同的，整个工作流的输出是用各链的输出构造的字典。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>组合语法&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>RunnableParallel的调用语法如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nv">RunnableParallel对象&lt;/span> &lt;span class="o">=&lt;/span> RunnableParallel&lt;span class="o">({&lt;/span>&lt;span class="s2">&amp;#34;Key1&amp;#34;&lt;/span>: 组件1, &lt;span class="s2">&amp;#34;Key2&amp;#34;&lt;/span>: 组件2, ..., &lt;span class="s2">&amp;#34;Keyn&amp;#34;&lt;/span>: 组件n&lt;span class="o">})&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>由于&lt;code>Runnable&lt;/code>支持类型转换，所以也可以这样调用：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nv">RunnableParallel对象&lt;/span> &lt;span class="o">=&lt;/span> RunnableParallel&lt;span class="o">(&lt;/span>&lt;span class="nv">Key1&lt;/span>&lt;span class="o">=&lt;/span>组件1, &lt;span class="nv">Key2&lt;/span>&lt;span class="o">=&lt;/span>组件2, ..., &lt;span class="nv">Keyn&lt;/span>&lt;span class="o">=&lt;/span>组件n&lt;span class="o">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>RunnableParallel的输出是字典格式，是由原键+组件执行结果组成的键值对，示例如下&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="o">{&lt;/span>&lt;span class="s1">&amp;#39;Key1&amp;#39;&lt;/span>: 组件1的结果, &lt;span class="s1">&amp;#39;Key2&amp;#39;&lt;/span>: 组件2的结果, ..., &lt;span class="s1">&amp;#39;Keyn&amp;#39;&lt;/span>: 组件n的结果&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>RunnableParallel构建工作流的示例如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nv">并行工作流对象&lt;/span> &lt;span class="o">=&lt;/span> RunnableParallel&lt;span class="o">({&lt;/span>&lt;span class="s2">&amp;#34;Key1&amp;#34;&lt;/span>: chain1, &lt;span class="s2">&amp;#34;Key2&amp;#34;&lt;/span>: chain2, ..., &lt;span class="s2">&amp;#34;Keyn&amp;#34;&lt;/span>: chainn&lt;span class="o">})&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;h2 id="3runnablesequence和runnableparallel的组合使用">(3)RunnableSequence和RunnableParallel的组合使用&lt;/h2>
&lt;p>遵循LCEL &lt;code>Runnable&lt;/code>协议的组件都可以使用上述两种方式组合。同时，由于组合成的链也是一个Runnable对象，这就意味着在一个链里可以混合使用RunnableSequence和RunnableParallel两种组合方式，进而实现了串并结合的工作流。&lt;/p>
&lt;h1 id="2快速上手">2.快速上手&lt;/h1>
&lt;p>下面通过一个实例来看下RunnableSequence和RunnableParallel的用法。&lt;/p>
&lt;p>示例场景：利用LLM做病情摘要，然后提供治疗建议，最后把结果翻译成英文和日语。&lt;/p>
&lt;p>我们用4个链实现上述功能，然后用RunnableSequence和RunnableParallel组合成完整工作流。&lt;/p>
&lt;h2 id="step1-构建chain1病情简介">STEP1: 构建chain1：病情简介&lt;/h2>
&lt;ul>
&lt;li>引入相关类库，构建第一个链chain1，任务是根据疾病标题和患者年龄生成病情简介。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B037-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(3)/image-20240108195544772.png" alt="">&lt;/p>
&lt;ul>
&lt;li>先执行chain1观察下输出结果，输出内容符合预期。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B037-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(3)/image-20240108195656025.png" alt="">&lt;/p>
&lt;h2 id="step2-构建chain2治疗方案">STEP2: 构建chain2：治疗方案&lt;/h2>
&lt;ul>
&lt;li>构建第二个链chain2，任务是根据病情简介生成治疗方案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B037-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(3)/image-20240108202230067.png" alt="">&lt;/p>
&lt;ul>
&lt;li>执行chain2观察输出结果，LLM给出了治疗方案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B037-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(3)/image-20240108195753143.png" alt="">&lt;/p>
&lt;h2 id="step3构建chain3chain4文本翻译">STEP3:构建Chain3、Chain4：文本翻译&lt;/h2>
&lt;ul>
&lt;li>构建Chain3、Chain4，任务是把指定的文本内容分别翻译成英文、日语&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B037-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(3)/image-20240108192549849.png" alt="">&lt;/p>
&lt;h2 id="step4-构建工作流链medical_chain组合chain1chain4">STEP4: 构建工作流链medical_chain：组合chain1~chain4&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>基于上面4个任务链，工作流设计为：首先生成病情简介，然后根据病情生成治疗方案，最后把治疗方案同时翻译成英语、日语。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>因此，工作流链medical_chain组合如下：&lt;/p>
&lt;ul>
&lt;li>chain1、chain2与后面的翻译链(chain3、chain4)是串行组合&lt;/li>
&lt;li>chain3、chain4使用RunnableParallel组合，把chain2的输出作为输入，并行执行&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B037-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(3)/image-20240108200421256.png" alt="">&lt;/p>
&lt;ul>
&lt;li>执行medical_chain观察结果，得到了英语和日语的治疗方案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B037-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(3)/image-20240108200458628.png" alt="">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本篇介绍了LCEL的两种主要的组合原语：**RunnableSequence(串行组合)**和 &lt;strong>RunnableParallel( 并行组合)&lt;/strong>。&lt;/p>
&lt;p>关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>RunnableSequence&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>可以将多个链组成一个串行工作流，各链串行执行。支持用管道符&lt;code>|&lt;/code>组合。&lt;/li>
&lt;li>每个链的输出是下个链的输入，最后一个链的输出就是该整个工作流的输出。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>RunnableParallel&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>可以把多个链组成并行工作流，各链并行执行。&lt;/li>
&lt;li>各链的输入是相同的，整个工作流的输出是用各链的输出构造的字典。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>用RunnableSequence和RunnableParallel构建了一个诊疗工作流。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>参考文档：翻译的LangChain官方文档&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记36-LangChain解读-LCEL语言之领域功能(2)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B036-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD2/</link><pubDate>Wed, 03 Jan 2024 10:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B036-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD2/</guid><description>&lt;p>并发是LLM应用常见的使用场景，LCEL提供了非常简便的方式来实现并发处理。&lt;/p>
&lt;p>本篇我们就来学习LCEL这一核心特性——batch/abatch。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B036-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(2)/image-20240104090138975.png" alt="">&lt;/p>
&lt;h1 id="1-lcel并发接口-batchabatch">1. LCEL并发接口-batch/abatch&lt;/h1>
&lt;h2 id="1接口介绍">(1)接口介绍&lt;/h2>
&lt;p>batch和abatch是两个非常实用的接口，它们允许并发处理多个用户输入，从而提高程序的执行效率。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>batch&lt;/strong>: 开发LLM应用时，有可能需要同时处理多个用户输入(如：多个提示词)，batch内部通过线程池并行处理多个用户输入(每个线程都是在调用上一篇介绍的&lt;code>invoke&lt;/code>接口)，最终汇总结果。&lt;/li>
&lt;li>&lt;strong>abatch&lt;/strong>: batch的非阻塞接口。&lt;/li>
&lt;/ul>
&lt;h2 id="2接口语法">(2)接口语法&lt;/h2>
&lt;p>batch/abatch是LCEL在Runnable协议中定义的标准接口，LangChain的组件和链(Runnable对象)可以直接调用该方法。&lt;/p>
&lt;p>以链chain为例：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>chain.batch([&amp;ldquo;input1&amp;rdquo;, &amp;ldquo;input2&amp;rdquo;, &amp;hellip;])&lt;/p>
&lt;/li>
&lt;li>
&lt;p>await chain.abatch([&amp;ldquo;input1&amp;rdquo;, &amp;ldquo;input2&amp;rdquo;, &amp;hellip;])&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="2快速上手">2.快速上手&lt;/h1>
&lt;p>以利用LLM做试题解析为例，用batch/abatch功能来批量处理多个试题。&lt;/p>
&lt;ul>
&lt;li>构造任务链&lt;/li>
&lt;li>使用batch方法处理&lt;/li>
&lt;li>使用abatch方法处理&lt;/li>
&lt;/ul>
&lt;h2 id="step1-构造任务链">STEP1: 构造任务链&lt;/h2>
&lt;p>任务链的构造方法不再赘述，见下面代码。&lt;/p>
&lt;ul>
&lt;li>链的任务是判断题目是否正确。&lt;/li>
&lt;li>设置列表变量topics，存放3个题目。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B036-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(2)/image-20240104084034633.png" alt="">&lt;/p>
&lt;h2 id="step2-使用batch方法处理">STEP2: 使用batch方法处理&lt;/h2>
&lt;ul>
&lt;li>调用语法：chain.batch(topics)&lt;/li>
&lt;li>执行效果：任务启动后，马上得到答案，没有因为问题多导致过多等待。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B036-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(2)/image-20240104084838085.png" alt="">&lt;/p>
&lt;h2 id="step3-使用abatch方法处理">STEP3: 使用abatch方法处理&lt;/h2>
&lt;ul>
&lt;li>调用语法：await.chain.abatch(topics)&lt;/li>
&lt;li>执行效果：任务启动后，马上得到答案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B036-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(2)/image-20240104084749830.png" alt="">&lt;/p>
&lt;h1 id="3batch-vs-invoke">3.Batch vs Invoke&lt;/h1>
&lt;p>看到这里，我们再来回顾一下本文的&lt;code>batch&lt;/code>和前文的&lt;code>invoke&lt;/code>的区别：&lt;/p>
&lt;ul>
&lt;li>&lt;code>batch&lt;/code>不仅实现了批量处理多个输入，而且是多线程并行调用LLM，很好的提升了处理效率。&lt;/li>
&lt;li>而&lt;code>invoke&lt;/code>更适合需要串行执行。&lt;/li>
&lt;/ul>
&lt;p>具体看前文的例子，我们发现耗时的差别如下：&lt;/p>
&lt;ul>
&lt;li>使用invoke处理单个题目，耗时1.13s&lt;/li>
&lt;li>使用batch处理3个题目，耗时1.3s&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B036-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(2)/image-20240104010153222.png" alt="">&lt;/p>
&lt;h1 id="4小结">4.小结&lt;/h1>
&lt;p>Batch/abatch 是LCEL中用于实现并发请求的重要工具，也为开发人员带来高效、简洁的编程体验。&lt;/p>
&lt;p>本文关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>LCEL并发接口-batch/abatch&lt;/p>
&lt;ul>
&lt;li>输入为列表，内部实际是使用线程池执行器&lt;strong>并行&lt;/strong>执行invoke()。&lt;/li>
&lt;li>LangChain的Runnable对象可以直接调用batch/abatch方法。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>以让LLM来批改试卷为例，演示batch/abatch语法。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>参考文档：翻译的LangChain官方文档&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记35-LangChain解读-LCEL语言之领域功能(1)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B035-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD1/</link><pubDate>Wed, 27 Dec 2023 10:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B035-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD1/</guid><description>&lt;p>LCEL是专门为方便开发LLM应用而设计的编程语言，它提供了一系列直观、好用的功能和语法。&lt;/p>
&lt;p>本篇我们来学习提升LLM应用体验的一个功能——stream流式输出。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B035-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(1)/image-20231227115947187.png" alt="image-20231227115947187">&lt;/p>
&lt;h1 id="1-lcel流式输出接口-stream">1. LCEL流式输出接口-stream&lt;/h1>
&lt;h2 id="1为什么要用流式输出">(1)为什么要用流式输出&lt;/h2>
&lt;p>在使用LLM应用时，用户总是期望立即得到答案，不管他的问题有多么复杂，或者让LLM生成的文本有多么长。&lt;/p>
&lt;p>&amp;ldquo;&lt;strong>流式输出&lt;/strong>&amp;ldquo;这时就派上用场了，它能够&lt;strong>使LLM在生成文本时逐步提供结果&lt;/strong>，而不是等到整个文本生成完成后再一次性返回给用户。&lt;/p>
&lt;p>流式输出的方式有以下几个优点：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>实时性&lt;/strong>：不用等待整个文本生成完毕再返回结果，减少响应时间，用户获得实时响应体验。&lt;/li>
&lt;li>&lt;strong>交互性&lt;/strong>：生成结果逐步提供，可匹配用户阅读速度，增强交互感。&lt;/li>
&lt;li>&lt;strong>节省资源和带宽&lt;/strong>：逐步返回生成的结果可以减少对网络带宽的需求。&lt;/li>
&lt;li>&lt;strong>支持长文本生成&lt;/strong>：生成长文本时无需担心超出内存限制。&lt;/li>
&lt;/ol>
&lt;p>总之，流式输出可以让用户得到更好的体验，让用户觉得你的LLM程序&amp;rdquo;&lt;strong>性能&lt;/strong>&amp;ldquo;很棒。&lt;/p>
&lt;h2 id="2流式输出接口的使用">(2)流式输出接口的使用&lt;/h2>
&lt;p>LangChain在Runnable协议中定义了流式输出方法&lt;strong>stream&lt;/strong>，以及它的异步方法&lt;strong>astream&lt;/strong>。&lt;/p>
&lt;p>LangChain的很多组件都是遵循Runnable的对象，可以直接调用stream/astream方法。以之前专栏多次构建过的链chain为例：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>chain.stream()&lt;/p>
&lt;/li>
&lt;li>
&lt;p>chain.astream()&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="2快速上手">2.快速上手&lt;/h1>
&lt;p>以让LLM生成一首诗为例，对比下直接输出、流式输出的差异效果。&lt;/p>
&lt;p>任务链的构建不再赘述，如下代码，我们构建了名为&lt;code>chain&lt;/code>的链，它的功能是根据输入的主题生成一首诗。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B035-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(1)/image-20231227125844993.png" alt="image-20231227125844993">&lt;/p>
&lt;h2 id="1使用invoke方法直接调用">(1)使用invoke方法直接调用&lt;/h2>
&lt;ul>
&lt;li>调用语法：chain.invoke(&amp;ldquo;犀牛&amp;rdquo;)&lt;/li>
&lt;li>执行效果：任务启动后，没有立即得到响应；大概6秒后，生成结果一次性闪现。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B035-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(1)/invoke.gif" alt="invoke">&lt;/p>
&lt;h2 id="2使用stream方法流式输出">(2)使用stream方法流式输出&lt;/h2>
&lt;ul>
&lt;li>调用语法：chain.stream(&amp;ldquo;犀牛&amp;rdquo;)
&lt;ul>
&lt;li>注意：由于stream()是迭代输出，因此用for语句来循环遍历输出结果。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>执行效果：任务启动后，立即得到响应，以一定的字频逐行输出结果。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B035-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(1)/stream.gif" alt="stream">&lt;/p>
&lt;ul>
&lt;li>如果想用异步方式astream，则调用语法如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B035-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(1)/image-20231227145757283.png" alt="image-20231227145757283">&lt;/p>
&lt;h2 id="3-对比总结-invoke-vs-stream">(3) 对比总结 Invoke vs Stream&lt;/h2>
&lt;p>对于一个交互式的LLM应用程序，stream流式输出的响应实时性和交互体验都更好。&lt;/p>
&lt;p>在 Python 中，没有名为&amp;quot;stream&amp;rdquo; 的内置方法，但是有类似于流式操作的机制，比如生成器(yield)、迭代器(iterator)。所以，如果没有LCEL提供的stream方法，而是要我们自己来实现的话，将是一件费脑筋的事。&lt;/p>
&lt;p>如下是不使用LCEL实现流式输出的示例代码，可以跟上面简单的一行方法调用对比下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B035-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%A2%86%E5%9F%9F%E5%8A%9F%E8%83%BD(1)/image-20231227124359421.png" alt="image-20231227124359421">&lt;/p>
&lt;p>LangChain的大牛们用python实现了与Java &amp;ldquo;Stream API&amp;quot;类似的流式处理方法，极大的方便了开发人员。&lt;/p>
&lt;p>某种意义上来说，LangChain不仅仅是定义了一套Runnable协议，也是对Python语法的重构，构建了自己的语法——LCEL。&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文解读了LangChain LCEL语法中提升性能的一种方法——stream流式输出。关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>流式输出接口&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;流式输出&amp;quot;使LLM在生成文本时逐步提供结果，提升LLM应用程序的性能，让用户得到更好的体验。&lt;/li>
&lt;li>LangChain的Runnable对象可以直接调用stream/astream方法。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>对比invoke直接输出和stream流式输出的效果差异。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>参考文档：翻译的LangChain官方文档&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记34-Show一下我们的语音克隆技术</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B034-show%E4%B8%80%E4%B8%8B%E6%88%91%E4%BB%AC%E7%9A%84%E8%AF%AD%E9%9F%B3%E5%85%8B%E9%9A%86%E6%8A%80%E6%9C%AF/</link><pubDate>Sun, 24 Dec 2023 10:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B034-show%E4%B8%80%E4%B8%8B%E6%88%91%E4%BB%AC%E7%9A%84%E8%AF%AD%E9%9F%B3%E5%85%8B%E9%9A%86%E6%8A%80%E6%9C%AF/</guid><description>&lt;p>小刚刚同学是小伙伴中的TTS专家，他训练的语音克隆模型已经初见雏形，口音、语速、情绪都还不错。&lt;/p>
&lt;p>小刚刚的AI模型克隆了他自己的声音之后为我们念出了如下文章，听到人工智能的声音，激动且开心，为小刚刚的AI儿子点赞！&lt;/p>
&lt;ul>
&lt;li>&lt;strong>这是AI的念稿的声音&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://www.bilibili.com/audio/au4209312?type=1">B站链接&lt;/a>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>如下为AI念的稿件&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;p>接下来，我给大家介绍一下TTS原理：&lt;/p>
&lt;h2 id="1-引言">1. 引言&lt;/h2>
&lt;p>文字到语音（TTS，Text-to-Speech）技术是将人类语言文本转换为人类语音输出的技术。随着人工智能、自然语言处理等技术的快速发展，TTS技术在智能语音助手、虚拟主播、教育、娱乐等领域得到了广泛应用。本文将介绍TTS技术的原理及其发展历程，并探讨其在未来的发展趋势。&lt;/p>
&lt;h2 id="2-tts原理">2. TTS原理&lt;/h2>
&lt;h3 id="21-语音合成">2.1 语音合成&lt;/h3>
&lt;p>语音合成是将文本转换为语音的过程，主要包括以下几个步骤：&lt;/p>
&lt;ol>
&lt;li>音素到状态的转换：将输入的音素序列转换为声道状态序列。&lt;/li>
&lt;li>声道状态到声码元的转换：将声道状态序列转换为声码元序列。&lt;/li>
&lt;li>声码元到语音的转换：将声码元序列转换为语音信号。&lt;/li>
&lt;/ol>
&lt;h3 id="22-语音合成模型">2.2 语音合成模型&lt;/h3>
&lt;p>目前主流的语音合成模型主要包括以下几种：&lt;/p>
&lt;ol>
&lt;li>参数模型：将语音合成看作是一个参数估计问题，通过训练模型来获得参数值。&lt;/li>
&lt;li>统计模型：基于统计学原理，通过概率模型来生成语音。&lt;/li>
&lt;li>深度学习模型：利用深度神经网络模型进行语音合成。&lt;/li>
&lt;/ol>
&lt;h3 id="23-声学模型">2.3 声学模型&lt;/h3>
&lt;p>声学模型是TTS技术中的关键部分，其主要任务是模拟人类听觉系统，通过声学模型可以计算出每个音素的声学特征，并将其用于语音合成。目前主流的声学模型包括线性预测编码（LPC）、高斯混合模型（GMM）等。&lt;/p>
&lt;h2 id="3-tts发展历程">3. TTS发展历程&lt;/h2>
&lt;p>TTS技术的发展历程可以分为以下几个阶段：&lt;/p>
&lt;ol>
&lt;li>基于规则的方法：早期的TTS技术采用基于规则的方法，通过手动设计规则来生成语音。&lt;/li>
&lt;li>基于模板的方法：基于模板的方法通过预先定义的语音模板来生成语音，效率较低。&lt;/li>
&lt;li>基于统计的方法：基于统计的方法采用概率模型来生成语音，效果较好，但需要大量的训练数据。&lt;/li>
&lt;li>基于深度学习的方法：基于深度学习的方法利用神经网络模型进行语音合成，效果最好，但需要大量的训练数据和计算资源。&lt;/li>
&lt;/ol>
&lt;h2 id="4-tts未来发展趋势">4. TTS未来发展趋势&lt;/h2>
&lt;p>随着人工智能、自然语言处理等技术的不断发展，TTS技术在未来将会呈现出以下发展趋势：&lt;/p>
&lt;ol>
&lt;li>更高的语音质量：通过改进声学模型和语音合成算法，提高语音质量。&lt;/li>
&lt;li>更自然的发音：通过改进语音合成算法，使生成的语音更加自然。&lt;/li>
&lt;li>更丰富的语言支持：通过扩大语言模型和语音合成模型的训练数据集，支持更多的语言。&lt;/li>
&lt;li>更广泛的应用：通过改进TTS技术，使其在更多的领域得到应用，如智能客服、智能家居等。&lt;/li>
&lt;/ol>
&lt;h2 id="5-结论">5. 结论&lt;/h2>
&lt;p>TTS技术是将文本转换为语音的技术，其原理主要包括语音合成、语音合成模型、声学模型等。随着人工智能、自然语言处理等技术的不断发展，TTS技术在未来将会呈现出更高的语音质量、更自然的发音、更丰富的语言支持和更广泛的应用等特点。&lt;/p></description></item><item><title>【chatGPT】学习笔记33-LangChain解读-LCEL语言之基础语法(2)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%952/</link><pubDate>Sat, 23 Dec 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%952/</guid><description>&lt;p>LCEL让我们可以用&lt;code>|&lt;/code>管道符把不同的组件或链组合起来，这都得益于这些组件都实现了Runnable接口。&lt;/p>
&lt;p>本篇我们就带着Runnable的概念继续学习下LCEL的基础用法。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231222104906413.png" alt="image-20231222104906413">&lt;/p>
&lt;h1 id="1-lcel核心接口runnable">1. LCEL核心接口Runnable&lt;/h1>
&lt;h2 id="1runnable接口">(1)Runnable接口&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Langchain定义了“Runnable”协议，协议中实现了一系列方法，比如对管道运算符&lt;code>|&lt;/code>的支持、invoke方法等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这里介绍下Runnable定义的一组标准调用接口（其中后三个是前面三个异步方式）：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#stream">&lt;code>stream&lt;/code>&lt;/a>：流式输出&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#invoke">&lt;code>invoke&lt;/code>&lt;/a>：基于单一输入调用链&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#batch">&lt;code>batch&lt;/code>&lt;/a>：基于列表输入调用链&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#async-stream">&lt;code>astream&lt;/code>&lt;/a>：异步流式输出&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#async-invoke">&lt;code>ainvoke&lt;/code>&lt;/a>：基于单一输入异步调用链&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#async-batch">&lt;code>abatch&lt;/code>&lt;/a>：基于列表输入异步调用链&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>LangChain的很多组件(对象)都应用了Runnable协议，可以把他们称为Runnable对象，这些对象都实现了上述接口，因此这些对象组成的链也都支持上述调用方法。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="2常用runnable对象的输入输出类型">(2)常用Runnable对象的输入输出类型&lt;/h2>
&lt;p>LCEL中使用&lt;code>|&lt;/code>将前一个Runnable对象的输出传递给下一个Runnable对象作为输入，因此需要保证管道两端的型号一致。&lt;/p>
&lt;p>LangChain常用组件的输入、输出数据类型如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>组件&lt;/strong>&lt;/th>
&lt;th>&lt;strong>输入类型&lt;/strong>&lt;/th>
&lt;th>&lt;strong>输出类型&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Prompt (提示词)&lt;/td>
&lt;td>字典&lt;/td>
&lt;td>PromptValue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ChatModel (聊天模型)&lt;/td>
&lt;td>单个字符串、聊天消息列表或 PromptValue&lt;/td>
&lt;td>ChatMessage&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>LLM (非聊天模型)&lt;/td>
&lt;td>单个字符串、聊天消息列表或 PromptValue&lt;/td>
&lt;td>String&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OutputParser (输出解析器)&lt;/td>
&lt;td>LLM 或 ChatModel 的输出&lt;/td>
&lt;td>取决于解析器&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Retriever (检索器 )&lt;/td>
&lt;td>单个字符串&lt;/td>
&lt;td>文档清单&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Tool (工具)&lt;/td>
&lt;td>单个字符串或字典，具体取决于工具&lt;/td>
&lt;td>取决于工具&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="3-runnablepassthrough在管道中的作用">(3) RunnablePassthrough在管道中的作用&lt;/h2>
&lt;p>在使用LCEL构建链时，原始用户输入可能不仅要传给第一个组件，还要传给后续组件，这时可以用RunnablePassthrough。RunnablePassthrough可以透传用户输入。&lt;/p>
&lt;h1 id="2快速上手">2.快速上手&lt;/h1>
&lt;p>下面我们通过一个包含4个组件的RAG检索链来再次体验LCEL的便捷。&lt;/p>
&lt;p>示例场景是基于给定的文本回答用户问题。&lt;/p>
&lt;h2 id="step1环境准备">STEP1.环境准备&lt;/h2>
&lt;ul>
&lt;li>注意：由于示例的是检索本地文本，所以安装了向量数据库及其所需的库。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223004634709.png" alt="image-20231223004634709">&lt;/p>
&lt;h2 id="step2构建检索器组件">STEP2.构建检索器组件&lt;/h2>
&lt;ul>
&lt;li>为方便演示，本地文本简单的放一句话：”大鱼吃小鱼，小鱼吃虾米“。&lt;/li>
&lt;li>用langchain的检索器&lt;code>as_retriever&lt;/code>，它可以根据输入查询向量库并返回相关文本。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223005234058.png" alt="image-20231223005234058">&lt;/p>
&lt;h2 id="step3构建prompt提示词组件">STEP3.构建Prompt提示词组件&lt;/h2>
&lt;ul>
&lt;li>提示词设计的是根据给定的文字回答问题。&lt;/li>
&lt;li>提示词中共2个变量：&lt;code>question&lt;/code>用来接收用户问题，&lt;code>context&lt;/code>来接收检索器的查询结果。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223010525145.png" alt="image-20231223010525145">&lt;/p>
&lt;h2 id="step4构建llm组件">STEP4.构建llm组件&lt;/h2>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223011307090.png" alt="image-20231223011307090">&lt;/p>
&lt;h2 id="step5组合成链">STEP5.组合成链&lt;/h2>
&lt;ul>
&lt;li>把检索器、提示词、模型、输出解析器四个组件串起来，命名为检索链&lt;code>retrieval_chain&lt;/code>。&lt;/li>
&lt;li>这一步注意两点：
&lt;ul>
&lt;li>用户输入的问题，不止组件1的检索器要用，组件2也要用它来构建提示词，因此组件1使用RunnablePassthrough方法把原始输入透传给下一步。&lt;/li>
&lt;li>由于组件2 prompt的输入要求是字典类型，所以组件1把检索器和用户问题写成字典格式，并用组件2的变量作为键。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223011350292.png" alt="image-20231223011350292">&lt;/p>
&lt;h2 id="step6运行链">STEP6.运行链&lt;/h2>
&lt;ul>
&lt;li>传入用户问题，得到期望结果。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223011640703.png" alt="image-20231223011640703">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文解读了LangChain LCEL及其Runnable基础语法，关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Runnable接口&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Runnable是Langchain表达式语言的核心接口&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Runnable提供了一组标准调用接口：stream、invoke、batch及对应的异步方法。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Langchain很多组件都遵循Runnable协议，因此可以方便的组合、调用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>常用Runnable对象的输入输出类型要求，用管道&lt;code>|&lt;/code>方式组合时需注意管道两端的类型一致。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RunnablePassthrough在管道中的作用。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>构建了包含四个组件的检索链。&lt;/li>
&lt;li>通过实操关注了管道前后数据类型的匹配、RunnablePassthrough的作用。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>参考文档：翻译的LangChain官方文档&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记32-LangChain解读-LCEL语言之基础语法(1)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%951/</link><pubDate>Wed, 13 Dec 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%951/</guid><description>&lt;p>在《【chatGPT】学习笔记29-LangChain解读1-快速入门》中，我们学习了LangChain的入门文档，了解到LangChain的模块化组件和链让开发LLM应用变得简单。&lt;/p>
&lt;p>同时，LangChain还推出了自己的语法——LCEL(LangChain表达式语言)，让复杂的组合链变得更简单。&lt;/p>
&lt;p>本篇我们跟着官方文档来学习LCEL的概念及如何使用。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(1)/image-20231208175706824.png" alt="image-20231208175706824">&lt;/p>
&lt;h1 id="1-lcel概览">1. LCEL概览&lt;/h1>
&lt;h2 id="1什么是lcel">(1)什么是LCEL&lt;/h2>
&lt;p>LCEL是LangChain表达式语言(LangChain Expression Language)的缩写，是LangChain官方推出的一种新的语法，它提供了一种声明式的方法(而不是编写普通代码)来组合链，简化了构建复杂LLM应用的过程。&lt;/p>
&lt;h2 id="2为什么要用lcel">(2)为什么要用LCEL&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>声明式编程&lt;/strong>：由于LLM强大的理解和生成能力，LLM应用开发侧重业务逻辑的编排，LCEL提供的声明式编程方法让这类操作更高效。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>统一接口&lt;/strong>：LCEL中实现了“Runnable”协议，每个LCEL 对象都应用了“Runnable”接口。&lt;/p>
&lt;ul>
&lt;li>该接口定义了一组通用的调用方法（&lt;code>invoke&lt;/code>、&lt;code>batch&lt;/code>、&lt;code>stream&lt;/code>、&lt;code>ainvoke&lt;/code>&amp;hellip;），因此采用LCEL构建的任何链都将自动支持流、同步、异步和批处理等能力。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>组合原语&lt;/strong>：LCEL 提供了许多原语，可以轻松组合链、并行化组件、添加回退、动态配置链内部等。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>为了更好地理解 LCEL，我们将分期介绍这些能力和实际应用效果。本篇我们先从看看如何用LCEL的声明式方法来组合业务组件和链。&lt;/p>
&lt;h1 id="2快速上手lcel">2.快速上手LCEL&lt;/h1>
&lt;p>以让LLM生成文本为例，来看看如何使用LCEL来完成任务。&lt;/p>
&lt;blockquote>
&lt;p>环境准备请参考《【chatGPT】学习笔记29-LangChain解读1-快速入门》。&lt;/p>
&lt;/blockquote>
&lt;h2 id="step1构造三组件">STEP1.构造三组件&lt;/h2>
&lt;p>我们在LangChain快速入门中学习过，一个常见的链包括三个组件：&lt;strong>提示词模板、模型、输出解析器&lt;/strong>。&lt;/p>
&lt;p>使用LangChain的方法构建如下——任务是给某个人或物写一句表扬的话：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(1)/image-20231210112756607.png" alt="image-20231210112756607">&lt;/p>
&lt;h2 id="step2构建自定义链">STEP2.构建自定义链&lt;/h2>
&lt;p>使用LCEL语法，用上面的3个组件组合成链，代码如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(1)/image-20231210113216116.png" alt="image-20231210113216116">&lt;/p>
&lt;p>你会发现，LCEL用&lt;code>|&lt;/code>把不同组件链接在一起，该符号类似于unix的管道运算符，将一个组件的输出作为下一个组件的输入。&lt;/p>
&lt;h2 id="step3调用链">STEP3.调用链&lt;/h2>
&lt;p>LCEL这种表达式方法是有效呢，我们调用一下看看。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(1)/image-20231210113642196.png" alt="image-20231210113642196">&lt;/p>
&lt;p>让链工作的方法也很简单，使用&lt;code>Runnable&lt;/code>接口的&lt;code>invoke&lt;/code>方法，传入主题字符串，任务就完成了。&lt;/p>
&lt;p>从上面的示例，我们可以看到LCEL的运作流程如下：&lt;/p>
&lt;ul>
&lt;li>传入用户输入，为提示词模板中的变量赋值。本例中是山姆奥特曼，则格式为{&amp;ldquo;topic&amp;rdquo;: &amp;ldquo;山姆奥特曼&amp;rdquo;}。&lt;/li>
&lt;li>&lt;code>prompt&lt;/code>获取用户输入，并使用&amp;quot;topic&amp;quot;构建提示词。&lt;/li>
&lt;li>&lt;code>model&lt;/code>组件拿到生成的提示词，并传递给LLM模型进行处理。模型生成的输出是一个&lt;code>ChatMessage&lt;/code>对象。&lt;/li>
&lt;li>最后，&lt;code>output_parser&lt;/code>组件接收&lt;code>ChatMessage&lt;/code>并将其转换为 Python 字符串，该字符串通过 invoke 方法返回。&lt;/li>
&lt;/ul>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文解读了LangChain官方文档的“LangChain Expression Language (LCEL)”的部分章节，关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>LCEL概览&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>LCEL是LangChain官方推出的一种声明式编程语法，让构建复杂LLM应用变得更简单。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LCEL的主要价值点：&lt;/p>
&lt;ul>
&lt;li>声明式编程方法，便于组件和链的编排。&lt;/li>
&lt;li>统一接口，每个LCEL 对象都应用了“Runnable”接口。&lt;/li>
&lt;li>组合原语。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>构造链的组件。&lt;/li>
&lt;li>LCEL使用&lt;code>|&lt;/code>把不同的组件组合成链。&lt;/li>
&lt;li>使用invoke方法调用链，完成任务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>参考文档：翻译的LangChain官方文档&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记31-提示词解读6-实战案例之扩展</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/</link><pubDate>Sun, 03 Dec 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/</guid><description>&lt;p>LLM可以帮忙写文案、写剧本、写论文？相信很多小伙伴当初都是被LLM的这个爆裂功能路转粉的。&lt;/p>
&lt;p>这种文本生成的能力——通常也被叫做AIGC(人工智能生成内容)，就是LLM的扩展能力。&lt;/p>
&lt;p>本篇我们跟着吴恩达老师的课程，学习如何激发LLM这个最受欢迎的能力——扩展(&lt;code>Expanding&lt;/code>)。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95//image-20231130080342036.png" alt="image-20231130080342036">&lt;/p>
&lt;h1 id="1激发扩展能力的提示词">1.激发扩展能力的提示词&lt;/h1>
&lt;h2 id="1什么是llm的扩展能力">(1)什么是LLM的扩展能力&lt;/h2>
&lt;p>LLM的扩展能力是指&lt;strong>基于一小段文字或指令或主题，让LLM生成连贯、有逻辑的长文本&lt;/strong>。&lt;/p>
&lt;p>LLM的扩展能力使得LLM可以生成更长、更丰富的文本，可以用在很多创作类的工作：&lt;/p>
&lt;ul>
&lt;li>写营销文案&lt;/li>
&lt;li>写工作报告&lt;/li>
&lt;li>创意策划(Brainstorming)&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;h2 id="2如何激发llm的扩展能力">(2)如何激发LLM的扩展能力&lt;/h2>
&lt;p>我们可以这样构建提示词：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>明确的指令词&lt;/strong>，让LLM知道是写文章还是出点子，如&amp;quot;请&lt;strong>撰写&lt;/strong>&amp;hellip;&amp;quot;，&amp;ldquo;请&lt;strong>设计&lt;/strong>&amp;hellip;&amp;quot;。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>明确的内容要求&lt;/strong>，如&amp;quot;以xxx&lt;strong>为主题&lt;/strong>&amp;quot;，&amp;ldquo;涵盖xxx&lt;strong>内容要点&lt;/strong>&amp;quot;，&amp;ldquo;针对xxx&lt;strong>举个例子&lt;/strong>&amp;quot;，&amp;ldquo;用新潮有趣的&lt;strong>文字风格&lt;/strong>&amp;quot;。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>提供背景信息&lt;/strong>，让LLM更好的模拟语境。如&amp;quot;你是个童话大王&amp;rdquo;，&amp;ldquo;这是给总裁的汇报材料&amp;rdquo;。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="2实战案例">2.实战案例&lt;/h1>
&lt;p>笔者最近在研究Java编程语言的面试题，要针对一些难度大的面试题编写案例解析。&lt;/p>
&lt;p>以下面这道面试题为例，用LLM的扩展能力来帮忙：&lt;/p>
&lt;ul>
&lt;li>制定提纲&lt;/li>
&lt;li>生成文章内容&lt;/li>
&lt;li>优化部分章节&lt;/li>
&lt;/ul>
&lt;p>面试题如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">以下有关垃圾收集器&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">说法正确的有&lt;/span>&lt;span class="err">：（&lt;/span> &lt;span class="err">）&lt;/span>
&lt;span class="n">A&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="n">ParNew收集器支持多线程垃圾收集&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">所以不会回收停顿&lt;/span>&lt;span class="err">。&lt;/span>&lt;span class="n">当老年代选择CMS收集器后&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">新生代智能选择Serial或ParNew收集器&lt;/span>&lt;span class="err">。&lt;/span>
&lt;span class="n">B&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="n">Parallel&lt;/span> &lt;span class="n">Scavenge收集器是一个新生代收集器&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">其目标是达到一个可控的吞吐量&lt;/span>&lt;span class="err">。&lt;/span>&lt;span class="n">MaxGCPauseMillis参数值设置越小&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">系统垃圾手机速度越快&lt;/span>&lt;span class="err">。&lt;/span>
&lt;span class="n">C&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="n">CMS收集器出生标记和重新标记阶段均需要停顿&lt;/span>&lt;span class="err">。&lt;/span>&lt;span class="n">CMS收集器若出现Concurrent&lt;/span> &lt;span class="n">Mode&lt;/span> &lt;span class="n">Failure&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">虚拟机就会启动Serial&lt;/span> &lt;span class="n">Old收集器进行垃圾回收&lt;/span>&lt;span class="err">。&lt;/span>
&lt;span class="n">D&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="n">G1收集器可用于新生代和老年代的垃圾回收&lt;/span>&lt;span class="err">。&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="step1制定提纲">STEP1.制定提纲&lt;/h2>
&lt;p>画虎先画骨。先跟LLM头脑风暴一下，把案例提纲定下来。&lt;/p>
&lt;p>让LLM生成题目解析案例的提纲。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231203161432017.png" alt="image-20231203161432017">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231203160613178.png" alt="image-20231203160613178">&lt;/p>
&lt;p>LLM给出了一个相对全面的目录结构，结合LLM带来的灵感，最终目录确定如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>1.题目描述&lt;/strong>：描述Java面试题原文&lt;/li>
&lt;li>&lt;strong>2.题目解析&lt;/strong>：对每个选项进行分析，说明是否是正确答案&lt;/li>
&lt;li>&lt;strong>3.知识点解读&lt;/strong>：列出该Java试题涉及的知识点，并做解读&lt;/li>
&lt;li>&lt;strong>4.知识点总结&lt;/strong>：对知识点做总结，说明用途和错误影响&lt;/li>
&lt;li>&lt;strong>5.推荐学习资料&lt;/strong>：该知识点相关的学习资料&lt;/li>
&lt;/ul>
&lt;h2 id="step2生成文章内容">STEP2.生成文章内容&lt;/h2>
&lt;p>接着让LLM根据目录提纲生成案例主体内容。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231203161448434.png" alt="image-20231203161448434">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231201200439022.png" alt="image-20231201200439022">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231201232902361.png" alt="image-20231201232902361">&lt;/p>
&lt;p>LLM根据提纲很好的生成了案例内容，对试题四个选项的解析、正确答案的识别也很到位。&lt;/p>
&lt;h2 id="step3优化部分章节">STEP3.优化部分章节&lt;/h2>
&lt;p>知识点解读是重点章节，增加一些示例可以帮助读者更好的理解。&lt;/p>
&lt;p>所以，让LLM帮忙优化知识点解读章节的内容，增加代码示例：&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231201233451643.png" alt="image-20231201233451643">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231201233557314.png" alt="image-20231201233557314">&lt;/p>
&lt;p>LLM不仅精通自然语言，同时也是个编程语言专家，所以生成代码示例的任务也很轻松的完成了。&lt;/p>
&lt;h2 id="step4编写正式文稿">STEP4.编写正式文稿&lt;/h2>
&lt;p>LLM已经帮忙完成了文稿内容的生成和优化，现在该笔者我出马了。&lt;/p>
&lt;p>笔者的意见是——稿件内容审核通过，可以用于发布 😄&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文介绍了激发LLM扩展能力的提示词技巧，让LLM成为设计、写作等工作中的得力助手。&lt;/p>
&lt;p>扩展提示词的构建方法：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>明确的指令词&lt;/strong>，让LLM知道是写文章还是出点子，如&amp;quot;请&lt;strong>撰写&lt;/strong>&amp;hellip;&amp;quot;，&amp;ldquo;请&lt;strong>设计&lt;/strong>&amp;hellip;&amp;quot;。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>明确的内容要求&lt;/strong>，如&amp;quot;以xxx&lt;strong>为主题&lt;/strong>&amp;quot;，&amp;ldquo;涵盖xxx&lt;strong>内容要点&lt;/strong>&amp;quot;，&amp;ldquo;针对xxx&lt;strong>举个例子&lt;/strong>&amp;quot;，&amp;ldquo;用新潮有趣的&lt;strong>文字风格&lt;/strong>&amp;quot;。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>提供背景信息&lt;/strong>，让LLM更好的模拟语境。如&amp;quot;你是个童话大王&amp;rdquo;，&amp;ldquo;这是给总裁的汇报材料&amp;rdquo;。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>至此，我们已经完成了吴恩达老师提示词课程的学习，包括：&lt;/p>
&lt;ul>
&lt;li>提示词的基本原则&lt;/li>
&lt;li>提示词的四个组成要素，及通用使用技巧&lt;/li>
&lt;li>提示词实战，解锁LLM四大能力：总结、推理、转换、扩展&lt;/li>
&lt;/ul>
&lt;p>LLM是个&amp;quot;通才&amp;rdquo;，而且还在快速成长，提示词是我们与这个&amp;quot;通才&amp;quot;对话的主要接口。小伙伴们也都行动起来吧，用好提示词，轻松驾驭LLM。&lt;/p>
&lt;h1 id="4资料汇总">4.资料汇总&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>本技术专栏&lt;/strong>：
&lt;ul>
&lt;li>《【chatGPT】学习笔记24-提示词解读1-提示词基本概念》&lt;/li>
&lt;li>《【chatGPT】学习笔记25-提示词解读2-通用技巧》&lt;/li>
&lt;li>《【chatGPT】学习笔记27-提示词解读3-实战案例之摘要总结》&lt;/li>
&lt;li>《【chatGPT】学习笔记28-提示词解读4-实战案例之推理》&lt;/li>
&lt;li>《【chatGPT】学习笔记30-提示词解读5-实战案例之转换》&lt;/li>
&lt;li>《【chatGPT】学习笔记31-提示词解读6-实战案例之扩展》&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>吴恩达提示词课程：
&lt;ul>
&lt;li>原文：https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction&lt;/li>
&lt;li>翻译：https://jherculesqz.gitbook.io/chatgpt-prompt-engineering-for-developers-1/&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记30-提示词解读5-实战案例之转换</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/</link><pubDate>Sat, 02 Dec 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/</guid><description>&lt;p>今天我们跟着吴恩达老师的课程，学习LLM另一个强大的能力——转换(&lt;code>Transforming&lt;/code>)。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231128162542742.png" alt="image-20231128162542742">&lt;/p>
&lt;h1 id="1激发转换能力的提示词">1.激发转换能力的提示词&lt;/h1>
&lt;h2 id="1什么是llm的转换能力">(1)什么是LLM的转换能力&lt;/h2>
&lt;p>LLM的转换能力是指&lt;strong>将文本从一种形式或格式转换为另一种形式或格式的能力&lt;/strong>。&lt;/p>
&lt;p>转换能力使得LLM成为一个强大的文本处理工具，可以在如下场景应用：&lt;/p>
&lt;ul>
&lt;li>文本翻译&lt;/li>
&lt;li>修正内容错误&lt;/li>
&lt;li>改变内容风格&lt;/li>
&lt;li>转换文本格式&lt;/li>
&lt;/ul>
&lt;p>注：目前很火的&lt;strong>LLM4SE领域&lt;/strong>(如：代码转换、代码修正、代码检视等)，&lt;strong>本质都是在激发LLM的转换能力&lt;/strong>。&lt;/p>
&lt;h2 id="2如何激发llm的转换能力">(2)如何激发LLM的转换能力&lt;/h2>
&lt;p>我们可以这样构建提示词：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>根据任务类型，使用清晰明确的指令词，如：&lt;strong>转换&lt;/strong>xxx、&lt;strong>翻译&lt;/strong>xxx、校正xxx。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>提供足够的上下文信息，让LLM知道要处理的内容。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="2实战案例">2.实战案例&lt;/h1>
&lt;p>假设我是某跨境电商的售前客服，要用LLM的转换能力来支撑处理用户问题：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>翻译&lt;/strong>国外用户反馈的问题。&lt;/li>
&lt;li>写问题回复，让LLM&lt;strong>校正&lt;/strong>内容错误。&lt;/li>
&lt;li>把回复内容&lt;strong>转换&lt;/strong>成商务邮件风格。&lt;/li>
&lt;li>将问题及回复&lt;strong>转换&lt;/strong>成JSON和表格，便于后续建单留档。&lt;/li>
&lt;/ul>
&lt;h2 id="step1翻译用户问题">STEP1.翻译用户问题&lt;/h2>
&lt;p>黑色星期五，电商客服收到一条问题如下：&lt;/p>
&lt;blockquote>
&lt;p>&lt;em>“Avez-vous encore des stocks de smartphones ? Comment puis-je participer à vos promotions ?”&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>这是哪国语言，什么意思？😵 (客服小姐姐一脸黑线)&lt;/p>
&lt;p>程序员小哥哥英雄救美，让LLM帮忙&lt;strong>翻译&lt;/strong>下。&lt;/p>
&lt;ul>
&lt;li>程序员小哥的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129171159198.png" alt="image-20231129171159198">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129171243074.png" alt="image-20231129171243074">&lt;/p>
&lt;p>LLM识别出了文字的语种，并按指令进行了机器翻译。&lt;/p>
&lt;h2 id="step2回复客户邮件">STEP2.回复客户邮件&lt;/h2>
&lt;p>生意上门，客服小姐姐非常开心，但迅速陷入了沉思：如何给法语客户回复专业的售前邮件呢？😵&lt;/p>
&lt;p>通常，回复售前邮件需要有如下流程：&lt;/p>
&lt;ul>
&lt;li>编写回复信息并校正&lt;/li>
&lt;li>设计回复信息风格&lt;/li>
&lt;li>记录JSON和表格，归档到IT系统&lt;/li>
&lt;/ul>
&lt;p>此时，程序员小哥哥再次出手，英雄救美。&lt;/p>
&lt;h3 id="step21编写并校正回复信息">STEP2.1.编写并校正回复信息&lt;/h3>
&lt;p>客服小姐姐用中文写了回复信息：&lt;em>“我们手机的库存非长充足。优惠活动是买两部送一步。尽管放心下单吧。”&lt;/em>&lt;/p>
&lt;p>程序员小哥哥让LLM帮忙&lt;strong>校对&lt;/strong>下是否有文字错误。&lt;/p>
&lt;ul>
&lt;li>程序员小哥的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129173833270.png" alt="image-20231129173833270">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129174109866.png" alt="image-20231129174109866">&lt;/p>
&lt;p>LLM识别出了错别字，并修正了回复信息。&lt;/p>
&lt;h3 id="step22改变内容风格">STEP2.2.改变内容风格&lt;/h3>
&lt;p>商务对话要正式点儿，让LLM把初始信息&lt;strong>转换&lt;/strong>成商务&lt;strong>风格&lt;/strong>的回复，然后翻译成法语。&lt;/p>
&lt;ul>
&lt;li>程序员小哥的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129181528670.png" alt="image-20231129181528670">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129181557507.png" alt="image-20231129181557507">&lt;/p>
&lt;p>LLM很好的完成了任务，让客服小姐姐不用在翻译、措辞上花太多时间。&lt;/p>
&lt;h3 id="step23将问题及回复转换成json和表格">STEP2.3.将问题及回复转换成JSON和表格&lt;/h3>
&lt;p>客户问题很多，需要客服小姐姐将问题及回复，整理成JSON和表格形式，提交到IT系统归档。&lt;/p>
&lt;p>程序员小哥哥，利用LLM的&lt;strong>文本格式转换功能&lt;/strong>快速处理这些文本。&lt;/p>
&lt;p>如：转换成程序容易处理的JSON格式：&lt;/p>
&lt;ul>
&lt;li>程序员小哥的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129183618410.png" alt="image-20231129183618410">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129183643134.png" alt="image-20231129183643134">&lt;/p>
&lt;p>还可以把JSON转成直观易读的表格：&lt;/p>
&lt;ul>
&lt;li>程序员小哥的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129183705048.png" alt="image-20231129183705048">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129183727101.png" alt="image-20231129183727101">&lt;/p>
&lt;p>最后，翻译、校正、文本转换、格式转换，只需用LLM一个工具就可以搞定。&lt;/p>
&lt;p>最后，程序员小哥哥和客服小姐姐开启了一段美好的爱情故事。&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文介绍了一个LLM另一个实用的提示词技巧，可以充分利用LLM的文本转换能力，帮助我们处理繁琐的文档工作。&lt;/p>
&lt;p>转换提示词的构建方法：&lt;/p>
&lt;ul>
&lt;li>根据任务类型，使用清晰明确的指令词，如&lt;strong>转换&lt;/strong>xxx、&lt;strong>翻译&lt;/strong>xxx、校正xxx。&lt;/li>
&lt;li>提供足够的上下文信息，让LLM知道要处理的内容。&lt;/li>
&lt;/ul>
&lt;p>此外，这个故事还告诉我们：作为程序员小哥哥，要努力学习AI，高效使用AI，才能抱得美人归。&lt;/p></description></item><item><title>【chatGPT】学习笔记29-LangChain解读1-快速入门</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-langchain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</link><pubDate>Thu, 23 Nov 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-langchain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</guid><description>&lt;p>虽然利用提示词工程，我们已经能较好地使用LLM，但即使开发一个很简单的LLM应用，依然需要编写大量复杂代码(调用LLM只是最简单的一步)。&lt;/p>
&lt;p>&lt;strong>LangChain&lt;/strong>的目标就是让开发LLM应用变的简单，但LangChain更新极快，导致我们的学习成本较高。&lt;/p>
&lt;p>因此，我们准备做两件事，帮助大家提升学习LangChain的效率：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>翻译LangChain官方文档&lt;/strong>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>解读LangChain官方文档&lt;/strong>
&lt;ul>
&lt;li>在本技术专栏中，将详细地逐一解读LangChain官方文档中的各个重要特性。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>本篇我们就来解读LangChain官方文档的《&lt;strong>Quickstart&lt;/strong>》章节(&lt;a href="https://python.langchain.com/docs/get_started/quickstart">https://python.langchain.com/docs/get_started/quickstart&lt;/a>)，帮助大家快速上手LangChain。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/5d7KfRriC6zji11ZFnwLotdqcHQ.svg" alt="LangChain">&lt;/p>
&lt;h1 id="1langchain概览">1.LangChain概览&lt;/h1>
&lt;h2 id="1什么是langchain">(1)什么是LangChain&lt;/h2>
&lt;p>&lt;strong>LangChain 是一个开源框架，支持由LLM驱动的应用程序的开发&lt;/strong>。它使应用程序能够：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>具有上下文感知能力&lt;/strong>：连接大语言模型和上下文的数据源 (如：提示词、few-shot、聊天历史记录等)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>推理&lt;/strong>：依靠语言模型进行推理 (如：根据给出的上下文回答问题，或者决定下一步动作）&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>LangChain 的价值点主要有两个:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>模块化组件&lt;/strong>：专注于组合和模块化，提供了基于LLM的各种组件。这些组件可以单独使用，也可以组合使用。&lt;/li>
&lt;li>&lt;strong>直接可用的链&lt;/strong>：将各种组件组合成可完成特定任务的&amp;quot;链&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;h2 id="2langchain整体架构">(2)LangChain整体架构&lt;/h2>
&lt;p>LangChain为以下模块提供标准的、可扩展的接口和外部集成，从简单到复杂排序如下:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Model I/O&lt;/strong>：与大语言模型的接口。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>检索 (Retrieval)&lt;/strong>：与应用程序特定数据的接口。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>链 (Chains)&lt;/strong>：构建调用序列。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>代理 (Agents)&lt;/strong>：让模型根据高级指令选择使用哪些工具。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Memory&lt;/strong>：在链运行期间保持应用程序状态。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Callbacks&lt;/strong>：记录并传送链的中间步骤。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="3如何构建llm应用程序">(3)如何构建LLM应用程序&lt;/h2>
&lt;p>LangChain提供了许多用来构建LLM应用程序的模块，其中最常用且最重要的模块是&lt;strong>LLMChain&lt;/strong>。&lt;/p>
&lt;p>&lt;strong>LLMChain&lt;/strong>包含三个主要组件:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>LLM&lt;/strong>：LLM是你要构建的应用程序的核心推理引擎。GPT、GLM等大模型LangChain都已适配支持。&lt;/li>
&lt;li>&lt;strong>提示模板&lt;/strong>：它为LLM提供指令，从而控制LLM的输出。所以大家要好好学习提示词工程。&lt;/li>
&lt;li>&lt;strong>输出解析器&lt;/strong>：把LLM的原始响应转化为程序更易处理的格式，方便后续使用。&lt;/li>
&lt;/ul>
&lt;p>接下来我们就基于LLMChain来体验LangChain的便捷吧。&lt;/p>
&lt;h1 id="2快速上手langchain">2.快速上手LangChain&lt;/h1>
&lt;p>下面，我们演示如何用LangChain来做文本总结：&lt;/p>
&lt;ul>
&lt;li>环境准备&lt;/li>
&lt;li>构造LLM&lt;/li>
&lt;li>构造提示词模板&lt;/li>
&lt;li>创建Chain，执行指定任务&lt;/li>
&lt;/ul>
&lt;h2 id="step1环境准备">STEP1.环境准备&lt;/h2>
&lt;ul>
&lt;li>安装LangChain。因为LangChain版本更新很快，安装时优先用&amp;rdquo;-U&amp;quot;升级模式安装。&lt;/li>
&lt;li>安装openai(需申请OpenAPI的Token)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123190055109.png" alt="image-20231123190055109">&lt;/p>
&lt;h2 id="step2构造llm">STEP2.构造LLM&lt;/h2>
&lt;ul>
&lt;li>使用langchain 中的 OpenAI 函数来初始化一个大语言模型&lt;code>llm&lt;/code>。
&lt;ul>
&lt;li>本例用的是&amp;quot;text-davinci-003&amp;rdquo;，当然你可以根据需求用gpt或其它模型。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123174527077.png" alt="image-20231123174527077">&lt;/p>
&lt;h2 id="step3构造提示词模板">STEP3.构造提示词模板&lt;/h2>
&lt;blockquote>
&lt;p>应用程序不会把用户的输入直接传给LLM，通常的做法是把用户输入传给提示词模板。&lt;/p>
&lt;p>提示词模板的好处是：&lt;/p>
&lt;ul>
&lt;li>格式化的提示词结构，包括指令、上下文、输入、输出要求等，为给LLM提供更详细的语境。&lt;/li>
&lt;li>支持设置变量，这可以让好用的提示词最大化被复用。&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;ul>
&lt;li>使用langchain的提示词模板函数初始化一个提示词模板&lt;code>prompt_template&lt;/code>
&lt;ul>
&lt;li>提示词指令是总结文本内容&lt;/li>
&lt;li>要处理的文本内容设成变量，本次任务是处理一段新闻，后面也可以随意处理其它文本内容&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123202743359.png" alt="image-20231123202743359">&lt;/p>
&lt;h2 id="step4创建chain">STEP4.创建Chain&lt;/h2>
&lt;p>现在，我们将以上组件组合成一个链，就可以执行任务了。&lt;/p>
&lt;ul>
&lt;li>使用LLMChain构建我们自己的链&lt;code>chain&lt;/code>，传入上面的两个组件&lt;code>llm&lt;/code>、&lt;code>prompt_template&lt;/code>。&lt;/li>
&lt;li>运行&lt;code>chain&lt;/code>，参数只需传入变量text(要处理的文本内容)，可以看到如下运行过程：
&lt;ul>
&lt;li>链开始，&lt;/li>
&lt;li>读取text变量，格式化提示词，传给LLM&lt;/li>
&lt;li>得到结果，链结束&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123203230173.png" alt="image-20231123203230173">&lt;/p>
&lt;p>从上面的示例可以看到，只需一个命令就实现了提示词构建和LLM调用，我们利用Langchain很好的完成了任务。&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文解读了LangChain官方文档的《QuickStart》章节，并给出了基于LangChain构建LLM应用的实例代码。QuickStart章节关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>LangChain简介&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>LangChain 是一个开源框架，支持由LLM驱动的应用程序的开发。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LangChain 的主要价值点：提供了各种模块化组件和好用的链&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LLMChain是LangChain最常见且最重要的一个链，它包含3个主要组件：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>LLM&lt;/strong>：应用程序的核心推理引擎。&lt;/li>
&lt;li>&lt;strong>提示模板&lt;/strong>：它为LLM提供指令，从而控制LLM的输出。&lt;/li>
&lt;li>&lt;strong>输出解析器&lt;/strong>：把LLM的原始响应转化为程序更易处理的格式。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>基于LangChain构建具备总结功能的LLM应用
&lt;ul>
&lt;li>环境准备&lt;/li>
&lt;li>构造LLM&lt;/li>
&lt;li>构造提示词模板&lt;/li>
&lt;li>创建Chain，执行指定任务&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记28-提示词解读4-实战案例之推理</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/</link><pubDate>Thu, 23 Nov 2023 13:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/</guid><description>&lt;p>在《【chatGPT】学习笔记27-提示词解读3-实战案例之摘要总结》中，我们演示了LLM的总结能力。&lt;/p>
&lt;p>接下来，我们继续跟着吴恩达老师的课程，解锁LLM另一个更强大的能力——推理(&lt;code>Inferring&lt;/code>)。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231122092928495.png" alt="image-20231122092928495">&lt;/p>
&lt;blockquote>
&lt;p>本文的“推理”是指利用LLM处理推理型的任务。&lt;/p>
&lt;/blockquote>
&lt;h1 id="1激发推理能力的提示词">1.激发推理能力的提示词&lt;/h1>
&lt;h2 id="1什么是llm的推理能力">(1)什么是LLM的推理能力&lt;/h2>
&lt;p>LLM的推理能力是指从已知信息中推导出新的结论的能力。&lt;/p>
&lt;p>例如在下面的例子中，LLM根据上下文理解用户意图，经过推理生成了新的信息，包括结论和相应的解释。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123133732549.png" alt="image-20231123133732549">&lt;/p>
&lt;h2 id="2如何激发llm的推理能力">(2)如何激发LLM的推理能力&lt;/h2>
&lt;p>我们可以这样构建提示词：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>使用清晰明确的指令词，让LLM理解做什么类型的推理任务，如判断xxx、预测xxx。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>提供足够的上下文信息，让LLM知道要处理的内容。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="2实战案例">2.实战案例&lt;/h1>
&lt;p>假设我是某智能问答系统的IT人员，要用LLM的推理能力帮忙做运营维护：&lt;/p>
&lt;ul>
&lt;li>判断用户对问答系统是否满意。&lt;/li>
&lt;li>用户问题千奇百怪，让智能客服能够应对各式花样提问。&lt;/li>
&lt;/ul>
&lt;h2 id="21满意度识别">2.1.满意度识别&lt;/h2>
&lt;p>一般问答系统都希望通过点赞👍/点踩👎按钮获取用户的反馈，但大部分用户都不会去点。&lt;/p>
&lt;p>利用LLM的推理能力，直接拿用户的对话信息来做满意度分析，可以大大提升运营效率。&lt;/p>
&lt;p>例如，让LLM判断用户回复的信息是什么感情色彩：&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123141130339.png" alt="image-20231123141130339">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123140406001.png" alt="image-20231123140406001">&lt;/p>
&lt;p>吴恩达老师&amp;quot;提示词工程课程&amp;quot;中说LLM擅长做情感判断，所以我又试了下让LLM列出评论中包含的情绪元素。看来LLM感情还是挺丰富的。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123141823738.png" alt="image-20231123141823738">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123141845933.png" alt="image-20231123141845933">&lt;/p>
&lt;h2 id="22应对花式提问">2.2.应对花式提问&lt;/h2>
&lt;p>传统智能问答系统是建立在知识库基础上的，通过关键词匹配最相关的答案，语义理解和推理能力非常有限。&lt;/p>
&lt;p>现实用户提问方式五花八门，如果某个问题不在知识库，系统将无法提供准确答案。&lt;/p>
&lt;p>基于LLM的推理能力，我们通过2个技巧快速提升智能问答系统的应对能力。&lt;/p>
&lt;h3 id="技巧1基于已知问题推导类似问题">技巧1：基于已知问题推导类似问题&lt;/h3>
&lt;p>基于知识库中的预置问题，利用LLM推导扩充不同的问法，丰富问题集，同时弥补传统问答系统语义理解的不足。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123152748076.png" alt="image-20231123152748076">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123152830392.png" alt="image-20231123152830392">&lt;/p>
&lt;h3 id="技巧2归纳推理">技巧2：归纳推理&lt;/h3>
&lt;p>上面的方法可能仍然不足以完全应对用户问题的多样性，那么可以继续用LLM来补漏。&lt;/p>
&lt;p>利用LLM的归纳推理能力，将用户问题和系统关键词检索出的相关问题做比较，从语义上判断是否相近。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153737082.png" alt="image-20231123153737082">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153803235.png" alt="image-20231123153803235">&lt;/p>
&lt;p>换个相关但不相近的问题&amp;ndash;都有关键词”会员“但语义不同，LLM仍然回答正确，看来LLM的推理能力还是可靠的。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153723987.png" alt="image-20231123153723987">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153820768.png" alt="image-20231123153820768">&lt;/p>
&lt;ul>
&lt;li>综上，利用LLM推导和归纳推理这两个技巧，可以实现快速扩充知识库、增强检索能力。&lt;/li>
&lt;/ul>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文介绍了一个LLM另一个实用的提示词技巧，解锁大语言模型的推理能力，充分利用大模型的智慧。&lt;/p>
&lt;p>推理提示词的构建方法：&lt;/p>
&lt;ul>
&lt;li>使用清晰明确的指令词，让LLM理解做什么类型的推理任务，如判断xxx、预测xxx。&lt;/li>
&lt;li>提供足够的上下文信息，让LLM知道要处理的内容。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记27-提示词解读3-实战案例之摘要总结</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 14 Nov 2023 13:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/</guid><description>&lt;p>在《【chatGPT】学习笔记25-提示词解读2-通用技巧》中，我们看到了提示词的各种通用技巧，但无论哪种技巧，都是为了激发大语言模型的某种潜在能力。&lt;/p>
&lt;p>那么，大语言模型有哪些常见、实用的能力呢？作为生成式语言模型，大模型常见、实用的能力如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231113210314835.png" alt="image-20231113210314835">&lt;/p>
&lt;p>本篇先阐述如何通过提示词激发LLM的第一种能力——总结能力(&lt;code>summarizing&lt;/code>)。&lt;/p>
&lt;h1 id="1激发总结能力的提示词">1.激发总结能力的提示词&lt;/h1>
&lt;h2 id="1什么是llm的总结能力">(1)什么是LLM的总结能力&lt;/h2>
&lt;p>在如下场景中，特别需要&lt;strong>LLM的总结能力&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>会议纪要&lt;/strong>：秘书MM，如何快速输出一个时长4小时的会议纪要？&lt;/li>
&lt;li>&lt;strong>编写书评&lt;/strong>：编辑GG，如何快速阅读一本书，提取要点，编写一个书评呢？&lt;/li>
&lt;li>&lt;strong>编写新闻稿&lt;/strong>：记者MM，如何快速输出一个4小时的产品发布会的新闻稿？&lt;/li>
&lt;/ul>
&lt;p>再来理解一下，&lt;strong>LLM的总结能力&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>LLM具备捕捉文本中的重要细节和关联关系的能力，所以它可对文本进行&lt;strong>总结(summary)&lt;strong>和&lt;/strong>摘录(extract)&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>总结(summary)&lt;strong>和&lt;/strong>摘录(extract)&lt;strong>就是&lt;/strong>LLM的总结能力&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>总结(summary)&lt;/strong>：归纳总结一段文本的核心思想、主要内容。&lt;/li>
&lt;li>&lt;strong>摘录(extract)&lt;/strong>：快速提炼一段文本的关键要点，原文出处。&lt;/li>
&lt;/ul>
&lt;h2 id="2如何激发llm的总结能力">(2)如何激发LLM的总结能力&lt;/h2>
&lt;p>我们可以这样构建提示词：&lt;/p>
&lt;ul>
&lt;li>提示词中，出现明确的指令词，如：请&lt;strong>总结&lt;/strong>xxxx，请&lt;strong>摘录&lt;/strong>xxxx。&lt;/li>
&lt;li>明确输出的总结、摘录的约束，如：总结成几句话，多少个字。&lt;/li>
&lt;li>明确总结的侧重点、关注点，如：请总结&lt;strong>价格方面&lt;/strong>的内容。&lt;/li>
&lt;li>设定背景信息，如：你是一名新华社记者，这是一篇新闻稿。&lt;/li>
&lt;/ul>
&lt;h1 id="2实战案例">2.实战案例&lt;/h1>
&lt;p>我们以智界S7发布会新闻稿为例，演示通过提示词激发LLM总结能力：&lt;/p>
&lt;ul>
&lt;li>我是一名自媒体记者，我获取了华为智界S7发布会的演讲稿。&lt;/li>
&lt;li>我想快速输出一篇&amp;quot;智界S7发布会的新闻稿&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;h2 id="step1编写引言">STEP1.编写引言&lt;/h2>
&lt;p>首先，我需要为新闻稿写一个引言，简明扼要地介绍新闻的核心内容，如：何时、何地、发生何事。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115111855070.png" alt="image-20231115111855070">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115111905241.png" alt="image-20231115111905241">&lt;/p>
&lt;h2 id="step2编写主体段落">STEP2.编写主体段落&lt;/h2>
&lt;p>接下来，写新闻稿的主体段落。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112026820.png" alt="image-20231115112026820">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112057272.png" alt="image-20231115112057272">&lt;/p>
&lt;h2 id="step3编写记者观点">STEP3.编写记者观点&lt;/h2>
&lt;p>接下来，需要记者输出对该产品的观点，如：通过产品的功能参数、产品的价格，记者如何看待该产品的性价比。&lt;/p>
&lt;ul>
&lt;li>我对价格方面的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112357958.png" alt="image-20231115112357958">&lt;/p>
&lt;ul>
&lt;li>LLM对价格的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112405603.png" alt="image-20231115112405603">&lt;/p>
&lt;ul>
&lt;li>我对产品参数的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112515271.png" alt="image-20231115112515271">&lt;/p>
&lt;ul>
&lt;li>LLM对产品参数的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112523094.png" alt="image-20231115112523094">&lt;/p>
&lt;ul>
&lt;li>综上，记者观点如下：
&lt;ul>
&lt;li>智界S7车长4971mm，轴距2950mm，车宽1963mm，首发搭载华为途灵智能底盘和HarmonyOS 4智能座舱，还有HUAWEI ADS 2.0高阶智能驾驶辅助系统等领先科技，将为轿车市场用户带来全场景智慧出行新体验。它的预售价仅25.8万起，&lt;strong>对于这样一辆高性能的新能源车，性价比极高&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="step4提炼发言人重要观点">STEP4.提炼发言人重要观点&lt;/h2>
&lt;p>然后，引用发言人余承东的几个重要观点，在新闻稿中突出发布会的重点信息。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115113113849.png" alt="image-20231115113113849">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115113122691.png" alt="image-20231115113122691">&lt;/p>
&lt;h2 id="step5汇总形成新闻稿">STEP5.汇总形成新闻稿&lt;/h2>
&lt;ul>
&lt;li>汇总上述信息，得到的新闻稿如下：&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>【标题】智界S7发布会再次引爆市场热点&lt;/p>
&lt;p>【引言】华为11月9日在深圳举行了智慧出行解决方案新战略发布会，同时推出华为智选车业务新生态。发布会上，华为智选车首款轿车智界S7正式开启预售，预售价格从25.8万元起，并将于11月28日正式发布。华为旨在通过全新平台和领先科技为用户带来全场景智慧出行新体验。&lt;/p>
&lt;p>【内容】&lt;/p>
&lt;p>华为于11月9日在深圳发布了智慧出行解决方案新战略，并推出华为智选车业务新生态，旗下拥有问界和智界系列车型。华为智选车首款轿车智界S7正式开启预售，预售价格为25.8万元起，并将于11月28日正式发布。华为常务董事余承东表示，问界系列车型的销量火爆，华为将全力提升产能以满足需求。&lt;/p>
&lt;p>华为智选车首款智慧轿车智界S7由华为与奇瑞强强联合打造，采用华为全栈智能汽车解决方案，拥有舒适大空间和出色性能体验。它搭载了华为途灵智能底盘和HarmonyOS 4智能座舱，以及HUAWEI ADS 2.0高阶智能驾驶辅助系统等先进技术。智界S7将为用户带来全新的智慧出行体验，11月28日将正式发布。&lt;/p>
&lt;p>华为表示要持续引领智能汽车的技术创新并推动智能化发展。华为与赛力斯联合打造的问界系列车型取得了优异的市场表现。余承东透露，问界新M7上市不到两月就获得了86000辆大定订单，其中70%以上的用户选择智驾版。问界M9订单突破25000台，火爆销售。华为将全力提升产能以满足订单需求。&lt;/p>
&lt;p>余承东表示：“价格方面我们内部反复讨论，多次测算，最后发现这款车四个版本定价我们都是亏钱的，只能期待后期这款车的放量出货来弥补亏损，目的也是让更多消费者体验华为的产品。”&lt;/p>
&lt;p>智界S7车长4971mm，轴距2950mm，车宽1963mm，首发搭载华为途灵智能底盘和HarmonyOS 4智能座舱，还有HUAWEI ADS 2.0高阶智能驾驶辅助系统等领先科技，将为轿车市场用户带来全场景智慧出行新体验。它的预售价仅25.8万起，&lt;strong>对于这样一辆高性能的新能源车，性价比极高&lt;/strong>。&lt;/p>
&lt;/blockquote>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文介绍了一个非常实用的提示词技巧，能够很好的激发大语言模型摘要总结的能力，让大模型成为我们的办公助手。&lt;/p>
&lt;p>摘要总结提示词构建方法：&lt;/p>
&lt;ul>
&lt;li>提示词中，出现明确的指令词，如：请&lt;strong>总结&lt;/strong>xxxx，请&lt;strong>摘录&lt;/strong>xxxx。&lt;/li>
&lt;li>明确输出的总结、摘录的约束，如：总结成几句话，多少个字。&lt;/li>
&lt;li>明确总结的侧重点、关注点，如：请总结&lt;strong>价格方面&lt;/strong>的内容。&lt;/li>
&lt;li>设定背景信息，如：你是一名新华社记者，这是一篇新闻稿。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记26-CNCC 2023参会纪要</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B026-cncc-2023%E5%8F%82%E4%BC%9A%E7%BA%AA%E8%A6%81/</link><pubDate>Fri, 10 Nov 2023 13:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B026-cncc-2023%E5%8F%82%E4%BC%9A%E7%BA%AA%E8%A6%81/</guid><description>&lt;p>本文记录笔者参加CNCC 2023 AI相关的议题，方便各位小伙伴快速了解学界在AI的理论研究和行业应用情况。&lt;/p>
&lt;h1 id="1cncc-2023概览">1.CNCC 2023概览&lt;/h1>
&lt;h2 id="1会议简介">(1)会议简介&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>本届大会以“&lt;strong>发展数字基础设施，支撑数字中国建设&lt;/strong>”为主题，探讨计算及信息科学技术领域的最新进展和宏观发展趋势，为数字中国建设提供支持。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>大会特邀了国际知名学者、两院院士、产学研各界代表在内的&lt;strong>700余位报告嘉宾&lt;/strong>，覆盖了&lt;strong>人工智能&lt;/strong>、安全、计算+、&lt;strong>软件工程&lt;/strong>、教育、网络、&lt;strong>芯片&lt;/strong>、&lt;strong>云计算&lt;/strong>等30余个领域，推动不同领域的交叉融合，为各界专业人士提供了广泛的专业内容。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>![image-20231109151407115](/AI拾遗/【chatGPT】学习笔记26-CNCC 2023参会纪要/image-20231109151407115.png)&lt;/p>
&lt;h2 id="2议题分布">(2)议题分布&lt;/h2>
&lt;p>CNCC 2023的众多议题中，LLM相关分会场73个。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>基础设施&lt;/strong>：18个分会场&lt;/li>
&lt;li>&lt;strong>LLM理论研究&amp;amp;工程化实践&lt;/strong>：15个分会场&lt;/li>
&lt;li>&lt;strong>LLM应用&lt;/strong>：38个分会场&lt;/li>
&lt;/ul>
&lt;p>![image-20231109195425387](/AI拾遗/【chatGPT】学习笔记26-CNCC 2023参会纪要/image-20231109195425387.png)&lt;/p>
&lt;h1 id="2方向1基础设施">2.方向1：基础设施&lt;/h1>
&lt;h2 id="21dpu相关">2.1.DPU相关&lt;/h2>
&lt;h3 id="议题1dpu标准化工作实践">议题1：DPU标准化工作实践&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>： 钟伟军，中国电子技术标准化研究院技术总监。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：DPU标准化工作，是DPU大规模落地应用中重要环节。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：DPU标准工作实践的成果和现状。如：《数据处理器(DPU)第1部分：参考框架》、《数据处理器(DPU)测试方法》等。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：DPU标准化工作的挑战及下一阶段的计划。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2面向ai时代的dpu云计算融合底座设计与实践">议题2：面向AI时代的DPU云计算融合底座设计与实践&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：曹辉，中科驭数产品运营部副总经理&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：越来越多的云计算基础设施组件正在计划融合或支持DPU方案，是下一代云计算架构演进的主流方向。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：在云原生领域，随着智算中心架构的发展，高吞吐、低时延是智算中心架构发展的挑战。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：中科驭数的解决方案是&lt;strong>IaaS on DPU&lt;/strong>，将IaaS平台下沉至DPU，提供高性能的容器、虚拟机、裸金属服务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3网络域场景dpu应用探索">议题3：网络域场景DPU应用探索&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：曹畅，中国联通研究院未来网络研究部总监&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：DPU具有高效、灵活的可编程网络数据处理加速能力，可支撑网络、存储、安全、管理等数据中心基础设施层可定制的业务加速能力。&lt;/li>
&lt;li>&lt;strong>枢纽&lt;/strong>：DPU衔接了算力和网络两大领域的重要枢纽，推动了计算和网络融合，助力传统算力基础设施向&lt;strong>算网一体的算力网络&lt;/strong>演进。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：在算力网络、5/6G、数据中心网络等网络域场景中，中国联通如果对DPU进行的探索及创新方案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4dpu--如何使能高性能ai网络">议题4：DPU , 如何使能高性能AI网络&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：王瑞雪，中国移动通信有限公司研究院基础网络技术研究所技术经理&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>NICC&lt;/strong>：New Intelligent Computing Center，以高性能GPU、AI加速卡为中心，以高速互联智算集群为目标，形成E级超大规模算力基础设施。&lt;/li>
&lt;li>&lt;strong>价值&lt;/strong>：强化互联技术、深化算力协同、定义新型存储、新增算力原生、升级绿色节能。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：AI大模型以GPU集群分布式训练为基础，集群节点间频繁参数同步带来大通信开销，因此网络是提升AI大模型训练效率的关键之一。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="22芯粒相关">2.2.芯粒相关&lt;/h2>
&lt;h3 id="议题1智能计算时代下的chiplet生态建设">议题1：智能计算时代下的Chiplet生态建设&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：谭展宏，北极雄芯信息科技有限公司CTO。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：海内外多家公司也陆续推出了基于Chiplet技术的产品。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：很多公司标榜着Chiplet这个关键词，但Chiplet的定义、使用方式和技术路线都有各自说法。&lt;/li>
&lt;li>&lt;strong>探索&lt;/strong>：本议题探讨Chiplet如何助力面向计算资源与智能计算，分享Chiplet的生态发展的思考。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2面向百芯万核的芯粒仿真初探">议题2：面向百芯万核的芯粒仿真初探&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：王小航，浙江大学教授。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：软件仿真器是探索集成芯片设计空间的重要工具&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：在大芯片和大模型的时代芯片规模提高，仿真性能无法支撑百芯万核规模的芯片仿真，仿真精度校准难，仿真配置多等。&lt;/li>
&lt;li>&lt;strong>方案&lt;/strong>：分析了上述问题的形成原因，通过并行仿真、精度调节、自动化设计空间探索等技术解决上述问题。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3芯粒测试关键技术研究">议题3：芯粒测试关键技术研究&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：蔡志匡，南京邮电大学教授。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：Chiplet是延续摩尔定律的关键技术，通过先进封装将芯粒集成在一个中介层上，解决芯片研制的规模大、成本高、周期长等问题。&lt;/li>
&lt;li>&lt;strong>关键点1&lt;/strong>：基本DFT技术、单芯粒测试技术、多芯粒测试技术。&lt;/li>
&lt;li>&lt;strong>关键点2&lt;/strong>：覆盖芯粒测试各个环节的芯粒系统级可测试设计方案(测试技术、测试EDA、测试装备)，实现高可靠性、全流程的系统级测试。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4从aigc到百模大战异构计算和chiplet-协同以致胜">议题4：从AIGC到百模大战，异构计算和Chiplet 协同以致胜&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：祝俊东，奇异摩尔产品及解决方案副总裁。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：随着LLM发展及百模大战，异构计算与Chiplet协同扮演关键角色。&lt;/li>
&lt;li>&lt;strong>趋势&lt;/strong>：百模大战引导出的关键挑战之一是&lt;strong>高性能芯片、更大规模的智算平台&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5面向25d集成的先进封装工艺与设计协同方案">议题5：面向2.5D集成的先进封装工艺与设计协同方案&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：樊嘉祺，华进半导体封装设计经理&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：摩尔定律趋缓，封装技术成为电子产品小型化、多功能化、降低功耗、提高带宽的重要手段。&lt;/li>
&lt;li>&lt;strong>趋势&lt;/strong>：芯片封装从传统的平面封装向系统集成、高速、高频、三维方向发展。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：芯片-封装协同设计、满足可靠性要求，材料和工艺方面，存在诸多挑战。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：华进半导体致力于系统封装设计、2.5D/3D 集成关键核心技术研发，提供设计仿真、晶圆制造、系统集成、模组测试等全方位解决方案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="23信息器件与智能计算相关">2.3.信息器件与智能计算相关&lt;/h2>
&lt;h3 id="议题1存算一体异构计算芯片">议题1：存算一体异构计算芯片&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：高滨，清华大学长聘副教授/博导，清华大学教务处副处长&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>背景&lt;/strong>：存算一体技术聚焦在单片三维集成的新型存储器技术。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：忆阻器相关的制造工艺和设计技术，包括28nm集成、EDA工具开发、IP单元电路设计、异构计算架构设计、编译器等。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：基于忆阻器的&lt;strong>超近存计算+存内计算&lt;/strong>的异构计算系统，在算力、灵活性、可扩展性、效率、精度等方面展现出巨大的优势，在多个场景已得到初步的应用验证。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2基于忆阻器的储池计算">议题2：基于忆阻器的储池计算&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：王中锐，香港大学电气与电子工程系助理教授&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：由于内存的物理上分离、处理单元以及晶体管工艺节点限制，传统数字硬件面临巨大挑战，忆阻器是高效和高集成度的深度学习解决方案。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：忆阻器的非理想特性使其难以在边缘侧AI实现原位学习。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：利用新颖的硬件-软件协同设计，利用忆阻器的高度并行和高效的存内计算，将忆阻器的随机性转化为优势。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：基于忆阻器的回声状态储池网络用于时空信号学习、利用随机忆阻器阵列进行图结构数据学习、图嵌入方法与忆阻器联想记忆相结合以满足少样本图学习的需求、基于忆阻器液态机的零样本学习用于多模态事件数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3新型神经元器件电路及其类脑系统应用">议题3：新型神经元器件、电路及其类脑系统应用&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：张续猛，复旦大学青年副研究员，2023年度CCF-之江实验室联合创新基金获得者，全国智能计算标准化工作组委员&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：忆阻器基神经元器件，具有丰富动力学、低功耗、以及高集成度等特点，被认为是构建紧凑神经元电路的理想单元之一。&lt;/li>
&lt;li>&lt;strong>技术&lt;/strong>：利用神经元不同放电模式实现高效计算方面的研究工作，神经元器件的本征温度响应和它在多模态感知方面的应用。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4模拟矩阵计算求解ax--b">议题4：模拟矩阵计算求解Ax = b&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：高滨，清华大学长聘副教授/博导，清华大学教务处副处长&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：求解矩阵方程&lt;strong>Ax = b&lt;/strong>是历史上计算机技术发展的重要驱动力，也构成了现代计算任务的核心。如：科学计算、机器学习、信号处理等。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：传统数字计算机通过执行串行算法(直接法/迭代法)求解该方程，具有高的计算复杂度。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：传统计算机采用冯·诺伊曼架构，求解速度与能效受存储器、处理器之间的通信瓶颈限制。&lt;/li>
&lt;li>&lt;strong>方案&lt;/strong>：模拟矩阵计算，基于存储器阵列架构与全局反馈实现，具有极高的计算并行度；设计存储器阵列的反馈连接方式，模拟矩阵计算电路能够以O(1)的时间求解矩阵求逆、广义逆(如最小二乘)，以及稀疏近似(如压缩感知还原、稀疏编码)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5基于rram硬件的高效小样本学习和图处理">议题5：基于RRAM硬件的高效小样本学习和图处理&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：李灿，香港大学电机与电子工程系的助理教授&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：RRAM，抗变存储器，一种新兴的非易失性模拟存储技术，在存算一体应用方面展示了巨大的潜力。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：使用RRAM进行哈希运算和相似度搜索。通过在交叉阵列中进行特殊编码以及在注意力机制中用于相似度搜索。结合这些操作能够使用基于记忆增强的神经网络(MANN)进行少样本学习，以及使用图注意力(Graph Attention Network)网络进行图数据处理。这可能相较于传统计算平台如CPU和GPU，能耗显著降低，准确度损失最小。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="25云计算相关">2.5.云计算相关&lt;/h2>
&lt;h3 id="议题1大模型与国产算力">议题1：大模型与国产算力&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：翟季冬，清华大学计算机系长聘教授。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：在新一代国产超级计算机上，从底层算子库、并行加速库、负载均衡和混合精度等多方面对大模型进行了性能优化，最终实现了百万亿级参数量的预训练模型训练加速，达到了 EFLOPS级别的训练性能。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="26国内厂商的基础设施情况">2.6.国内厂商的基础设施情况&lt;/h2>
&lt;h3 id="议题1构建泛化普惠的智能算力中科曙光">议题1：构建泛化普惠的智能算力(中科曙光)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：杜夏威，中科曙光智能计算产品事业部总经理。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：通用超算中心-&amp;gt;专用智算中心-&amp;gt;通用智能计算中心。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：成熟兼容的DTK，&lt;strong>兼容CUDA和ROCm&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：适配百度飞桨，上限飞桨官网。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2算力为基共筑数智未来华为昇腾">议题2：算力为基，共筑数智未来(华为昇腾)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：刘鑫，华为昇腾计算业务副总裁。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>介绍华为在AI领域通过昇腾计算构筑坚实算力底座，聚焦根技术创新，打造好用、易用、可信的人工智能平台，发展普惠算力，降低大模型开发门槛，加速大模型模型创新落地，与各产业界共同构筑AI生态未来。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3昇腾大模型基础设施解决方案华为昇腾">议题3：昇腾大模型基础设施解决方案(华为昇腾)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：周斌，华为昇腾计算业务研发总裁&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：大模型是复杂系统工程，每个环节都存在大量工程技术挑战。&lt;/li>
&lt;li>&lt;strong>关键技术&lt;/strong>：高密度计算、复杂通信、内存优化等，打造大模型超级流水线，全流程使能大模型创新落地。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4华为计算领域技术挑战难题解读华为昇腾">议题4：华为计算领域技术挑战难题解读(华为昇腾)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：石晓钟，华为计算产品线技术合作总监&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>难题1&lt;/strong>：计算系统的高可靠计算容错技术。&lt;/li>
&lt;li>&lt;strong>难题2&lt;/strong>：片上和系统相结合的内存纠错技术。&lt;/li>
&lt;li>&lt;strong>难题3&lt;/strong>：多言行算力下的高鲁棒性混合精度求解。&lt;/li>
&lt;li>&lt;strong>难题4&lt;/strong>：基于原生硬件的高性能算子/算法(Matmul、Self-Attention)。&lt;/li>
&lt;li>&lt;strong>难题5&lt;/strong>：基于原生硬件的高性能算子/算法(FFT、Conv2D)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5壁仞科技">议题5：壁仞科技&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：丁云帆，壁仞科技系统架构副总裁&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>服务于百度飞桨、文心一言。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：GPT的大规模分布式训练在模型的参数规模、算力规模和训练性能等维度都存在巨大的挑战，大模型的应用落地也存在成本高、延时大的难题。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：本报告介绍GPT大模型的分布式并行训练策略、如何基于国产大算力通用GPU打造大模型训练系统及低延时高性能的大模型推理引擎。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题6飞腾">议题6：飞腾&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：窦强，中国电子信息产业集团科技委副主任，飞腾信息技术有限公司首席科学家&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>归属&lt;/strong>：隶属于中国电子信息产业集团。&lt;/li>
&lt;li>&lt;strong>关键路径&lt;/strong>：体系结构优化、设计工艺协同优化DTCO、先进封装推动Chiplet、系统垂直优化。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="3方向2llm基础理论工程化实践">3.方向2：LLM基础理论&amp;amp;工程化实践&lt;/h1>
&lt;h2 id="31预训练微调">3.1.预训练&amp;amp;微调&lt;/h2>
&lt;h3 id="议题1大模型技术研究及应用">议题1：大模型技术研究及应用&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：宗成庆，中国科学院自动化研究所研究员、博士生导师&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>PS：宗老师这个议题讲的非常通透，NLP造诣很深厚。&lt;/li>
&lt;li>&lt;strong>对大模型改进1&lt;/strong>：丰富生成文本的信息。预训练模型过于关注提示词中给出的实体or事件，难以包含更丰富的实体和信息。&lt;/li>
&lt;li>&lt;strong>对大模型改进2&lt;/strong>：无梯度计算的大模型参数调试。即，仅微调模型参数的一小部分就可以达到不错的微调性能。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="32端云协同下分布式训练">3.2.端云协同下，分布式训练&lt;/h2>
&lt;h3 id="议题1端云协同下分布式模型训练">议题1：端云协同下分布式模型训练&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：吴飞，浙江大学求是特聘教授，博士生导师&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：在&lt;strong>泛在互联、端云协同、AI赋能&lt;/strong>背景下，形成端云协同机器学习计算范式，是人工智能成为&lt;strong>普惠化能力&lt;/strong>的关键问题之一。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：将&lt;strong>云侧的泛化能力&lt;/strong>与&lt;strong>端侧的个性化能力&lt;/strong>结合起来，体现&lt;strong>须弥纳于芥子&lt;/strong>的哲学思想。云端or端侧学习能力提升、端云协同模型化、端云系统开放平台是研究重点。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="33神经符号计算">3.3.神经符号计算&lt;/h2>
&lt;h3 id="议题1神经符号双轮驱动的信息检索与知识获取">议题1：神经符号双轮驱动的信息检索与知识获取&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：程学旗，中国科学院计算技术研究所副所长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：反绎学习面临弱标注数据和弱逻辑规则情形时，可能导致性能下降、不稳定。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：反绎学习是融合机器学习与逻辑推理并使它们能够比较均衡地协同发挥作用的新范式，提升反绎学习鲁棒性是研究重点。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2细粒度多模态协同感知认知与生成">议题2：细粒度多模态协同感知、认知与生成&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：彭宇新，北京大学博雅特聘教授、国家杰青、国家万人。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：细粒度多模态协同感知、认知与生成对于刻画真实世界和人类生产生活方式具有重要意义。&lt;/li>
&lt;li>&lt;strong>研究目标&lt;/strong>：借鉴人脑的跨模态特性，通过挖掘并协同多源、互补、关联的细粒度和多模态信息，实现对真实世界概念、规则及其演化的深层感知、认知与综合归纳。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：细粒度图像分类、行人再识别、细粒度视频检索、细粒度跨媒体检索、跨媒体推理、细粒度视觉生成。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3从语言大模型到神经符号ai">议题3：从语言大模型到神经符号AI&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：杨博，吉林大学计算机学院教授/博导，计算机学院、软件学院院长。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：神经符号AI期望将符号主义和链接注意融合起来，取长补短，建立具有高效、鲁棒、可解释的智能系统，是当前人工智能研究的一个热点。&lt;/li>
&lt;li>&lt;strong>本质&lt;/strong>：符号主义和链接主义是人工智能的两大方法论，分别模拟演绎推理和归纳学习两种认知过程。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4鲁棒反绎学习迈向安全利用弱标注与弱规则">议题4：鲁棒反绎学习：迈向安全利用弱标注与弱规则&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：李宇峰，南京大学人工智能学院教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>**关键：**提升反绎学习鲁棒性方面的近期研究进展。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="34知识图谱">3.4.知识图谱&lt;/h2>
&lt;h3 id="议题1大模型时代的知识图谱">议题1：大模型时代的知识图谱&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：白硕，CCF上海分部主席，CCF理事，恒生电子有限公司首席科学家。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人从逻辑学出发，阐述命题逻辑、描述逻辑、一阶逻辑、高阶逻辑等，深入剖析NLP领域的远距关联、隐形资产以及大语言模型的短板。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：从描述逻辑到知识图谱，事理图谱，阐述知识图谱的四大特点，进一步阐述了知识图谱融合大模型的应用场景分类和应用深度分类。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2大模型应用体会澜舟科技">议题2：大模型应用体会(澜舟科技)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：周明，澜舟科技创始人兼CEO。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>定位&lt;/strong>：在大语言模型时代，各公司应如何选择产品定位？澜舟科技介绍了自身在大模型时代的定位。&lt;/li>
&lt;li>&lt;strong>模型选择&lt;/strong>：报告人提出了&lt;strong>周明曲线&lt;/strong>，阐述了如何为客户选择合适的大模型规模，量体裁衣，打造专业赛道的垂域大模型。&lt;/li>
&lt;li>&lt;strong>趋势&lt;/strong>：&lt;strong>AI Agents&lt;/strong>是大模型落地的必然趋势，以解决复杂问题求解、实时信息获取和分析、领域专业知识补充、外部系统交互等问题。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：报告人分享了&lt;strong>垂域知识库搜索问答、企业用户智能搜索+AI问答、对话生成式BI分析、智能客服、会议内容智能分析&lt;/strong>领域的案例。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3类chatgpt语言大模型与知识图谱新进展">议题3：类ChatGPT语言大模型与知识图谱新进展&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：王鑫，天津大学智能与计算学部教授、博导，人工智能学院副院长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：以ChatGPT为代表的语言大模型是“联结主义”的最新成果，而知识图谱是“符号主义”的集大成者，如何充分发挥知识图谱的积累的能力，补齐大语言模型的短板，是重要的研究方向。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：探究类ChatGPT语言大模型与知识图谱相互作用而实现“神经+符号”结合的可能途径。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="35安全治理价值观对齐联邦学习">3.5.安全治理&amp;amp;价值观对齐&amp;amp;联邦学习&lt;/h2>
&lt;h3 id="议题1大语言模型之价值观对齐">议题1：大语言模型之价值观对齐&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：秦兵，哈尔滨工业大学计算学部教授，博士生导师。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：大模型智能时代革命到来，生成式人工智能存在的安全隐患等价值观伦理问题。&lt;/li>
&lt;li>&lt;strong>研究方向&lt;/strong>：探索大模型安全性内容生成方法，包括研究大模型辨别是非能力，以及人类普世价值观，社会文化价值观及立场对齐上的内容检测与生成方法，探索AI社会协作式的价值观对齐机制。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2面向异构计算环境的去中心化联邦学习框架">议题2：面向异构计算环境的去中心化联邦学习框架&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：吕建成，四川大学教授/博导、计算机学院(软件学院、智能科学与技术学院)院长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：联邦学习可以突破数据孤岛和隐私保护瓶颈，是助力人工智能落地的新兴技术。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：联邦学习应用于实际场景时，面临异构的计算环境：设备计算性能异构、通信网络和训练数据异构。现有基于中心化参数服务器的主流优化范式存在计算和通信瓶颈，面临扩展性差、通信开销大、模型性能低等现实问题。&lt;/li>
&lt;li>&lt;strong>方案&lt;/strong>：以去中心基础架构、通信优化、个性化模型优化为代表的去中心化架构及其衍生算法 。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="36机器语音机器听觉">3.6.机器语音/机器听觉&lt;/h2>
&lt;h3 id="议题1听觉注意力的理论与算法">议题1：听觉注意力的理论与算法&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：李海洲，新加坡工程院院士，新加坡国立大学终身教授、德国不来梅大学卓越讲座教授&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>技术点&lt;/strong>：听觉注意力是面对复杂的声学场景，人的眼睛和耳朵紧密配合、由大脑协调而实现对目标声源的选择。报告人阐述了听觉注意力算法在语音增强、说话人提取、语言提取等应用课题中的实践。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2说话人声音模仿与鉴别技术">议题2：说话人声音模仿与鉴别技术&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：陶建华，CCF语音对话与听觉专委会副主任，清华大学自动化系教授，博导&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：迁移学习&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：高度拟人化和个性化的人物声音模仿技术，对通信、教育、金融、社交、娱乐等领域有重要作用。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：阐述了通过迁移学习、生成式网络模型，声音模仿技术的多项成果。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：系统性地介绍伪造声音鉴别技术，伪造溯源分析方法、面向复杂场景的声音生成与鉴别对抗博弈机制。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3speechgpt让大语言模型具有内生的语音对话能力">议题3：SpeechGPT：让大语言模型具有内生的语音对话能力&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：邱锡鹏，复旦大学计算机学院教授，博导&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>案例&lt;/strong>：介绍SpeechGPT的跨模态能力，SpeechGPT突破了传统语音到语音对话流水线方式 (ASR+LLM+TTS) 的束缚，实现了模态之间的知识传递，不需要额外的ASR和TTS系统也能和LLM直接进行语音对话。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="37全脑神经联接与类脑智能">3.7.全脑神经联接与类脑智能&lt;/h2>
&lt;h3 id="议题1破解脊椎动物全脑神经联接--脑与类脑研究的基石">议题1：破解脊椎动物全脑神经联接 – 脑与类脑研究的基石&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：杜久林，中国科学院脑科学与智能技术卓越创新中心副主任&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：大脑是在跨时空尺度上具有高度非线性作用的复杂动力学系统，心智的奥秘就蕴藏在这精巧的组织结构中。揭示大脑组织规律及其基础上产生的神经功能的机制，不仅是理解大脑奥秘的必由之路，也将为发展类脑智能构架与算法、突破冯•偌依曼构架提供新策略。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：斑马鱼具有脊椎动物保守的神经系统结构，可以从全脑尺度上解读其大脑工作的基本原理。报告人讲述本研究团队运用自创的“既见森林(全脑)、又见树木(神经元)甚或树叶(突触)”的研究范式，实现了对脊椎动物全脑所有神经元形态结构与神经活动的在体观测与调控、以及动物行为的同时记录。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2文曲星基于开源芯片与敏捷开发的开源类脑芯片">议题2：文曲星：基于“开源芯片与敏捷开发”的开源类脑芯片&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：赵地，中科院计算所副研究员&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：在神经形态计算中，脉冲神经网络(Spiking Neural Network，SNN)是硬件实现的最佳选择。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：大多数加速器解决方案都基于CPU 加速器架构，这种结构因为复杂的控制流程而能源效率低下。报告人基于脉冲卷积神经网络的开源芯片构架：开发脉冲卷积单元，对现有的卷积神经网络单元进行特征提取和事件驱动设置，进一步提高单元工作工作的效率，并降低功耗的开销。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3全脑尺度的信息维持和行为策略调整">议题3：全脑尺度的信息维持和行为策略调整&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：穆宇，中国科学院脑科学与智能技术卓越创新中心研究员&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：空间上，大脑的每个部分都接收来自其他区域的输入并对其产生作用。时间上，每一刻的大脑都携带着前一刻的信息并影响着下一刻。对&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人阐述如何开发一种系统，支持在单个细胞的分辨率监测整个斑马鱼大脑，并实时处理所获得的神经元或行为信息以生成闭环干扰从感觉到运动的完整转导过程，在全脑尺度上进行剖析，助力理解复杂的脑功能并总结其完整的计算原理。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4类脑器件与系统">议题4：类脑器件与系统&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：缪峰，南京大学物理学院教授、博导、副院长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人阐述了二维材料与“原子乐高”电子学如何在发展未来的类脑智能技术中发挥重要作用，包括神经形态计算与类视网膜形态计算等。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="4方向3llm应用落地">4.方向3：LLM应用落地&lt;/h1>
&lt;h2 id="41软件工程">4.1.软件工程&lt;/h2>
&lt;h3 id="议题1大模型时代的软件研发华为">议题1：大模型时代的软件研发(华为)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：王千祥，华为云智能化软件研发首席专家&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>引导&lt;/strong>：从软件研发角度，大模型将带来哪些变化？报告人结合华为在基于LLM的代码生成等软件研发领域开展的系列探索，分享软件研发大模型的进展。&lt;/li>
&lt;li>&lt;strong>问题&lt;/strong>：开发者如何与大模型协同研发？程序如何与大模型协同运行？人类如何与大模型协同存在？&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2大模型催生ai原生研发新范式百度">议题2：大模型催生AI原生研发新范式(百度)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：臧志，百度工程效能部总监&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：探讨在大模型技术影响下，&lt;strong>产品思维-应用框架-研发过程&lt;/strong>将发生哪些变化。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：如何适配大模型时代的新要素构建新的研发生产力，以及新型的研发智能体如何在企业场景中落地应用。&lt;/li>
&lt;li>&lt;strong>核心要点&lt;/strong>：&lt;strong>SE 4 AI，AI 4 SE&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3代码大模型赋能软件研发的探索与实践科大讯飞">议题3：代码大模型赋能软件研发的探索与实践(科大讯飞)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：薛增奎，科大讯飞效能平台首席技术专家&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：介绍科大讯飞的iFlyCode(基于自研代码大模型的智能编程助手产品)，以及在内外部应用的典型场景和成效。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4基于代码大模型的代码智能体字节跳动">议题4：基于代码大模型的代码智能体(字节跳动)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：许晶晶，字节跳动研究员&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：讨论基于代码大模型的自主代理的构建和具体的应用场景。在智能体构建方面，如何结合代码规划、代码执行等能力？在应用场景方面，以数据分析场景为例，探讨智能体在其中的应用和实践。&lt;/li>
&lt;li>PS：这个小姐姐功力深厚。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5大模型对软件开发模式的影响北大">议题5：大模型对软件开发模式的影响(北大)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：李戈，北京大学长聘教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：软件自动化理论认为AI辅助研发的瓶颈是模型大小。大语言模型为软件自动化打开了一扇窗。反之，模型不够大就是多少人工多少智能。&lt;/li>
&lt;li>**PS：**李老师很诙谐，净说大实话。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题6大模型时代软件测试技术方向与趋势同济大学">议题6：大模型时代软件测试技术方向与趋势(同济大学)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：朱少民，同济大学特聘教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：阐述了早期采用遗传算法、粒子群优化算法等生成测试数据，AI覆盖了测试建模、测试用例集优化、GUI白动化测试、测试结果分析等方面。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人着重讨论如何应用大模型为软件测试赋能、如何借助LLM相关技术更高效地完成测试工作，以及未来技术发展方向。阐述了大模型时代软件测试的新范式、大模型时代软件测试的技术方向。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="42智慧交通">4.2.智慧交通&lt;/h2>
&lt;h3 id="议题1视频物联网中云端协同智能计算">议题1：视频物联网中云端协同智能计算&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：马华东，北京邮电大学计算机学院教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：视频物联是物联网的一种重要形态，也是支撑智慧城市、智能安防等应用的关键基础设施。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人以人、车、事件为典型目标，阐述了面向多任务多场景的深度神经网络智能视频算法体系&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：针对端设备资源受限、云端协同计算难、单一视觉模型能力弱等挑战，介绍了模型轻量化、云端模型互动、视觉大模型等相关技术&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="43智慧医疗">4.3.智慧医疗&lt;/h2>
&lt;h3 id="议题1exploring-different-modalities-for-healthcare-applications">议题1：Exploring Different Modalities for Healthcare Applications&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：邱锂力，微软亚洲研究院副院长&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人介绍如何利用无线传感和机器学习技术利用不同模式进行疾病诊断的探索，从语言、运动、呼吸、心跳、脑电波、医学图像等方面衡量一个人的健康状况。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2生命科学基础模型">议题2：生命科学基础模型&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：宋乐，BioMap CTO和首席人工智能科学家&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：能否利用大量无监督数据来加速生命科学发现和药物设计？&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：介绍xTrimo系列跨多尺度生物过程的大规模预训练模型，整合来自蛋白质序列、结构、蛋白质-蛋白质相互作用和单细胞转录组数据的大量数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="44智慧农业">4.4.智慧农业&lt;/h2>
&lt;h3 id="议题1智慧农业领域的大模型初探">议题1：智慧农业领域的大模型初探&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：刘劼，哈尔滨工业大学（深圳）国际人工智能研究院院长，IEEE Fellow&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：介绍大模型在遥感图像处理、作物数据生成等方面的尝试，并展望建立作物生长等大模型的前景。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="45aiot">4.5.AIoT&lt;/h2>
&lt;h3 id="议题1aiiot-human-centric-smart-sensing-design">议题1：AI+IoT: Human-Centric Smart Sensing Design&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：张黔，香港科技大学腾讯工程学教授、计算机科学与工程系讲座教授、IEEE Fellow、香港工程科学院院士&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：AI与IoT的融合，为以人为中心的应用创造了赋能的机会，也产生了相关的挑战。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：如何处理数据的异构特性、不同终端用户数据的不完整性、以及终端设备资源受限造成的低质量数据等问题？感知模态的多样性为感知能力的突破带来的新机会点？&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记25-提示词解读2-通用技巧</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/</link><pubDate>Fri, 10 Nov 2023 12:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/</guid><description>&lt;p>上一篇，我们了解了提示词基本概念，本篇我们继续解读吴恩达老师的《ChatGPT Prompt Engineering for Developers》课程，看一下提示词常用技巧。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231108115607959.png" alt="image-20231108115607959">&lt;/p>
&lt;h1 id="1技巧构建合理的提示词结构">1.技巧：构建合理的提示词结构&lt;/h1>
&lt;p>完整的提示词包含以下四个要素：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>要素&lt;/th>
&lt;th>说明&lt;/th>
&lt;th>举例&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>指令词&lt;/strong>&lt;/td>
&lt;td>想要模型执行的特定任务或指令&lt;/td>
&lt;td>如：翻译、总结、生成&amp;hellip;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>背景(上下文)&lt;/strong>&lt;/td>
&lt;td>包含外部信息或额外的上下文信息，引导语言模型更好地响应&lt;/td>
&lt;td>如：“在人工智能领域”, “在医学领域”&amp;hellip;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>输入&lt;/strong>&lt;/td>
&lt;td>用户输入的内容或问题&lt;/td>
&lt;td>如：需要总结的文章&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>输出要求&lt;/strong>&lt;/td>
&lt;td>指定输出的类型或格式&lt;/td>
&lt;td>如：以JSON格式输出&amp;hellip;&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;font color=red>**注意：**提示词结构取决于您的任务类型，并非所有以上要素都是必须的。&lt;/font>&lt;/p>
&lt;h1 id="2技巧设定角色">2.技巧：设定角色&lt;/h1>
&lt;h2 id="1设定llm的角色">(1)设定LLM的角色&lt;/h2>
&lt;p>在提示词中设定LLM角色，&lt;strong>让模型进行角色扮演&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>直接提问&lt;/strong>，ChatGPT返回的答案较笼统，没有针对性。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110154844353.png" alt="image-20231110154844353">&lt;/p>
&lt;ul>
&lt;li>在提示词中&lt;strong>让LLM角色扮演&lt;/strong>，ChatGPT再次返回的答案就会出现医学领域的专有名词和专业指导。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110155206497.png" alt="image-20231110155206497">&lt;/p>
&lt;h2 id="2设定提问者的角色">(2)设定提问者的角色&lt;/h2>
&lt;p>除了让大语言模型进行角色扮演，还可以设定提问者的角色，为不同的提问对象生成定制化的答案。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>设定提问者的角色是一位百岁老人&lt;/strong>，ChatGPT的回答会考虑到老人的身体状况。(PS：百岁老人你都敢建议他去跑马拉松&amp;hellip;)&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110155639302.png" alt="image-20231110155639302">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>设定提问者的角色是缺乏运动的程序员&lt;/strong>，ChatGPT的回答会提醒程序员循序渐进。(PS：这个缺乏运动的程序员就是我&amp;hellip;)&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110155824839.png" alt="image-20231110155824839">&lt;/p>
&lt;h1 id="3技巧分隔符划分指令和内容">3.技巧：分隔符划分指令和内容&lt;/h1>
&lt;p>如果提示词包含2个要素：&lt;strong>指令词&lt;/strong>和&lt;strong>输入&lt;/strong>，那么我们如何让大语言模型知道哪些是&lt;strong>指令词&lt;/strong>，哪些是&lt;strong>输入&lt;/strong>？&lt;/p>
&lt;ul>
&lt;li>我们可以&lt;strong>使用分隔符&lt;/strong>(如```、&amp;quot;&amp;quot;&amp;quot;、&amp;lt;&amp;gt;等)区分&lt;strong>指令&lt;/strong>和待处理的&lt;strong>输入&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>看一个例子：&lt;/p>
&lt;ul>
&lt;li>我们不是想大语言模型给100岁老人参加马拉松的建议，而是希望将这段文字翻译为英文——我们可以通过&lt;code>&amp;quot;&amp;quot;&amp;quot;&lt;/code>，&lt;strong>区分出指令和输入&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110160402261.png" alt="">&lt;/p>
&lt;h1 id="4技巧指定文本判断条件">4.技巧：指定文本判断条件&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>在提示词中&lt;strong>指定文本判断条件&lt;/strong>，激发大语言模型对文字的分类能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>示例：在本示例中，激发了大语言模型对**&amp;ldquo;是否为指令&amp;rdquo;**的分类能力。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110161203289.png" alt="image-20231110161203289">&lt;/p>
&lt;h1 id="5技巧指定输出的格式">5.技巧：指定输出的格式&lt;/h1>
&lt;ul>
&lt;li>在提示词中&lt;strong>指定输出答案的格式&lt;/strong>，便于应用软件系统获得答案后的文本处理。&lt;/li>
&lt;li>示例：在本示例中，ChatGPT按照提示词中设定的JSON格式返回了答案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110163709627.png" alt="image-20231110163709627">&lt;/p>
&lt;h1 id="6-技巧few-shot">6. 技巧：Few-Shot&lt;/h1>
&lt;ul>
&lt;li>在提示词中，给出&lt;strong>一些示例的问答&lt;/strong>，可能&lt;strong>激发大语言模型的模仿能力&lt;/strong>。&lt;/li>
&lt;li>根据给出的示例问答的数量，可分为：
&lt;ul>
&lt;li>
&lt;p>&lt;strong>zero-shot&lt;/strong>：零样本提示。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>one-shot&lt;/strong>：单样本提示。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>few-shot&lt;/strong>：少样本提示。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>我们来看一个示例：&lt;/p>
&lt;ul>
&lt;li>直接问大语言模型问题，属于&lt;strong>zero-shot&lt;/strong>，大语言模型的答案风格比较自由。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110162842622.png" alt="image-20231110162842622">&lt;/p>
&lt;ul>
&lt;li>问大语言模型的同时，给出了老师、学生的一个问答对，属于&lt;strong>one-shot&lt;/strong>，大语言模型的答案风格就会&lt;strong>大致模仿&lt;/strong>一下示例问答对的风格。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110163038324.png" alt="image-20231110163038324">&lt;/p>
&lt;ul>
&lt;li>问大语言模型的同时，给出了老师、学生的多个问答对，属于&lt;strong>few-shot&lt;/strong>，大语言模型的答案风格就会&lt;strong>模仿&lt;/strong>示例问答对的风格及&lt;strong>老师的情绪&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110163115561.png" alt="image-20231110163115561">&lt;/p>
&lt;h1 id="7技巧cot">7.技巧：CoT&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>CoT&lt;/strong>：Chain of Thought，思维链。AI科学家在研究中发现，只需要在提示词最后增加一句话——&amp;ldquo;让我们一步一步思考&amp;rdquo;，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>我们看一下示例：我们的提问是大语言模型目前的短板能力(数学问题)，在没有任何提示的情况下，答案是错的。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110165008611.png" alt="image-20231110165008611">&lt;/p>
&lt;ul>
&lt;li>我们加上这句神奇的咒语——&lt;code>Let's think step by step.&lt;/code>，ChatGPT就可以回答正确了。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110165440078.png" alt="image-20231110165440078">&lt;/p>
&lt;h1 id="8技巧自洽self-consistency">8.技巧：自洽(SELF-CONSISTENCY)&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>Self-Consistency&lt;/strong>：自洽，即推理过程中，用多种推理路径得到结果，出现最大的答案大概率就是正确答案，从而体现了&lt;strong>自洽性&lt;/strong>。&lt;/li>
&lt;li>随着大语言模型能力日益增强，Self-Consistency已成为大语言模型的内部能力，需要多次实验才能观测到自洽的推理过程。&lt;/li>
&lt;li>我们来看一个例子：通过CoT，激发大语言模型推理思考，从它的回答中，可以看出大语言模型的推理过程产生了多种不同推理路径及答案，最终大语言模型自行选择了一个自洽的回答。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110170209475.png" alt="image-20231110170209475">&lt;/p>
&lt;h1 id="9小结">9.小结&lt;/h1>
&lt;p>本文阐述了多种提示词常用技巧，实战中需要综合应用上述技巧，根据场景激发大语言模型的不同能力：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>技巧1：构建合理的提示词结构&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧2：设定角色&lt;/strong>，设定LLM角色、设定提问者角色。&lt;/li>
&lt;li>&lt;strong>技巧3：分隔符划分指令和内容&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧4：指定文本判断条件&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧5：指定输出格式&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧6：Few-Shot。&lt;/strong>&lt;/li>
&lt;li>&lt;strong>技巧7：CoT&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧8：Self-Consistency&lt;/strong>。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记24-提示词解读1-提示词基本概念</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link><pubDate>Thu, 09 Nov 2023 15:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid><description>&lt;p>吴恩达老师的《ChatGPT Prompt Engineering for Developers》是一门学习提示词工程不错的课程，我们接下来用几篇文章来解读这门课程。&lt;/p>
&lt;h1 id="1什么是提示词工程">1.什么是提示词工程&lt;/h1>
&lt;p>首先看1个问题：&lt;/p>
&lt;ul>
&lt;li>向大语言模型输入&amp;quot;一二三四五&amp;rdquo;，它很可能回答&amp;quot;上山打老虎&amp;rdquo;。但，我们的意图是希望它把&amp;quot;一二三四五&amp;rdquo;&lt;strong>翻译成英文&lt;/strong>，怎么办？&lt;/li>
&lt;/ul>
&lt;p>我们的解决方法是：&lt;/p>
&lt;ul>
&lt;li>问大语言模型：&amp;ldquo;请将如下文字翻译为英文：一二三四五&amp;rdquo;，大语言模型就会回答&amp;quot;One Two Three Four Five&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;p>上述解决方法本质是什么呢？&lt;/p>
&lt;ul>
&lt;li>即在问题里明确表达&lt;strong>期望大语言模型如何处理&lt;/strong>一段文字。&lt;/li>
&lt;li>明确表达期望大语言模型做什么，就是一条指令，也就是&lt;strong>提示词&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>提示词理论的出现，源于两个假设：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>假设1&lt;/strong>：大语言模型已经掌握了很多世界知识，但由于知道的太多，一时想不起来。&lt;/li>
&lt;li>&lt;strong>假设2&lt;/strong>：自然语言存在二义性，需要更多的提示，才能准确地向大语言模型表达人类的真实意图。&lt;/li>
&lt;/ul>
&lt;p>因此，人类通过提示词，可以唤起大语言模型对已有知识的记忆，也可以让大语言模型更加准确地理解人类意图。&lt;/p>
&lt;p>开发提示词、优化提示词的过程，被称为&lt;strong>提示词工程&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>提示词工程包含了诸多工程方法，如：设计有效的提示策略、优化提示词表达等。&lt;/li>
&lt;/ul>
&lt;p>伴随着大语言模型的发展，提示词工程也形成了一套体系化的工程方法。它成为AI领域的热点技术之一，是AI工程师的必备技能。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231110144405400.png" alt="From《Pre-train, Prompt, and Predict: A Systematic Survey ofPrompting Methods in Natural Language Processing》">&lt;/p>
&lt;h1 id="2提示词基本原则">2.提示词基本原则&lt;/h1>
&lt;h2 id="1原则1简洁明确">(1)原则1：简洁明确&lt;/h2>
&lt;p>假想两个人类在说话，两人的表达能力有限，词不达意、含糊其辞、鸡同鸭讲&amp;hellip;，最终就导致两人之间的沟通极其困难。&lt;/p>
&lt;p>与大语言模型交互，和人类交流类似，也需要简洁明确的同问，向大语言模型清晰表达意图。&lt;/p>
&lt;p>我们来看一个例子：&lt;/p>
&lt;ul>
&lt;li>我们让ChatGPT写一首诗，它以立冬为题生成一首诗：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231110145755795.png" alt="image-20231110145755795">&lt;/p>
&lt;ul>
&lt;li>如果我们希望这首诗是五言绝句，则进一步这样提问，可以看到ChatGPT生成了一首以立冬为题的五言绝句。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231110145923990.png" alt="image-20231110145923990">&lt;/p>
&lt;p>上述示例，可以看出：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>写一首诗&lt;/strong>是一条&lt;strong>简洁的指令&lt;/strong>。&lt;/li>
&lt;li>相较于写一首诗，&lt;strong>写一首五言绝句&lt;/strong>是一条更加&lt;strong>简洁明确的指令&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;h2 id="2原则2迭代式提示词开发">(2)原则2：迭代式提示词开发&lt;/h2>
&lt;p>我们要知道两个事实：&lt;/p>
&lt;ul>
&lt;li>没有可以适应所有场景的完美提示词，需要我们针对不同场景，开发不同的提示词。&lt;/li>
&lt;li>即使在一个很小的场景下存在完美提示词，我们也无法一次性就找到它。&lt;/li>
&lt;/ul>
&lt;p>针对某个场景，寻找提示词的过程，就是&lt;strong>迭代式提示词开发&lt;/strong>。&lt;/p>
&lt;p>迭代式提示词开发的过程如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：针对特定场景，设计初始提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将初始提示词传递给大语言模型，获得返回结果(&lt;code>Experimental result&lt;/code>)。&lt;/li>
&lt;li>&lt;strong>Error Analysis阶段&lt;/strong>：分析返回结果，思考改进提示词的方法，重新进入&lt;strong>Idea阶段&lt;/strong>，直到找到特定场景下的完美提示词。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108102255487.png" alt="From 吴恩达提示词课程">&lt;/p>
&lt;p>我们再来看一个示例：我们需要一段用于营销的产品介绍。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：针对产品介绍场景，设计初始提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将初始提示词传递给大语言模型，获得返回结果。可以看到ChatGPT返回了一段不错的文案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108110737288.png" alt="image-20231108110737288">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Error Analysis阶段&lt;/strong>：从上一步获得的ChatGPT文案内容太长，我们思考改进提示词的方法是进一步明确字数要求。&lt;/li>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：根据上一阶段的改进思路，编写改进后的提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将改进后的提示词传递给大语言模型，获得返回结果。可以看到ChatGPT返回了一段简短的文案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108110819852.png" alt="image-20231108110819852">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Error Analysis阶段&lt;/strong>：从上一步获得的ChatGPT文案没有突出要点，我们思考改进提示词的方法是限定明确要突出的关键点。&lt;/li>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：根据上一阶段的改进思路，编写改进后的提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将改进后的提示词传递给大语言模型，获得返回结果。可以看到ChatGPT返回了一段简短、要点突出的文案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108110848960.png" alt="image-20231108110848960">&lt;/p>
&lt;p>这就是&lt;strong>迭代式提示词开发&lt;/strong>的流程，核心要点是&lt;strong>多次迭代&lt;/strong>。&lt;/p>
&lt;h2 id="3原则3选择合适的提示词风格">(3)原则3：选择合适的提示词风格&lt;/h2>
&lt;p>提示词工程是一种&lt;code>Instruct-Tuning&lt;/code>技术，提示词的风格包含：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Prompt&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Instruction&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>初学者极易混淆这两种风格，我们来看一个例子：&lt;/p>
&lt;ul>
&lt;li>幼儿园老师希望引导小朋友唱歌，于是她说：在小小的花园里面挖呀挖呀挖&amp;hellip;，老师此时停顿下来并对小朋友投去了期待的目光，小朋友按耐不住激动的心情，接下句：种小小的种子开小小的花——这就是&lt;strong>Prompt(提示)&lt;/strong>。&lt;/li>
&lt;li>幼儿园老师希望小朋友背诵五言绝句，于是她说：请背诵《鹅鹅鹅》，小朋友在老师又一次期待的目光下，整齐划一地背诵出&amp;quot;鹅鹅鹅曲项向天歌&amp;hellip;&amp;quot;——这就是&lt;strong>Instruction(指令)&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>我们了解了提示词的两大风格后，就要针对不同场景、不同意图，选择不同的提示词风格。&lt;/p>
&lt;h1 id="4小结">4.小结&lt;/h1>
&lt;p>提示词工程是一项热门技术，本文对提示词工程基本概念进行了阐述：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>提示词工程是开发和优化提示词的过程&lt;/strong>，包括选择合适的提示词、设计有效的提示策略，以及优化提示词的表达方式等。&lt;/li>
&lt;li>提示词三个基本原则：
&lt;ul>
&lt;li>&lt;strong>简洁、明确&lt;/strong>&lt;/li>
&lt;li>&lt;strong>迭代式提示词开发&lt;/strong>&lt;/li>
&lt;li>&lt;strong>选择合适的提示词风格&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记23-让我们一起来翻译吴恩达LLM课程</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BEllm%E8%AF%BE%E7%A8%8B/</link><pubDate>Thu, 02 Nov 2023 15:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BEllm%E8%AF%BE%E7%A8%8B/</guid><description>&lt;p>哈喽小伙伴，我是小牛，初次见面，请多关照。&lt;/p>
&lt;p>最近跟着猴哥的学习笔记各种手撸GPT，理解了LLM原理。&lt;/p>
&lt;p>但我跟GPT的交情好像只停留在say hello的程度，说好的能替代“表哥”、“码农”、“ppt经理”的能力呢？&lt;/p>
&lt;p>然后chatGPT跟我说，有个叫吴恩达的大咖，有好几门神课，理论+实践，易学易懂，学会了就可以在职场上大放异彩。那还犹豫什么，卷！&lt;/p>
&lt;p>这些课程都是英文视频，为了方便学习，我们准备把它们翻译成中文。&lt;/p>
&lt;p>欢迎感兴趣的小伙伴们一起来翻译。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BELLM%E8%AF%BE%E7%A8%8B/image-20231102181630937.png" alt="image-20231102181630937">&lt;/p>
&lt;h1 id="1已翻译的课程">1.已翻译的课程&lt;/h1>
&lt;ul>
&lt;li>《提示词工程 by 吴恩达》：https://jherculesqz.gitbook.io/chatgpt-prompt-engineering-for-developers-1&lt;/li>
&lt;li>《LangChain by 吴恩达》：https://jherculesqz.gitbook.io/langchain-by-wu-en-da&lt;/li>
&lt;/ul>
&lt;h2 id="11提示词工程-by-吴恩达简介">1.1.《提示词工程 by 吴恩达》简介&lt;/h2>
&lt;p>GPT神器虽好，但要会用。本课程将介绍：&lt;/p>
&lt;ul>
&lt;li>如何构建清晰、明确的提示词，有哪些技巧&lt;/li>
&lt;li>如何通过提示词发掘大语言模型总结、推理、转换以及生成文本的能力&lt;/li>
&lt;li>动手做一个自己的聊天机器人&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BELLM%E8%AF%BE%E7%A8%8B/image-20231102181807030.png" alt="image-20231102181807030">&lt;/p>
&lt;h2 id="12langchain-by-吴恩达简介">1.2.《LangChain by 吴恩达》简介&lt;/h2>
&lt;p>LangChain是开发LLM应用的开发框架，是当红炸子鸡。本课程将介绍：&lt;/p>
&lt;ul>
&lt;li>什么是LangChain&lt;/li>
&lt;li>LangChain有哪些Chain&lt;/li>
&lt;li>如何用LangChain做聊天模型、QA问答系统&lt;/li>
&lt;li>如何用LangChain的agent功能使能大模型的推理能力&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BELLM%E8%AF%BE%E7%A8%8B/image-20231102181929184.png" alt="image-20231102181929184">&lt;/p>
&lt;h1 id="2待翻译的课程">2.待翻译的课程&lt;/h1>
&lt;p>我们已经计划翻译的课程、论文有：&lt;/p>
&lt;ul>
&lt;li>《Finetuning Large Language Models》&lt;/li>
&lt;li>《Attention Is All You Need》&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>如果小伙伴们对其它LLM相关的文献、课程感兴趣，欢迎后台联系我们。&lt;/p>
&lt;blockquote>
&lt;p>免责声明：我们的翻译出于对技术的执着和个人兴趣，开源免费，仅供个人学习，不得商用。&lt;/p>
&lt;/blockquote></description></item></channel></rss>