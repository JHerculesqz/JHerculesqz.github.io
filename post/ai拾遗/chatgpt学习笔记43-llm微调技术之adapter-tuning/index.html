<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>【chatGPT】学习笔记43-LLM微调技术之Adapter Tuning - 妙木山</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="猴王无敌"><meta name=description content="Adapter Tuning是LLM微调技术中一个重要的技术分支，于2019年由Google的Neil Houlsby等研究员提出。 Adapter Tuning方法证明了"><meta name=keywords content="Hugo,theme,jane"><meta name=generator content="Hugo 0.74.2"><link rel=canonical href=https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8Badapter-tuning/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.b3a8813c06e6d785beba22bf8264e174fa2cb3a396b22f9ba24e2c00c18aaf7f.css integrity="sha256-s6iBPAbm14W+uiK/gmThdPoss6OWsi+bok4sAMGKr38=" media=screen crossorigin=anonymous><meta property="og:title" content="【chatGPT】学习笔记43-LLM微调技术之Adapter Tuning"><meta property="og:description" content="Adapter Tuning是LLM微调技术中一个重要的技术分支，于2019年由Google的Neil Houlsby等研究员提出。 Adapter Tuning方法证明了"><meta property="og:type" content="article"><meta property="og:url" content="https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8Badapter-tuning/"><meta property="article:published_time" content="2024-03-22T10:00:59+08:00"><meta property="article:modified_time" content="2024-03-22T10:00:59+08:00"><meta itemprop=name content="【chatGPT】学习笔记43-LLM微调技术之Adapter Tuning"><meta itemprop=description content="Adapter Tuning是LLM微调技术中一个重要的技术分支，于2019年由Google的Neil Houlsby等研究员提出。 Adapter Tuning方法证明了"><meta itemprop=datePublished content="2024-03-22T10:00:59+08:00"><meta itemprop=dateModified content="2024-03-22T10:00:59+08:00"><meta itemprop=wordCount content="2416"><meta itemprop=keywords content="AI拾遗-chat GPT,"><meta name=twitter:card content="summary"><meta name=twitter:title content="【chatGPT】学习笔记43-LLM微调技术之Adapter Tuning"><meta name=twitter:description content="Adapter Tuning是LLM微调技术中一个重要的技术分支，于2019年由Google的Neil Houlsby等研究员提出。 Adapter Tuning方法证明了"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>妙木山</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/>首页</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/categories/>技术专栏</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/tags/>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/post/>全部文章</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/about/>关于</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>妙木山</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/>首页</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/categories/>技术专栏</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/post/>全部文章</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/about/>关于</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>【chatGPT】学习笔记43-LLM微调技术之Adapter Tuning</h1><div class=post-meta><time datetime=2024-03-22 class=post-time>2024-03-22</time><div class=post-category><a href=https://jherculesqz.github.io/categories/ai%E6%8B%BE%E9%81%97/>AI拾遗</a></div><span class=more-meta>约 2416 字</span>
<span class=more-meta>预计阅读 5 分钟</span>
<span id=busuanzi_container_page_pv>| 阅读 <span id=busuanzi_value_page_pv></span></span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#1abstract摘要>1.Abstract(摘要)</a></li><li><a href=#2introduction介绍>2.Introduction(介绍)</a></li><li><a href=#3adapter-tuning原理>3.Adapter Tuning(原理)</a></li><li><a href=#4experiments实验结果>4.Experiments(实验结果)</a></li><li><a href=#5总结>5.总结</a></li></ul></nav></div></div><div class=post-content><p><code>Adapter Tuning</code>是LLM微调技术中一个重要的技术分支，于2019年由Google的Neil Houlsby等研究员提出。</p><p><code>Adapter Tuning</code>方法证明了：微调<strong>少量参数</strong>即可获得与<strong>全参数微调</strong>接近的大模型性能。</p><p>本文解读Neil Houlsby的论文**《Parameter-Efficient Transfer Learning for NLP》**，与小伙伴们一起学习理解<code>Adapter Tuning</code>思想和方法。</p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BAdapterTuning/image-20240322130214258.png alt=image-20240322130214258></p><h1 id=1abstract摘要>1.Abstract(摘要)</h1><p>首先我们看一下论文摘要，快速理解论文的<strong>核心内容</strong>：</p><ul><li><p><strong>问题</strong>：基于迁移学习思想，需要针对特定的下游任务，对预训练模型进行<strong>全参数微调</strong>。但针对每个下游任务都要做一次全参数微调，<strong>成本高效率低</strong>。</p></li><li><p><strong>解决方案</strong>：论文提出的<code>Adapter Tuning</code>，是一种使用<strong><code>Adapter(适配器模块)</code></strong>进行迁移学习的方法。<strong><code>Adapter(适配器模块)</code></strong>仅需要微调少量参数，就可以支持不同的下游任务。</p></li><li><p><strong>实验效果</strong>：在<strong>GLUE基准测试</strong>中，用<strong><code>Adapter Tuning</code></strong>方法仅需在预训练模型基础上<strong>增加并微调3.6%的参数</strong>，即可达到BERT Transformer模型全参数微调的效果。</p></li></ul><p>通过上述摘要的内容，我们可以想象一下，在2019年绝大多数人还在采用全参数微调这种高成本方案时，<strong><code>Adapter Tuning</code></strong>仅需微调3.6%的少量参数，会产生多大的<strong>生产效率差异</strong>。</p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BAdapterTuning/image-20240322103351046.png alt=image-20240322103351046></p><h1 id=2introduction介绍>2.Introduction(介绍)</h1><ul><li><strong>背景技术1</strong>：<strong>基于特征的迁移和微调</strong>(<code>feature-based transfer and fine-tuning</code>)是迁移学习思想中的重要工程方法，它也是BERT模型的重要理论基础。论文中：<code>Fine-tuning involves copying the weights from a pre-trained network and tuning them on the downstream task</code>，表达了BERT模型的训练范式——复用1个BERT的预训练模型的参数(<strong>基于特征的迁移</strong>)，再针对不同下游任务进行微调(<strong>基于特征的微调</strong>)。</li><li><strong>背景技术2</strong>：历史上，已证明针对预训练模型的网络结构中的高层(<code>top layer</code>)进行<strong>基于特征的微调</strong>，相较于<strong>基于特征的全参数微调</strong>，更具有性价比。</li><li><strong>实验效果</strong>：对比<strong>Adapter Tuning</strong>、<strong>Top Layer Fine Tuing</strong>、<strong>Full Fine Tuning</strong>在多任务微调场景下的效果：<ul><li><strong>在小参数模型上的表现</strong>：<strong>Adapter Tuning</strong>可达到<strong>Full Fine Tuning</strong>的效果，<strong>Top Layer Fine Tuing</strong>达不到。</li><li><strong>在稳定性方面的表现</strong>：<strong>Adapter Tuning</strong>的训练效果很稳定，<strong>Top Layer Fine Tuing</strong>在小参数模型上波动大、只有在大参数模型上才能保证稳定的训练效果。</li><li><strong>在性价比方面的对比</strong>：<strong>Adapter Tuning</strong>可以微调少量参数，即可达到<strong>Full Fine Tuning</strong>的训练效果。</li></ul></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BAdapterTuning/image-20240322115129249.png alt=image-20240322115129249></p><ul><li><strong>Adapter Tuning的核心思想</strong>：<ul><li><strong>基于特征的迁移和微调</strong>的思想是将预训练模型抽象为<code>f(w)</code>，对下游任务微调抽象为<code>g(v, f(w))</code>，微调的过程是不断学习修改参数<code>w</code>和<code>v</code>，这样就导致预训练模型的参数<code>w</code>被修改，进而导致极高的训练成本。</li><li><strong>Adapter Tuning</strong>的思想是将预训练模型抽象为<code>f(w)</code>，对下游任务微调抽象为<code>g(v, w)</code>，微调的过程是不断学习修改参数<code>v</code>，直接复用预训练模型的参数<code>w</code>而不是修改它，又因为参数<code>v</code>的数量级远小于参数<code>w</code>，因此训练成本极低。另外，针对新的<code>下游任务n</code>只需要增加新的Adapter，训练对应的参数<code>vn</code>。</li><li><code>g(v, w)</code>的具体代码实现等效于，在原有预训练模型的网络结构中，插入一些<strong>Adapter层</strong>，预训练模型参数<code>w</code>作为Adapter层的入参，<strong>训练的目标是学习并修改Adapter层的参数<code>v</code></strong>。</li></ul></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BAdapterTuning/image-20240322120647325.png alt=image-20240322120647325></p><ul><li><strong>容易与Adapter Tuning混淆的其它训练方法</strong>：<ul><li><strong>多任务学习</strong>：multi-task learning，也会在预训练模型的网络结构中增加新层，最终也是修改了新层的参数。但多任务学习的训练，是将所有下游任务作为训练新层参数的输入。</li><li><strong>持续学习</strong>：contiuanl learning，是将N个下游任务组成任务流后逐一学习，这样就要求训练<code>任务m</code>时，预训练模型的网络结构能够记住之前已经训练过的<code>任务1~任务m-1</code>得到的参数。这将对预训练模型的记忆能力产生巨大的挑战。</li></ul></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BAdapterTuning/image-20240322122001309.png alt=image-20240322122001309></p><h1 id=3adapter-tuning原理>3.Adapter Tuning(原理)</h1><p>Adatper Tuning具体是如何实现的呢？论文中详细解释了Adapter层的网络结构，以及如何在原始的预训练模型上插入这些Adapter层：</p><ul><li><strong>Adapter层的插入位置</strong>：在Transformer的多头注意力+前馈网络层之后，2x前馈网络层之后，分别插入了<strong>Adapter层</strong>。另外，在每个Adapter层之后还插入了一个Layer Norm层。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BAdapterTuning/image-20240322124748365.png alt=image-20240322124748365></p><ul><li><strong>Adapter层的内部结构</strong>：Adapter层包含3层<ul><li><strong>前馈网络的向量降维层</strong>：用于将前一层预训练模型输出的高维向量，降维为低维向量。</li><li><strong>非线性处理层</strong>：对下游任务微调时，学习参数<code>v</code>。</li><li><strong>前馈网络的向量升维层</strong>：用于将Adapter层输出的低维向量，升维为高维向量。</li></ul></li><li><strong>Adapter层的参数数量计算公式</strong>：<code>count(v)=2md+d+m</code><ul><li><strong>d</strong>：前一层预训练模型输出的高维向量的维数。</li><li><strong>m</strong>：Adapter层降维后的低维向量维数。</li><li><strong>实践经验</strong>：当m远小于d时，Adapter层的参数量会很小。论文给出的经验数据是可以通过控制m的数值，将Adapter层的参数量控制为预训练大模型参数量的0.5%~8%。这样，可以精准控制微调成本。</li></ul></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BAdapterTuning/image-20240322124814661.png alt=image-20240322124814661></p><h1 id=4experiments实验结果>4.Experiments(实验结果)</h1><p>论文至此就一个实验结论：<strong>Adapter Tuning</strong>就是香，具体如下：</p><ul><li>在GLUE基准测试和其他17个公共文本分类任务上，适配器调优效果，优于全参数微调。</li><li>适配器调优在参数数量大幅减少的情况下，仍能保持与全参数微调相近的性能。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BAdapterTuning/image-20240322125615723.png alt=image-20240322125615723></p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B043-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BAdapterTuning/image-20240322125621882.png alt=image-20240322125621882></p><h1 id=5总结>5.总结</h1><p>从上述论文解读中，我们收获了如下技术观点：</p><ul><li><strong>Adapter Tuning的价值</strong>：追求微调少量参数，仍能达到全参数微调效果。</li><li><strong>Adapter Tuning的核心思想</strong>：增加一个新的小模型，微调小模型的少量参数，冻结预训练模型的海量参数。</li><li><strong>Adapter Tuning的具体实现</strong>：改变预训练模型的网络结构，通过高维向量到低维向量的转换，训练不同下游任务的Adapter层。</li></ul><p>论文链接：https://arxiv.org/pdf/1902.00751.pdf</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>猴王无敌</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2024-03-22</span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><div class=post-reward><input type=checkbox name=reward id=reward hidden>
<label class=reward-button for=reward>赞赏支持</label><div class=qr-code><label class=qr-code-image for=reward><img class=image src=/weixin.png>
<span>微信打赏</span></label>
<label class=qr-code-image for=reward><img class=image src=/alipay.png>
<span>支付宝打赏</span></label></div></div><footer class=post-footer><div class=post-tags></div><nav class=post-nav><a class=prev href=/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B044-llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8Bprefix-tuning/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">【chatGPT】学习笔记44-LLM微调技术之Prefix Tuning</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B042-llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/><span class="next-text nav-default">【chatGPT】学习笔记42-LLM微调技术概览</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=mailto:JHercules_qz@qq.com rel="me noopener" class=iconfont title=email><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408 1361.641813S1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523L83.726336 1024H682.532949 753.579947 1348.948139L1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955C777.248 802.205449 742.347691 811.03081 718.063616 811.603883z"/></svg></a><a href=https://github.com/JHerculesqz rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=https://jherculesqz.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2021 -
2024
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>猴王无敌</span></span>
<span id=busuanzi_container>访客数/访问量：<span id=busuanzi_value_site_uv></span>/<span id=busuanzi_value_site_pv></span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script><script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script><script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script><script type=text/javascript src=/js/load-photoswipe.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>