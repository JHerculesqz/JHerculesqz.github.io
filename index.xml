<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>妙木山</title><link>https://jherculesqz.github.io/</link><description>Recent content on 妙木山</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 24 Dec 2023 10:00:59 +0800</lastBuildDate><atom:link href="https://jherculesqz.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>关于</title><link>https://jherculesqz.github.io/about/</link><pubDate>Thu, 05 Aug 2021 13:01:37 +0800</pubDate><guid>https://jherculesqz.github.io/about/</guid><description>&lt;h1 id="关于博客">关于博客&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>独立&lt;/strong>：一直在写技术博客，从微信公众号、头条号、SegmentFault、掘金、简书一路折腾过来，还是希望有一个自己独立的空间。&lt;/li>
&lt;li>&lt;strong>坚持&lt;/strong>：随着年龄增长，逐渐欲说还休，还是文字更有韵味，希望自己能坚持写下去。&lt;/li>
&lt;li>&lt;strong>浪漫&lt;/strong>：按照&lt;a href="https://archiveprogram.github.com">Archive Program&lt;/a>计划的愿景，我的博客会在&amp;rdquo; GitHub北极代码库&amp;quot;中保存千年。想想1000年以后，我的后代们能读到我这个中二祖先的文字，还是一件挺浪漫的事儿。&lt;/li>
&lt;li>&lt;strong>感谢&lt;/strong>：感谢GitHub Pages、Hugo、Jane提供的技术支持。&lt;/li>
&lt;li>&lt;strong>妙木山&lt;/strong>：妙木山是修炼仙术的地方，作为火影的死忠粉，&amp;ldquo;妙木山&amp;quot;无比适合这个博客的定位——修炼、探索。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/about/MiaoMu.png" alt="MiaoMu">&lt;/p>
&lt;h1 id="关于我">关于我&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>行业&lt;/strong>：软件行业16年，无法用语言表达对编程的喜爱——举个栗子吧：有段时间喜欢在酒吧里写代码，同去的小伙伴无聊地陌陌上约人，自我介绍就是&amp;quot;A+吧台，旁边有个写代码的沙雕&amp;rdquo;。&lt;/li>
&lt;li>&lt;strong>技术方向&lt;/strong>：近几年痴迷语言和编译器技术，还有点痴迷计算机图形学。
&lt;ul>
&lt;li>&lt;strong>编程语言&lt;/strong>：目前工作Java和JavaScript用的最多，但我最喜欢C#——PHP是最好的语言，行了吧！&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>哲学&lt;/strong>：不知何时，开始期待理解生命的意义。东一本西一本的书拿来乱翻，也没找到答案。不过，也不是全无收获——能模模糊糊地体会诗词的意境、能回味出毛选的奇妙、能敬畏金刚经的高深……继续求索吧……&lt;/li>
&lt;li>&lt;strong>兴趣&lt;/strong>：年轻的时候，喜欢轮滑、滑板、快乐肥仔水。现在，喜欢滑雪、乒乓球、茶(特指正山小种)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/about/Me.png" alt="Me">&lt;/p></description></item><item><title>【chatGPT】学习笔记34-Show一下我们的语音克隆技术</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B034-show%E4%B8%80%E4%B8%8B%E6%88%91%E4%BB%AC%E7%9A%84%E8%AF%AD%E9%9F%B3%E5%85%8B%E9%9A%86%E6%8A%80%E6%9C%AF/</link><pubDate>Sun, 24 Dec 2023 10:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B034-show%E4%B8%80%E4%B8%8B%E6%88%91%E4%BB%AC%E7%9A%84%E8%AF%AD%E9%9F%B3%E5%85%8B%E9%9A%86%E6%8A%80%E6%9C%AF/</guid><description>&lt;p>小刚刚同学是小伙伴中的TTS专家，他训练的语音克隆模型已经初见雏形，口音、语速、情绪都还不错。&lt;/p>
&lt;p>小刚刚的AI模型克隆了他自己的声音之后为我们念出了如下文章，听到人工智能的声音，激动且开心，为小刚刚的AI儿子点赞！&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>这是AI的念稿的声音&lt;/strong>：&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>如下为AI念的稿件&lt;/strong>：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>接下来，我给大家介绍一下TTS原理：&lt;/p>
&lt;h2 id="1-引言">1. 引言&lt;/h2>
&lt;p>文字到语音（TTS，Text-to-Speech）技术是将人类语言文本转换为人类语音输出的技术。随着人工智能、自然语言处理等技术的快速发展，TTS技术在智能语音助手、虚拟主播、教育、娱乐等领域得到了广泛应用。本文将介绍TTS技术的原理及其发展历程，并探讨其在未来的发展趋势。&lt;/p>
&lt;h2 id="2-tts原理">2. TTS原理&lt;/h2>
&lt;h3 id="21-语音合成">2.1 语音合成&lt;/h3>
&lt;p>语音合成是将文本转换为语音的过程，主要包括以下几个步骤：&lt;/p>
&lt;ol>
&lt;li>音素到状态的转换：将输入的音素序列转换为声道状态序列。&lt;/li>
&lt;li>声道状态到声码元的转换：将声道状态序列转换为声码元序列。&lt;/li>
&lt;li>声码元到语音的转换：将声码元序列转换为语音信号。&lt;/li>
&lt;/ol>
&lt;h3 id="22-语音合成模型">2.2 语音合成模型&lt;/h3>
&lt;p>目前主流的语音合成模型主要包括以下几种：&lt;/p>
&lt;ol>
&lt;li>参数模型：将语音合成看作是一个参数估计问题，通过训练模型来获得参数值。&lt;/li>
&lt;li>统计模型：基于统计学原理，通过概率模型来生成语音。&lt;/li>
&lt;li>深度学习模型：利用深度神经网络模型进行语音合成。&lt;/li>
&lt;/ol>
&lt;h3 id="23-声学模型">2.3 声学模型&lt;/h3>
&lt;p>声学模型是TTS技术中的关键部分，其主要任务是模拟人类听觉系统，通过声学模型可以计算出每个音素的声学特征，并将其用于语音合成。目前主流的声学模型包括线性预测编码（LPC）、高斯混合模型（GMM）等。&lt;/p>
&lt;h2 id="3-tts发展历程">3. TTS发展历程&lt;/h2>
&lt;p>TTS技术的发展历程可以分为以下几个阶段：&lt;/p>
&lt;ol>
&lt;li>基于规则的方法：早期的TTS技术采用基于规则的方法，通过手动设计规则来生成语音。&lt;/li>
&lt;li>基于模板的方法：基于模板的方法通过预先定义的语音模板来生成语音，效率较低。&lt;/li>
&lt;li>基于统计的方法：基于统计的方法采用概率模型来生成语音，效果较好，但需要大量的训练数据。&lt;/li>
&lt;li>基于深度学习的方法：基于深度学习的方法利用神经网络模型进行语音合成，效果最好，但需要大量的训练数据和计算资源。&lt;/li>
&lt;/ol>
&lt;h2 id="4-tts未来发展趋势">4. TTS未来发展趋势&lt;/h2>
&lt;p>随着人工智能、自然语言处理等技术的不断发展，TTS技术在未来将会呈现出以下发展趋势：&lt;/p>
&lt;ol>
&lt;li>更高的语音质量：通过改进声学模型和语音合成算法，提高语音质量。&lt;/li>
&lt;li>更自然的发音：通过改进语音合成算法，使生成的语音更加自然。&lt;/li>
&lt;li>更丰富的语言支持：通过扩大语言模型和语音合成模型的训练数据集，支持更多的语言。&lt;/li>
&lt;li>更广泛的应用：通过改进TTS技术，使其在更多的领域得到应用，如智能客服、智能家居等。&lt;/li>
&lt;/ol>
&lt;h2 id="5-结论">5. 结论&lt;/h2>
&lt;p>TTS技术是将文本转换为语音的技术，其原理主要包括语音合成、语音合成模型、声学模型等。随着人工智能、自然语言处理等技术的不断发展，TTS技术在未来将会呈现出更高的语音质量、更自然的发音、更丰富的语言支持和更广泛的应用等特点。&lt;/p></description></item><item><title>【chatGPT】学习笔记33-LangChain解读-LCEL语言之基础语法(2)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%952/</link><pubDate>Sat, 23 Dec 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%952/</guid><description>&lt;p>LCEL让我们可以用&lt;code>|&lt;/code>管道符把不同的组件或链组合起来，这都得益于这些组件都实现了Runnable接口。&lt;/p>
&lt;p>本篇我们就带着Runnable的概念继续学习下LCEL的基础用法。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231222104906413.png" alt="image-20231222104906413">&lt;/p>
&lt;h1 id="1-lcel核心接口runnable">1. LCEL核心接口Runnable&lt;/h1>
&lt;h2 id="1runnable接口">(1)Runnable接口&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Langchain定义了“Runnable”协议，协议中实现了一系列方法，比如对管道运算符&lt;code>|&lt;/code>的支持、invoke方法等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这里介绍下Runnable定义的一组标准调用接口（其中后三个是前面三个异步方式）：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#stream">&lt;code>stream&lt;/code>&lt;/a>：流式输出&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#invoke">&lt;code>invoke&lt;/code>&lt;/a>：基于单一输入调用链&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#batch">&lt;code>batch&lt;/code>&lt;/a>：基于列表输入调用链&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#async-stream">&lt;code>astream&lt;/code>&lt;/a>：异步流式输出&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#async-invoke">&lt;code>ainvoke&lt;/code>&lt;/a>：基于单一输入异步调用链&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://python.langchain.com/docs/expression_language/interface#async-batch">&lt;code>abatch&lt;/code>&lt;/a>：基于列表输入异步调用链&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>LangChain的很多组件(对象)都应用了Runnable协议，可以把他们称为Runnable对象，这些对象都实现了上述接口，因此这些对象组成的链也都支持上述调用方法。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="2常用runnable对象的输入输出类型">(2)常用Runnable对象的输入输出类型&lt;/h2>
&lt;p>LCEL中使用&lt;code>|&lt;/code>将前一个Runnable对象的输出传递给下一个Runnable对象作为输入，因此需要保证管道两端的型号一致。&lt;/p>
&lt;p>LangChain常用组件的输入、输出数据类型如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>组件&lt;/strong>&lt;/th>
&lt;th>&lt;strong>输入类型&lt;/strong>&lt;/th>
&lt;th>&lt;strong>输出类型&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Prompt (提示词)&lt;/td>
&lt;td>字典&lt;/td>
&lt;td>PromptValue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ChatModel (聊天模型)&lt;/td>
&lt;td>单个字符串、聊天消息列表或 PromptValue&lt;/td>
&lt;td>ChatMessage&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>LLM (非聊天模型)&lt;/td>
&lt;td>单个字符串、聊天消息列表或 PromptValue&lt;/td>
&lt;td>String&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OutputParser (输出解析器)&lt;/td>
&lt;td>LLM 或 ChatModel 的输出&lt;/td>
&lt;td>取决于解析器&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Retriever (检索器 )&lt;/td>
&lt;td>单个字符串&lt;/td>
&lt;td>文档清单&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Tool (工具)&lt;/td>
&lt;td>单个字符串或字典，具体取决于工具&lt;/td>
&lt;td>取决于工具&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="3-runnablepassthrough在管道中的作用">(3) RunnablePassthrough在管道中的作用&lt;/h2>
&lt;p>在使用LCEL构建链时，原始用户输入可能不仅要传给第一个组件，还要传给后续组件，这时可以用RunnablePassthrough。RunnablePassthrough可以透传用户输入。&lt;/p>
&lt;h1 id="2快速上手">2.快速上手&lt;/h1>
&lt;p>下面我们通过一个包含4个组件的RAG检索链来再次体验LCEL的便捷。&lt;/p>
&lt;p>示例场景是基于给定的文本回答用户问题。&lt;/p>
&lt;h2 id="step1环境准备">STEP1.环境准备&lt;/h2>
&lt;ul>
&lt;li>注意：由于示例的是检索本地文本，所以安装了向量数据库及其所需的库。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223004634709.png" alt="image-20231223004634709">&lt;/p>
&lt;h2 id="step2构建检索器组件">STEP2.构建检索器组件&lt;/h2>
&lt;ul>
&lt;li>为方便演示，本地文本简单的放一句话：”大鱼吃小鱼，小鱼吃虾米“。&lt;/li>
&lt;li>用langchain的检索器&lt;code>as_retriever&lt;/code>，它可以根据输入查询向量库并返回相关文本。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223005234058.png" alt="image-20231223005234058">&lt;/p>
&lt;h2 id="step3构建prompt提示词组件">STEP3.构建Prompt提示词组件&lt;/h2>
&lt;ul>
&lt;li>提示词设计的是根据给定的文字回答问题。&lt;/li>
&lt;li>提示词中共2个变量：&lt;code>question&lt;/code>用来接收用户问题，&lt;code>context&lt;/code>来接收检索器的查询结果。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223010525145.png" alt="image-20231223010525145">&lt;/p>
&lt;h2 id="step4构建llm组件">STEP4.构建llm组件&lt;/h2>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223011307090.png" alt="image-20231223011307090">&lt;/p>
&lt;h2 id="step5组合成链">STEP5.组合成链&lt;/h2>
&lt;ul>
&lt;li>把检索器、提示词、模型、输出解析器四个组件串起来，命名为检索链&lt;code>retrieval_chain&lt;/code>。&lt;/li>
&lt;li>这一步注意两点：
&lt;ul>
&lt;li>用户输入的问题，不止组件1的检索器要用，组件2也要用它来构建提示词，因此组件1使用RunnablePassthrough方法把原始输入透传给下一步。&lt;/li>
&lt;li>由于组件2 prompt的输入要求是字典类型，所以组件1把检索器和用户问题写成字典格式，并用组件2的变量作为键。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223011350292.png" alt="image-20231223011350292">&lt;/p>
&lt;h2 id="step6运行链">STEP6.运行链&lt;/h2>
&lt;ul>
&lt;li>传入用户问题，得到期望结果。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(2)/image-20231223011640703.png" alt="image-20231223011640703">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文解读了LangChain LCEL及其Runnable基础语法，关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Runnable接口&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Runnable是Langchain表达式语言的核心接口&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Runnable提供了一组标准调用接口：stream、invoke、batch及对应的异步方法。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Langchain很多组件都遵循Runnable协议，因此可以方便的组合、调用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>常用Runnable对象的输入输出类型要求，用管道&lt;code>|&lt;/code>方式组合时需注意管道两端的类型一致。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RunnablePassthrough在管道中的作用。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>构建了包含四个组件的检索链。&lt;/li>
&lt;li>通过实操关注了管道前后数据类型的匹配、RunnablePassthrough的作用。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>参考文档：翻译的LangChain官方文档&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记32-LangChain解读-LCEL语言之基础语法(1)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%951/</link><pubDate>Wed, 13 Dec 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-langchain%E8%A7%A3%E8%AF%BB-lcel%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%951/</guid><description>&lt;p>在《【chatGPT】学习笔记29-LangChain解读1-快速入门》中，我们学习了LangChain的入门文档，了解到LangChain的模块化组件和链让开发LLM应用变得简单。&lt;/p>
&lt;p>同时，LangChain还推出了自己的语法——LCEL(LangChain表达式语言)，让复杂的组合链变得更简单。&lt;/p>
&lt;p>本篇我们跟着官方文档来学习LCEL的概念及如何使用。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(1)/image-20231208175706824.png" alt="image-20231208175706824">&lt;/p>
&lt;h1 id="1-lcel概览">1. LCEL概览&lt;/h1>
&lt;h2 id="1什么是lcel">(1)什么是LCEL&lt;/h2>
&lt;p>LCEL是LangChain表达式语言(LangChain Expression Language)的缩写，是LangChain官方推出的一种新的语法，它提供了一种声明式的方法(而不是编写普通代码)来组合链，简化了构建复杂LLM应用的过程。&lt;/p>
&lt;h2 id="2为什么要用lcel">(2)为什么要用LCEL&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>声明式编程&lt;/strong>：由于LLM强大的理解和生成能力，LLM应用开发侧重业务逻辑的编排，LCEL提供的声明式编程方法让这类操作更高效。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>统一接口&lt;/strong>：LCEL中实现了“Runnable”协议，每个LCEL 对象都应用了“Runnable”接口。&lt;/p>
&lt;ul>
&lt;li>该接口定义了一组通用的调用方法（&lt;code>invoke&lt;/code>、&lt;code>batch&lt;/code>、&lt;code>stream&lt;/code>、&lt;code>ainvoke&lt;/code>&amp;hellip;），因此采用LCEL构建的任何链都将自动支持流、同步、异步和批处理等能力。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>组合原语&lt;/strong>：LCEL 提供了许多原语，可以轻松组合链、并行化组件、添加回退、动态配置链内部等。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>为了更好地理解 LCEL，我们将分期介绍这些能力和实际应用效果。本篇我们先从看看如何用LCEL的声明式方法来组合业务组件和链。&lt;/p>
&lt;h1 id="2快速上手lcel">2.快速上手LCEL&lt;/h1>
&lt;p>以让LLM生成文本为例，来看看如何使用LCEL来完成任务。&lt;/p>
&lt;blockquote>
&lt;p>环境准备请参考《【chatGPT】学习笔记29-LangChain解读1-快速入门》。&lt;/p>
&lt;/blockquote>
&lt;h2 id="step1构造三组件">STEP1.构造三组件&lt;/h2>
&lt;p>我们在LangChain快速入门中学习过，一个常见的链包括三个组件：&lt;strong>提示词模板、模型、输出解析器&lt;/strong>。&lt;/p>
&lt;p>使用LangChain的方法构建如下——任务是给某个人或物写一句表扬的话：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(1)/image-20231210112756607.png" alt="image-20231210112756607">&lt;/p>
&lt;h2 id="step2构建自定义链">STEP2.构建自定义链&lt;/h2>
&lt;p>使用LCEL语法，用上面的3个组件组合成链，代码如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(1)/image-20231210113216116.png" alt="image-20231210113216116">&lt;/p>
&lt;p>你会发现，LCEL用&lt;code>|&lt;/code>把不同组件链接在一起，该符号类似于unix的管道运算符，将一个组件的输出作为下一个组件的输入。&lt;/p>
&lt;h2 id="step3调用链">STEP3.调用链&lt;/h2>
&lt;p>LCEL这种表达式方法是有效呢，我们调用一下看看。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-LangChain%E8%A7%A3%E8%AF%BB-LCEL%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95(1)/image-20231210113642196.png" alt="image-20231210113642196">&lt;/p>
&lt;p>让链工作的方法也很简单，使用&lt;code>Runnable&lt;/code>接口的&lt;code>invoke&lt;/code>方法，传入主题字符串，任务就完成了。&lt;/p>
&lt;p>从上面的示例，我们可以看到LCEL的运作流程如下：&lt;/p>
&lt;ul>
&lt;li>传入用户输入，为提示词模板中的变量赋值。本例中是山姆奥特曼，则格式为{&amp;ldquo;topic&amp;rdquo;: &amp;ldquo;山姆奥特曼&amp;rdquo;}。&lt;/li>
&lt;li>&lt;code>prompt&lt;/code>获取用户输入，并使用&amp;quot;topic&amp;quot;构建提示词。&lt;/li>
&lt;li>&lt;code>model&lt;/code>组件拿到生成的提示词，并传递给LLM模型进行处理。模型生成的输出是一个&lt;code>ChatMessage&lt;/code>对象。&lt;/li>
&lt;li>最后，&lt;code>output_parser&lt;/code>组件接收&lt;code>ChatMessage&lt;/code>并将其转换为 Python 字符串，该字符串通过 invoke 方法返回。&lt;/li>
&lt;/ul>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文解读了LangChain官方文档的“LangChain Expression Language (LCEL)”的部分章节，关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>LCEL概览&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>LCEL是LangChain官方推出的一种声明式编程语法，让构建复杂LLM应用变得更简单。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LCEL的主要价值点：&lt;/p>
&lt;ul>
&lt;li>声明式编程方法，便于组件和链的编排。&lt;/li>
&lt;li>统一接口，每个LCEL 对象都应用了“Runnable”接口。&lt;/li>
&lt;li>组合原语。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>构造链的组件。&lt;/li>
&lt;li>LCEL使用&lt;code>|&lt;/code>把不同的组件组合成链。&lt;/li>
&lt;li>使用invoke方法调用链，完成任务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>参考文档：翻译的LangChain官方文档&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记31-提示词解读6-实战案例之扩展</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/</link><pubDate>Sun, 03 Dec 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/</guid><description>&lt;p>LLM可以帮忙写文案、写剧本、写论文？相信很多小伙伴当初都是被LLM的这个爆裂功能路转粉的。&lt;/p>
&lt;p>这种文本生成的能力——通常也被叫做AIGC(人工智能生成内容)，就是LLM的扩展能力。&lt;/p>
&lt;p>本篇我们跟着吴恩达老师的课程，学习如何激发LLM这个最受欢迎的能力——扩展(&lt;code>Expanding&lt;/code>)。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95//image-20231130080342036.png" alt="image-20231130080342036">&lt;/p>
&lt;h1 id="1激发扩展能力的提示词">1.激发扩展能力的提示词&lt;/h1>
&lt;h2 id="1什么是llm的扩展能力">(1)什么是LLM的扩展能力&lt;/h2>
&lt;p>LLM的扩展能力是指&lt;strong>基于一小段文字或指令或主题，让LLM生成连贯、有逻辑的长文本&lt;/strong>。&lt;/p>
&lt;p>LLM的扩展能力使得LLM可以生成更长、更丰富的文本，可以用在很多创作类的工作：&lt;/p>
&lt;ul>
&lt;li>写营销文案&lt;/li>
&lt;li>写工作报告&lt;/li>
&lt;li>创意策划(Brainstorming)&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;h2 id="2如何激发llm的扩展能力">(2)如何激发LLM的扩展能力&lt;/h2>
&lt;p>我们可以这样构建提示词：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>明确的指令词&lt;/strong>，让LLM知道是写文章还是出点子，如&amp;quot;请&lt;strong>撰写&lt;/strong>&amp;hellip;&amp;quot;，&amp;ldquo;请&lt;strong>设计&lt;/strong>&amp;hellip;&amp;quot;。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>明确的内容要求&lt;/strong>，如&amp;quot;以xxx&lt;strong>为主题&lt;/strong>&amp;quot;，&amp;ldquo;涵盖xxx&lt;strong>内容要点&lt;/strong>&amp;quot;，&amp;ldquo;针对xxx&lt;strong>举个例子&lt;/strong>&amp;quot;，&amp;ldquo;用新潮有趣的&lt;strong>文字风格&lt;/strong>&amp;quot;。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>提供背景信息&lt;/strong>，让LLM更好的模拟语境。如&amp;quot;你是个童话大王&amp;rdquo;，&amp;ldquo;这是给总裁的汇报材料&amp;rdquo;。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="2实战案例">2.实战案例&lt;/h1>
&lt;p>笔者最近在研究Java编程语言的面试题，要针对一些难度大的面试题编写案例解析。&lt;/p>
&lt;p>以下面这道面试题为例，用LLM的扩展能力来帮忙：&lt;/p>
&lt;ul>
&lt;li>制定提纲&lt;/li>
&lt;li>生成文章内容&lt;/li>
&lt;li>优化部分章节&lt;/li>
&lt;/ul>
&lt;p>面试题如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">以下有关垃圾收集器&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">说法正确的有&lt;/span>&lt;span class="err">：（&lt;/span> &lt;span class="err">）&lt;/span>
&lt;span class="n">A&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="n">ParNew收集器支持多线程垃圾收集&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">所以不会回收停顿&lt;/span>&lt;span class="err">。&lt;/span>&lt;span class="n">当老年代选择CMS收集器后&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">新生代智能选择Serial或ParNew收集器&lt;/span>&lt;span class="err">。&lt;/span>
&lt;span class="n">B&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="n">Parallel&lt;/span> &lt;span class="n">Scavenge收集器是一个新生代收集器&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">其目标是达到一个可控的吞吐量&lt;/span>&lt;span class="err">。&lt;/span>&lt;span class="n">MaxGCPauseMillis参数值设置越小&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">系统垃圾手机速度越快&lt;/span>&lt;span class="err">。&lt;/span>
&lt;span class="n">C&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="n">CMS收集器出生标记和重新标记阶段均需要停顿&lt;/span>&lt;span class="err">。&lt;/span>&lt;span class="n">CMS收集器若出现Concurrent&lt;/span> &lt;span class="n">Mode&lt;/span> &lt;span class="n">Failure&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="n">虚拟机就会启动Serial&lt;/span> &lt;span class="n">Old收集器进行垃圾回收&lt;/span>&lt;span class="err">。&lt;/span>
&lt;span class="n">D&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="n">G1收集器可用于新生代和老年代的垃圾回收&lt;/span>&lt;span class="err">。&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="step1制定提纲">STEP1.制定提纲&lt;/h2>
&lt;p>画虎先画骨。先跟LLM头脑风暴一下，把案例提纲定下来。&lt;/p>
&lt;p>让LLM生成题目解析案例的提纲。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231203161432017.png" alt="image-20231203161432017">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231203160613178.png" alt="image-20231203160613178">&lt;/p>
&lt;p>LLM给出了一个相对全面的目录结构，结合LLM带来的灵感，最终目录确定如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>1.题目描述&lt;/strong>：描述Java面试题原文&lt;/li>
&lt;li>&lt;strong>2.题目解析&lt;/strong>：对每个选项进行分析，说明是否是正确答案&lt;/li>
&lt;li>&lt;strong>3.知识点解读&lt;/strong>：列出该Java试题涉及的知识点，并做解读&lt;/li>
&lt;li>&lt;strong>4.知识点总结&lt;/strong>：对知识点做总结，说明用途和错误影响&lt;/li>
&lt;li>&lt;strong>5.推荐学习资料&lt;/strong>：该知识点相关的学习资料&lt;/li>
&lt;/ul>
&lt;h2 id="step2生成文章内容">STEP2.生成文章内容&lt;/h2>
&lt;p>接着让LLM根据目录提纲生成案例主体内容。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231203161448434.png" alt="image-20231203161448434">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231201200439022.png" alt="image-20231201200439022">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231201232902361.png" alt="image-20231201232902361">&lt;/p>
&lt;p>LLM根据提纲很好的生成了案例内容，对试题四个选项的解析、正确答案的识别也很到位。&lt;/p>
&lt;h2 id="step3优化部分章节">STEP3.优化部分章节&lt;/h2>
&lt;p>知识点解读是重点章节，增加一些示例可以帮助读者更好的理解。&lt;/p>
&lt;p>所以，让LLM帮忙优化知识点解读章节的内容，增加代码示例：&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231201233451643.png" alt="image-20231201233451643">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB6-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%A9%E5%B1%95/image-20231201233557314.png" alt="image-20231201233557314">&lt;/p>
&lt;p>LLM不仅精通自然语言，同时也是个编程语言专家，所以生成代码示例的任务也很轻松的完成了。&lt;/p>
&lt;h2 id="step4编写正式文稿">STEP4.编写正式文稿&lt;/h2>
&lt;p>LLM已经帮忙完成了文稿内容的生成和优化，现在该笔者我出马了。&lt;/p>
&lt;p>笔者的意见是——稿件内容审核通过，可以用于发布 😄&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文介绍了激发LLM扩展能力的提示词技巧，让LLM成为设计、写作等工作中的得力助手。&lt;/p>
&lt;p>扩展提示词的构建方法：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>明确的指令词&lt;/strong>，让LLM知道是写文章还是出点子，如&amp;quot;请&lt;strong>撰写&lt;/strong>&amp;hellip;&amp;quot;，&amp;ldquo;请&lt;strong>设计&lt;/strong>&amp;hellip;&amp;quot;。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>明确的内容要求&lt;/strong>，如&amp;quot;以xxx&lt;strong>为主题&lt;/strong>&amp;quot;，&amp;ldquo;涵盖xxx&lt;strong>内容要点&lt;/strong>&amp;quot;，&amp;ldquo;针对xxx&lt;strong>举个例子&lt;/strong>&amp;quot;，&amp;ldquo;用新潮有趣的&lt;strong>文字风格&lt;/strong>&amp;quot;。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>提供背景信息&lt;/strong>，让LLM更好的模拟语境。如&amp;quot;你是个童话大王&amp;rdquo;，&amp;ldquo;这是给总裁的汇报材料&amp;rdquo;。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>至此，我们已经完成了吴恩达老师提示词课程的学习，包括：&lt;/p>
&lt;ul>
&lt;li>提示词的基本原则&lt;/li>
&lt;li>提示词的四个组成要素，及通用使用技巧&lt;/li>
&lt;li>提示词实战，解锁LLM四大能力：总结、推理、转换、扩展&lt;/li>
&lt;/ul>
&lt;p>LLM是个&amp;quot;通才&amp;rdquo;，而且还在快速成长，提示词是我们与这个&amp;quot;通才&amp;quot;对话的主要接口。小伙伴们也都行动起来吧，用好提示词，轻松驾驭LLM。&lt;/p>
&lt;h1 id="4资料汇总">4.资料汇总&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>本技术专栏&lt;/strong>：
&lt;ul>
&lt;li>《【chatGPT】学习笔记24-提示词解读1-提示词基本概念》&lt;/li>
&lt;li>《【chatGPT】学习笔记25-提示词解读2-通用技巧》&lt;/li>
&lt;li>《【chatGPT】学习笔记27-提示词解读3-实战案例之摘要总结》&lt;/li>
&lt;li>《【chatGPT】学习笔记28-提示词解读4-实战案例之推理》&lt;/li>
&lt;li>《【chatGPT】学习笔记30-提示词解读5-实战案例之转换》&lt;/li>
&lt;li>《【chatGPT】学习笔记31-提示词解读6-实战案例之扩展》&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>吴恩达提示词课程：
&lt;ul>
&lt;li>原文：https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction&lt;/li>
&lt;li>翻译：https://jherculesqz.gitbook.io/chatgpt-prompt-engineering-for-developers-1/&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记30-提示词解读5-实战案例之转换</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/</link><pubDate>Sat, 02 Dec 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/</guid><description>&lt;p>今天我们跟着吴恩达老师的课程，学习LLM另一个强大的能力——转换(&lt;code>Transforming&lt;/code>)。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231128162542742.png" alt="image-20231128162542742">&lt;/p>
&lt;h1 id="1激发转换能力的提示词">1.激发转换能力的提示词&lt;/h1>
&lt;h2 id="1什么是llm的转换能力">(1)什么是LLM的转换能力&lt;/h2>
&lt;p>LLM的转换能力是指&lt;strong>将文本从一种形式或格式转换为另一种形式或格式的能力&lt;/strong>。&lt;/p>
&lt;p>转换能力使得LLM成为一个强大的文本处理工具，可以在如下场景应用：&lt;/p>
&lt;ul>
&lt;li>文本翻译&lt;/li>
&lt;li>修正内容错误&lt;/li>
&lt;li>改变内容风格&lt;/li>
&lt;li>转换文本格式&lt;/li>
&lt;/ul>
&lt;p>注：目前很火的&lt;strong>LLM4SE领域&lt;/strong>(如：代码转换、代码修正、代码检视等)，&lt;strong>本质都是在激发LLM的转换能力&lt;/strong>。&lt;/p>
&lt;h2 id="2如何激发llm的转换能力">(2)如何激发LLM的转换能力&lt;/h2>
&lt;p>我们可以这样构建提示词：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>根据任务类型，使用清晰明确的指令词，如：&lt;strong>转换&lt;/strong>xxx、&lt;strong>翻译&lt;/strong>xxx、校正xxx。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>提供足够的上下文信息，让LLM知道要处理的内容。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="2实战案例">2.实战案例&lt;/h1>
&lt;p>假设我是某跨境电商的售前客服，要用LLM的转换能力来支撑处理用户问题：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>翻译&lt;/strong>国外用户反馈的问题。&lt;/li>
&lt;li>写问题回复，让LLM&lt;strong>校正&lt;/strong>内容错误。&lt;/li>
&lt;li>把回复内容&lt;strong>转换&lt;/strong>成商务邮件风格。&lt;/li>
&lt;li>将问题及回复&lt;strong>转换&lt;/strong>成JSON和表格，便于后续建单留档。&lt;/li>
&lt;/ul>
&lt;h2 id="step1翻译用户问题">STEP1.翻译用户问题&lt;/h2>
&lt;p>黑色星期五，电商客服收到一条问题如下：&lt;/p>
&lt;blockquote>
&lt;p>&lt;em>“Avez-vous encore des stocks de smartphones ? Comment puis-je participer à vos promotions ?”&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>这是哪国语言，什么意思？😵 (客服小姐姐一脸黑线)&lt;/p>
&lt;p>程序员小哥哥英雄救美，让LLM帮忙&lt;strong>翻译&lt;/strong>下。&lt;/p>
&lt;ul>
&lt;li>程序员小哥的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129171159198.png" alt="image-20231129171159198">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129171243074.png" alt="image-20231129171243074">&lt;/p>
&lt;p>LLM识别出了文字的语种，并按指令进行了机器翻译。&lt;/p>
&lt;h2 id="step2回复客户邮件">STEP2.回复客户邮件&lt;/h2>
&lt;p>生意上门，客服小姐姐非常开心，但迅速陷入了沉思：如何给法语客户回复专业的售前邮件呢？😵&lt;/p>
&lt;p>通常，回复售前邮件需要有如下流程：&lt;/p>
&lt;ul>
&lt;li>编写回复信息并校正&lt;/li>
&lt;li>设计回复信息风格&lt;/li>
&lt;li>记录JSON和表格，归档到IT系统&lt;/li>
&lt;/ul>
&lt;p>此时，程序员小哥哥再次出手，英雄救美。&lt;/p>
&lt;h3 id="step21编写并校正回复信息">STEP2.1.编写并校正回复信息&lt;/h3>
&lt;p>客服小姐姐用中文写了回复信息：&lt;em>“我们手机的库存非长充足。优惠活动是买两部送一步。尽管放心下单吧。”&lt;/em>&lt;/p>
&lt;p>程序员小哥哥让LLM帮忙&lt;strong>校对&lt;/strong>下是否有文字错误。&lt;/p>
&lt;ul>
&lt;li>程序员小哥的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129173833270.png" alt="image-20231129173833270">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129174109866.png" alt="image-20231129174109866">&lt;/p>
&lt;p>LLM识别出了错别字，并修正了回复信息。&lt;/p>
&lt;h3 id="step22改变内容风格">STEP2.2.改变内容风格&lt;/h3>
&lt;p>商务对话要正式点儿，让LLM把初始信息&lt;strong>转换&lt;/strong>成商务&lt;strong>风格&lt;/strong>的回复，然后翻译成法语。&lt;/p>
&lt;ul>
&lt;li>程序员小哥的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129181528670.png" alt="image-20231129181528670">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129181557507.png" alt="image-20231129181557507">&lt;/p>
&lt;p>LLM很好的完成了任务，让客服小姐姐不用在翻译、措辞上花太多时间。&lt;/p>
&lt;h3 id="step23将问题及回复转换成json和表格">STEP2.3.将问题及回复转换成JSON和表格&lt;/h3>
&lt;p>客户问题很多，需要客服小姐姐将问题及回复，整理成JSON和表格形式，提交到IT系统归档。&lt;/p>
&lt;p>程序员小哥哥，利用LLM的&lt;strong>文本格式转换功能&lt;/strong>快速处理这些文本。&lt;/p>
&lt;p>如：转换成程序容易处理的JSON格式：&lt;/p>
&lt;ul>
&lt;li>程序员小哥的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129183618410.png" alt="image-20231129183618410">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129183643134.png" alt="image-20231129183643134">&lt;/p>
&lt;p>还可以把JSON转成直观易读的表格：&lt;/p>
&lt;ul>
&lt;li>程序员小哥的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129183705048.png" alt="image-20231129183705048">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB5-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E8%BD%AC%E6%8D%A2/image-20231129183727101.png" alt="image-20231129183727101">&lt;/p>
&lt;p>最后，翻译、校正、文本转换、格式转换，只需用LLM一个工具就可以搞定。&lt;/p>
&lt;p>最后，程序员小哥哥和客服小姐姐开启了一段美好的爱情故事。&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文介绍了一个LLM另一个实用的提示词技巧，可以充分利用LLM的文本转换能力，帮助我们处理繁琐的文档工作。&lt;/p>
&lt;p>转换提示词的构建方法：&lt;/p>
&lt;ul>
&lt;li>根据任务类型，使用清晰明确的指令词，如&lt;strong>转换&lt;/strong>xxx、&lt;strong>翻译&lt;/strong>xxx、校正xxx。&lt;/li>
&lt;li>提供足够的上下文信息，让LLM知道要处理的内容。&lt;/li>
&lt;/ul>
&lt;p>此外，这个故事还告诉我们：作为程序员小哥哥，要努力学习AI，高效使用AI，才能抱得美人归。&lt;/p></description></item><item><title>【chatGPT】学习笔记29-LangChain解读1-快速入门</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-langchain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</link><pubDate>Thu, 23 Nov 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-langchain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</guid><description>&lt;p>虽然利用提示词工程，我们已经能较好地使用LLM，但即使开发一个很简单的LLM应用，依然需要编写大量复杂代码(调用LLM只是最简单的一步)。&lt;/p>
&lt;p>&lt;strong>LangChain&lt;/strong>的目标就是让开发LLM应用变的简单，但LangChain更新极快，导致我们的学习成本较高。&lt;/p>
&lt;p>因此，我们准备做两件事，帮助大家提升学习LangChain的效率：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>翻译LangChain官方文档&lt;/strong>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>解读LangChain官方文档&lt;/strong>
&lt;ul>
&lt;li>在本技术专栏中，将详细地逐一解读LangChain官方文档中的各个重要特性。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>本篇我们就来解读LangChain官方文档的《&lt;strong>Quickstart&lt;/strong>》章节(&lt;a href="https://python.langchain.com/docs/get_started/quickstart">https://python.langchain.com/docs/get_started/quickstart&lt;/a>)，帮助大家快速上手LangChain。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/5d7KfRriC6zji11ZFnwLotdqcHQ.svg" alt="LangChain">&lt;/p>
&lt;h1 id="1langchain概览">1.LangChain概览&lt;/h1>
&lt;h2 id="1什么是langchain">(1)什么是LangChain&lt;/h2>
&lt;p>&lt;strong>LangChain 是一个开源框架，支持由LLM驱动的应用程序的开发&lt;/strong>。它使应用程序能够：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>具有上下文感知能力&lt;/strong>：连接大语言模型和上下文的数据源 (如：提示词、few-shot、聊天历史记录等)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>推理&lt;/strong>：依靠语言模型进行推理 (如：根据给出的上下文回答问题，或者决定下一步动作）&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>LangChain 的价值点主要有两个:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>模块化组件&lt;/strong>：专注于组合和模块化，提供了基于LLM的各种组件。这些组件可以单独使用，也可以组合使用。&lt;/li>
&lt;li>&lt;strong>直接可用的链&lt;/strong>：将各种组件组合成可完成特定任务的&amp;quot;链&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;h2 id="2langchain整体架构">(2)LangChain整体架构&lt;/h2>
&lt;p>LangChain为以下模块提供标准的、可扩展的接口和外部集成，从简单到复杂排序如下:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Model I/O&lt;/strong>：与大语言模型的接口。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>检索 (Retrieval)&lt;/strong>：与应用程序特定数据的接口。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>链 (Chains)&lt;/strong>：构建调用序列。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>代理 (Agents)&lt;/strong>：让模型根据高级指令选择使用哪些工具。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Memory&lt;/strong>：在链运行期间保持应用程序状态。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Callbacks&lt;/strong>：记录并传送链的中间步骤。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="3如何构建llm应用程序">(3)如何构建LLM应用程序&lt;/h2>
&lt;p>LangChain提供了许多用来构建LLM应用程序的模块，其中最常用且最重要的模块是&lt;strong>LLMChain&lt;/strong>。&lt;/p>
&lt;p>&lt;strong>LLMChain&lt;/strong>包含三个主要组件:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>LLM&lt;/strong>：LLM是你要构建的应用程序的核心推理引擎。GPT、GLM等大模型LangChain都已适配支持。&lt;/li>
&lt;li>&lt;strong>提示模板&lt;/strong>：它为LLM提供指令，从而控制LLM的输出。所以大家要好好学习提示词工程。&lt;/li>
&lt;li>&lt;strong>输出解析器&lt;/strong>：把LLM的原始响应转化为程序更易处理的格式，方便后续使用。&lt;/li>
&lt;/ul>
&lt;p>接下来我们就基于LLMChain来体验LangChain的便捷吧。&lt;/p>
&lt;h1 id="2快速上手langchain">2.快速上手LangChain&lt;/h1>
&lt;p>下面，我们演示如何用LangChain来做文本总结：&lt;/p>
&lt;ul>
&lt;li>环境准备&lt;/li>
&lt;li>构造LLM&lt;/li>
&lt;li>构造提示词模板&lt;/li>
&lt;li>创建Chain，执行指定任务&lt;/li>
&lt;/ul>
&lt;h2 id="step1环境准备">STEP1.环境准备&lt;/h2>
&lt;ul>
&lt;li>安装LangChain。因为LangChain版本更新很快，安装时优先用&amp;rdquo;-U&amp;quot;升级模式安装。&lt;/li>
&lt;li>安装openai(需申请OpenAPI的Token)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123190055109.png" alt="image-20231123190055109">&lt;/p>
&lt;h2 id="step2构造llm">STEP2.构造LLM&lt;/h2>
&lt;ul>
&lt;li>使用langchain 中的 OpenAI 函数来初始化一个大语言模型&lt;code>llm&lt;/code>。
&lt;ul>
&lt;li>本例用的是&amp;quot;text-davinci-003&amp;rdquo;，当然你可以根据需求用gpt或其它模型。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123174527077.png" alt="image-20231123174527077">&lt;/p>
&lt;h2 id="step3构造提示词模板">STEP3.构造提示词模板&lt;/h2>
&lt;blockquote>
&lt;p>应用程序不会把用户的输入直接传给LLM，通常的做法是把用户输入传给提示词模板。&lt;/p>
&lt;p>提示词模板的好处是：&lt;/p>
&lt;ul>
&lt;li>格式化的提示词结构，包括指令、上下文、输入、输出要求等，为给LLM提供更详细的语境。&lt;/li>
&lt;li>支持设置变量，这可以让好用的提示词最大化被复用。&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;ul>
&lt;li>使用langchain的提示词模板函数初始化一个提示词模板&lt;code>prompt_template&lt;/code>
&lt;ul>
&lt;li>提示词指令是总结文本内容&lt;/li>
&lt;li>要处理的文本内容设成变量，本次任务是处理一段新闻，后面也可以随意处理其它文本内容&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123202743359.png" alt="image-20231123202743359">&lt;/p>
&lt;h2 id="step4创建chain">STEP4.创建Chain&lt;/h2>
&lt;p>现在，我们将以上组件组合成一个链，就可以执行任务了。&lt;/p>
&lt;ul>
&lt;li>使用LLMChain构建我们自己的链&lt;code>chain&lt;/code>，传入上面的两个组件&lt;code>llm&lt;/code>、&lt;code>prompt_template&lt;/code>。&lt;/li>
&lt;li>运行&lt;code>chain&lt;/code>，参数只需传入变量text(要处理的文本内容)，可以看到如下运行过程：
&lt;ul>
&lt;li>链开始，&lt;/li>
&lt;li>读取text变量，格式化提示词，传给LLM&lt;/li>
&lt;li>得到结果，链结束&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123203230173.png" alt="image-20231123203230173">&lt;/p>
&lt;p>从上面的示例可以看到，只需一个命令就实现了提示词构建和LLM调用，我们利用Langchain很好的完成了任务。&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文解读了LangChain官方文档的《QuickStart》章节，并给出了基于LangChain构建LLM应用的实例代码。QuickStart章节关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>LangChain简介&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>LangChain 是一个开源框架，支持由LLM驱动的应用程序的开发。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LangChain 的主要价值点：提供了各种模块化组件和好用的链&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LLMChain是LangChain最常见且最重要的一个链，它包含3个主要组件：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>LLM&lt;/strong>：应用程序的核心推理引擎。&lt;/li>
&lt;li>&lt;strong>提示模板&lt;/strong>：它为LLM提供指令，从而控制LLM的输出。&lt;/li>
&lt;li>&lt;strong>输出解析器&lt;/strong>：把LLM的原始响应转化为程序更易处理的格式。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>基于LangChain构建具备总结功能的LLM应用
&lt;ul>
&lt;li>环境准备&lt;/li>
&lt;li>构造LLM&lt;/li>
&lt;li>构造提示词模板&lt;/li>
&lt;li>创建Chain，执行指定任务&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记28-提示词解读4-实战案例之推理</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/</link><pubDate>Thu, 23 Nov 2023 13:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/</guid><description>&lt;p>在《【chatGPT】学习笔记27-提示词解读3-实战案例之摘要总结》中，我们演示了LLM的总结能力。&lt;/p>
&lt;p>接下来，我们继续跟着吴恩达老师的课程，解锁LLM另一个更强大的能力——推理(&lt;code>Inferring&lt;/code>)。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231122092928495.png" alt="image-20231122092928495">&lt;/p>
&lt;blockquote>
&lt;p>本文的“推理”是指利用LLM处理推理型的任务。&lt;/p>
&lt;/blockquote>
&lt;h1 id="1激发推理能力的提示词">1.激发推理能力的提示词&lt;/h1>
&lt;h2 id="1什么是llm的推理能力">(1)什么是LLM的推理能力&lt;/h2>
&lt;p>LLM的推理能力是指从已知信息中推导出新的结论的能力。&lt;/p>
&lt;p>例如在下面的例子中，LLM根据上下文理解用户意图，经过推理生成了新的信息，包括结论和相应的解释。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123133732549.png" alt="image-20231123133732549">&lt;/p>
&lt;h2 id="2如何激发llm的推理能力">(2)如何激发LLM的推理能力&lt;/h2>
&lt;p>我们可以这样构建提示词：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>使用清晰明确的指令词，让LLM理解做什么类型的推理任务，如判断xxx、预测xxx。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>提供足够的上下文信息，让LLM知道要处理的内容。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="2实战案例">2.实战案例&lt;/h1>
&lt;p>假设我是某智能问答系统的IT人员，要用LLM的推理能力帮忙做运营维护：&lt;/p>
&lt;ul>
&lt;li>判断用户对问答系统是否满意。&lt;/li>
&lt;li>用户问题千奇百怪，让智能客服能够应对各式花样提问。&lt;/li>
&lt;/ul>
&lt;h2 id="21满意度识别">2.1.满意度识别&lt;/h2>
&lt;p>一般问答系统都希望通过点赞👍/点踩👎按钮获取用户的反馈，但大部分用户都不会去点。&lt;/p>
&lt;p>利用LLM的推理能力，直接拿用户的对话信息来做满意度分析，可以大大提升运营效率。&lt;/p>
&lt;p>例如，让LLM判断用户回复的信息是什么感情色彩：&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123141130339.png" alt="image-20231123141130339">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123140406001.png" alt="image-20231123140406001">&lt;/p>
&lt;p>吴恩达老师&amp;quot;提示词工程课程&amp;quot;中说LLM擅长做情感判断，所以我又试了下让LLM列出评论中包含的情绪元素。看来LLM感情还是挺丰富的。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123141823738.png" alt="image-20231123141823738">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123141845933.png" alt="image-20231123141845933">&lt;/p>
&lt;h2 id="22应对花式提问">2.2.应对花式提问&lt;/h2>
&lt;p>传统智能问答系统是建立在知识库基础上的，通过关键词匹配最相关的答案，语义理解和推理能力非常有限。&lt;/p>
&lt;p>现实用户提问方式五花八门，如果某个问题不在知识库，系统将无法提供准确答案。&lt;/p>
&lt;p>基于LLM的推理能力，我们通过2个技巧快速提升智能问答系统的应对能力。&lt;/p>
&lt;h3 id="技巧1基于已知问题推导类似问题">技巧1：基于已知问题推导类似问题&lt;/h3>
&lt;p>基于知识库中的预置问题，利用LLM推导扩充不同的问法，丰富问题集，同时弥补传统问答系统语义理解的不足。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123152748076.png" alt="image-20231123152748076">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123152830392.png" alt="image-20231123152830392">&lt;/p>
&lt;h3 id="技巧2归纳推理">技巧2：归纳推理&lt;/h3>
&lt;p>上面的方法可能仍然不足以完全应对用户问题的多样性，那么可以继续用LLM来补漏。&lt;/p>
&lt;p>利用LLM的归纳推理能力，将用户问题和系统关键词检索出的相关问题做比较，从语义上判断是否相近。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153737082.png" alt="image-20231123153737082">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153803235.png" alt="image-20231123153803235">&lt;/p>
&lt;p>换个相关但不相近的问题&amp;ndash;都有关键词”会员“但语义不同，LLM仍然回答正确，看来LLM的推理能力还是可靠的。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153723987.png" alt="image-20231123153723987">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153820768.png" alt="image-20231123153820768">&lt;/p>
&lt;ul>
&lt;li>综上，利用LLM推导和归纳推理这两个技巧，可以实现快速扩充知识库、增强检索能力。&lt;/li>
&lt;/ul>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文介绍了一个LLM另一个实用的提示词技巧，解锁大语言模型的推理能力，充分利用大模型的智慧。&lt;/p>
&lt;p>推理提示词的构建方法：&lt;/p>
&lt;ul>
&lt;li>使用清晰明确的指令词，让LLM理解做什么类型的推理任务，如判断xxx、预测xxx。&lt;/li>
&lt;li>提供足够的上下文信息，让LLM知道要处理的内容。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记27-提示词解读3-实战案例之摘要总结</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 14 Nov 2023 13:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/</guid><description>&lt;p>在《【chatGPT】学习笔记25-提示词解读2-通用技巧》中，我们看到了提示词的各种通用技巧，但无论哪种技巧，都是为了激发大语言模型的某种潜在能力。&lt;/p>
&lt;p>那么，大语言模型有哪些常见、实用的能力呢？作为生成式语言模型，大模型常见、实用的能力如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231113210314835.png" alt="image-20231113210314835">&lt;/p>
&lt;p>本篇先阐述如何通过提示词激发LLM的第一种能力——总结能力(&lt;code>summarizing&lt;/code>)。&lt;/p>
&lt;h1 id="1激发总结能力的提示词">1.激发总结能力的提示词&lt;/h1>
&lt;h2 id="1什么是llm的总结能力">(1)什么是LLM的总结能力&lt;/h2>
&lt;p>在如下场景中，特别需要&lt;strong>LLM的总结能力&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>会议纪要&lt;/strong>：秘书MM，如何快速输出一个时长4小时的会议纪要？&lt;/li>
&lt;li>&lt;strong>编写书评&lt;/strong>：编辑GG，如何快速阅读一本书，提取要点，编写一个书评呢？&lt;/li>
&lt;li>&lt;strong>编写新闻稿&lt;/strong>：记者MM，如何快速输出一个4小时的产品发布会的新闻稿？&lt;/li>
&lt;/ul>
&lt;p>再来理解一下，&lt;strong>LLM的总结能力&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>LLM具备捕捉文本中的重要细节和关联关系的能力，所以它可对文本进行&lt;strong>总结(summary)&lt;strong>和&lt;/strong>摘录(extract)&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>总结(summary)&lt;strong>和&lt;/strong>摘录(extract)&lt;strong>就是&lt;/strong>LLM的总结能力&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>总结(summary)&lt;/strong>：归纳总结一段文本的核心思想、主要内容。&lt;/li>
&lt;li>&lt;strong>摘录(extract)&lt;/strong>：快速提炼一段文本的关键要点，原文出处。&lt;/li>
&lt;/ul>
&lt;h2 id="2如何激发llm的总结能力">(2)如何激发LLM的总结能力&lt;/h2>
&lt;p>我们可以这样构建提示词：&lt;/p>
&lt;ul>
&lt;li>提示词中，出现明确的指令词，如：请&lt;strong>总结&lt;/strong>xxxx，请&lt;strong>摘录&lt;/strong>xxxx。&lt;/li>
&lt;li>明确输出的总结、摘录的约束，如：总结成几句话，多少个字。&lt;/li>
&lt;li>明确总结的侧重点、关注点，如：请总结&lt;strong>价格方面&lt;/strong>的内容。&lt;/li>
&lt;li>设定背景信息，如：你是一名新华社记者，这是一篇新闻稿。&lt;/li>
&lt;/ul>
&lt;h1 id="2实战案例">2.实战案例&lt;/h1>
&lt;p>我们以智界S7发布会新闻稿为例，演示通过提示词激发LLM总结能力：&lt;/p>
&lt;ul>
&lt;li>我是一名自媒体记者，我获取了华为智界S7发布会的演讲稿。&lt;/li>
&lt;li>我想快速输出一篇&amp;quot;智界S7发布会的新闻稿&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;h2 id="step1编写引言">STEP1.编写引言&lt;/h2>
&lt;p>首先，我需要为新闻稿写一个引言，简明扼要地介绍新闻的核心内容，如：何时、何地、发生何事。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115111855070.png" alt="image-20231115111855070">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115111905241.png" alt="image-20231115111905241">&lt;/p>
&lt;h2 id="step2编写主体段落">STEP2.编写主体段落&lt;/h2>
&lt;p>接下来，写新闻稿的主体段落。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112026820.png" alt="image-20231115112026820">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112057272.png" alt="image-20231115112057272">&lt;/p>
&lt;h2 id="step3编写记者观点">STEP3.编写记者观点&lt;/h2>
&lt;p>接下来，需要记者输出对该产品的观点，如：通过产品的功能参数、产品的价格，记者如何看待该产品的性价比。&lt;/p>
&lt;ul>
&lt;li>我对价格方面的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112357958.png" alt="image-20231115112357958">&lt;/p>
&lt;ul>
&lt;li>LLM对价格的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112405603.png" alt="image-20231115112405603">&lt;/p>
&lt;ul>
&lt;li>我对产品参数的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112515271.png" alt="image-20231115112515271">&lt;/p>
&lt;ul>
&lt;li>LLM对产品参数的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112523094.png" alt="image-20231115112523094">&lt;/p>
&lt;ul>
&lt;li>综上，记者观点如下：
&lt;ul>
&lt;li>智界S7车长4971mm，轴距2950mm，车宽1963mm，首发搭载华为途灵智能底盘和HarmonyOS 4智能座舱，还有HUAWEI ADS 2.0高阶智能驾驶辅助系统等领先科技，将为轿车市场用户带来全场景智慧出行新体验。它的预售价仅25.8万起，&lt;strong>对于这样一辆高性能的新能源车，性价比极高&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="step4提炼发言人重要观点">STEP4.提炼发言人重要观点&lt;/h2>
&lt;p>然后，引用发言人余承东的几个重要观点，在新闻稿中突出发布会的重点信息。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115113113849.png" alt="image-20231115113113849">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115113122691.png" alt="image-20231115113122691">&lt;/p>
&lt;h2 id="step5汇总形成新闻稿">STEP5.汇总形成新闻稿&lt;/h2>
&lt;ul>
&lt;li>汇总上述信息，得到的新闻稿如下：&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>【标题】智界S7发布会再次引爆市场热点&lt;/p>
&lt;p>【引言】华为11月9日在深圳举行了智慧出行解决方案新战略发布会，同时推出华为智选车业务新生态。发布会上，华为智选车首款轿车智界S7正式开启预售，预售价格从25.8万元起，并将于11月28日正式发布。华为旨在通过全新平台和领先科技为用户带来全场景智慧出行新体验。&lt;/p>
&lt;p>【内容】&lt;/p>
&lt;p>华为于11月9日在深圳发布了智慧出行解决方案新战略，并推出华为智选车业务新生态，旗下拥有问界和智界系列车型。华为智选车首款轿车智界S7正式开启预售，预售价格为25.8万元起，并将于11月28日正式发布。华为常务董事余承东表示，问界系列车型的销量火爆，华为将全力提升产能以满足需求。&lt;/p>
&lt;p>华为智选车首款智慧轿车智界S7由华为与奇瑞强强联合打造，采用华为全栈智能汽车解决方案，拥有舒适大空间和出色性能体验。它搭载了华为途灵智能底盘和HarmonyOS 4智能座舱，以及HUAWEI ADS 2.0高阶智能驾驶辅助系统等先进技术。智界S7将为用户带来全新的智慧出行体验，11月28日将正式发布。&lt;/p>
&lt;p>华为表示要持续引领智能汽车的技术创新并推动智能化发展。华为与赛力斯联合打造的问界系列车型取得了优异的市场表现。余承东透露，问界新M7上市不到两月就获得了86000辆大定订单，其中70%以上的用户选择智驾版。问界M9订单突破25000台，火爆销售。华为将全力提升产能以满足订单需求。&lt;/p>
&lt;p>余承东表示：“价格方面我们内部反复讨论，多次测算，最后发现这款车四个版本定价我们都是亏钱的，只能期待后期这款车的放量出货来弥补亏损，目的也是让更多消费者体验华为的产品。”&lt;/p>
&lt;p>智界S7车长4971mm，轴距2950mm，车宽1963mm，首发搭载华为途灵智能底盘和HarmonyOS 4智能座舱，还有HUAWEI ADS 2.0高阶智能驾驶辅助系统等领先科技，将为轿车市场用户带来全场景智慧出行新体验。它的预售价仅25.8万起，&lt;strong>对于这样一辆高性能的新能源车，性价比极高&lt;/strong>。&lt;/p>
&lt;/blockquote>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文介绍了一个非常实用的提示词技巧，能够很好的激发大语言模型摘要总结的能力，让大模型成为我们的办公助手。&lt;/p>
&lt;p>摘要总结提示词构建方法：&lt;/p>
&lt;ul>
&lt;li>提示词中，出现明确的指令词，如：请&lt;strong>总结&lt;/strong>xxxx，请&lt;strong>摘录&lt;/strong>xxxx。&lt;/li>
&lt;li>明确输出的总结、摘录的约束，如：总结成几句话，多少个字。&lt;/li>
&lt;li>明确总结的侧重点、关注点，如：请总结&lt;strong>价格方面&lt;/strong>的内容。&lt;/li>
&lt;li>设定背景信息，如：你是一名新华社记者，这是一篇新闻稿。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记26-CNCC 2023参会纪要</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B026-cncc-2023%E5%8F%82%E4%BC%9A%E7%BA%AA%E8%A6%81/</link><pubDate>Fri, 10 Nov 2023 13:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B026-cncc-2023%E5%8F%82%E4%BC%9A%E7%BA%AA%E8%A6%81/</guid><description>&lt;p>本文记录笔者参加CNCC 2023 AI相关的议题，方便各位小伙伴快速了解学界在AI的理论研究和行业应用情况。&lt;/p>
&lt;h1 id="1cncc-2023概览">1.CNCC 2023概览&lt;/h1>
&lt;h2 id="1会议简介">(1)会议简介&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>本届大会以“&lt;strong>发展数字基础设施，支撑数字中国建设&lt;/strong>”为主题，探讨计算及信息科学技术领域的最新进展和宏观发展趋势，为数字中国建设提供支持。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>大会特邀了国际知名学者、两院院士、产学研各界代表在内的&lt;strong>700余位报告嘉宾&lt;/strong>，覆盖了&lt;strong>人工智能&lt;/strong>、安全、计算+、&lt;strong>软件工程&lt;/strong>、教育、网络、&lt;strong>芯片&lt;/strong>、&lt;strong>云计算&lt;/strong>等30余个领域，推动不同领域的交叉融合，为各界专业人士提供了广泛的专业内容。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>![image-20231109151407115](/AI拾遗/【chatGPT】学习笔记26-CNCC 2023参会纪要/image-20231109151407115.png)&lt;/p>
&lt;h2 id="2议题分布">(2)议题分布&lt;/h2>
&lt;p>CNCC 2023的众多议题中，LLM相关分会场73个。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>基础设施&lt;/strong>：18个分会场&lt;/li>
&lt;li>&lt;strong>LLM理论研究&amp;amp;工程化实践&lt;/strong>：15个分会场&lt;/li>
&lt;li>&lt;strong>LLM应用&lt;/strong>：38个分会场&lt;/li>
&lt;/ul>
&lt;p>![image-20231109195425387](/AI拾遗/【chatGPT】学习笔记26-CNCC 2023参会纪要/image-20231109195425387.png)&lt;/p>
&lt;h1 id="2方向1基础设施">2.方向1：基础设施&lt;/h1>
&lt;h2 id="21dpu相关">2.1.DPU相关&lt;/h2>
&lt;h3 id="议题1dpu标准化工作实践">议题1：DPU标准化工作实践&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>： 钟伟军，中国电子技术标准化研究院技术总监。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：DPU标准化工作，是DPU大规模落地应用中重要环节。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：DPU标准工作实践的成果和现状。如：《数据处理器(DPU)第1部分：参考框架》、《数据处理器(DPU)测试方法》等。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：DPU标准化工作的挑战及下一阶段的计划。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2面向ai时代的dpu云计算融合底座设计与实践">议题2：面向AI时代的DPU云计算融合底座设计与实践&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：曹辉，中科驭数产品运营部副总经理&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：越来越多的云计算基础设施组件正在计划融合或支持DPU方案，是下一代云计算架构演进的主流方向。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：在云原生领域，随着智算中心架构的发展，高吞吐、低时延是智算中心架构发展的挑战。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：中科驭数的解决方案是&lt;strong>IaaS on DPU&lt;/strong>，将IaaS平台下沉至DPU，提供高性能的容器、虚拟机、裸金属服务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3网络域场景dpu应用探索">议题3：网络域场景DPU应用探索&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：曹畅，中国联通研究院未来网络研究部总监&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：DPU具有高效、灵活的可编程网络数据处理加速能力，可支撑网络、存储、安全、管理等数据中心基础设施层可定制的业务加速能力。&lt;/li>
&lt;li>&lt;strong>枢纽&lt;/strong>：DPU衔接了算力和网络两大领域的重要枢纽，推动了计算和网络融合，助力传统算力基础设施向&lt;strong>算网一体的算力网络&lt;/strong>演进。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：在算力网络、5/6G、数据中心网络等网络域场景中，中国联通如果对DPU进行的探索及创新方案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4dpu--如何使能高性能ai网络">议题4：DPU , 如何使能高性能AI网络&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：王瑞雪，中国移动通信有限公司研究院基础网络技术研究所技术经理&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>NICC&lt;/strong>：New Intelligent Computing Center，以高性能GPU、AI加速卡为中心，以高速互联智算集群为目标，形成E级超大规模算力基础设施。&lt;/li>
&lt;li>&lt;strong>价值&lt;/strong>：强化互联技术、深化算力协同、定义新型存储、新增算力原生、升级绿色节能。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：AI大模型以GPU集群分布式训练为基础，集群节点间频繁参数同步带来大通信开销，因此网络是提升AI大模型训练效率的关键之一。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="22芯粒相关">2.2.芯粒相关&lt;/h2>
&lt;h3 id="议题1智能计算时代下的chiplet生态建设">议题1：智能计算时代下的Chiplet生态建设&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：谭展宏，北极雄芯信息科技有限公司CTO。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：海内外多家公司也陆续推出了基于Chiplet技术的产品。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：很多公司标榜着Chiplet这个关键词，但Chiplet的定义、使用方式和技术路线都有各自说法。&lt;/li>
&lt;li>&lt;strong>探索&lt;/strong>：本议题探讨Chiplet如何助力面向计算资源与智能计算，分享Chiplet的生态发展的思考。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2面向百芯万核的芯粒仿真初探">议题2：面向百芯万核的芯粒仿真初探&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：王小航，浙江大学教授。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：软件仿真器是探索集成芯片设计空间的重要工具&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：在大芯片和大模型的时代芯片规模提高，仿真性能无法支撑百芯万核规模的芯片仿真，仿真精度校准难，仿真配置多等。&lt;/li>
&lt;li>&lt;strong>方案&lt;/strong>：分析了上述问题的形成原因，通过并行仿真、精度调节、自动化设计空间探索等技术解决上述问题。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3芯粒测试关键技术研究">议题3：芯粒测试关键技术研究&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：蔡志匡，南京邮电大学教授。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：Chiplet是延续摩尔定律的关键技术，通过先进封装将芯粒集成在一个中介层上，解决芯片研制的规模大、成本高、周期长等问题。&lt;/li>
&lt;li>&lt;strong>关键点1&lt;/strong>：基本DFT技术、单芯粒测试技术、多芯粒测试技术。&lt;/li>
&lt;li>&lt;strong>关键点2&lt;/strong>：覆盖芯粒测试各个环节的芯粒系统级可测试设计方案(测试技术、测试EDA、测试装备)，实现高可靠性、全流程的系统级测试。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4从aigc到百模大战异构计算和chiplet-协同以致胜">议题4：从AIGC到百模大战，异构计算和Chiplet 协同以致胜&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：祝俊东，奇异摩尔产品及解决方案副总裁。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：随着LLM发展及百模大战，异构计算与Chiplet协同扮演关键角色。&lt;/li>
&lt;li>&lt;strong>趋势&lt;/strong>：百模大战引导出的关键挑战之一是&lt;strong>高性能芯片、更大规模的智算平台&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5面向25d集成的先进封装工艺与设计协同方案">议题5：面向2.5D集成的先进封装工艺与设计协同方案&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：樊嘉祺，华进半导体封装设计经理&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：摩尔定律趋缓，封装技术成为电子产品小型化、多功能化、降低功耗、提高带宽的重要手段。&lt;/li>
&lt;li>&lt;strong>趋势&lt;/strong>：芯片封装从传统的平面封装向系统集成、高速、高频、三维方向发展。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：芯片-封装协同设计、满足可靠性要求，材料和工艺方面，存在诸多挑战。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：华进半导体致力于系统封装设计、2.5D/3D 集成关键核心技术研发，提供设计仿真、晶圆制造、系统集成、模组测试等全方位解决方案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="23信息器件与智能计算相关">2.3.信息器件与智能计算相关&lt;/h2>
&lt;h3 id="议题1存算一体异构计算芯片">议题1：存算一体异构计算芯片&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：高滨，清华大学长聘副教授/博导，清华大学教务处副处长&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>背景&lt;/strong>：存算一体技术聚焦在单片三维集成的新型存储器技术。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：忆阻器相关的制造工艺和设计技术，包括28nm集成、EDA工具开发、IP单元电路设计、异构计算架构设计、编译器等。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：基于忆阻器的&lt;strong>超近存计算+存内计算&lt;/strong>的异构计算系统，在算力、灵活性、可扩展性、效率、精度等方面展现出巨大的优势，在多个场景已得到初步的应用验证。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2基于忆阻器的储池计算">议题2：基于忆阻器的储池计算&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：王中锐，香港大学电气与电子工程系助理教授&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：由于内存的物理上分离、处理单元以及晶体管工艺节点限制，传统数字硬件面临巨大挑战，忆阻器是高效和高集成度的深度学习解决方案。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：忆阻器的非理想特性使其难以在边缘侧AI实现原位学习。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：利用新颖的硬件-软件协同设计，利用忆阻器的高度并行和高效的存内计算，将忆阻器的随机性转化为优势。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：基于忆阻器的回声状态储池网络用于时空信号学习、利用随机忆阻器阵列进行图结构数据学习、图嵌入方法与忆阻器联想记忆相结合以满足少样本图学习的需求、基于忆阻器液态机的零样本学习用于多模态事件数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3新型神经元器件电路及其类脑系统应用">议题3：新型神经元器件、电路及其类脑系统应用&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：张续猛，复旦大学青年副研究员，2023年度CCF-之江实验室联合创新基金获得者，全国智能计算标准化工作组委员&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：忆阻器基神经元器件，具有丰富动力学、低功耗、以及高集成度等特点，被认为是构建紧凑神经元电路的理想单元之一。&lt;/li>
&lt;li>&lt;strong>技术&lt;/strong>：利用神经元不同放电模式实现高效计算方面的研究工作，神经元器件的本征温度响应和它在多模态感知方面的应用。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4模拟矩阵计算求解ax--b">议题4：模拟矩阵计算求解Ax = b&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：高滨，清华大学长聘副教授/博导，清华大学教务处副处长&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：求解矩阵方程&lt;strong>Ax = b&lt;/strong>是历史上计算机技术发展的重要驱动力，也构成了现代计算任务的核心。如：科学计算、机器学习、信号处理等。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：传统数字计算机通过执行串行算法(直接法/迭代法)求解该方程，具有高的计算复杂度。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：传统计算机采用冯·诺伊曼架构，求解速度与能效受存储器、处理器之间的通信瓶颈限制。&lt;/li>
&lt;li>&lt;strong>方案&lt;/strong>：模拟矩阵计算，基于存储器阵列架构与全局反馈实现，具有极高的计算并行度；设计存储器阵列的反馈连接方式，模拟矩阵计算电路能够以O(1)的时间求解矩阵求逆、广义逆(如最小二乘)，以及稀疏近似(如压缩感知还原、稀疏编码)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5基于rram硬件的高效小样本学习和图处理">议题5：基于RRAM硬件的高效小样本学习和图处理&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：李灿，香港大学电机与电子工程系的助理教授&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：RRAM，抗变存储器，一种新兴的非易失性模拟存储技术，在存算一体应用方面展示了巨大的潜力。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：使用RRAM进行哈希运算和相似度搜索。通过在交叉阵列中进行特殊编码以及在注意力机制中用于相似度搜索。结合这些操作能够使用基于记忆增强的神经网络(MANN)进行少样本学习，以及使用图注意力(Graph Attention Network)网络进行图数据处理。这可能相较于传统计算平台如CPU和GPU，能耗显著降低，准确度损失最小。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="25云计算相关">2.5.云计算相关&lt;/h2>
&lt;h3 id="议题1大模型与国产算力">议题1：大模型与国产算力&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：翟季冬，清华大学计算机系长聘教授。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：在新一代国产超级计算机上，从底层算子库、并行加速库、负载均衡和混合精度等多方面对大模型进行了性能优化，最终实现了百万亿级参数量的预训练模型训练加速，达到了 EFLOPS级别的训练性能。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="26国内厂商的基础设施情况">2.6.国内厂商的基础设施情况&lt;/h2>
&lt;h3 id="议题1构建泛化普惠的智能算力中科曙光">议题1：构建泛化普惠的智能算力(中科曙光)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：杜夏威，中科曙光智能计算产品事业部总经理。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：通用超算中心-&amp;gt;专用智算中心-&amp;gt;通用智能计算中心。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：成熟兼容的DTK，&lt;strong>兼容CUDA和ROCm&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：适配百度飞桨，上限飞桨官网。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2算力为基共筑数智未来华为昇腾">议题2：算力为基，共筑数智未来(华为昇腾)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：刘鑫，华为昇腾计算业务副总裁。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>介绍华为在AI领域通过昇腾计算构筑坚实算力底座，聚焦根技术创新，打造好用、易用、可信的人工智能平台，发展普惠算力，降低大模型开发门槛，加速大模型模型创新落地，与各产业界共同构筑AI生态未来。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3昇腾大模型基础设施解决方案华为昇腾">议题3：昇腾大模型基础设施解决方案(华为昇腾)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：周斌，华为昇腾计算业务研发总裁&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：大模型是复杂系统工程，每个环节都存在大量工程技术挑战。&lt;/li>
&lt;li>&lt;strong>关键技术&lt;/strong>：高密度计算、复杂通信、内存优化等，打造大模型超级流水线，全流程使能大模型创新落地。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4华为计算领域技术挑战难题解读华为昇腾">议题4：华为计算领域技术挑战难题解读(华为昇腾)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：石晓钟，华为计算产品线技术合作总监&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>难题1&lt;/strong>：计算系统的高可靠计算容错技术。&lt;/li>
&lt;li>&lt;strong>难题2&lt;/strong>：片上和系统相结合的内存纠错技术。&lt;/li>
&lt;li>&lt;strong>难题3&lt;/strong>：多言行算力下的高鲁棒性混合精度求解。&lt;/li>
&lt;li>&lt;strong>难题4&lt;/strong>：基于原生硬件的高性能算子/算法(Matmul、Self-Attention)。&lt;/li>
&lt;li>&lt;strong>难题5&lt;/strong>：基于原生硬件的高性能算子/算法(FFT、Conv2D)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5壁仞科技">议题5：壁仞科技&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：丁云帆，壁仞科技系统架构副总裁&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>服务于百度飞桨、文心一言。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：GPT的大规模分布式训练在模型的参数规模、算力规模和训练性能等维度都存在巨大的挑战，大模型的应用落地也存在成本高、延时大的难题。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：本报告介绍GPT大模型的分布式并行训练策略、如何基于国产大算力通用GPU打造大模型训练系统及低延时高性能的大模型推理引擎。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题6飞腾">议题6：飞腾&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：窦强，中国电子信息产业集团科技委副主任，飞腾信息技术有限公司首席科学家&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>归属&lt;/strong>：隶属于中国电子信息产业集团。&lt;/li>
&lt;li>&lt;strong>关键路径&lt;/strong>：体系结构优化、设计工艺协同优化DTCO、先进封装推动Chiplet、系统垂直优化。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="3方向2llm基础理论工程化实践">3.方向2：LLM基础理论&amp;amp;工程化实践&lt;/h1>
&lt;h2 id="31预训练微调">3.1.预训练&amp;amp;微调&lt;/h2>
&lt;h3 id="议题1大模型技术研究及应用">议题1：大模型技术研究及应用&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：宗成庆，中国科学院自动化研究所研究员、博士生导师&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>PS：宗老师这个议题讲的非常通透，NLP造诣很深厚。&lt;/li>
&lt;li>&lt;strong>对大模型改进1&lt;/strong>：丰富生成文本的信息。预训练模型过于关注提示词中给出的实体or事件，难以包含更丰富的实体和信息。&lt;/li>
&lt;li>&lt;strong>对大模型改进2&lt;/strong>：无梯度计算的大模型参数调试。即，仅微调模型参数的一小部分就可以达到不错的微调性能。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="32端云协同下分布式训练">3.2.端云协同下，分布式训练&lt;/h2>
&lt;h3 id="议题1端云协同下分布式模型训练">议题1：端云协同下分布式模型训练&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：吴飞，浙江大学求是特聘教授，博士生导师&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：在&lt;strong>泛在互联、端云协同、AI赋能&lt;/strong>背景下，形成端云协同机器学习计算范式，是人工智能成为&lt;strong>普惠化能力&lt;/strong>的关键问题之一。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：将&lt;strong>云侧的泛化能力&lt;/strong>与&lt;strong>端侧的个性化能力&lt;/strong>结合起来，体现&lt;strong>须弥纳于芥子&lt;/strong>的哲学思想。云端or端侧学习能力提升、端云协同模型化、端云系统开放平台是研究重点。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="33神经符号计算">3.3.神经符号计算&lt;/h2>
&lt;h3 id="议题1神经符号双轮驱动的信息检索与知识获取">议题1：神经符号双轮驱动的信息检索与知识获取&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：程学旗，中国科学院计算技术研究所副所长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：反绎学习面临弱标注数据和弱逻辑规则情形时，可能导致性能下降、不稳定。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：反绎学习是融合机器学习与逻辑推理并使它们能够比较均衡地协同发挥作用的新范式，提升反绎学习鲁棒性是研究重点。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2细粒度多模态协同感知认知与生成">议题2：细粒度多模态协同感知、认知与生成&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：彭宇新，北京大学博雅特聘教授、国家杰青、国家万人。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：细粒度多模态协同感知、认知与生成对于刻画真实世界和人类生产生活方式具有重要意义。&lt;/li>
&lt;li>&lt;strong>研究目标&lt;/strong>：借鉴人脑的跨模态特性，通过挖掘并协同多源、互补、关联的细粒度和多模态信息，实现对真实世界概念、规则及其演化的深层感知、认知与综合归纳。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：细粒度图像分类、行人再识别、细粒度视频检索、细粒度跨媒体检索、跨媒体推理、细粒度视觉生成。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3从语言大模型到神经符号ai">议题3：从语言大模型到神经符号AI&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：杨博，吉林大学计算机学院教授/博导，计算机学院、软件学院院长。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：神经符号AI期望将符号主义和链接注意融合起来，取长补短，建立具有高效、鲁棒、可解释的智能系统，是当前人工智能研究的一个热点。&lt;/li>
&lt;li>&lt;strong>本质&lt;/strong>：符号主义和链接主义是人工智能的两大方法论，分别模拟演绎推理和归纳学习两种认知过程。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4鲁棒反绎学习迈向安全利用弱标注与弱规则">议题4：鲁棒反绎学习：迈向安全利用弱标注与弱规则&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：李宇峰，南京大学人工智能学院教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>**关键：**提升反绎学习鲁棒性方面的近期研究进展。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="34知识图谱">3.4.知识图谱&lt;/h2>
&lt;h3 id="议题1大模型时代的知识图谱">议题1：大模型时代的知识图谱&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：白硕，CCF上海分部主席，CCF理事，恒生电子有限公司首席科学家。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人从逻辑学出发，阐述命题逻辑、描述逻辑、一阶逻辑、高阶逻辑等，深入剖析NLP领域的远距关联、隐形资产以及大语言模型的短板。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：从描述逻辑到知识图谱，事理图谱，阐述知识图谱的四大特点，进一步阐述了知识图谱融合大模型的应用场景分类和应用深度分类。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2大模型应用体会澜舟科技">议题2：大模型应用体会(澜舟科技)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：周明，澜舟科技创始人兼CEO。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>定位&lt;/strong>：在大语言模型时代，各公司应如何选择产品定位？澜舟科技介绍了自身在大模型时代的定位。&lt;/li>
&lt;li>&lt;strong>模型选择&lt;/strong>：报告人提出了&lt;strong>周明曲线&lt;/strong>，阐述了如何为客户选择合适的大模型规模，量体裁衣，打造专业赛道的垂域大模型。&lt;/li>
&lt;li>&lt;strong>趋势&lt;/strong>：&lt;strong>AI Agents&lt;/strong>是大模型落地的必然趋势，以解决复杂问题求解、实时信息获取和分析、领域专业知识补充、外部系统交互等问题。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：报告人分享了&lt;strong>垂域知识库搜索问答、企业用户智能搜索+AI问答、对话生成式BI分析、智能客服、会议内容智能分析&lt;/strong>领域的案例。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3类chatgpt语言大模型与知识图谱新进展">议题3：类ChatGPT语言大模型与知识图谱新进展&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：王鑫，天津大学智能与计算学部教授、博导，人工智能学院副院长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：以ChatGPT为代表的语言大模型是“联结主义”的最新成果，而知识图谱是“符号主义”的集大成者，如何充分发挥知识图谱的积累的能力，补齐大语言模型的短板，是重要的研究方向。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：探究类ChatGPT语言大模型与知识图谱相互作用而实现“神经+符号”结合的可能途径。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="35安全治理价值观对齐联邦学习">3.5.安全治理&amp;amp;价值观对齐&amp;amp;联邦学习&lt;/h2>
&lt;h3 id="议题1大语言模型之价值观对齐">议题1：大语言模型之价值观对齐&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：秦兵，哈尔滨工业大学计算学部教授，博士生导师。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：大模型智能时代革命到来，生成式人工智能存在的安全隐患等价值观伦理问题。&lt;/li>
&lt;li>&lt;strong>研究方向&lt;/strong>：探索大模型安全性内容生成方法，包括研究大模型辨别是非能力，以及人类普世价值观，社会文化价值观及立场对齐上的内容检测与生成方法，探索AI社会协作式的价值观对齐机制。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2面向异构计算环境的去中心化联邦学习框架">议题2：面向异构计算环境的去中心化联邦学习框架&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：吕建成，四川大学教授/博导、计算机学院(软件学院、智能科学与技术学院)院长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：联邦学习可以突破数据孤岛和隐私保护瓶颈，是助力人工智能落地的新兴技术。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：联邦学习应用于实际场景时，面临异构的计算环境：设备计算性能异构、通信网络和训练数据异构。现有基于中心化参数服务器的主流优化范式存在计算和通信瓶颈，面临扩展性差、通信开销大、模型性能低等现实问题。&lt;/li>
&lt;li>&lt;strong>方案&lt;/strong>：以去中心基础架构、通信优化、个性化模型优化为代表的去中心化架构及其衍生算法 。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="36机器语音机器听觉">3.6.机器语音/机器听觉&lt;/h2>
&lt;h3 id="议题1听觉注意力的理论与算法">议题1：听觉注意力的理论与算法&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：李海洲，新加坡工程院院士，新加坡国立大学终身教授、德国不来梅大学卓越讲座教授&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>技术点&lt;/strong>：听觉注意力是面对复杂的声学场景，人的眼睛和耳朵紧密配合、由大脑协调而实现对目标声源的选择。报告人阐述了听觉注意力算法在语音增强、说话人提取、语言提取等应用课题中的实践。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2说话人声音模仿与鉴别技术">议题2：说话人声音模仿与鉴别技术&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：陶建华，CCF语音对话与听觉专委会副主任，清华大学自动化系教授，博导&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：迁移学习&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：高度拟人化和个性化的人物声音模仿技术，对通信、教育、金融、社交、娱乐等领域有重要作用。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：阐述了通过迁移学习、生成式网络模型，声音模仿技术的多项成果。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：系统性地介绍伪造声音鉴别技术，伪造溯源分析方法、面向复杂场景的声音生成与鉴别对抗博弈机制。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3speechgpt让大语言模型具有内生的语音对话能力">议题3：SpeechGPT：让大语言模型具有内生的语音对话能力&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：邱锡鹏，复旦大学计算机学院教授，博导&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>案例&lt;/strong>：介绍SpeechGPT的跨模态能力，SpeechGPT突破了传统语音到语音对话流水线方式 (ASR+LLM+TTS) 的束缚，实现了模态之间的知识传递，不需要额外的ASR和TTS系统也能和LLM直接进行语音对话。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="37全脑神经联接与类脑智能">3.7.全脑神经联接与类脑智能&lt;/h2>
&lt;h3 id="议题1破解脊椎动物全脑神经联接--脑与类脑研究的基石">议题1：破解脊椎动物全脑神经联接 – 脑与类脑研究的基石&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：杜久林，中国科学院脑科学与智能技术卓越创新中心副主任&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：大脑是在跨时空尺度上具有高度非线性作用的复杂动力学系统，心智的奥秘就蕴藏在这精巧的组织结构中。揭示大脑组织规律及其基础上产生的神经功能的机制，不仅是理解大脑奥秘的必由之路，也将为发展类脑智能构架与算法、突破冯•偌依曼构架提供新策略。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：斑马鱼具有脊椎动物保守的神经系统结构，可以从全脑尺度上解读其大脑工作的基本原理。报告人讲述本研究团队运用自创的“既见森林(全脑)、又见树木(神经元)甚或树叶(突触)”的研究范式，实现了对脊椎动物全脑所有神经元形态结构与神经活动的在体观测与调控、以及动物行为的同时记录。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2文曲星基于开源芯片与敏捷开发的开源类脑芯片">议题2：文曲星：基于“开源芯片与敏捷开发”的开源类脑芯片&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：赵地，中科院计算所副研究员&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：在神经形态计算中，脉冲神经网络(Spiking Neural Network，SNN)是硬件实现的最佳选择。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：大多数加速器解决方案都基于CPU 加速器架构，这种结构因为复杂的控制流程而能源效率低下。报告人基于脉冲卷积神经网络的开源芯片构架：开发脉冲卷积单元，对现有的卷积神经网络单元进行特征提取和事件驱动设置，进一步提高单元工作工作的效率，并降低功耗的开销。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3全脑尺度的信息维持和行为策略调整">议题3：全脑尺度的信息维持和行为策略调整&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：穆宇，中国科学院脑科学与智能技术卓越创新中心研究员&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：空间上，大脑的每个部分都接收来自其他区域的输入并对其产生作用。时间上，每一刻的大脑都携带着前一刻的信息并影响着下一刻。对&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人阐述如何开发一种系统，支持在单个细胞的分辨率监测整个斑马鱼大脑，并实时处理所获得的神经元或行为信息以生成闭环干扰从感觉到运动的完整转导过程，在全脑尺度上进行剖析，助力理解复杂的脑功能并总结其完整的计算原理。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4类脑器件与系统">议题4：类脑器件与系统&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：缪峰，南京大学物理学院教授、博导、副院长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人阐述了二维材料与“原子乐高”电子学如何在发展未来的类脑智能技术中发挥重要作用，包括神经形态计算与类视网膜形态计算等。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="4方向3llm应用落地">4.方向3：LLM应用落地&lt;/h1>
&lt;h2 id="41软件工程">4.1.软件工程&lt;/h2>
&lt;h3 id="议题1大模型时代的软件研发华为">议题1：大模型时代的软件研发(华为)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：王千祥，华为云智能化软件研发首席专家&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>引导&lt;/strong>：从软件研发角度，大模型将带来哪些变化？报告人结合华为在基于LLM的代码生成等软件研发领域开展的系列探索，分享软件研发大模型的进展。&lt;/li>
&lt;li>&lt;strong>问题&lt;/strong>：开发者如何与大模型协同研发？程序如何与大模型协同运行？人类如何与大模型协同存在？&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2大模型催生ai原生研发新范式百度">议题2：大模型催生AI原生研发新范式(百度)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：臧志，百度工程效能部总监&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：探讨在大模型技术影响下，&lt;strong>产品思维-应用框架-研发过程&lt;/strong>将发生哪些变化。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：如何适配大模型时代的新要素构建新的研发生产力，以及新型的研发智能体如何在企业场景中落地应用。&lt;/li>
&lt;li>&lt;strong>核心要点&lt;/strong>：&lt;strong>SE 4 AI，AI 4 SE&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3代码大模型赋能软件研发的探索与实践科大讯飞">议题3：代码大模型赋能软件研发的探索与实践(科大讯飞)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：薛增奎，科大讯飞效能平台首席技术专家&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：介绍科大讯飞的iFlyCode(基于自研代码大模型的智能编程助手产品)，以及在内外部应用的典型场景和成效。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4基于代码大模型的代码智能体字节跳动">议题4：基于代码大模型的代码智能体(字节跳动)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：许晶晶，字节跳动研究员&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：讨论基于代码大模型的自主代理的构建和具体的应用场景。在智能体构建方面，如何结合代码规划、代码执行等能力？在应用场景方面，以数据分析场景为例，探讨智能体在其中的应用和实践。&lt;/li>
&lt;li>PS：这个小姐姐功力深厚。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5大模型对软件开发模式的影响北大">议题5：大模型对软件开发模式的影响(北大)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：李戈，北京大学长聘教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：软件自动化理论认为AI辅助研发的瓶颈是模型大小。大语言模型为软件自动化打开了一扇窗。反之，模型不够大就是多少人工多少智能。&lt;/li>
&lt;li>**PS：**李老师很诙谐，净说大实话。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题6大模型时代软件测试技术方向与趋势同济大学">议题6：大模型时代软件测试技术方向与趋势(同济大学)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：朱少民，同济大学特聘教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：阐述了早期采用遗传算法、粒子群优化算法等生成测试数据，AI覆盖了测试建模、测试用例集优化、GUI白动化测试、测试结果分析等方面。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人着重讨论如何应用大模型为软件测试赋能、如何借助LLM相关技术更高效地完成测试工作，以及未来技术发展方向。阐述了大模型时代软件测试的新范式、大模型时代软件测试的技术方向。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="42智慧交通">4.2.智慧交通&lt;/h2>
&lt;h3 id="议题1视频物联网中云端协同智能计算">议题1：视频物联网中云端协同智能计算&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：马华东，北京邮电大学计算机学院教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：视频物联是物联网的一种重要形态，也是支撑智慧城市、智能安防等应用的关键基础设施。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人以人、车、事件为典型目标，阐述了面向多任务多场景的深度神经网络智能视频算法体系&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：针对端设备资源受限、云端协同计算难、单一视觉模型能力弱等挑战，介绍了模型轻量化、云端模型互动、视觉大模型等相关技术&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="43智慧医疗">4.3.智慧医疗&lt;/h2>
&lt;h3 id="议题1exploring-different-modalities-for-healthcare-applications">议题1：Exploring Different Modalities for Healthcare Applications&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：邱锂力，微软亚洲研究院副院长&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人介绍如何利用无线传感和机器学习技术利用不同模式进行疾病诊断的探索，从语言、运动、呼吸、心跳、脑电波、医学图像等方面衡量一个人的健康状况。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2生命科学基础模型">议题2：生命科学基础模型&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：宋乐，BioMap CTO和首席人工智能科学家&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：能否利用大量无监督数据来加速生命科学发现和药物设计？&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：介绍xTrimo系列跨多尺度生物过程的大规模预训练模型，整合来自蛋白质序列、结构、蛋白质-蛋白质相互作用和单细胞转录组数据的大量数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="44智慧农业">4.4.智慧农业&lt;/h2>
&lt;h3 id="议题1智慧农业领域的大模型初探">议题1：智慧农业领域的大模型初探&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：刘劼，哈尔滨工业大学（深圳）国际人工智能研究院院长，IEEE Fellow&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：介绍大模型在遥感图像处理、作物数据生成等方面的尝试，并展望建立作物生长等大模型的前景。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="45aiot">4.5.AIoT&lt;/h2>
&lt;h3 id="议题1aiiot-human-centric-smart-sensing-design">议题1：AI+IoT: Human-Centric Smart Sensing Design&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：张黔，香港科技大学腾讯工程学教授、计算机科学与工程系讲座教授、IEEE Fellow、香港工程科学院院士&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：AI与IoT的融合，为以人为中心的应用创造了赋能的机会，也产生了相关的挑战。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：如何处理数据的异构特性、不同终端用户数据的不完整性、以及终端设备资源受限造成的低质量数据等问题？感知模态的多样性为感知能力的突破带来的新机会点？&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记25-提示词解读2-通用技巧</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/</link><pubDate>Fri, 10 Nov 2023 12:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/</guid><description>&lt;p>上一篇，我们了解了提示词基本概念，本篇我们继续解读吴恩达老师的《ChatGPT Prompt Engineering for Developers》课程，看一下提示词常用技巧。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231108115607959.png" alt="image-20231108115607959">&lt;/p>
&lt;h1 id="1技巧构建合理的提示词结构">1.技巧：构建合理的提示词结构&lt;/h1>
&lt;p>完整的提示词包含以下四个要素：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>要素&lt;/th>
&lt;th>说明&lt;/th>
&lt;th>举例&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>指令词&lt;/strong>&lt;/td>
&lt;td>想要模型执行的特定任务或指令&lt;/td>
&lt;td>如：翻译、总结、生成&amp;hellip;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>背景(上下文)&lt;/strong>&lt;/td>
&lt;td>包含外部信息或额外的上下文信息，引导语言模型更好地响应&lt;/td>
&lt;td>如：“在人工智能领域”, “在医学领域”&amp;hellip;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>输入&lt;/strong>&lt;/td>
&lt;td>用户输入的内容或问题&lt;/td>
&lt;td>如：需要总结的文章&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>输出要求&lt;/strong>&lt;/td>
&lt;td>指定输出的类型或格式&lt;/td>
&lt;td>如：以JSON格式输出&amp;hellip;&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;font color=red>**注意：**提示词结构取决于您的任务类型，并非所有以上要素都是必须的。&lt;/font>&lt;/p>
&lt;h1 id="2技巧设定角色">2.技巧：设定角色&lt;/h1>
&lt;h2 id="1设定llm的角色">(1)设定LLM的角色&lt;/h2>
&lt;p>在提示词中设定LLM角色，&lt;strong>让模型进行角色扮演&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>直接提问&lt;/strong>，ChatGPT返回的答案较笼统，没有针对性。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110154844353.png" alt="image-20231110154844353">&lt;/p>
&lt;ul>
&lt;li>在提示词中&lt;strong>让LLM角色扮演&lt;/strong>，ChatGPT再次返回的答案就会出现医学领域的专有名词和专业指导。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110155206497.png" alt="image-20231110155206497">&lt;/p>
&lt;h2 id="2设定提问者的角色">(2)设定提问者的角色&lt;/h2>
&lt;p>除了让大语言模型进行角色扮演，还可以设定提问者的角色，为不同的提问对象生成定制化的答案。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>设定提问者的角色是一位百岁老人&lt;/strong>，ChatGPT的回答会考虑到老人的身体状况。(PS：百岁老人你都敢建议他去跑马拉松&amp;hellip;)&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110155639302.png" alt="image-20231110155639302">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>设定提问者的角色是缺乏运动的程序员&lt;/strong>，ChatGPT的回答会提醒程序员循序渐进。(PS：这个缺乏运动的程序员就是我&amp;hellip;)&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110155824839.png" alt="image-20231110155824839">&lt;/p>
&lt;h1 id="3技巧分隔符划分指令和内容">3.技巧：分隔符划分指令和内容&lt;/h1>
&lt;p>如果提示词包含2个要素：&lt;strong>指令词&lt;/strong>和&lt;strong>输入&lt;/strong>，那么我们如何让大语言模型知道哪些是&lt;strong>指令词&lt;/strong>，哪些是&lt;strong>输入&lt;/strong>？&lt;/p>
&lt;ul>
&lt;li>我们可以&lt;strong>使用分隔符&lt;/strong>(如```、&amp;quot;&amp;quot;&amp;quot;、&amp;lt;&amp;gt;等)区分&lt;strong>指令&lt;/strong>和待处理的&lt;strong>输入&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>看一个例子：&lt;/p>
&lt;ul>
&lt;li>我们不是想大语言模型给100岁老人参加马拉松的建议，而是希望将这段文字翻译为英文——我们可以通过&lt;code>&amp;quot;&amp;quot;&amp;quot;&lt;/code>，&lt;strong>区分出指令和输入&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110160402261.png" alt="">&lt;/p>
&lt;h1 id="4技巧指定文本判断条件">4.技巧：指定文本判断条件&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>在提示词中&lt;strong>指定文本判断条件&lt;/strong>，激发大语言模型对文字的分类能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>示例：在本示例中，激发了大语言模型对**&amp;ldquo;是否为指令&amp;rdquo;**的分类能力。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110161203289.png" alt="image-20231110161203289">&lt;/p>
&lt;h1 id="5技巧指定输出的格式">5.技巧：指定输出的格式&lt;/h1>
&lt;ul>
&lt;li>在提示词中&lt;strong>指定输出答案的格式&lt;/strong>，便于应用软件系统获得答案后的文本处理。&lt;/li>
&lt;li>示例：在本示例中，ChatGPT按照提示词中设定的JSON格式返回了答案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110163709627.png" alt="image-20231110163709627">&lt;/p>
&lt;h1 id="6-技巧few-shot">6. 技巧：Few-Shot&lt;/h1>
&lt;ul>
&lt;li>在提示词中，给出&lt;strong>一些示例的问答&lt;/strong>，可能&lt;strong>激发大语言模型的模仿能力&lt;/strong>。&lt;/li>
&lt;li>根据给出的示例问答的数量，可分为：
&lt;ul>
&lt;li>
&lt;p>&lt;strong>zero-shot&lt;/strong>：零样本提示。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>one-shot&lt;/strong>：单样本提示。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>few-shot&lt;/strong>：少样本提示。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>我们来看一个示例：&lt;/p>
&lt;ul>
&lt;li>直接问大语言模型问题，属于&lt;strong>zero-shot&lt;/strong>，大语言模型的答案风格比较自由。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110162842622.png" alt="image-20231110162842622">&lt;/p>
&lt;ul>
&lt;li>问大语言模型的同时，给出了老师、学生的一个问答对，属于&lt;strong>one-shot&lt;/strong>，大语言模型的答案风格就会&lt;strong>大致模仿&lt;/strong>一下示例问答对的风格。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110163038324.png" alt="image-20231110163038324">&lt;/p>
&lt;ul>
&lt;li>问大语言模型的同时，给出了老师、学生的多个问答对，属于&lt;strong>few-shot&lt;/strong>，大语言模型的答案风格就会&lt;strong>模仿&lt;/strong>示例问答对的风格及&lt;strong>老师的情绪&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110163115561.png" alt="image-20231110163115561">&lt;/p>
&lt;h1 id="7技巧cot">7.技巧：CoT&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>CoT&lt;/strong>：Chain of Thought，思维链。AI科学家在研究中发现，只需要在提示词最后增加一句话——&amp;ldquo;让我们一步一步思考&amp;rdquo;，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>我们看一下示例：我们的提问是大语言模型目前的短板能力(数学问题)，在没有任何提示的情况下，答案是错的。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110165008611.png" alt="image-20231110165008611">&lt;/p>
&lt;ul>
&lt;li>我们加上这句神奇的咒语——&lt;code>Let's think step by step.&lt;/code>，ChatGPT就可以回答正确了。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110165440078.png" alt="image-20231110165440078">&lt;/p>
&lt;h1 id="8技巧自洽self-consistency">8.技巧：自洽(SELF-CONSISTENCY)&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>Self-Consistency&lt;/strong>：自洽，即推理过程中，用多种推理路径得到结果，出现最大的答案大概率就是正确答案，从而体现了&lt;strong>自洽性&lt;/strong>。&lt;/li>
&lt;li>随着大语言模型能力日益增强，Self-Consistency已成为大语言模型的内部能力，需要多次实验才能观测到自洽的推理过程。&lt;/li>
&lt;li>我们来看一个例子：通过CoT，激发大语言模型推理思考，从它的回答中，可以看出大语言模型的推理过程产生了多种不同推理路径及答案，最终大语言模型自行选择了一个自洽的回答。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110170209475.png" alt="image-20231110170209475">&lt;/p>
&lt;h1 id="9小结">9.小结&lt;/h1>
&lt;p>本文阐述了多种提示词常用技巧，实战中需要综合应用上述技巧，根据场景激发大语言模型的不同能力：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>技巧1：构建合理的提示词结构&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧2：设定角色&lt;/strong>，设定LLM角色、设定提问者角色。&lt;/li>
&lt;li>&lt;strong>技巧3：分隔符划分指令和内容&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧4：指定文本判断条件&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧5：指定输出格式&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧6：Few-Shot。&lt;/strong>&lt;/li>
&lt;li>&lt;strong>技巧7：CoT&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧8：Self-Consistency&lt;/strong>。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记24-提示词解读1-提示词基本概念</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link><pubDate>Thu, 09 Nov 2023 15:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid><description>&lt;p>吴恩达老师的《ChatGPT Prompt Engineering for Developers》是一门学习提示词工程不错的课程，我们接下来用几篇文章来解读这门课程。&lt;/p>
&lt;h1 id="1什么是提示词工程">1.什么是提示词工程&lt;/h1>
&lt;p>首先看1个问题：&lt;/p>
&lt;ul>
&lt;li>向大语言模型输入&amp;quot;一二三四五&amp;rdquo;，它很可能回答&amp;quot;上山打老虎&amp;rdquo;。但，我们的意图是希望它把&amp;quot;一二三四五&amp;rdquo;&lt;strong>翻译成英文&lt;/strong>，怎么办？&lt;/li>
&lt;/ul>
&lt;p>我们的解决方法是：&lt;/p>
&lt;ul>
&lt;li>问大语言模型：&amp;ldquo;请将如下文字翻译为英文：一二三四五&amp;rdquo;，大语言模型就会回答&amp;quot;One Two Three Four Five&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;p>上述解决方法本质是什么呢？&lt;/p>
&lt;ul>
&lt;li>即在问题里明确表达&lt;strong>期望大语言模型如何处理&lt;/strong>一段文字。&lt;/li>
&lt;li>明确表达期望大语言模型做什么，就是一条指令，也就是&lt;strong>提示词&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>提示词理论的出现，源于两个假设：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>假设1&lt;/strong>：大语言模型已经掌握了很多世界知识，但由于知道的太多，一时想不起来。&lt;/li>
&lt;li>&lt;strong>假设2&lt;/strong>：自然语言存在二义性，需要更多的提示，才能准确地向大语言模型表达人类的真实意图。&lt;/li>
&lt;/ul>
&lt;p>因此，人类通过提示词，可以唤起大语言模型对已有知识的记忆，也可以让大语言模型更加准确地理解人类意图。&lt;/p>
&lt;p>开发提示词、优化提示词的过程，被称为&lt;strong>提示词工程&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>提示词工程包含了诸多工程方法，如：设计有效的提示策略、优化提示词表达等。&lt;/li>
&lt;/ul>
&lt;p>伴随着大语言模型的发展，提示词工程也形成了一套体系化的工程方法。它成为AI领域的热点技术之一，是AI工程师的必备技能。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231110144405400.png" alt="From《Pre-train, Prompt, and Predict: A Systematic Survey ofPrompting Methods in Natural Language Processing》">&lt;/p>
&lt;h1 id="2提示词基本原则">2.提示词基本原则&lt;/h1>
&lt;h2 id="1原则1简洁明确">(1)原则1：简洁明确&lt;/h2>
&lt;p>假想两个人类在说话，两人的表达能力有限，词不达意、含糊其辞、鸡同鸭讲&amp;hellip;，最终就导致两人之间的沟通极其困难。&lt;/p>
&lt;p>与大语言模型交互，和人类交流类似，也需要简洁明确的同问，向大语言模型清晰表达意图。&lt;/p>
&lt;p>我们来看一个例子：&lt;/p>
&lt;ul>
&lt;li>我们让ChatGPT写一首诗，它以立冬为题生成一首诗：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231110145755795.png" alt="image-20231110145755795">&lt;/p>
&lt;ul>
&lt;li>如果我们希望这首诗是五言绝句，则进一步这样提问，可以看到ChatGPT生成了一首以立冬为题的五言绝句。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231110145923990.png" alt="image-20231110145923990">&lt;/p>
&lt;p>上述示例，可以看出：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>写一首诗&lt;/strong>是一条&lt;strong>简洁的指令&lt;/strong>。&lt;/li>
&lt;li>相较于写一首诗，&lt;strong>写一首五言绝句&lt;/strong>是一条更加&lt;strong>简洁明确的指令&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;h2 id="2原则2迭代式提示词开发">(2)原则2：迭代式提示词开发&lt;/h2>
&lt;p>我们要知道两个事实：&lt;/p>
&lt;ul>
&lt;li>没有可以适应所有场景的完美提示词，需要我们针对不同场景，开发不同的提示词。&lt;/li>
&lt;li>即使在一个很小的场景下存在完美提示词，我们也无法一次性就找到它。&lt;/li>
&lt;/ul>
&lt;p>针对某个场景，寻找提示词的过程，就是&lt;strong>迭代式提示词开发&lt;/strong>。&lt;/p>
&lt;p>迭代式提示词开发的过程如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：针对特定场景，设计初始提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将初始提示词传递给大语言模型，获得返回结果(&lt;code>Experimental result&lt;/code>)。&lt;/li>
&lt;li>&lt;strong>Error Analysis阶段&lt;/strong>：分析返回结果，思考改进提示词的方法，重新进入&lt;strong>Idea阶段&lt;/strong>，直到找到特定场景下的完美提示词。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108102255487.png" alt="From 吴恩达提示词课程">&lt;/p>
&lt;p>我们再来看一个示例：我们需要一段用于营销的产品介绍。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：针对产品介绍场景，设计初始提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将初始提示词传递给大语言模型，获得返回结果。可以看到ChatGPT返回了一段不错的文案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108110737288.png" alt="image-20231108110737288">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Error Analysis阶段&lt;/strong>：从上一步获得的ChatGPT文案内容太长，我们思考改进提示词的方法是进一步明确字数要求。&lt;/li>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：根据上一阶段的改进思路，编写改进后的提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将改进后的提示词传递给大语言模型，获得返回结果。可以看到ChatGPT返回了一段简短的文案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108110819852.png" alt="image-20231108110819852">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Error Analysis阶段&lt;/strong>：从上一步获得的ChatGPT文案没有突出要点，我们思考改进提示词的方法是限定明确要突出的关键点。&lt;/li>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：根据上一阶段的改进思路，编写改进后的提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将改进后的提示词传递给大语言模型，获得返回结果。可以看到ChatGPT返回了一段简短、要点突出的文案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108110848960.png" alt="image-20231108110848960">&lt;/p>
&lt;p>这就是&lt;strong>迭代式提示词开发&lt;/strong>的流程，核心要点是&lt;strong>多次迭代&lt;/strong>。&lt;/p>
&lt;h2 id="3原则3选择合适的提示词风格">(3)原则3：选择合适的提示词风格&lt;/h2>
&lt;p>提示词工程是一种&lt;code>Instruct-Tuning&lt;/code>技术，提示词的风格包含：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Prompt&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Instruction&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>初学者极易混淆这两种风格，我们来看一个例子：&lt;/p>
&lt;ul>
&lt;li>幼儿园老师希望引导小朋友唱歌，于是她说：在小小的花园里面挖呀挖呀挖&amp;hellip;，老师此时停顿下来并对小朋友投去了期待的目光，小朋友按耐不住激动的心情，接下句：种小小的种子开小小的花——这就是&lt;strong>Prompt(提示)&lt;/strong>。&lt;/li>
&lt;li>幼儿园老师希望小朋友背诵五言绝句，于是她说：请背诵《鹅鹅鹅》，小朋友在老师又一次期待的目光下，整齐划一地背诵出&amp;quot;鹅鹅鹅曲项向天歌&amp;hellip;&amp;quot;——这就是&lt;strong>Instruction(指令)&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>我们了解了提示词的两大风格后，就要针对不同场景、不同意图，选择不同的提示词风格。&lt;/p>
&lt;h1 id="4小结">4.小结&lt;/h1>
&lt;p>提示词工程是一项热门技术，本文对提示词工程基本概念进行了阐述：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>提示词工程是开发和优化提示词的过程&lt;/strong>，包括选择合适的提示词、设计有效的提示策略，以及优化提示词的表达方式等。&lt;/li>
&lt;li>提示词三个基本原则：
&lt;ul>
&lt;li>&lt;strong>简洁、明确&lt;/strong>&lt;/li>
&lt;li>&lt;strong>迭代式提示词开发&lt;/strong>&lt;/li>
&lt;li>&lt;strong>选择合适的提示词风格&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记23-让我们一起来翻译吴恩达LLM课程</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BEllm%E8%AF%BE%E7%A8%8B/</link><pubDate>Thu, 02 Nov 2023 15:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BEllm%E8%AF%BE%E7%A8%8B/</guid><description>&lt;p>哈喽小伙伴，我是小牛，初次见面，请多关照。&lt;/p>
&lt;p>最近跟着猴哥的学习笔记各种手撸GPT，理解了LLM原理。&lt;/p>
&lt;p>但我跟GPT的交情好像只停留在say hello的程度，说好的能替代“表哥”、“码农”、“ppt经理”的能力呢？&lt;/p>
&lt;p>然后chatGPT跟我说，有个叫吴恩达的大咖，有好几门神课，理论+实践，易学易懂，学会了就可以在职场上大放异彩。那还犹豫什么，卷！&lt;/p>
&lt;p>这些课程都是英文视频，为了方便学习，我们准备把它们翻译成中文。&lt;/p>
&lt;p>欢迎感兴趣的小伙伴们一起来翻译。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BELLM%E8%AF%BE%E7%A8%8B/image-20231102181630937.png" alt="image-20231102181630937">&lt;/p>
&lt;h1 id="1已翻译的课程">1.已翻译的课程&lt;/h1>
&lt;ul>
&lt;li>《提示词工程 by 吴恩达》：https://jherculesqz.gitbook.io/chatgpt-prompt-engineering-for-developers-1&lt;/li>
&lt;li>《LangChain by 吴恩达》：https://jherculesqz.gitbook.io/langchain-by-wu-en-da&lt;/li>
&lt;/ul>
&lt;h2 id="11提示词工程-by-吴恩达简介">1.1.《提示词工程 by 吴恩达》简介&lt;/h2>
&lt;p>GPT神器虽好，但要会用。本课程将介绍：&lt;/p>
&lt;ul>
&lt;li>如何构建清晰、明确的提示词，有哪些技巧&lt;/li>
&lt;li>如何通过提示词发掘大语言模型总结、推理、转换以及生成文本的能力&lt;/li>
&lt;li>动手做一个自己的聊天机器人&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BELLM%E8%AF%BE%E7%A8%8B/image-20231102181807030.png" alt="image-20231102181807030">&lt;/p>
&lt;h2 id="12langchain-by-吴恩达简介">1.2.《LangChain by 吴恩达》简介&lt;/h2>
&lt;p>LangChain是开发LLM应用的开发框架，是当红炸子鸡。本课程将介绍：&lt;/p>
&lt;ul>
&lt;li>什么是LangChain&lt;/li>
&lt;li>LangChain有哪些Chain&lt;/li>
&lt;li>如何用LangChain做聊天模型、QA问答系统&lt;/li>
&lt;li>如何用LangChain的agent功能使能大模型的推理能力&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BELLM%E8%AF%BE%E7%A8%8B/image-20231102181929184.png" alt="image-20231102181929184">&lt;/p>
&lt;h1 id="2待翻译的课程">2.待翻译的课程&lt;/h1>
&lt;p>我们已经计划翻译的课程、论文有：&lt;/p>
&lt;ul>
&lt;li>《Finetuning Large Language Models》&lt;/li>
&lt;li>《Attention Is All You Need》&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>如果小伙伴们对其它LLM相关的文献、课程感兴趣，欢迎后台联系我们。&lt;/p>
&lt;blockquote>
&lt;p>免责声明：我们的翻译出于对技术的执着和个人兴趣，开源免费，仅供个人学习，不得商用。&lt;/p>
&lt;/blockquote></description></item><item><title>【chatGPT】学习笔记22-LangChain之Agent，对LLM的抽象5</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-langchain%E4%B9%8Bagent%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A15/</link><pubDate>Tue, 31 Oct 2023 15:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-langchain%E4%B9%8Bagent%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A15/</guid><description>&lt;p>业界目前的AI助手应用集中于两大功能：&lt;/p>
&lt;ul>
&lt;li>基于垂直领域知识的&lt;strong>智能问答&lt;/strong>&lt;/li>
&lt;li>基于垂直领域知识的&lt;strong>智能行动&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>在《【chatGPT】学习笔记21-LangChain之Retrieval，对LLM的抽象4》中，着重介绍了&lt;strong>智能问答&lt;/strong>依赖的技术点。&lt;/p>
&lt;p>本文重点介绍与&lt;strong>智能行动&lt;/strong>依赖的技术点。&lt;/p>
&lt;h1 id="1什么是react">1.什么是ReAct&lt;/h1>
&lt;h2 id="1基本概念">(1)基本概念&lt;/h2>
&lt;p>常见的LLM推理模式有两种：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Reason Only&lt;/strong>：比如CoT，利用提示词诱导LLM进行逻辑推理，进而回答偏数理逻辑类的问题。&lt;/li>
&lt;li>&lt;strong>Act Only&lt;/strong>：比如指令微调提到的，明确在问题中带有指令。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>ReAct&lt;/strong>提出了一种新的推理模式——&lt;strong>Reason + Act&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>LLM推理出&amp;rdquo;&lt;strong>把大象装进冰箱需要几步&lt;/strong>&amp;quot;，&lt;/li>
&lt;li>再针对待执行的每一步&lt;strong>选择合适的工具&lt;/strong>，&lt;/li>
&lt;li>在执行当前步骤后，通过环境的反馈，&lt;strong>决策下一步是什么&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-LangChain%E4%B9%8BAgent%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A15/image-20231031152602671.png" alt="image-20231031152602671">&lt;/p>
&lt;h2 id="2react优势">(2)ReAct优势&lt;/h2>
&lt;p>在论文《ReAct: Synergizing Reasoning and Acting in Language Models》中，阐述了ReAct的训练效果比&lt;code>Reson Only&lt;/code>和&lt;code>Act Only&lt;/code>都好：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-LangChain%E4%B9%8BAgent%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A15/image-20231031153243968.png" alt="image-20231031153243968">&lt;/p>
&lt;h2 id="3agents内部结构">(3)Agents内部结构&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>数据结构&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>AgentAction&lt;/code>：表示Agent应采取的行为。包含1个&lt;code>tool&lt;/code>属性和一个&lt;code>tool_input&lt;/code>属性，表示这个行为可采用的工具及工具输入。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>AgentFinish&lt;/code>：表示Agent完成后的返回结果。包含1个&lt;code>return_values&lt;/code>属性，字典类型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>intermediate_steps&lt;/code>：表示之前的Agent行为和返回结果。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Agent&lt;/strong>：智能体，可以分析出&amp;rdquo;&lt;strong>将大象放进冰箱里需要几步&lt;/strong>&amp;quot;，内部实现&lt;strong>依赖LLM的逻辑推理能力&lt;/strong>。它的输入包括：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>工具列表&lt;/strong>：&lt;code>List of available tools&lt;/code>，Agent可以用的工具集合。&lt;/li>
&lt;li>&lt;strong>用户输入&lt;/strong>：User input。&lt;/li>
&lt;li>&lt;strong>之前的Agent行为和返回结果&lt;/strong>：Any previously executed steps，就是&lt;code>intermediate_steps&lt;/code>对象。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tools&lt;/strong>：它是Agent某个行为可以使用的工具。每个工具需要有两个明确信息：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>工具的可用性&lt;/strong>：如&amp;quot;使用Google搜索&amp;quot;是一个工具，这个工具本身要真的可用、可靠。&lt;/li>
&lt;li>&lt;strong>工具的准确描述&lt;/strong>：对工具的作用有准确的描述，这段描述最终会变成提示词，帮助Agent知道要执行什么行为的时候，应该选择哪个工具更合适。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>AgentExecutor&lt;/strong>：Agent执行器。能够调用&lt;code>Agent&lt;/code>，不断获得下一步&lt;code>action(行为)&lt;/code>并执行。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>除了&lt;code>AgentExecutor&lt;/code>，LangChain还提供了实验性质的其它Agent执行器：&lt;/p>
&lt;ul>
&lt;li>Plan-and-execute Agent&lt;/li>
&lt;li>Baby AGI&lt;/li>
&lt;li>Auto GPT&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>AgentExecutor&lt;/code>核心代码如下：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="n">next_action&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">agent&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_action&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">while&lt;/span> &lt;span class="n">next_action&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="n">AgentFinish&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">observation&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">next_action&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">next_action&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">agent&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_action&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">next_action&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">observation&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">next_action&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="4langchain已经支持的agent和tool列表">(4)LangChain已经支持的Agent和Tool列表&lt;/h2>
&lt;ul>
&lt;li>LangChain已经提供了很多&lt;code>Agent&lt;/code>和&lt;code>Tools&lt;/code>，具体如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-LangChain%E4%B9%8BAgent%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A15/image-20231031151549996.png" alt="image-20231031151549996">&lt;/p>
&lt;h1 id="2代码示例">2.代码示例&lt;/h1>
&lt;p>&lt;code>Agent&lt;/code>是当前LLM App的一个热点方向，展开阐述会有很多的内容。本文仅通过1个经典问题代码示例，为各位小伙伴建立&lt;code>Agent&lt;/code>的宏观认识。后续本专栏再详细阐述&lt;code>Agent&lt;/code>开发的内容。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>问题&lt;/strong>：周杰伦的老婆是谁？她现在的年龄的0.43次方等于多少？&lt;/li>
&lt;li>&lt;strong>代码&lt;/strong>：
&lt;ul>
&lt;li>创建了&lt;code>tools&lt;/code>工具集对象&lt;/li>
&lt;li>初始化了&lt;code>agent&lt;/code>对象，&lt;code>agent&lt;/code>对象包含1个&lt;code>LLM&lt;/code>和1个&lt;code>tools&lt;/code>对象&lt;/li>
&lt;li>执行&lt;code>agent&lt;/code>对象的&lt;code>run&lt;/code>方法，由&lt;code>LLM&lt;/code>自行开展行动，直到获得最终答案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>运行结果分析&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>&lt;code>LLM&lt;/code>首先明确任务目标&lt;/strong>：背后应该是由一个复杂的提示词驱动的。&lt;/li>
&lt;li>&lt;strong>&lt;code>LLM&lt;/code>再分解出三个步骤&lt;/strong>：每个步骤的输出，都会作为下一个步骤的输入。&lt;/li>
&lt;li>&lt;strong>&lt;code>LLM&lt;/code>最后汇总结果&lt;/strong>：&lt;code>LLM&lt;/code>判断如果达成目标，则给出最终答案，并终止执行。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-LangChain%E4%B9%8BAgent%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A15/image-20231031154927730.png" alt="image-20231031154927730">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-LangChain%E4%B9%8BAgent%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A15/image-20231031160426352.png" alt="image-20231031160426352">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文关键要点如下：&lt;/p>
&lt;ul>
&lt;li>简述了&lt;code>Agent&lt;/code>理论基础&lt;code>ReAct&lt;/code>&lt;/li>
&lt;li>描述了论文&lt;code>ReAct: Synergizing Reasoning and Acting in Language Models&lt;/code>中的实验现象、&lt;code>ReAct&lt;/code>的优势。&lt;/li>
&lt;li>给出了一个有关&lt;strong>大语言模型不知道的有时效性的知识&lt;/strong>的问题，&lt;code>Agent&lt;/code>如何&lt;strong>利用大语言模型的推理能力&lt;/strong>解决此类问题的代码示例。&lt;/li>
&lt;/ul>
&lt;p>如果说上篇文章的&lt;code>Retrieval&lt;/code>帮助AI助手具备了&lt;strong>智能问答&lt;/strong>能力，这篇文章的&lt;code>Agent&lt;/code>则帮助AI助手实现了&lt;strong>智能行动&lt;/strong>。&lt;/p>
&lt;p>所以，&lt;code>Agent&lt;/code>这个方向是目前开发LLM应用的诸多厂商的关注热点，这里还有一些未及展开讨论的内容：&lt;/p>
&lt;ul>
&lt;li>如何自定义1个满足垂直领域的&lt;strong>自定义Agent&lt;/strong>？&lt;/li>
&lt;li>如何自定义1组满足垂直领域的&lt;strong>自定义Tool&lt;/strong>？&lt;/li>
&lt;/ul>
&lt;p>这些高级话题，留待本专栏后续分解，敬请期待。&lt;/p></description></item><item><title>【chatGPT】学习笔记21-LangChain之Retrieval，对LLM的抽象4</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-langchain%E4%B9%8Bretrieval%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A14/</link><pubDate>Mon, 30 Oct 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-langchain%E4%B9%8Bretrieval%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A14/</guid><description>&lt;p>本专栏通过解读了Transformer模型，实现简版GPT后，帮大家建立了对NLP原理、关键技术的理解。&lt;/p>
&lt;p>接下来，我们再关注一下应用层面的技术——如何开发LLM App。&lt;/p>
&lt;p>前面我们了解了LangChain的三大重要模块**&amp;ldquo;Model I/O、Memory、Chain&amp;rdquo;**，具体如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>LangChain的Model I/O&lt;/strong>：详见《【chatGPT】学习笔记10-LangChain之Model I/O，对LLM的抽象1》&lt;/li>
&lt;li>&lt;strong>LangChain的Memory&lt;/strong>：详见《【chatGPT】学习笔记14-LangChain之Memory，对LLM的抽象2》&lt;/li>
&lt;li>&lt;strong>LangChain的Chain&lt;/strong>：详见《【chatGPT】学习笔记15-LangChain之Chain，对LLM的抽象3》&lt;/li>
&lt;/ul>
&lt;p>本文继续展示LangChain的第四大模块&amp;rdquo;&lt;strong>Retrieval&lt;/strong>&amp;quot;。&lt;/p>
&lt;blockquote>
&lt;p>LangChain曾经把此模块称为Data Connection，其实更为贴切。&lt;/p>
&lt;/blockquote>
&lt;h1 id="1整体流程">1.整体流程&lt;/h1>
&lt;p>如果我们要开发一个基于LLM的AI问答系统，整体流程如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>文档加载&lt;/strong>：加载各类文档。&lt;/li>
&lt;li>&lt;strong>文档转换&lt;/strong>：将文档分割为一段段的文本。&lt;/li>
&lt;li>&lt;strong>文档向量化&lt;/strong>：将文本进行词嵌入，并存储于向量数据库。&lt;/li>
&lt;li>&lt;strong>文档检索&lt;/strong>：针对用户的问题进行向量检索。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231030140913593.png" alt="image-20231030140913593">&lt;/p>
&lt;p>我们接下来看看，LangChain如何支撑上述整体流程。&lt;/p>
&lt;h1 id="2文档加载器">2.文档加载器&lt;/h1>
&lt;h2 id="21基本概念">2.1.基本概念&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>LangChain提供的文档加载器(&lt;code>Document loaders&lt;/code>)，支持从不同数据源加载数据，最终输出为&lt;code>Document&lt;/code>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LangChain的厉害之处在于：它支持了100+的数据源，丰富程度基本覆盖了所有的数据源。具体支持的Loader如下：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231030143143187.png" alt="image-20231030143143187">&lt;/p>
&lt;p>接下来，我们通过阅读LangChain的源码，深入理解文档加载器。&lt;/p>
&lt;h2 id="22document">2.2.Document&lt;/h2>
&lt;h3 id="1源码解读">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;code>Document&lt;/code>类是文档加载器的输出。&lt;/li>
&lt;li>&lt;code>Document&lt;/code>类的代码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/schema/document.py&lt;/li>
&lt;li>&lt;code>Document&lt;/code>类的关键代码如下：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">Document&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Serializable&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Class for storing a piece of text and associated metadata.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">page_content&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;String text.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="err">文档内容&lt;/span>
&lt;span class="n">metadata&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">dict&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">default_factory&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">dict&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Arbitrary metadata about the page content (e.g., source, relationships to other
&lt;/span>&lt;span class="s2"> documents, etc.).
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="nb">type&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Literal&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;Document&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Document&amp;#34;&lt;/span>
&lt;span class="nd">@classmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">is_lc_serializable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">cls&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Return whether this class is serializable.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">True&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="23baseloader">2.3.BaseLoader&lt;/h2>
&lt;h3 id="1源码解读-1">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;code>BaseLoader&lt;/code>类是各种不同&lt;code>Loader&lt;/code>的基类。&lt;/li>
&lt;li>&lt;code>BaseLoader&lt;/code>类的代码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/document_loaders/base.py&lt;/li>
&lt;li>&lt;code>BaseLoader&lt;/code>类的关键代码如下：关键方法是&lt;code>load&lt;/code>、&lt;code>load_and_split&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">BaseLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ABC&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Interface for Document Loader.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Implementations should implement the lazy-loading method using generators
&lt;/span>&lt;span class="s2"> to avoid loading all Documents into memory at once.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> The `load` method will remain as is for backwards compatibility, but its
&lt;/span>&lt;span class="s2"> implementation should be just `list(self.lazy_load())`.
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="c1"># Sub-classes should implement this method&lt;/span>
&lt;span class="c1"># as return list(self.lazy_load()).&lt;/span>
&lt;span class="c1"># This method returns a List which is materialized in memory.&lt;/span>
&lt;span class="nd">@abstractmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load data into Document objects.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="err">加载数据并将其转换为文档对象&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load_and_split&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">text_splitter&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">TextSplitter&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load Documents and split into chunks. Chunks are returned as Documents.
&lt;/span>&lt;span class="s2"> 加载文档并分割成块
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Args:
&lt;/span>&lt;span class="s2"> text_splitter: TextSplitter instance to use for splitting documents.
&lt;/span>&lt;span class="s2"> Defaults to RecursiveCharacterTextSplitter.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Returns:
&lt;/span>&lt;span class="s2"> List of Documents.
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">text_splitter&lt;/span> &lt;span class="ow">is&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_text_splitter&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">TextSplitter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">RecursiveCharacterTextSplitter&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_text_splitter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">text_splitter&lt;/span>
&lt;span class="n">docs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">_text_splitter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split_documents&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">docs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Attention: This method will be upgraded into an abstractmethod once it&amp;#39;s&lt;/span>
&lt;span class="c1"># implemented in all the existing subclasses.&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">lazy_load&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Iterator&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;A lazy loader for Documents.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">NotImplementedError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;{self.__class__.__name__} does not implement lazy_load()&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="24textloader">2.4.TextLoader&lt;/h2>
&lt;h3 id="1源码解读-2">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;code>TextLoader&lt;/code>类是用于加载文本的Loader，继承于&lt;code>BaseLoader&lt;/code>。&lt;/li>
&lt;li>&lt;code>TextLoader&lt;/code>类的代码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/document_loaders/text.py&lt;/li>
&lt;li>&lt;code>TextLoader&lt;/code>类的关键代码如下：关键方法是实现了自己的&lt;code>load&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">TextLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BaseLoader&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load text file.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Args:
&lt;/span>&lt;span class="s2"> file_path: Path to the file to load.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> encoding: File encoding to use. If `None`, the file will be loaded
&lt;/span>&lt;span class="s2"> with the default system encoding.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> autodetect_encoding: Whether to try to autodetect the file encoding
&lt;/span>&lt;span class="s2"> if the specified encoding fails.
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">file_path&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">encoding&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">autodetect_encoding&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Initialize with file path.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">file_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">file_path&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encoding&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">encoding&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">autodetect_encoding&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">autodetect_encoding&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load from file path.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">file_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">encoding&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encoding&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">UnicodeDecodeError&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">autodetect_encoding&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">detected_encodings&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">detect_file_encodings&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">file_path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">encoding&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">detected_encodings&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">debug&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Trying encoding: {encoding.encoding}&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">file_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">encoding&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">encoding&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encoding&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">break&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">UnicodeDecodeError&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">continue&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">RuntimeError&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Error loading {self.file_path}&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="kn">from&lt;/span> &lt;span class="nn">e&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">Exception&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">RuntimeError&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Error loading {self.file_path}&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="kn">from&lt;/span> &lt;span class="nn">e&lt;/span>
&lt;span class="n">metadata&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;source&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">file_path&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">page_content&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metadata&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">metadata&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2代码示例">(2)代码示例&lt;/h3>
&lt;ul>
&lt;li>构造TextLoader，读取txt文件，返回docs对象。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031071416742.png" alt="image-20231031071416742">&lt;/p>
&lt;ul>
&lt;li>观测docs对象&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031071531911.png" alt="image-20231031071531911">&lt;/p>
&lt;h2 id="25arxivloader">2.5.ArxivLoader&lt;/h2>
&lt;h3 id="1源码解读-3">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;code>ArxivLoader&lt;/code>类是用于加载Arxiv的Loader，继承于&lt;code>BaseLoader&lt;/code>。&lt;/li>
&lt;li>&lt;code>ArxivLoader&lt;/code>类的代码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/document_loaders/arxiv.py&lt;/li>
&lt;li>&lt;code>ArxivLoader&lt;/code>类的关键代码如下：关键方法是实现了自己的&lt;code>load&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">ArxivLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BaseLoader&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load a query result from `Arxiv`.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> The loader converts the original PDF format into the text.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Args:
&lt;/span>&lt;span class="s2"> Supports all arguments of `ArxivAPIWrapper`.
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">query&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">doc_content_chars_max&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Any&lt;/span>
&lt;span class="p">):&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">query&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">query&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">client&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ArxivAPIWrapper&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">doc_content_chars_max&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">doc_content_chars_max&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">client&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">query&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2代码示例-1">(2)代码示例&lt;/h3>
&lt;ul>
&lt;li>读取指定版本号的论文，得到docs对象，docs对象包含了指定版本号的相关论文信息。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031071610543.png" alt="image-20231031071610543">&lt;/p>
&lt;h2 id="26unstructuredurlloader">2.6.UnstructuredURLLoader&lt;/h2>
&lt;h3 id="1源码解读-4">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;code>UnstructuredURLLoader&lt;/code>类是用于加载指定URL的Loader，继承于&lt;code>BaseLoader&lt;/code>。&lt;/li>
&lt;li>&lt;code>UnstructuredURLLoader&lt;/code>类的代码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/document_loaders/url.py&lt;/li>
&lt;li>&lt;code>UnstructuredURLLoader&lt;/code>类的关键代码如下：关键方法是实现了自己的&lt;code>load&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt"> 10
&lt;/span>&lt;span class="lnt"> 11
&lt;/span>&lt;span class="lnt"> 12
&lt;/span>&lt;span class="lnt"> 13
&lt;/span>&lt;span class="lnt"> 14
&lt;/span>&lt;span class="lnt"> 15
&lt;/span>&lt;span class="lnt"> 16
&lt;/span>&lt;span class="lnt"> 17
&lt;/span>&lt;span class="lnt"> 18
&lt;/span>&lt;span class="lnt"> 19
&lt;/span>&lt;span class="lnt"> 20
&lt;/span>&lt;span class="lnt"> 21
&lt;/span>&lt;span class="lnt"> 22
&lt;/span>&lt;span class="lnt"> 23
&lt;/span>&lt;span class="lnt"> 24
&lt;/span>&lt;span class="lnt"> 25
&lt;/span>&lt;span class="lnt"> 26
&lt;/span>&lt;span class="lnt"> 27
&lt;/span>&lt;span class="lnt"> 28
&lt;/span>&lt;span class="lnt"> 29
&lt;/span>&lt;span class="lnt"> 30
&lt;/span>&lt;span class="lnt"> 31
&lt;/span>&lt;span class="lnt"> 32
&lt;/span>&lt;span class="lnt"> 33
&lt;/span>&lt;span class="lnt"> 34
&lt;/span>&lt;span class="lnt"> 35
&lt;/span>&lt;span class="lnt"> 36
&lt;/span>&lt;span class="lnt"> 37
&lt;/span>&lt;span class="lnt"> 38
&lt;/span>&lt;span class="lnt"> 39
&lt;/span>&lt;span class="lnt"> 40
&lt;/span>&lt;span class="lnt"> 41
&lt;/span>&lt;span class="lnt"> 42
&lt;/span>&lt;span class="lnt"> 43
&lt;/span>&lt;span class="lnt"> 44
&lt;/span>&lt;span class="lnt"> 45
&lt;/span>&lt;span class="lnt"> 46
&lt;/span>&lt;span class="lnt"> 47
&lt;/span>&lt;span class="lnt"> 48
&lt;/span>&lt;span class="lnt"> 49
&lt;/span>&lt;span class="lnt"> 50
&lt;/span>&lt;span class="lnt"> 51
&lt;/span>&lt;span class="lnt"> 52
&lt;/span>&lt;span class="lnt"> 53
&lt;/span>&lt;span class="lnt"> 54
&lt;/span>&lt;span class="lnt"> 55
&lt;/span>&lt;span class="lnt"> 56
&lt;/span>&lt;span class="lnt"> 57
&lt;/span>&lt;span class="lnt"> 58
&lt;/span>&lt;span class="lnt"> 59
&lt;/span>&lt;span class="lnt"> 60
&lt;/span>&lt;span class="lnt"> 61
&lt;/span>&lt;span class="lnt"> 62
&lt;/span>&lt;span class="lnt"> 63
&lt;/span>&lt;span class="lnt"> 64
&lt;/span>&lt;span class="lnt"> 65
&lt;/span>&lt;span class="lnt"> 66
&lt;/span>&lt;span class="lnt"> 67
&lt;/span>&lt;span class="lnt"> 68
&lt;/span>&lt;span class="lnt"> 69
&lt;/span>&lt;span class="lnt"> 70
&lt;/span>&lt;span class="lnt"> 71
&lt;/span>&lt;span class="lnt"> 72
&lt;/span>&lt;span class="lnt"> 73
&lt;/span>&lt;span class="lnt"> 74
&lt;/span>&lt;span class="lnt"> 75
&lt;/span>&lt;span class="lnt"> 76
&lt;/span>&lt;span class="lnt"> 77
&lt;/span>&lt;span class="lnt"> 78
&lt;/span>&lt;span class="lnt"> 79
&lt;/span>&lt;span class="lnt"> 80
&lt;/span>&lt;span class="lnt"> 81
&lt;/span>&lt;span class="lnt"> 82
&lt;/span>&lt;span class="lnt"> 83
&lt;/span>&lt;span class="lnt"> 84
&lt;/span>&lt;span class="lnt"> 85
&lt;/span>&lt;span class="lnt"> 86
&lt;/span>&lt;span class="lnt"> 87
&lt;/span>&lt;span class="lnt"> 88
&lt;/span>&lt;span class="lnt"> 89
&lt;/span>&lt;span class="lnt"> 90
&lt;/span>&lt;span class="lnt"> 91
&lt;/span>&lt;span class="lnt"> 92
&lt;/span>&lt;span class="lnt"> 93
&lt;/span>&lt;span class="lnt"> 94
&lt;/span>&lt;span class="lnt"> 95
&lt;/span>&lt;span class="lnt"> 96
&lt;/span>&lt;span class="lnt"> 97
&lt;/span>&lt;span class="lnt"> 98
&lt;/span>&lt;span class="lnt"> 99
&lt;/span>&lt;span class="lnt">100
&lt;/span>&lt;span class="lnt">101
&lt;/span>&lt;span class="lnt">102
&lt;/span>&lt;span class="lnt">103
&lt;/span>&lt;span class="lnt">104
&lt;/span>&lt;span class="lnt">105
&lt;/span>&lt;span class="lnt">106
&lt;/span>&lt;span class="lnt">107
&lt;/span>&lt;span class="lnt">108
&lt;/span>&lt;span class="lnt">109
&lt;/span>&lt;span class="lnt">110
&lt;/span>&lt;span class="lnt">111
&lt;/span>&lt;span class="lnt">112
&lt;/span>&lt;span class="lnt">113
&lt;/span>&lt;span class="lnt">114
&lt;/span>&lt;span class="lnt">115
&lt;/span>&lt;span class="lnt">116
&lt;/span>&lt;span class="lnt">117
&lt;/span>&lt;span class="lnt">118
&lt;/span>&lt;span class="lnt">119
&lt;/span>&lt;span class="lnt">120
&lt;/span>&lt;span class="lnt">121
&lt;/span>&lt;span class="lnt">122
&lt;/span>&lt;span class="lnt">123
&lt;/span>&lt;span class="lnt">124
&lt;/span>&lt;span class="lnt">125
&lt;/span>&lt;span class="lnt">126
&lt;/span>&lt;span class="lnt">127
&lt;/span>&lt;span class="lnt">128
&lt;/span>&lt;span class="lnt">129
&lt;/span>&lt;span class="lnt">130
&lt;/span>&lt;span class="lnt">131
&lt;/span>&lt;span class="lnt">132
&lt;/span>&lt;span class="lnt">133
&lt;/span>&lt;span class="lnt">134
&lt;/span>&lt;span class="lnt">135
&lt;/span>&lt;span class="lnt">136
&lt;/span>&lt;span class="lnt">137
&lt;/span>&lt;span class="lnt">138
&lt;/span>&lt;span class="lnt">139
&lt;/span>&lt;span class="lnt">140
&lt;/span>&lt;span class="lnt">141
&lt;/span>&lt;span class="lnt">142
&lt;/span>&lt;span class="lnt">143
&lt;/span>&lt;span class="lnt">144
&lt;/span>&lt;span class="lnt">145
&lt;/span>&lt;span class="lnt">146
&lt;/span>&lt;span class="lnt">147
&lt;/span>&lt;span class="lnt">148
&lt;/span>&lt;span class="lnt">149
&lt;/span>&lt;span class="lnt">150
&lt;/span>&lt;span class="lnt">151
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">UnstructuredURLLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BaseLoader&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load files from remote URLs using `Unstructured`.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Use the unstructured partition function to detect the MIME type
&lt;/span>&lt;span class="s2"> and route the file to the appropriate partitioner.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> You can run the loader in one of two modes: &amp;#34;single&amp;#34; and &amp;#34;elements&amp;#34;.
&lt;/span>&lt;span class="s2"> If you use &amp;#34;single&amp;#34; mode, the document will be returned as a single
&lt;/span>&lt;span class="s2"> langchain Document object. If you use &amp;#34;elements&amp;#34; mode, the unstructured
&lt;/span>&lt;span class="s2"> library will split the document into elements such as Title and NarrativeText.
&lt;/span>&lt;span class="s2"> You can pass in additional unstructured kwargs after mode to apply
&lt;/span>&lt;span class="s2"> different unstructured settings.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Examples
&lt;/span>&lt;span class="s2"> --------
&lt;/span>&lt;span class="s2"> from langchain.document_loaders import UnstructuredURLLoader
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> loader = UnstructuredURLLoader(
&lt;/span>&lt;span class="s2"> ursl=[&amp;#34;&amp;lt;url-1&amp;gt;&amp;#34;, &amp;#34;&amp;lt;url-2&amp;gt;&amp;#34;], mode=&amp;#34;elements&amp;#34;, strategy=&amp;#34;fast&amp;#34;,
&lt;/span>&lt;span class="s2"> )
&lt;/span>&lt;span class="s2"> docs = loader.load()
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> References
&lt;/span>&lt;span class="s2"> ----------
&lt;/span>&lt;span class="s2"> https://unstructured-io.github.io/unstructured/bricks.html#partition
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">urls&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">],&lt;/span>
&lt;span class="n">continue_on_failure&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">mode&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;single&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">show_progress_bar&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="o">**&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Initialize with file path.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">unstructured&lt;/span> &lt;span class="c1"># noqa:F401&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">unstructured.__version__&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">__version__&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">__unstructured_version__&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">__unstructured_version__&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">ImportError&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">ImportError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s2">&amp;#34;unstructured package not found, please install it with &amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;`pip install unstructured`&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_validate_mode&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mode&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mode&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mode&lt;/span>
&lt;span class="n">headers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">unstructured_kwargs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pop&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;headers&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{})&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">headers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keys&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">warn_about_headers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_non_html_available&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="n">warn_about_headers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_headers_available_for_non_html&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">warn_about_headers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_headers_available_for_html&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">warn_about_headers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">warning&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s2">&amp;#34;You are using an old version of unstructured. &amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;The headers parameter is ignored&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">urls&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">urls&lt;/span>
&lt;span class="err">待加载网页&lt;/span> &lt;span class="n">URL&lt;/span> &lt;span class="err">列表&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">continue_on_failure&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">continue_on_failure&lt;/span>
&lt;span class="err">默认&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="err">，某个&lt;/span>&lt;span class="n">URL加载失败后&lt;/span>&lt;span class="err">，是否继续&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">headers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">headers&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">unstructured_kwargs&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show_progress_bar&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">show_progress_bar&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">_validate_mode&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">mode&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_valid_modes&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;single&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;elements&amp;#34;&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">mode&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">_valid_modes&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">ValueError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Got {mode} for `mode`, but should be one of `{_valid_modes}`&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">__is_headers_available_for_html&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;-&amp;#34;&lt;/span>&lt;span class="p">)[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">tuple&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">_unstructured_version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;.&amp;#34;&lt;/span>&lt;span class="p">)])&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">__is_headers_available_for_non_html&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;-&amp;#34;&lt;/span>&lt;span class="p">)[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">tuple&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">_unstructured_version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;.&amp;#34;&lt;/span>&lt;span class="p">)])&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">__is_non_html_available&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;-&amp;#34;&lt;/span>&lt;span class="p">)[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">tuple&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">_unstructured_version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;.&amp;#34;&lt;/span>&lt;span class="p">)])&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load file.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">unstructured.partition.auto&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">partition&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">unstructured.partition.html&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">partition_html&lt;/span>
&lt;span class="n">docs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show_progress_bar&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">tqdm&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">tqdm&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">ImportError&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">ImportError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s2">&amp;#34;Package tqdm must be installed if show_progress_bar=True. &amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;Please install with &amp;#39;pip install tqdm&amp;#39; or set &amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;show_progress_bar=False.&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="kn">from&lt;/span> &lt;span class="nn">e&lt;/span>
&lt;span class="n">urls&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tqdm&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">urls&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">urls&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">urls&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">url&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">urls&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_non_html_available&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_headers_available_for_non_html&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="n">elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">partition&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">url&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">headers&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">headers&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">partition&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_headers_available_for_html&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="n">elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">partition_html&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">url&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">headers&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">headers&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">partition_html&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">Exception&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">continue_on_failure&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">error&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Error fetching or processing {url}, exception: {e}&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">continue&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="n">e&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mode&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;single&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">el&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">el&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">elements&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">metadata&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;source&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">url&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="n">docs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">page_content&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metadata&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">metadata&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mode&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;elements&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">element&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">elements&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">metadata&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metadata&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">to_dict&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">metadata&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;category&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">category&lt;/span>
&lt;span class="n">docs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">page_content&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">metadata&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">metadata&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">docs&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2代码示例-2">(2)代码示例&lt;/h3>
&lt;ul>
&lt;li>读取指定URL网页，返回data对象&lt;/li>
&lt;li>data对象包含了网页中各类元素信息&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031071807666.png" alt="image-20231031071807666">&lt;/p>
&lt;h1 id="3文档转换器">3.文档转换器&lt;/h1>
&lt;h2 id="31基本概念">3.1.基本概念&lt;/h2>
&lt;ul>
&lt;li>LangChain提供的文档转器(&lt;code>Document transformers&lt;/code>)，支持用不同的分割方法，将&lt;code>Loader&lt;/code>获取的文档进行分割。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031072618565.png" alt="image-20231031072618565">&lt;/p>
&lt;p>这些文档转换器并不复杂，需要实操熟练掌握，本文不赘述，重点演示一下最常用的&lt;code>RecursiveCharacterTextSplitter&lt;/code>。&lt;/p>
&lt;h2 id="32recursivecharactertextsplitter">3.2.RecursiveCharacterTextSplitter&lt;/h2>
&lt;h3 id="1源码解读-5">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>作用：可输入字符列表作为切块分隔符，并根据第一个字符进行切块。如果切块太大，则使用下一个字符切块，以此类推。&lt;/li>
&lt;li>源码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/text_splitter.py&lt;/li>
&lt;li>核心源码如下：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt"> 10
&lt;/span>&lt;span class="lnt"> 11
&lt;/span>&lt;span class="lnt"> 12
&lt;/span>&lt;span class="lnt"> 13
&lt;/span>&lt;span class="lnt"> 14
&lt;/span>&lt;span class="lnt"> 15
&lt;/span>&lt;span class="lnt"> 16
&lt;/span>&lt;span class="lnt"> 17
&lt;/span>&lt;span class="lnt"> 18
&lt;/span>&lt;span class="lnt"> 19
&lt;/span>&lt;span class="lnt"> 20
&lt;/span>&lt;span class="lnt"> 21
&lt;/span>&lt;span class="lnt"> 22
&lt;/span>&lt;span class="lnt"> 23
&lt;/span>&lt;span class="lnt"> 24
&lt;/span>&lt;span class="lnt"> 25
&lt;/span>&lt;span class="lnt"> 26
&lt;/span>&lt;span class="lnt"> 27
&lt;/span>&lt;span class="lnt"> 28
&lt;/span>&lt;span class="lnt"> 29
&lt;/span>&lt;span class="lnt"> 30
&lt;/span>&lt;span class="lnt"> 31
&lt;/span>&lt;span class="lnt"> 32
&lt;/span>&lt;span class="lnt"> 33
&lt;/span>&lt;span class="lnt"> 34
&lt;/span>&lt;span class="lnt"> 35
&lt;/span>&lt;span class="lnt"> 36
&lt;/span>&lt;span class="lnt"> 37
&lt;/span>&lt;span class="lnt"> 38
&lt;/span>&lt;span class="lnt"> 39
&lt;/span>&lt;span class="lnt"> 40
&lt;/span>&lt;span class="lnt"> 41
&lt;/span>&lt;span class="lnt"> 42
&lt;/span>&lt;span class="lnt"> 43
&lt;/span>&lt;span class="lnt"> 44
&lt;/span>&lt;span class="lnt"> 45
&lt;/span>&lt;span class="lnt"> 46
&lt;/span>&lt;span class="lnt"> 47
&lt;/span>&lt;span class="lnt"> 48
&lt;/span>&lt;span class="lnt"> 49
&lt;/span>&lt;span class="lnt"> 50
&lt;/span>&lt;span class="lnt"> 51
&lt;/span>&lt;span class="lnt"> 52
&lt;/span>&lt;span class="lnt"> 53
&lt;/span>&lt;span class="lnt"> 54
&lt;/span>&lt;span class="lnt"> 55
&lt;/span>&lt;span class="lnt"> 56
&lt;/span>&lt;span class="lnt"> 57
&lt;/span>&lt;span class="lnt"> 58
&lt;/span>&lt;span class="lnt"> 59
&lt;/span>&lt;span class="lnt"> 60
&lt;/span>&lt;span class="lnt"> 61
&lt;/span>&lt;span class="lnt"> 62
&lt;/span>&lt;span class="lnt"> 63
&lt;/span>&lt;span class="lnt"> 64
&lt;/span>&lt;span class="lnt"> 65
&lt;/span>&lt;span class="lnt"> 66
&lt;/span>&lt;span class="lnt"> 67
&lt;/span>&lt;span class="lnt"> 68
&lt;/span>&lt;span class="lnt"> 69
&lt;/span>&lt;span class="lnt"> 70
&lt;/span>&lt;span class="lnt"> 71
&lt;/span>&lt;span class="lnt"> 72
&lt;/span>&lt;span class="lnt"> 73
&lt;/span>&lt;span class="lnt"> 74
&lt;/span>&lt;span class="lnt"> 75
&lt;/span>&lt;span class="lnt"> 76
&lt;/span>&lt;span class="lnt"> 77
&lt;/span>&lt;span class="lnt"> 78
&lt;/span>&lt;span class="lnt"> 79
&lt;/span>&lt;span class="lnt"> 80
&lt;/span>&lt;span class="lnt"> 81
&lt;/span>&lt;span class="lnt"> 82
&lt;/span>&lt;span class="lnt"> 83
&lt;/span>&lt;span class="lnt"> 84
&lt;/span>&lt;span class="lnt"> 85
&lt;/span>&lt;span class="lnt"> 86
&lt;/span>&lt;span class="lnt"> 87
&lt;/span>&lt;span class="lnt"> 88
&lt;/span>&lt;span class="lnt"> 89
&lt;/span>&lt;span class="lnt"> 90
&lt;/span>&lt;span class="lnt"> 91
&lt;/span>&lt;span class="lnt"> 92
&lt;/span>&lt;span class="lnt"> 93
&lt;/span>&lt;span class="lnt"> 94
&lt;/span>&lt;span class="lnt"> 95
&lt;/span>&lt;span class="lnt"> 96
&lt;/span>&lt;span class="lnt"> 97
&lt;/span>&lt;span class="lnt"> 98
&lt;/span>&lt;span class="lnt"> 99
&lt;/span>&lt;span class="lnt">100
&lt;/span>&lt;span class="lnt">101
&lt;/span>&lt;span class="lnt">102
&lt;/span>&lt;span class="lnt">103
&lt;/span>&lt;span class="lnt">104
&lt;/span>&lt;span class="lnt">105
&lt;/span>&lt;span class="lnt">106
&lt;/span>&lt;span class="lnt">107
&lt;/span>&lt;span class="lnt">108
&lt;/span>&lt;span class="lnt">109
&lt;/span>&lt;span class="lnt">110
&lt;/span>&lt;span class="lnt">111
&lt;/span>&lt;span class="lnt">112
&lt;/span>&lt;span class="lnt">113
&lt;/span>&lt;span class="lnt">114
&lt;/span>&lt;span class="lnt">115
&lt;/span>&lt;span class="lnt">116
&lt;/span>&lt;span class="lnt">117
&lt;/span>&lt;span class="lnt">118
&lt;/span>&lt;span class="lnt">119
&lt;/span>&lt;span class="lnt">120
&lt;/span>&lt;span class="lnt">121
&lt;/span>&lt;span class="lnt">122
&lt;/span>&lt;span class="lnt">123
&lt;/span>&lt;span class="lnt">124
&lt;/span>&lt;span class="lnt">125
&lt;/span>&lt;span class="lnt">126
&lt;/span>&lt;span class="lnt">127
&lt;/span>&lt;span class="lnt">128
&lt;/span>&lt;span class="lnt">129
&lt;/span>&lt;span class="lnt">130
&lt;/span>&lt;span class="lnt">131
&lt;/span>&lt;span class="lnt">132
&lt;/span>&lt;span class="lnt">133
&lt;/span>&lt;span class="lnt">134
&lt;/span>&lt;span class="lnt">135
&lt;/span>&lt;span class="lnt">136
&lt;/span>&lt;span class="lnt">137
&lt;/span>&lt;span class="lnt">138
&lt;/span>&lt;span class="lnt">139
&lt;/span>&lt;span class="lnt">140
&lt;/span>&lt;span class="lnt">141
&lt;/span>&lt;span class="lnt">142
&lt;/span>&lt;span class="lnt">143
&lt;/span>&lt;span class="lnt">144
&lt;/span>&lt;span class="lnt">145
&lt;/span>&lt;span class="lnt">146
&lt;/span>&lt;span class="lnt">147
&lt;/span>&lt;span class="lnt">148
&lt;/span>&lt;span class="lnt">149
&lt;/span>&lt;span class="lnt">150
&lt;/span>&lt;span class="lnt">151
&lt;/span>&lt;span class="lnt">152
&lt;/span>&lt;span class="lnt">153
&lt;/span>&lt;span class="lnt">154
&lt;/span>&lt;span class="lnt">155
&lt;/span>&lt;span class="lnt">156
&lt;/span>&lt;span class="lnt">157
&lt;/span>&lt;span class="lnt">158
&lt;/span>&lt;span class="lnt">159
&lt;/span>&lt;span class="lnt">160
&lt;/span>&lt;span class="lnt">161
&lt;/span>&lt;span class="lnt">162
&lt;/span>&lt;span class="lnt">163
&lt;/span>&lt;span class="lnt">164
&lt;/span>&lt;span class="lnt">165
&lt;/span>&lt;span class="lnt">166
&lt;/span>&lt;span class="lnt">167
&lt;/span>&lt;span class="lnt">168
&lt;/span>&lt;span class="lnt">169
&lt;/span>&lt;span class="lnt">170
&lt;/span>&lt;span class="lnt">171
&lt;/span>&lt;span class="lnt">172
&lt;/span>&lt;span class="lnt">173
&lt;/span>&lt;span class="lnt">174
&lt;/span>&lt;span class="lnt">175
&lt;/span>&lt;span class="lnt">176
&lt;/span>&lt;span class="lnt">177
&lt;/span>&lt;span class="lnt">178
&lt;/span>&lt;span class="lnt">179
&lt;/span>&lt;span class="lnt">180
&lt;/span>&lt;span class="lnt">181
&lt;/span>&lt;span class="lnt">182
&lt;/span>&lt;span class="lnt">183
&lt;/span>&lt;span class="lnt">184
&lt;/span>&lt;span class="lnt">185
&lt;/span>&lt;span class="lnt">186
&lt;/span>&lt;span class="lnt">187
&lt;/span>&lt;span class="lnt">188
&lt;/span>&lt;span class="lnt">189
&lt;/span>&lt;span class="lnt">190
&lt;/span>&lt;span class="lnt">191
&lt;/span>&lt;span class="lnt">192
&lt;/span>&lt;span class="lnt">193
&lt;/span>&lt;span class="lnt">194
&lt;/span>&lt;span class="lnt">195
&lt;/span>&lt;span class="lnt">196
&lt;/span>&lt;span class="lnt">197
&lt;/span>&lt;span class="lnt">198
&lt;/span>&lt;span class="lnt">199
&lt;/span>&lt;span class="lnt">200
&lt;/span>&lt;span class="lnt">201
&lt;/span>&lt;span class="lnt">202
&lt;/span>&lt;span class="lnt">203
&lt;/span>&lt;span class="lnt">204
&lt;/span>&lt;span class="lnt">205
&lt;/span>&lt;span class="lnt">206
&lt;/span>&lt;span class="lnt">207
&lt;/span>&lt;span class="lnt">208
&lt;/span>&lt;span class="lnt">209
&lt;/span>&lt;span class="lnt">210
&lt;/span>&lt;span class="lnt">211
&lt;/span>&lt;span class="lnt">212
&lt;/span>&lt;span class="lnt">213
&lt;/span>&lt;span class="lnt">214
&lt;/span>&lt;span class="lnt">215
&lt;/span>&lt;span class="lnt">216
&lt;/span>&lt;span class="lnt">217
&lt;/span>&lt;span class="lnt">218
&lt;/span>&lt;span class="lnt">219
&lt;/span>&lt;span class="lnt">220
&lt;/span>&lt;span class="lnt">221
&lt;/span>&lt;span class="lnt">222
&lt;/span>&lt;span class="lnt">223
&lt;/span>&lt;span class="lnt">224
&lt;/span>&lt;span class="lnt">225
&lt;/span>&lt;span class="lnt">226
&lt;/span>&lt;span class="lnt">227
&lt;/span>&lt;span class="lnt">228
&lt;/span>&lt;span class="lnt">229
&lt;/span>&lt;span class="lnt">230
&lt;/span>&lt;span class="lnt">231
&lt;/span>&lt;span class="lnt">232
&lt;/span>&lt;span class="lnt">233
&lt;/span>&lt;span class="lnt">234
&lt;/span>&lt;span class="lnt">235
&lt;/span>&lt;span class="lnt">236
&lt;/span>&lt;span class="lnt">237
&lt;/span>&lt;span class="lnt">238
&lt;/span>&lt;span class="lnt">239
&lt;/span>&lt;span class="lnt">240
&lt;/span>&lt;span class="lnt">241
&lt;/span>&lt;span class="lnt">242
&lt;/span>&lt;span class="lnt">243
&lt;/span>&lt;span class="lnt">244
&lt;/span>&lt;span class="lnt">245
&lt;/span>&lt;span class="lnt">246
&lt;/span>&lt;span class="lnt">247
&lt;/span>&lt;span class="lnt">248
&lt;/span>&lt;span class="lnt">249
&lt;/span>&lt;span class="lnt">250
&lt;/span>&lt;span class="lnt">251
&lt;/span>&lt;span class="lnt">252
&lt;/span>&lt;span class="lnt">253
&lt;/span>&lt;span class="lnt">254
&lt;/span>&lt;span class="lnt">255
&lt;/span>&lt;span class="lnt">256
&lt;/span>&lt;span class="lnt">257
&lt;/span>&lt;span class="lnt">258
&lt;/span>&lt;span class="lnt">259
&lt;/span>&lt;span class="lnt">260
&lt;/span>&lt;span class="lnt">261
&lt;/span>&lt;span class="lnt">262
&lt;/span>&lt;span class="lnt">263
&lt;/span>&lt;span class="lnt">264
&lt;/span>&lt;span class="lnt">265
&lt;/span>&lt;span class="lnt">266
&lt;/span>&lt;span class="lnt">267
&lt;/span>&lt;span class="lnt">268
&lt;/span>&lt;span class="lnt">269
&lt;/span>&lt;span class="lnt">270
&lt;/span>&lt;span class="lnt">271
&lt;/span>&lt;span class="lnt">272
&lt;/span>&lt;span class="lnt">273
&lt;/span>&lt;span class="lnt">274
&lt;/span>&lt;span class="lnt">275
&lt;/span>&lt;span class="lnt">276
&lt;/span>&lt;span class="lnt">277
&lt;/span>&lt;span class="lnt">278
&lt;/span>&lt;span class="lnt">279
&lt;/span>&lt;span class="lnt">280
&lt;/span>&lt;span class="lnt">281
&lt;/span>&lt;span class="lnt">282
&lt;/span>&lt;span class="lnt">283
&lt;/span>&lt;span class="lnt">284
&lt;/span>&lt;span class="lnt">285
&lt;/span>&lt;span class="lnt">286
&lt;/span>&lt;span class="lnt">287
&lt;/span>&lt;span class="lnt">288
&lt;/span>&lt;span class="lnt">289
&lt;/span>&lt;span class="lnt">290
&lt;/span>&lt;span class="lnt">291
&lt;/span>&lt;span class="lnt">292
&lt;/span>&lt;span class="lnt">293
&lt;/span>&lt;span class="lnt">294
&lt;/span>&lt;span class="lnt">295
&lt;/span>&lt;span class="lnt">296
&lt;/span>&lt;span class="lnt">297
&lt;/span>&lt;span class="lnt">298
&lt;/span>&lt;span class="lnt">299
&lt;/span>&lt;span class="lnt">300
&lt;/span>&lt;span class="lnt">301
&lt;/span>&lt;span class="lnt">302
&lt;/span>&lt;span class="lnt">303
&lt;/span>&lt;span class="lnt">304
&lt;/span>&lt;span class="lnt">305
&lt;/span>&lt;span class="lnt">306
&lt;/span>&lt;span class="lnt">307
&lt;/span>&lt;span class="lnt">308
&lt;/span>&lt;span class="lnt">309
&lt;/span>&lt;span class="lnt">310
&lt;/span>&lt;span class="lnt">311
&lt;/span>&lt;span class="lnt">312
&lt;/span>&lt;span class="lnt">313
&lt;/span>&lt;span class="lnt">314
&lt;/span>&lt;span class="lnt">315
&lt;/span>&lt;span class="lnt">316
&lt;/span>&lt;span class="lnt">317
&lt;/span>&lt;span class="lnt">318
&lt;/span>&lt;span class="lnt">319
&lt;/span>&lt;span class="lnt">320
&lt;/span>&lt;span class="lnt">321
&lt;/span>&lt;span class="lnt">322
&lt;/span>&lt;span class="lnt">323
&lt;/span>&lt;span class="lnt">324
&lt;/span>&lt;span class="lnt">325
&lt;/span>&lt;span class="lnt">326
&lt;/span>&lt;span class="lnt">327
&lt;/span>&lt;span class="lnt">328
&lt;/span>&lt;span class="lnt">329
&lt;/span>&lt;span class="lnt">330
&lt;/span>&lt;span class="lnt">331
&lt;/span>&lt;span class="lnt">332
&lt;/span>&lt;span class="lnt">333
&lt;/span>&lt;span class="lnt">334
&lt;/span>&lt;span class="lnt">335
&lt;/span>&lt;span class="lnt">336
&lt;/span>&lt;span class="lnt">337
&lt;/span>&lt;span class="lnt">338
&lt;/span>&lt;span class="lnt">339
&lt;/span>&lt;span class="lnt">340
&lt;/span>&lt;span class="lnt">341
&lt;/span>&lt;span class="lnt">342
&lt;/span>&lt;span class="lnt">343
&lt;/span>&lt;span class="lnt">344
&lt;/span>&lt;span class="lnt">345
&lt;/span>&lt;span class="lnt">346
&lt;/span>&lt;span class="lnt">347
&lt;/span>&lt;span class="lnt">348
&lt;/span>&lt;span class="lnt">349
&lt;/span>&lt;span class="lnt">350
&lt;/span>&lt;span class="lnt">351
&lt;/span>&lt;span class="lnt">352
&lt;/span>&lt;span class="lnt">353
&lt;/span>&lt;span class="lnt">354
&lt;/span>&lt;span class="lnt">355
&lt;/span>&lt;span class="lnt">356
&lt;/span>&lt;span class="lnt">357
&lt;/span>&lt;span class="lnt">358
&lt;/span>&lt;span class="lnt">359
&lt;/span>&lt;span class="lnt">360
&lt;/span>&lt;span class="lnt">361
&lt;/span>&lt;span class="lnt">362
&lt;/span>&lt;span class="lnt">363
&lt;/span>&lt;span class="lnt">364
&lt;/span>&lt;span class="lnt">365
&lt;/span>&lt;span class="lnt">366
&lt;/span>&lt;span class="lnt">367
&lt;/span>&lt;span class="lnt">368
&lt;/span>&lt;span class="lnt">369
&lt;/span>&lt;span class="lnt">370
&lt;/span>&lt;span class="lnt">371
&lt;/span>&lt;span class="lnt">372
&lt;/span>&lt;span class="lnt">373
&lt;/span>&lt;span class="lnt">374
&lt;/span>&lt;span class="lnt">375
&lt;/span>&lt;span class="lnt">376
&lt;/span>&lt;span class="lnt">377
&lt;/span>&lt;span class="lnt">378
&lt;/span>&lt;span class="lnt">379
&lt;/span>&lt;span class="lnt">380
&lt;/span>&lt;span class="lnt">381
&lt;/span>&lt;span class="lnt">382
&lt;/span>&lt;span class="lnt">383
&lt;/span>&lt;span class="lnt">384
&lt;/span>&lt;span class="lnt">385
&lt;/span>&lt;span class="lnt">386
&lt;/span>&lt;span class="lnt">387
&lt;/span>&lt;span class="lnt">388
&lt;/span>&lt;span class="lnt">389
&lt;/span>&lt;span class="lnt">390
&lt;/span>&lt;span class="lnt">391
&lt;/span>&lt;span class="lnt">392
&lt;/span>&lt;span class="lnt">393
&lt;/span>&lt;span class="lnt">394
&lt;/span>&lt;span class="lnt">395
&lt;/span>&lt;span class="lnt">396
&lt;/span>&lt;span class="lnt">397
&lt;/span>&lt;span class="lnt">398
&lt;/span>&lt;span class="lnt">399
&lt;/span>&lt;span class="lnt">400
&lt;/span>&lt;span class="lnt">401
&lt;/span>&lt;span class="lnt">402
&lt;/span>&lt;span class="lnt">403
&lt;/span>&lt;span class="lnt">404
&lt;/span>&lt;span class="lnt">405
&lt;/span>&lt;span class="lnt">406
&lt;/span>&lt;span class="lnt">407
&lt;/span>&lt;span class="lnt">408
&lt;/span>&lt;span class="lnt">409
&lt;/span>&lt;span class="lnt">410
&lt;/span>&lt;span class="lnt">411
&lt;/span>&lt;span class="lnt">412
&lt;/span>&lt;span class="lnt">413
&lt;/span>&lt;span class="lnt">414
&lt;/span>&lt;span class="lnt">415
&lt;/span>&lt;span class="lnt">416
&lt;/span>&lt;span class="lnt">417
&lt;/span>&lt;span class="lnt">418
&lt;/span>&lt;span class="lnt">419
&lt;/span>&lt;span class="lnt">420
&lt;/span>&lt;span class="lnt">421
&lt;/span>&lt;span class="lnt">422
&lt;/span>&lt;span class="lnt">423
&lt;/span>&lt;span class="lnt">424
&lt;/span>&lt;span class="lnt">425
&lt;/span>&lt;span class="lnt">426
&lt;/span>&lt;span class="lnt">427
&lt;/span>&lt;span class="lnt">428
&lt;/span>&lt;span class="lnt">429
&lt;/span>&lt;span class="lnt">430
&lt;/span>&lt;span class="lnt">431
&lt;/span>&lt;span class="lnt">432
&lt;/span>&lt;span class="lnt">433
&lt;/span>&lt;span class="lnt">434
&lt;/span>&lt;span class="lnt">435
&lt;/span>&lt;span class="lnt">436
&lt;/span>&lt;span class="lnt">437
&lt;/span>&lt;span class="lnt">438
&lt;/span>&lt;span class="lnt">439
&lt;/span>&lt;span class="lnt">440
&lt;/span>&lt;span class="lnt">441
&lt;/span>&lt;span class="lnt">442
&lt;/span>&lt;span class="lnt">443
&lt;/span>&lt;span class="lnt">444
&lt;/span>&lt;span class="lnt">445
&lt;/span>&lt;span class="lnt">446
&lt;/span>&lt;span class="lnt">447
&lt;/span>&lt;span class="lnt">448
&lt;/span>&lt;span class="lnt">449
&lt;/span>&lt;span class="lnt">450
&lt;/span>&lt;span class="lnt">451
&lt;/span>&lt;span class="lnt">452
&lt;/span>&lt;span class="lnt">453
&lt;/span>&lt;span class="lnt">454
&lt;/span>&lt;span class="lnt">455
&lt;/span>&lt;span class="lnt">456
&lt;/span>&lt;span class="lnt">457
&lt;/span>&lt;span class="lnt">458
&lt;/span>&lt;span class="lnt">459
&lt;/span>&lt;span class="lnt">460
&lt;/span>&lt;span class="lnt">461
&lt;/span>&lt;span class="lnt">462
&lt;/span>&lt;span class="lnt">463
&lt;/span>&lt;span class="lnt">464
&lt;/span>&lt;span class="lnt">465
&lt;/span>&lt;span class="lnt">466
&lt;/span>&lt;span class="lnt">467
&lt;/span>&lt;span class="lnt">468
&lt;/span>&lt;span class="lnt">469
&lt;/span>&lt;span class="lnt">470
&lt;/span>&lt;span class="lnt">471
&lt;/span>&lt;span class="lnt">472
&lt;/span>&lt;span class="lnt">473
&lt;/span>&lt;span class="lnt">474
&lt;/span>&lt;span class="lnt">475
&lt;/span>&lt;span class="lnt">476
&lt;/span>&lt;span class="lnt">477
&lt;/span>&lt;span class="lnt">478
&lt;/span>&lt;span class="lnt">479
&lt;/span>&lt;span class="lnt">480
&lt;/span>&lt;span class="lnt">481
&lt;/span>&lt;span class="lnt">482
&lt;/span>&lt;span class="lnt">483
&lt;/span>&lt;span class="lnt">484
&lt;/span>&lt;span class="lnt">485
&lt;/span>&lt;span class="lnt">486
&lt;/span>&lt;span class="lnt">487
&lt;/span>&lt;span class="lnt">488
&lt;/span>&lt;span class="lnt">489
&lt;/span>&lt;span class="lnt">490
&lt;/span>&lt;span class="lnt">491
&lt;/span>&lt;span class="lnt">492
&lt;/span>&lt;span class="lnt">493
&lt;/span>&lt;span class="lnt">494
&lt;/span>&lt;span class="lnt">495
&lt;/span>&lt;span class="lnt">496
&lt;/span>&lt;span class="lnt">497
&lt;/span>&lt;span class="lnt">498
&lt;/span>&lt;span class="lnt">499
&lt;/span>&lt;span class="lnt">500
&lt;/span>&lt;span class="lnt">501
&lt;/span>&lt;span class="lnt">502
&lt;/span>&lt;span class="lnt">503
&lt;/span>&lt;span class="lnt">504
&lt;/span>&lt;span class="lnt">505
&lt;/span>&lt;span class="lnt">506
&lt;/span>&lt;span class="lnt">507
&lt;/span>&lt;span class="lnt">508
&lt;/span>&lt;span class="lnt">509
&lt;/span>&lt;span class="lnt">510
&lt;/span>&lt;span class="lnt">511
&lt;/span>&lt;span class="lnt">512
&lt;/span>&lt;span class="lnt">513
&lt;/span>&lt;span class="lnt">514
&lt;/span>&lt;span class="lnt">515
&lt;/span>&lt;span class="lnt">516
&lt;/span>&lt;span class="lnt">517
&lt;/span>&lt;span class="lnt">518
&lt;/span>&lt;span class="lnt">519
&lt;/span>&lt;span class="lnt">520
&lt;/span>&lt;span class="lnt">521
&lt;/span>&lt;span class="lnt">522
&lt;/span>&lt;span class="lnt">523
&lt;/span>&lt;span class="lnt">524
&lt;/span>&lt;span class="lnt">525
&lt;/span>&lt;span class="lnt">526
&lt;/span>&lt;span class="lnt">527
&lt;/span>&lt;span class="lnt">528
&lt;/span>&lt;span class="lnt">529
&lt;/span>&lt;span class="lnt">530
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">RecursiveCharacterTextSplitter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">TextSplitter&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Splitting text by recursively look at characters.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Recursively tries to split by different characters to find one
&lt;/span>&lt;span class="s2"> that works.
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">separators&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">keep_separator&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">is_separator_regex&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Create a new TextSplitter.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="nb">super&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">keep_separator&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">keep_separator&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_separators&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">separators&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_is_separator_regex&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">is_separator_regex&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">_split_text&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">separators&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Split incoming text and return chunks.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">final_chunks&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="c1"># Get appropriate separator to use&lt;/span>
&lt;span class="n">separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">separators&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">new_separators&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_s&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">separators&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">_separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">_s&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_is_separator_regex&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="n">re&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">escape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_s&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">_s&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">_s&lt;/span>
&lt;span class="k">break&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">re&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">search&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_separator&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">_s&lt;/span>
&lt;span class="n">new_separators&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">separators&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="p">:]&lt;/span>
&lt;span class="k">break&lt;/span>
&lt;span class="n">_separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">separator&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_is_separator_regex&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="n">re&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">escape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">separator&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">splits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">_split_text_with_regex&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_separator&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_keep_separator&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Now go merging things, recursively splitting longer texts.&lt;/span>
&lt;span class="n">_good_splits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="n">_separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_keep_separator&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="n">separator&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">s&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">splits&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_length_function&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_chunk_size&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_good_splits&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">_good_splits&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">merged_text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_merge_splits&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_good_splits&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_separator&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">final_chunks&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extend&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">merged_text&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">_good_splits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">new_separators&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">final_chunks&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">other_info&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_split_text&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">new_separators&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">final_chunks&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extend&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">other_info&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">_good_splits&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">merged_text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_merge_splits&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_good_splits&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_separator&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">final_chunks&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extend&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">merged_text&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">final_chunks&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">split_text&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_split_text&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_separators&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nd">@classmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">from_language&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">cls&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">language&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Any&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">RecursiveCharacterTextSplitter&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">separators&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">cls&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_separators_for_language&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">language&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">cls&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">separators&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">separators&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">is_separator_regex&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nd">@staticmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">get_separators_for_language&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">language&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CPP&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">void &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">int &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">float &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">double &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GO&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">func &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">var &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">const &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">type &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">JAVA&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">public &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">protected &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">private &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">static &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">KOTLIN&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">public &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">protected &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">private &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">internal &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">companion &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">fun &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">val &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">var &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">when &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">else &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">JS&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">function &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">const &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">let &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">var &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">default &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TS&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">enum &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">interface &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">namespace &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">type &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">function &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">const &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">let &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">var &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">default &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PHP&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">function &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">foreach &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">do &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PROTO&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along message definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">message &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along service definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">service &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along enum definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">enum &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along option definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">option &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along import statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">import &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along syntax declarations&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">syntax &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PYTHON&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># First, try to split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">def &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\t&lt;/span>&lt;span class="s2">def &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Now split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RST&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along section titles&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">=+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">-+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\&lt;/span>&lt;span class="s2">*+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along directive markers&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">.. *&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RUBY&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">def &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">unless &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">do &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">begin &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">rescue &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RUST&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">fn &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">const &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">let &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">loop &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">match &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">const &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SCALA&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">object &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">def &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">val &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">var &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">match &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SWIFT&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">func &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">struct &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">enum &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">do &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MARKDOWN&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># First, try to split along Markdown headings (starting with level 2)&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">#{1,6} &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Note the alternative syntax for headings (below) is not handled here&lt;/span>
&lt;span class="c1"># Heading level 2&lt;/span>
&lt;span class="c1"># ---------------&lt;/span>
&lt;span class="c1"># End of code block&lt;/span>
&lt;span class="s2">&amp;#34;```&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Horizontal lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\&lt;/span>&lt;span class="s2">*&lt;/span>&lt;span class="se">\\&lt;/span>&lt;span class="s2">*&lt;/span>&lt;span class="se">\\&lt;/span>&lt;span class="s2">*+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">---+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">___+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Note that this splitter doesn&amp;#39;t handle horizontal lines defined&lt;/span>
&lt;span class="c1"># by *three or more* of ***, ---, or ___, but this is not handled&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">LATEX&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># First, try to split along Latex sections&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">chapter{&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">section{&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">subsection{&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">subsubsection{&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Now split by environments&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{enumerate}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{itemize}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{description}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{list}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{quote}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{quotation}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{verse}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{verbatim}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Now split by math environments&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\b&lt;/span>&lt;span class="s2">egin{align}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;$$&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;$&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Now split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">HTML&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># First, try to split along HTML tags&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;body&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;div&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;p&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;br&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;li&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h1&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h2&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h3&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h4&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h5&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h6&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;span&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;table&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;tr&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;td&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;th&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;ul&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;ol&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;header&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;footer&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;nav&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Head&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;head&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;style&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;script&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;meta&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;title&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CSHARP&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">interface &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">enum &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">implements &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">delegate &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">event &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">abstract &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">public &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">protected &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">private &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">static &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">return &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">continue &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">foreach &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">break &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">else &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by exceptions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">try &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">throw &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">finally &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">catch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SOL&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along compiler information definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">pragma &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">using &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along contract definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">contract &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">interface &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">library &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">constructor &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">type &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">function &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">event &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">modifier &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">error &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">struct &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">enum &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">do while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">assembly &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">COBOL&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along divisions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">IDENTIFICATION DIVISION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">ENVIRONMENT DIVISION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">DATA DIVISION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">PROCEDURE DIVISION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along sections within DATA DIVISION&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">WORKING-STORAGE SECTION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">LINKAGE SECTION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">FILE SECTION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along sections within PROCEDURE DIVISION&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">INPUT-OUTPUT SECTION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along paragraphs and common statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">OPEN &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">CLOSE &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">READ &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">WRITE &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">IF &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">ELSE &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">MOVE &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">PERFORM &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">UNTIL &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">VARYING &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">ACCEPT &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">DISPLAY &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">STOP RUN.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">ValueError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Language {language} is not supported! &amp;#34;&lt;/span>
&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Please choose from {list(Language)}&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2代码示例-3">(2)代码示例&lt;/h3>
&lt;ul>
&lt;li>使用&lt;code>RecursiveCharacterTextSplitter&lt;/code>，定义好块的大小、切割重合度等参数，得到切分后的texts对象。&lt;/li>
&lt;li>texts对象就是将文档切分后的文本块集合。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231023063036651.png" alt="image-20231023063036651">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231023063047761.png" alt="image-20231023063047761">&lt;/p>
&lt;h1 id="4文档向量化">4.文档向量化&lt;/h1>
&lt;h2 id="41基本概念">4.1.基本概念&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>当我们获得了文本块以后，就需要将其向量化并持久化下来。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LangChain提供的词嵌入模型(&lt;code>Text Embedding Models&lt;/code>)，支持丰富的词嵌入模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LangChain提供的向量存储器(&lt;code>Vector Stores&lt;/code>)，支持丰富的向量数据库。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这部分也是LangChain很强大的特性之一，几乎覆盖了世界上所有&lt;strong>主流的词嵌入模型&lt;/strong>和&lt;strong>主流的向量数据库&lt;/strong>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>词嵌入模型列表：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031082141950.png" alt="image-20231031082141950">&lt;/p>
&lt;ul>
&lt;li>向量数据库列表：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031073927426.png" alt="image-20231031073927426">&lt;/p>
&lt;h2 id="42代码示例">4.2.代码示例&lt;/h2>
&lt;ul>
&lt;li>以OpenAI的词嵌入模型为例，展示了如何使用LangChain的词嵌入模型。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231023065210069.png" alt="image-20231023065210069">&lt;/p>
&lt;h1 id="5检索器">5.检索器&lt;/h1>
&lt;h2 id="1基本概念">(1)基本概念&lt;/h2>
&lt;ul>
&lt;li>LangChain提供的检索器(&lt;code>Retrieves&lt;/code>)，支持丰富的检索能力。&lt;/li>
&lt;li>基础的，基于向量数据库的检索器如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031082838616.png" alt="image-20231031082838616">&lt;/p>
&lt;ul>
&lt;li>高级的(如：云原生)，基于云原生的检索器如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031083352096.png" alt="image-20231031083352096">&lt;/p>
&lt;h2 id="2代码示例-4">(2)代码示例&lt;/h2>
&lt;ul>
&lt;li>如下代码演示了&lt;code>similarity_search&lt;/code>方法的使用：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231023065351312.png" alt="image-20231023065351312">&lt;/p>
&lt;h1 id="6小结">6.小结&lt;/h1>
&lt;ul>
&lt;li>LangChain的&lt;code>Retrieval&lt;/code>特性的整体流程是：文档加载-&amp;gt;文档转换-&amp;gt;文档向量化-&amp;gt;数据检索&lt;/li>
&lt;li>文档加载器支持各类数据格式，各类数据源，实战时需熟悉各类文档加载器。&lt;/li>
&lt;li>文档转换器支持各类文本分割策略，实战时需熟悉各类文档分割策略。&lt;/li>
&lt;li>文档向量化时，有多种词嵌入模型，有多种向量数据库，实战时也需要熟练掌握。&lt;/li>
&lt;li>文档检索时，支持多种文档检索策略，实战时需熟练掌握。&lt;/li>
&lt;/ul>
&lt;p>下一篇，我们对LangChain最火的模块Agents进行探索，下篇见！&lt;/p></description></item><item><title>【chatGPT】学习笔记20-如何搭建ChatGLM3</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAchatglm3/</link><pubDate>Sun, 29 Oct 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAchatglm3/</guid><description>&lt;h1 id="1chatglm3更新了什么">1.ChatGLM3更新了什么&lt;/h1>
&lt;h2 id="1模型列表">(1)模型列表&lt;/h2>
&lt;p>智谱AI刚刚发布了ChatGLM3，其中&lt;strong>ChatGLM3-6B&lt;/strong>的能力提升如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>更强大的基础模型&lt;/strong>： 采用了更多样的训练数据、更充分的训练步数和更合理的训练策略。在语义、数学、推理、代码、知识等不同角度的数据集上表现更好。&lt;/li>
&lt;li>&lt;strong>更完整的功能支持&lt;/strong>：重新设计了Prompt模版格式，支持&lt;code>Function Call&lt;/code>、&lt;code>Code Interpreter&lt;/code>、&lt;code>Agent&lt;/code>。&lt;/li>
&lt;/ul>
&lt;p>除了ChatGLM3-6B，还发布了：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>ChatGLM3-6B-Base&lt;/strong>：它是ChatGLM3-6B的预训练模型，在10B以下的表现同比更好。&lt;/li>
&lt;li>&lt;strong>ChatGLM3-6B-32K&lt;/strong>：适用于长文本对话场景。&lt;/li>
&lt;/ul>
&lt;p>ChatGLM3发布的&lt;strong>模型列表&lt;/strong>如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Model&lt;/th>
&lt;th>Seq Length&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ChatGLM3-6B&lt;/td>
&lt;td>8k&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ChatGLM3-6B-Base&lt;/td>
&lt;td>8k&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ChatGLM3-6B-32K&lt;/td>
&lt;td>32k&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="2测评结果">(2)测评结果&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>典型数据集测试&lt;/strong>：在8个中英文典型数据集上，ChatGLM3-6B-Base的性能表现如下：
&lt;ul>
&lt;li>&lt;strong>测试方法&lt;/strong>：BBH 采用3-shot测试，GSM8K(需要推理)采用0-shot CoT测试、MATH(需要推理)采用0-shot CoT测试，MBPP 采用0-shot生成后运行测例计算 Pass@1 ，其它选择题类型数据集均采用0-shot测试。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Model&lt;/th>
&lt;th>GSM8K&lt;/th>
&lt;th>MATH&lt;/th>
&lt;th>BBH&lt;/th>
&lt;th>MMLU&lt;/th>
&lt;th>C-Eval&lt;/th>
&lt;th>CMMLU&lt;/th>
&lt;th>MBPP&lt;/th>
&lt;th>AGIEval&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ChatGLM2-6B-Base&lt;/td>
&lt;td>32.4&lt;/td>
&lt;td>6.5&lt;/td>
&lt;td>33.7&lt;/td>
&lt;td>47.9&lt;/td>
&lt;td>51.7&lt;/td>
&lt;td>50.0&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Best Baseline&lt;/td>
&lt;td>52.1&lt;/td>
&lt;td>13.1&lt;/td>
&lt;td>45.0&lt;/td>
&lt;td>60.1&lt;/td>
&lt;td>63.5&lt;/td>
&lt;td>62.2&lt;/td>
&lt;td>47.5&lt;/td>
&lt;td>45.8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ChatGLM3-6B-Base&lt;/td>
&lt;td>72.3&lt;/td>
&lt;td>25.7&lt;/td>
&lt;td>66.1&lt;/td>
&lt;td>61.4&lt;/td>
&lt;td>69.0&lt;/td>
&lt;td>67.5&lt;/td>
&lt;td>52.4&lt;/td>
&lt;td>53.7&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>&lt;strong>长文本测试&lt;/strong>：进行人工评估测试，ChatGLM3-6B-32K的性能表现如下。
&lt;ul>
&lt;li>&lt;strong>测试结论&lt;/strong>：与ChatGLM2相比，效果提升超50%(对论文阅读、文档摘要和财报分析等提升显著)。&lt;/li>
&lt;li>&lt;strong>测试方法&lt;/strong>：在LongBench评测集上进行。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Model&lt;/th>
&lt;th>平均&lt;/th>
&lt;th>Summary&lt;/th>
&lt;th>Single-Doc QA&lt;/th>
&lt;th>Multi-Doc QA&lt;/th>
&lt;th>Code&lt;/th>
&lt;th>Few-shot&lt;/th>
&lt;th>Synthetic&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ChatGLM2-6B-32K&lt;/td>
&lt;td>41.5&lt;/td>
&lt;td>24.8&lt;/td>
&lt;td>37.6&lt;/td>
&lt;td>34.7&lt;/td>
&lt;td>52.8&lt;/td>
&lt;td>51.3&lt;/td>
&lt;td>47.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ChatGLM3-6B-32K&lt;/td>
&lt;td>50.2&lt;/td>
&lt;td>26.6&lt;/td>
&lt;td>45.8&lt;/td>
&lt;td>46.1&lt;/td>
&lt;td>56.2&lt;/td>
&lt;td>61.2&lt;/td>
&lt;td>65&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="2准备硬件资源及基础软件">2.准备硬件资源及基础软件&lt;/h1>
&lt;p>笔者准备的硬件资源及基础软件如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>GPU&lt;/strong>：V100，32G显存，避免OOM问题。&lt;/li>
&lt;li>&lt;strong>CUDA&lt;/strong>：Cuda11.6&lt;/li>
&lt;li>&lt;strong>OS&lt;/strong>：Ubuntu22.04&lt;/li>
&lt;li>&lt;strong>Conda&lt;/strong>：Miniconda3&lt;/li>
&lt;li>&lt;strong>Python&lt;/strong>：Python3.10&lt;/li>
&lt;li>&lt;strong>Pytorch&lt;/strong>：Pytorch3.8&lt;/li>
&lt;/ul>
&lt;h1 id="3创建虚拟环境">3.创建虚拟环境&lt;/h1>
&lt;ul>
&lt;li>创建虚拟环境：&lt;code>conda create -p ./envs/HCZ_ChatGLM2 python=3.10&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030003623799.png" alt="image-20231030003623799">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>激活虚拟环境&lt;/strong>：&lt;code>conda activate ./envs/HCZ_ChatGLM3&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030003931661.png" alt="image-20231030003931661">&lt;/p>
&lt;h1 id="4上传模型及模型容器">4.上传模型及模型容器&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>chatglm3-6b下载地址&lt;/strong>：https://huggingface.co/THUDM/chatglm3-6b&lt;/li>
&lt;li>&lt;strong>chatglm3-6b容器下载地址&lt;/strong>：https://github.com/THUDM/ChatGLM3/archive/refs/heads/main.zip&lt;/li>
&lt;li>下载完成后，&lt;strong>上传到服务器&lt;/strong>，如下图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030071806371.png" alt="image-20231030071806371">&lt;/p>
&lt;h1 id="5安装依赖包">5.安装依赖包&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>进入容器目录&lt;/strong>：&lt;code>cd /opt/model/THUDM_chatglm3-6b-container&lt;/code>&lt;/li>
&lt;li>&lt;strong>安装依赖包&lt;/strong>：&lt;code>pip install -r requirements.txt&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030071933817.png" alt="image-20231030071933817">&lt;/p>
&lt;h1 id="6构建restful接口">6.构建Restful接口&lt;/h1>
&lt;ul>
&lt;li>借鉴ChatGLM2的&lt;code>api.py&lt;/code>，具体代码如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030074839307.png" alt="image-20231030074839307">&lt;/p>
&lt;h1 id="7运行chatglm3服务">7.运行ChatGLM3服务&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>进入容器目录&lt;/strong>：&lt;code>cd /opt/model/THUDM_chatglm3-6b-container&lt;/code>&lt;/li>
&lt;li>&lt;strong>运行服务&lt;/strong>：&lt;code>python api.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030075223648.png" alt="image-20231030075223648">&lt;/p>
&lt;h1 id="8测试">8.测试&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>向ChatGLM3提问&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030083402685.png" alt="image-20231030083402685">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>服务器端运行日志如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030083320605.png" alt="image-20231030083320605">&lt;/p>
&lt;h1 id="9小结">9.小结&lt;/h1>
&lt;ul>
&lt;li>本文阐述了ChatGLM3的官宣能力，并演示了如何搭建自己的ChatGLM3。&lt;/li>
&lt;li>ChatGLM3的新能力有待进一步集成到产品中进行验证。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记19-自己实现一个简版ChatGPT(下)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%8B/</link><pubDate>Fri, 20 Oct 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%8B/</guid><description>&lt;p>前两篇实现了简版GPT，并对其进行了SFT，我们接下来看ChatGPT整体训练流程的最后一个环节——&lt;strong>对齐训练(Alignment Training)&lt;/strong>。&lt;/p>
&lt;h1 id="1方法3对齐训练alignment-training">1.方法3：对齐训练(Alignment Training)&lt;/h1>
&lt;h2 id="1与chatgpt整体训练流程图的对应关系">(1)与ChatGPT整体训练流程图的对应关系&lt;/h2>
&lt;ul>
&lt;li>方法3对应于&lt;strong>ChatGPT整体训练流程的STEP2、STEP3&lt;/strong>。&lt;/li>
&lt;li>方法3的核心思想是利用了强化学习，最终将GPT3演进为了&lt;strong>更通人性的ChatGPT&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020062050959.png" alt="image-20231020062050959">&lt;/p>
&lt;ul>
&lt;li>ChatGPT整体训练流程中的&lt;strong>STEP2、STEP3&lt;/strong>，就是大名鼎鼎的&lt;strong>RLHF&lt;/strong>——&lt;strong>基于人类反馈的强化学习&lt;/strong>。
&lt;ul>
&lt;li>&lt;strong>RL：Reinforcement Learning&lt;/strong>&lt;/li>
&lt;li>&lt;strong>HF：Human Feedback&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>ChatGPT整体训练流程中的&lt;strong>STEP2&lt;/strong>，&lt;strong>对应于&lt;/strong>强化学习模型的&lt;strong>Interpreter模型&lt;/strong>。&lt;/li>
&lt;li>ChatGPT整体训练流程中的&lt;strong>STEP3&lt;/strong>，&lt;strong>对应于&lt;/strong>强化学习模型的&lt;strong>Action模型&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020085551189.png" alt="image-20231020085551189">&lt;/p>
&lt;h2 id="2什么是对齐训练">(2)什么是对齐训练&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>对齐训练&lt;/strong>：Alignment Training，它就是一种机器学习的模型训练方法。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>核心思想&lt;/strong>：训练出人类主观感受的模型，这个模型具备预测人类的决策的能力。&lt;/p>
&lt;ul>
&lt;li>这样，训练好的模型，就可以在未见过的场景下，按照类似人的行为模式做出选择。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>对齐训练与强化学习的关系&lt;/strong>：OpenAI在对齐训练中，结合了强化学习。&lt;/p>
&lt;ul>
&lt;li>ChatGPT整体训练流程的STEP2就是对齐训练，学习出预测人类回答问题的偏好模型。&lt;/li>
&lt;li>ChatGPT整体训练流程的STEP3就是强化学习，STEP2输出的这个模型，作为强化学习的Interpreter模型。STEP3不断迭代，最终学习到Action模型。
&lt;ul>
&lt;li>通过SFT训练之后GPT3，本质就是一个能机械式地回答问题的机器人。&lt;/li>
&lt;li>通过RLHF学习的Action模型，才是帮助SFT之后的GPT3，类似人类回答问题的关键机关。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>细节&lt;/strong>：ChatGPT整体训练流程图中，出现了PPO算法，PPO算法是近端策略梯度优化，增加一个限制Action模型在训练过程中梯度上升速度，本质就是避免Action模型产生一个离谱的Action。&lt;/p>
&lt;ul>
&lt;li>PPO算法展开说内容太多，本文不赘述，详见论文：https://arxiv.org/abs/1707.06347&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="3step2的reward-model模型训练伪码">(3)STEP2的Reward Model模型训练伪码&lt;/h2>
&lt;ul>
&lt;li>我们再来看看STEP2的伪码，如下图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020093407332.png" alt="image-20231020093407332">&lt;/p>
&lt;h2 id="4step3的rlhf训练伪码">(4)STEP3的RLHF训练伪码&lt;/h2>
&lt;ul>
&lt;li>我们再来看看STEP3的伪码，如下图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020095154134.png" alt="image-20231020095154134">&lt;/p>
&lt;h1 id="2deepspeed">2.DeepSpeed&lt;/h1>
&lt;p>RLHF，是ChatGPT最核心的技术机密，除了在《Introducing ChatGPT》(&lt;a href="https://openai.com/blog/chatgpt">https://openai.com/blog/chatgpt&lt;/a>)中提到了，并未公开过源码。&lt;/p>
&lt;p>在前文的伪码实现部分，虽然通过伪码描述了RLHF的核心逻辑，但距离商用还欠缺很多东西(如：分布式训练等)。&lt;/p>
&lt;p>幸好微软开源了类似的框架，DeepSpeed，我们可以通过阅读它的源码、使用它，开展RLHF。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020100752488.png" alt="image-20231020100752488">&lt;/p>
&lt;h1 id="3实例-开展rlhf训练">3.实例-开展RLHF训练&lt;/h1>
&lt;h2 id="step0前置准备">STEP0.前置准备&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>硬件&lt;/strong>：V100一块，32G显存&lt;/li>
&lt;li>&lt;strong>基础软件&lt;/strong>：Ubuntun20.04，Minicoda3，Pytorch3.8，CUDA11.6，Python3.10&lt;/li>
&lt;li>&lt;strong>预训练模型&lt;/strong>：选择Facebook的opt1.3B，即&lt;strong>13亿参数&lt;/strong>的预训练模型。&lt;/li>
&lt;li>&lt;strong>环境初始配置&lt;/strong>：创建虚拟环境，&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020102932305.png" alt="image-20231020102932305">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>安装依赖&lt;/strong>：进入DeepSpeed-Chat目录，安装相关依赖&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020103116451.png" alt="image-20231020103116451">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>环境测试&lt;/strong>：确认相关基础软件版本号。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020103548543.png" alt="image-20231020103548543">&lt;/p>
&lt;h2 id="step1sft">STEP1.SFT&lt;/h2>
&lt;ul>
&lt;li>开展SFT训练时，由于服务器资源不足(省钱)，需要避免OOM异常，因此需要修改一下训练脚本。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>路径：training/step1_supervised_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020104103388.png" alt="image-20231020104103388">&lt;/p>
&lt;ul>
&lt;li>设置待微调的预训练模型，以及输出路径。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>路径：training/step1_supervised_finetuning/evaluation_scripts/run_prompt.sh&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020110616405.png" alt="image-20231020110616405">&lt;/p>
&lt;ul>
&lt;li>执行训练脚本run_1.3b.sh，触发DeepSpeed开始SFT训练。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=959965022&amp;bvid=BV1Hp4y1M7Ly&amp;cid=1305868791&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;h2 id="step2rm">STEP2.RM&lt;/h2>
&lt;ul>
&lt;li>开展RM训练时，由于服务器资源不足(省钱)，需要避免OOM异常，因此需要修改一下训练脚本。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>路径：training_scripts/opt/single_gpu/run_350m.sh&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020145149415.png" alt="image-20231020145149415">&lt;/p>
&lt;ul>
&lt;li>指定Reward Model的输出路径。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>路径：evaluation_scripts/run_eval.sh&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020145843742.png" alt="image-20231020145843742">&lt;/p>
&lt;ul>
&lt;li>执行训练脚本run_350m.sh，触发DeepSpeed开始RW训练。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=534943541&amp;bvid=BV1gM411R7Z5&amp;cid=1305868897&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;h2 id="step3rlhf">STEP3.RLHF&lt;/h2>
&lt;ul>
&lt;li>开展RLHF训练时，由于服务器资源不足(省钱)，需要避免OOM异常，因此需要修改一下训练脚本。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>training_scripts/opt/single_gpu/run_1.3b.sh&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020155704428.png" alt="image-20231020155704428">&lt;/p>
&lt;ul>
&lt;li>执行训练脚本run_1.3b.sh，触发DeepSpeed开始RLHF训练。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=277474259&amp;bvid=BV1Ww411F7xw&amp;cid=1305868938&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;h2 id="step4模型测试">STEP4.模型测试&lt;/h2>
&lt;ul>
&lt;li>执行测试脚本&lt;code>python chat.py --path training/step3_rlhf_finetuning/output/actor&lt;/code>，不赘述。&lt;/li>
&lt;/ul>
&lt;h1 id="4小结">4.小结&lt;/h1>
&lt;p>本文是实现简版GPT的三篇中的最后一篇，也是最难理解的一部分内容：&lt;/p>
&lt;ul>
&lt;li>对齐训练是什么？&lt;/li>
&lt;li>对齐训练和强化学习的关系是什么？&lt;/li>
&lt;li>ChatGPT整体训练流程的STEP2、STEP3与强化学习的Interpreter和Action模型如何对应？&lt;/li>
&lt;li>DeepSpeed的实际操作？&lt;/li>
&lt;/ul>
&lt;p>本文也有没有展开探讨的内容，待本专栏后续继续展开：&lt;/p>
&lt;ul>
&lt;li>RLHF的策略梯度优化算法&lt;/li>
&lt;li>PPO算法&lt;/li>
&lt;li>……&lt;/li>
&lt;/ul>
&lt;p>编写本专栏受益匪浅，也非常感恩因为编写本专栏认识的大神们，期待与各位小伙伴持续的讨论和思辨！&lt;/p></description></item><item><title>【chatGPT】学习笔记18-自己实现一个简版ChatGPT(中)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%AD/</link><pubDate>Wed, 18 Oct 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%AD/</guid><description>&lt;p>根据上文我们实现的简版GPT，在足够数据、足够算力的前提下，理论上是可以训练出类GPT3的大语言模型的。&lt;/p>
&lt;p>但GPT3距离ChatGPT还有很远的距离，这一段距离涉及OpenAI未公开论文、源码的关键技术。&lt;/p>
&lt;p>我们接下来从OpenAPI已公开的信息来看看&lt;font color=red>&lt;strong>ChatGPT是如何炼成的&lt;/strong>&lt;/font>。&lt;/p>
&lt;h1 id="1chatgpt的历史版本">1.ChatGPT的历史版本&lt;/h1>
&lt;p>下图摘自Yule Wang的技术专栏，阐述了基于Transformer的大语言模型不同版本的脉络：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>BERT&lt;/strong>是编码器Only架构，&lt;strong>BART&lt;/strong>是编码器-解码器架构，它们延伸出去大语言模型下载后&lt;font color=red>&lt;strong>不能直接使用，需要垂域微调&lt;/strong>&lt;/font>。&lt;/li>
&lt;li>&lt;strong>T5&lt;/strong>是编码器-解码器架构，&lt;strong>GPT-2&lt;/strong>是解码器Only架构，它们下载后&lt;font color=red>&lt;strong>不做垂域微调，也能完成一些AI任务&lt;/strong>&lt;/font>。&lt;/li>
&lt;li>&lt;strong>GPT-3、GPT-4&lt;/strong>是解码器Only架构，它们下载后&lt;font color=red>&lt;strong>不做垂域微调，能完成大部分AI任务&lt;/strong>&lt;/font>。&lt;/li>
&lt;li>针对&lt;strong>GPT-3&lt;/strong>进行&lt;font color=red>&lt;strong>SFT(有监督微调)+RLHF(基于人类反馈的强化学习)&lt;strong>&lt;/font>，最终得到了&lt;/strong>ChatGPT&lt;/strong>，&lt;strong>GPT-3.5、InstructGPT&lt;/strong>算是过渡产品。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019083053465.png" alt="image-20231019083053465">&lt;/p>
&lt;h1 id="2chatgpt的整体训练流程">2.ChatGPT的整体训练流程&lt;/h1>
&lt;p>在《Introducing ChatGPT》(详见https://openai.com/blog/chatgpt)中，给出了从GPT3演进到ChatGPT的整体训练流程图：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/ChatGPT_Diagram.svg" alt="ChatGPT_Diagram">&lt;/p>
&lt;p>以前看这张图很模糊，通过前面复现Transformer架构、简版GPT的代码，才逐渐变得清晰。&lt;/p>
&lt;p>接下来，我们来逐一拆解。&lt;/p>
&lt;h1 id="3chatgpt的三大训练方法">3.ChatGPT的三大训练方法&lt;/h1>
&lt;p>下图比较形象地归纳了ChatGPT整体训练流程：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019094239673.png" alt="image-20231019094239673">&lt;/p>
&lt;h2 id="1方法1预训练pre-traning">(1)方法1：预训练(Pre-Traning)&lt;/h2>
&lt;ul>
&lt;li>构建好大语言模型的神经网络架构后，&lt;strong>通过大数据、大算力进行训练&lt;/strong>，得到预训练模型。如：GPT3就属于这类预训练模型。&lt;/li>
&lt;li>大语言模型的本质是生成内容，构建训练数据基本都是自动化的，所以&lt;strong>预训练的过程属于无监督学习&lt;/strong>。&lt;/li>
&lt;li>预训练模型非常庞大，&lt;strong>算是通才&lt;/strong>，具备&lt;strong>基本的自然语言处理能力、世界知识&lt;/strong>，甚至还有了&lt;strong>顿悟能力(涌现能力)&lt;/strong>。&lt;/li>
&lt;li>就好像下图红框内庞大的AI大脑(&lt;strong>画的有点恶心&lt;/strong>)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019150044511.png" alt="image-20231019150044511">&lt;/p>
&lt;h2 id="2方法2指令调优instruction-tuning">(2)方法2：指令调优(Instruction Tuning)&lt;/h2>
&lt;ul>
&lt;li>虽然花了巨大的时间成本和空间成本获得了预训练模型，但是它的水平，依然无法像一个真人，与人类对话。&lt;/li>
&lt;li>接下来还要进行微调——人工&lt;strong>准备少量的数据&lt;/strong>，对&lt;strong>预训练模型进行增量训练&lt;/strong>——因此也称为&lt;strong>有监督微调(SFT，Supervised Fine-tunning)&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>指令微调&lt;/strong>本质是站在巨人的肩膀上&lt;strong>对预训练模型进行增量训练&lt;/strong>。它可以针对世界知识进行增强，也可以针对某个垂直领域进行增强。&lt;/li>
&lt;li>指令微调后得到的大语言训练模型，将会接近于一个真人。&lt;/li>
&lt;li>就好像下图红框内的红色人脸(&lt;strong>画的也挺恶心&lt;/strong>)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019150129023.png" alt="image-20231019150129023">&lt;/p>
&lt;h2 id="3方法3对齐alignment">(3)方法3：对齐(Alignment)&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>在指令调优后，大语言模型虽然接近于真人，但生成的内容依然会很生硬。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>为什么呢？这就是人类的主观感受——人类对某些问题的答案，会有情绪、语气、风格等主观的特征。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>那么，又如何&lt;strong>让AI学会人类的主观感受&lt;/strong>呢？这&lt;strong>就是对齐Alignment&lt;/strong>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RLHF(基于人类反馈的强化学习)就是对齐的具体实现之一，利用这种强化学习手段，让大语言模型学会人类的主观感受，GPT3就演进成为了ChatGPT。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>就好像下图右侧红框内小黄球(&lt;strong>画的依然挺恶心&lt;/strong>)。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019151032099.png" alt="image-20231019151032099">&lt;/p>
&lt;p>接下来，我们逐一分析这三大方法。&lt;/p>
&lt;h1 id="4方法1预训练pre-training">4.方法1：预训练(Pre-Training)&lt;/h1>
&lt;h2 id="1与chatgpt整体训练流程图的对应关系">(1)与ChatGPT整体训练流程图的对应关系&lt;/h2>
&lt;p>我们对比两张图：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>预训练&lt;/strong>得到的大语言模型，就&lt;strong>是ChatGPT整体训练流程STEP1的输入&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019151849173.png" alt="image-20231019151849173">&lt;/p>
&lt;h2 id="2辩证看待预训练模型涌现能力神经网络">(2)辩证看待预训练模型、涌现能力、神经网络&lt;/h2>
&lt;p>前段时间，师父问了我3个终极问题，让我一时语塞：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>为什么ChatGPT大力能出奇迹，小力就不行？&lt;/strong>&lt;/li>
&lt;li>&lt;strong>为什么这样的神经网络模型就可以大力出奇迹，换个神经网络模型行不行？&lt;/strong>&lt;/li>
&lt;li>&lt;strong>如果无论什么神经网络模型只要能做到大力就能出奇迹，那么这些神经网络的本质是什么？&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>前面半年一直在复现Transformer论文的细节中，的确缺少了对宏观本质的思考，结合预训练这个章节的写作，正好梳理一下我的宏观思考：&lt;/p>
&lt;h3 id="思考1神经网络的本质是什么">思考1：神经网络的本质是什么？&lt;/h3>
&lt;ul>
&lt;li>观点1：客观世界中，&lt;strong>一切问题都能用函数表达&lt;/strong>。
&lt;ul>
&lt;li>只不过有的函数极其复杂，只有上帝才知道这个函数是什么。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>观点2：&lt;strong>神经网络的本质进行函数近似(Function Approximation)的工具&lt;/strong>。
&lt;ul>
&lt;li>&lt;strong>神经网络的输入&lt;/strong>：是大量的数据，数据中隐藏了某个问题背后的函数的数学规律。&lt;/li>
&lt;li>&lt;strong>神经网络的输出&lt;/strong>：找到无限逼近于某个问题背后的函数的近似函数。&lt;/li>
&lt;li>数学上，已经证明&lt;strong>神经网络能够近似出任意一个问题背后的函数&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>神经网络的结构&lt;/strong>，&lt;strong>决定了找到这个近似函数的成本&lt;/strong>(时间成本、空间成本……)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="思考2假设思考1正确如何解释神经网络的5种现象">思考2：假设思考1正确，如何解释神经网络的5种现象？&lt;/h3>
&lt;ul>
&lt;li>现象1：&lt;strong>过于简单的神经网络&lt;/strong>，需要很大力才能出奇迹。
&lt;ul>
&lt;li>任务是&amp;quot;让AI对红点和蓝点进行分类&amp;rdquo;，由于神经网络过于简单，所以迭代了2000多次才找出答案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=364782652&amp;bvid=BV1F94y1b7MW&amp;cid=1304339810&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>现象2：&lt;strong>过于简单的任务&lt;/strong>，不需要大力也能出奇迹。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=874844018&amp;bvid=BV1EN4y1C7v2&amp;cid=1304340008&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>现象3：恒定难度的任务，&lt;strong>加宽神经网络&lt;/strong>，大力能出奇迹。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=234774107&amp;bvid=BV1N8411r78C&amp;cid=1304339757&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>现象4：恒定难度的任务，&lt;strong>加深神经网络&lt;/strong>，大力能出奇迹。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=789763364&amp;bvid=BV1Ry4y1N7CU&amp;cid=1304340937&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>现象5：恒定难度的任务，&lt;strong>增强神经元&lt;/strong>，大力能出奇迹。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=277344904&amp;bvid=BV14w411w7Nx&amp;cid=1304343623&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;p>从上述5种现象，应该可以得到2个结论：&lt;/p>
&lt;ul>
&lt;li>在神经网络结构恒定的前提下，&lt;strong>待执行的任务难度&lt;/strong>，决定了&lt;strong>能否大力出奇迹、是否需要大力&lt;/strong>。&lt;/li>
&lt;li>在待执行的任务难度恒定的前提下，&lt;strong>神经网络结构&lt;/strong>，决定了&lt;strong>能否大力出奇迹、是否需要大力&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;h3 id="思考3辩证地看待预训练模型涌现能力transformer">思考3：辩证地看待预训练模型、涌现能力、Transformer&lt;/h3>
&lt;p>当GPT3.5出现&lt;strong>涌现能力(emergent capabilities)&lt;strong>后，它似乎被神话成了&lt;/strong>人类尚无办法解释的神迹&lt;/strong>。&lt;/p>
&lt;p>我们应该如此这般辩证地看待预训练模型、涌现、Transformer&lt;/p>
&lt;ul>
&lt;li>预训练模型不是ChatGPT首创，在深度学习时代就有了，有很多神经网络都是预训练好，节省后来人的训练成本。&lt;/li>
&lt;li>Transformer只是GPT3这种预训练模型遵循的神经网络结构，&lt;strong>Transformer这种神经网络结构本质是换了一种姿势寻找近似函数&lt;/strong>。&lt;/li>
&lt;li>如果问题P1、问题P2、……问题Pn背后的函数都极为相近，当神经网络结构找到了问题P1的近似函数，那么这个近似函数也能用来解决问题P2、……问题Pn——这就是经过训练，神经网络能自我学习到一些额外的能力的原因，即涌现能力。
&lt;ul>
&lt;li>进一步思考：深度学习时代有没有涌现呢？可能有，只是n这个值比较小，不太明显吧。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="5方法2指令调优instruction-tuning">5.方法2：指令调优(Instruction Tuning)&lt;/h1>
&lt;h2 id="1与chatgpt整体训练流程图的对应关系-1">(1)与ChatGPT整体训练流程图的对应关系&lt;/h2>
&lt;ul>
&lt;li>指令调优对应于ChatGPT整体训练流程的STEP1。&lt;/li>
&lt;li>&lt;strong>SFT&lt;/strong>：有监督微调，属于有监督学习。包括In-context Tuning(上下文调优)和Instruction Tuning(指令调优)。
&lt;ul>
&lt;li>&lt;strong>In-context Tuning&lt;/strong>：上下文调优，这种调优方式的本质是将多轮对话的聊天记录一起发送给大语言模型，有了上下文，大语言模型就能更好地回答问题。&lt;/li>
&lt;li>&lt;strong>Instruction Tuning&lt;/strong>：指令调优，这种调优方式的本质就是问题中带有明确的指令、明确的要求。Instruction Tuning是OpenAI在GPT-3.5-turbo模型中引入的一种新方法，是在传统的微调过程上的一种变体。&lt;/li>
&lt;li>对于上述两种调优方式，在提示词工程中都体现了它们的思想——&lt;strong>&amp;ldquo;上下文&amp;rdquo;、&amp;ldquo;指令&amp;rdquo;&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019170641604.png" alt="image-20231019170641604">&lt;/p>
&lt;h2 id="2训练sft模型的伪码">(2)训练SFT模型的伪码&lt;/h2>
&lt;p>前文讲了很多理论，还是需要撸一下代码比较便于理解。&lt;/p>
&lt;blockquote>
&lt;p>由于OpenAI对于SFT、RLHF并未公开源码，所以在这里只编写伪码，在后续实例中展示真实代码。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019181420212.png" alt="image-20231019181420212">&lt;/p>
&lt;h2 id="3sft实例">(3)SFT实例&lt;/h2>
&lt;p>针对简版GPT，只需要增加如下代码：&lt;/p>
&lt;ul>
&lt;li>首先，通过&lt;code>torch.load方法&lt;/code>加载上一篇已经预训练好的简版GPT模型，这个模型的训练数据仅包含了维基百科的基本数据。&lt;/li>
&lt;li>然后，将新增的医学知识数据集，对简版GPT模型进行增量训练。&lt;/li>
&lt;li>最后，通过&lt;code>torch.save方法&lt;/code>保存增量训练的简版GPT模型，此时，这个模型就包含了医学知识了。&lt;/li>
&lt;li>具体代码详见下图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019182641050.png" alt="image-20231019182641050">&lt;/p>
&lt;h1 id="6小结">6.小结&lt;/h1>
&lt;p>讲到这里，内容已经比较饱和了，我们将在最后一篇阐述&lt;strong>方法3：对齐训练&lt;/strong>以及&lt;strong>RLHF的实例&lt;/strong>。&lt;/p>
&lt;p>我们接下来对本文进行一下小结：&lt;/p>
&lt;ul>
&lt;li>ChatGPT的历史版本：&lt;strong>GPT3、InstructGPT、ChatGPT&lt;/strong>。&lt;/li>
&lt;li>ChatGPT&lt;strong>整体训练流程&lt;/strong>，支撑了&lt;strong>GPT3到ChatGPT的演进&lt;/strong>。&lt;/li>
&lt;li>预训练模型是什么？如何&lt;strong>辩证地&lt;/strong>看待&lt;strong>预训练模型、涌现能力、神经网络的学习能力&lt;/strong>？&lt;/li>
&lt;li>SFT(有监督微调)的概念、原理，最后展示了&lt;strong>如何针对简版GPT进行SFT&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>我们下一步继续针对简版ChatGPT开展RLHF，且听下回分解。&lt;/p></description></item><item><title>【chatGPT】学习笔记17-自己实现一个简版ChatGPT(上)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%8A/</link><pubDate>Mon, 16 Oct 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%8A/</guid><description>&lt;p>接下来，我们用三篇文章阐述&lt;font color=red>**如何实现一个简版ChatGPT。**&lt;/font>&lt;/p>
&lt;h1 id="1回顾">1.回顾&lt;/h1>
&lt;p>想实现一个简版ChatGPT，依赖于如下前置知识：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>机器学习基本原理&lt;/strong>，可参考笔者这几篇文章：
&lt;ul>
&lt;li>《【chatGPT】学习笔记3-机器学习基本原理(上)》&lt;/li>
&lt;li>《【chatGPT】学习笔记4-机器学习基本原理(下)》&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>经典NLP相关技术&lt;/strong>，可参考笔者这几篇文章：
&lt;ul>
&lt;li>&lt;strong>N-Gram&lt;/strong>：《【chatGPT】学习笔记6-手撸一个上古GPT》&lt;/li>
&lt;li>&lt;strong>Embedding&lt;/strong>：《【chatGPT】学习笔记7-词的向量化，大语言模型的关键部件》&lt;/li>
&lt;li>&lt;strong>神经概率语言模型&lt;/strong>：《【chatGPT】学习笔记8-神经概率语言模型，大语言模型的关键部件2》&lt;/li>
&lt;li>&lt;strong>Seq2Seq&lt;/strong>：《【chatGPT】学习笔记9-Transformer之Seq2Seq，大语言模型的关键部件3》&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>现代NLP相关技术&lt;/strong>，可参考笔者这几篇文章：
&lt;ul>
&lt;li>&lt;strong>注意力机制&lt;/strong>：《【chatGPT】学习笔记13-Transformer之注意力机制，大语言模型的关键部件4》&lt;/li>
&lt;li>&lt;strong>Transformer&lt;/strong>：《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="2实现简版gpt">2.实现简版GPT&lt;/h1>
&lt;p>这是参考Transformer架构绘制的简版ChatGPT整体架构，我们将对它进行拆解：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017113929233.png" alt="image-20231017113929233">&lt;/p>
&lt;h2 id="1整体">(1)整体&lt;/h2>
&lt;p>将上图抽象化，我们可以看到：&lt;/p>
&lt;ul>
&lt;li>简版GPT遵循Transfomer架构，但是没有实现编码器&lt;/li>
&lt;li>Decoder的输出交给一个线性层，将解码器的输出转换为目标词汇表大小的概率分布——这属于常规操作，与Transformer核心思想关系不大。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017134713086.png" alt="image-20231017134713086">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>1&lt;/strong>：对应上图将&lt;strong>Outputs&lt;/strong>输入给&lt;strong>Decoder&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>2&lt;/strong>：对应上图将&lt;strong>Decoder的输出&lt;/strong>，传入给线性层。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017135734066.png" alt="image-20231017135734066">&lt;/p>
&lt;h2 id="2局部1正弦位置编码表">(2)局部1：正弦位置编码表&lt;/h2>
&lt;p>首先，我们来细化&lt;strong>Outputs&lt;/strong>和&lt;strong>Decoder&lt;/strong>之间的流程：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP1&lt;/strong>.对&lt;strong>Outputs&lt;/strong>实施词嵌入，得到词向量。&lt;/li>
&lt;li>&lt;strong>STEP2&lt;/strong>.在&lt;strong>词向量&lt;/strong>和&lt;strong>Decoder&lt;/strong>之间增加了&lt;strong>位置编码表&lt;/strong>(也是一个向量)，这个位置编码表体现了&lt;strong>词和词序的关系&lt;/strong>。
&lt;ul>
&lt;li>由于Transformer取消了RNN，也就不再逐个词串行处理，所以必须建立&lt;strong>词和词序的关系&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>STEP3&lt;/strong>.将STEP2的&lt;strong>位置表码表&lt;/strong>向量和&lt;strong>词向量&lt;/strong>相加，输入给&lt;strong>Decoder&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017140335543.png" alt="image-20231017140335543">&lt;/p>
&lt;p>正弦位置编码表的计算原理参见《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》的&amp;rdquo;(2)局部1：正弦位置编码表&amp;quot;章节，本文不再赘述。&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017140636308.png" alt="image-20231017140636308">&lt;/p>
&lt;h2 id="3局部2解码器堆栈">(3)局部2：解码器堆栈&lt;/h2>
&lt;p>我们再来细化&lt;strong>解码器&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>编码器本质上由&lt;strong>N个解码器&lt;/strong>串联而成的&lt;strong>解码器堆栈&lt;/strong>。&lt;/li>
&lt;li>我们的实现，也按照论文的设定层数，&lt;strong>N=6&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150909585.png" alt="image-20231017150909585">&lt;/p>
&lt;h2 id="4局部3解码器">(4)局部3：解码器&lt;/h2>
&lt;p>我们再进一步细化&lt;strong>解码器Decoder&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>解码器Decoder&lt;/strong>由&lt;strong>多头注意力&lt;/strong>和&lt;strong>前向传播网络&lt;/strong>组成。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150925061.png" alt="image-20231017150925061">&lt;/p>
&lt;p>&lt;strong>解码器堆栈&lt;/strong>的代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>①&lt;/strong>：这就是创建的&lt;strong>位置编码层&lt;/strong>，再将&lt;strong>词向量和位置编码向量相加&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>②&lt;/strong>：这就是将多个&lt;strong>解码器&lt;/strong>叠加成&lt;strong>解码器堆栈&lt;/strong>，每个&lt;strong>解码器的输入&lt;/strong>是&lt;strong>上个解码器的输出&lt;/strong>和&lt;strong>上个解码器输出的注意力权重&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>③&lt;/strong>：这就是表示&lt;strong>解码器堆栈&lt;/strong>输出的&lt;strong>解码器输出&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017142049236.png" alt="image-20231017142049236">&lt;/p>
&lt;p>&lt;strong>解码器&lt;/strong>的代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>①&lt;/strong>：就是&lt;strong>多头注意力层&lt;/strong>，&lt;strong>第一个解码器&lt;/strong>的&lt;strong>多头注意力层&lt;/strong>的输入是&lt;strong>词嵌入+位置编码向量之和&lt;/strong>以及&lt;strong>自注意力掩码&lt;/strong>，&lt;strong>后续解码器&lt;/strong>的&lt;strong>多头注意力层&lt;/strong>的输入是&lt;strong>上一个解码器的输出&lt;/strong>和&lt;strong>自注意力掩码&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>②&lt;/strong>：就是&lt;strong>前向传播网络&lt;/strong>，它的输入是&lt;strong>多头注意力层的输出&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017145220345.png" alt="image-20231017145220345">&lt;/p>
&lt;p>我们接下来看&lt;strong>多头注意力层、前向传播网络、自注意力位置掩码&lt;/strong>如何实现？&lt;/p>
&lt;h2 id="5局部4多头注意力">(5)局部4：多头注意力&lt;/h2>
&lt;p>多头注意力的原理参见《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》的&amp;rdquo;(5)局部4：多头注意力&amp;quot;章节，本文不再赘述。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150943298.png" alt="image-20231017150943298">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017145622219.png" alt="image-20231017145622219">&lt;/p>
&lt;h2 id="6局部5前向传播网络">(6)局部5：前向传播网络&lt;/h2>
&lt;p>多头注意力的原理参见《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》的&amp;rdquo;(6)局部5：前向传播网络&amp;quot;章节，本文不再赘述。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151000709.png" alt="image-20231017151000709">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150114991.png" alt="image-20231017150114991">&lt;/p>
&lt;h2 id="7局部6填充位置掩码">(7)局部6：填充位置掩码&lt;/h2>
&lt;p>多头注意力的原理参见《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》的&amp;rdquo;(7)局部6：填充位置掩码&amp;quot;章节，本文不再赘述。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151014381.png" alt="image-20231017151014381">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150413819.png" alt="image-20231017150413819">&lt;/p>
&lt;h2 id="8局部7后续位置掩码">(8)局部7：后续位置掩码&lt;/h2>
&lt;p>多头注意力的原理参见《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》的&amp;rdquo;(10)局部9：后续位置掩码&amp;quot;章节，本文不再赘述。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151026419.png" alt="image-20231017151026419">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150515799.png" alt="image-20231017150515799">&lt;/p>
&lt;h2 id="9模型训练">(9)模型训练&lt;/h2>
&lt;p>至此，我们已经完整地实现了Transformer架构，我们开始对其进行训练：&lt;/p>
&lt;ul>
&lt;li>数据集如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151515137.png" alt="image-20231017151515137">&lt;/p>
&lt;ul>
&lt;li>模型训练：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151651529.png" alt="image-20231017151651529">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151717714.png" alt="image-20231017151717714">&lt;/p>
&lt;ul>
&lt;li>训练好后，会生成简版GPT的pth模型文件：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151835127.png" alt="image-20231017151835127">&lt;/p>
&lt;h2 id="10模型测试">(10)模型测试&lt;/h2>
&lt;ul>
&lt;li>测试用例采用贪婪编码和集束编码，比较简单，具体代码如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151956136.png" alt="image-20231017151956136">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;ul>
&lt;li>本文基于Transformer架构，复现了简版ChatGPT，其关键在于只有解码器。&lt;/li>
&lt;li>理论上，如果有足够算力、足够训练数据，可以将此简版ChatGPT训练到GPT3的水平。&lt;/li>
&lt;li>那么，GPT3到ChatGPT还有一定的距离，我们知道ChatGPT公开的信息中，还对GPT3进行了&lt;strong>监督学习微调SFT&lt;/strong>、&lt;strong>基于人类反馈的强化学习RLHF&lt;/strong>等，得到了InstructGPT，进而得到了ChatGPT。&lt;/li>
&lt;/ul>
&lt;p>我们下一步继续针对简版ChatGPT开展SFT和RLHF，且听下回分解。&lt;/p></description></item><item><title>【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-transformer%E6%9E%B6%E6%9E%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/</link><pubDate>Tue, 26 Sep 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-transformer%E6%9E%B6%E6%9E%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/</guid><description>&lt;p>在《AI拾遗》这个专栏中，我们建立了从&lt;strong>N-Gram&lt;/strong>到&lt;strong>词嵌入&lt;/strong>再到&lt;strong>神经概率语言模型&lt;/strong>，从&lt;strong>Seq2Seq&lt;/strong>到&lt;strong>注意力机制&lt;/strong>的知识脉络。&lt;/p>
&lt;p>这条脉络本质就是NLP发展的路线图，有了这些知识储备，我们终于可以来理解论文**《Attention Is All You Need》**中大名鼎鼎的**Transformer架构**了！&lt;/p>
&lt;h1 id="1问题">1.问题&lt;/h1>
&lt;p>在《【chatGPT】学习笔记13-Transformer之注意力机制，大语言模型的关键部件4》中，笔者为&lt;strong>编码器-解码器架构&lt;/strong>增加了&lt;strong>注意力机制&lt;/strong>，进而实现了&lt;strong>增强版的Seq2Seq模型&lt;/strong>，模型能力的确有所增强，但并不是彻底解决了&lt;strong>长距离依赖&lt;/strong>问题和&lt;strong>信息压缩&lt;/strong>问题。&lt;/p>
&lt;p>在《Attention Is All You Need》的第一章阐述了这个观点：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>howerver, remains&lt;/strong>(第二段最后一句)：历史上很多论文和技术都在增强&lt;strong>编码器-解码器架构&lt;/strong>，注意力机制也成为序列建模必备的技术，但&lt;strong>长距离依赖&lt;/strong>问题依然存在。&lt;/li>
&lt;li>&lt;strong>parallelization&lt;/strong>(第三段)：这里提到了并行化，这是前面没有提到的问题——RNN网络决定了Seq2Seq只能一个词一个词的处理。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926072417665.png" alt="image-20230926072417665">&lt;/p>
&lt;h1 id="2transformer逐步拆解">2.Transformer逐步拆解&lt;/h1>
&lt;p>这是论文中第三段绘制的Transformer整体架构，我们将对它进行拆解：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926074022967.png" alt="image-20230926074022967">&lt;/p>
&lt;h2 id="1整体transformer">(1)整体：Transformer&lt;/h2>
&lt;p>将上图抽象化，我们可以看到：&lt;/p>
&lt;ul>
&lt;li>Transformer依然可以遵循Encoder-Decoder架构&lt;/li>
&lt;li>Decoder的输出交给一个线性层，将解码器的输出转换为目标词汇表大小的概率分布——这属于常规操作，与Transformer核心思想关系不大。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926082223230.png" alt="image-20230926082223230">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>1&lt;/strong>：对应上图将&lt;strong>Inputs&lt;/strong>输入给&lt;strong>Encoder&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>2&lt;/strong>：对应上图将&lt;strong>Outputs+Encoder的输出&lt;/strong>，传入给&lt;strong>Decoder&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>3&lt;/strong>：对应上图将&lt;strong>Decoder的输出&lt;/strong>，传入给线性层。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926083838772.png" alt="image-20230926083838772">&lt;/p>
&lt;p>PS：这里的&lt;code>corpus&lt;/code>是一个封装了&lt;code>Inputs&lt;/code>和&lt;code>Outputs&lt;/code>的工具类，代码如下(比较简单，不赘述)：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926083336984.png" alt="image-20230926083336984">&lt;/p>
&lt;h2 id="2局部1正弦位置编码表">(2)局部1：正弦位置编码表&lt;/h2>
&lt;p>首先，我们来细化&lt;strong>Inputs&lt;/strong>和&lt;strong>Encoder&lt;/strong>之间的流程：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP1&lt;/strong>.对&lt;strong>Inputs&lt;/strong>实施词嵌入，得到词向量。&lt;/li>
&lt;li>&lt;strong>STEP2&lt;/strong>.在&lt;strong>词向量&lt;/strong>和&lt;strong>Encoder&lt;/strong>之间增加了&lt;strong>位置编码表&lt;/strong>(也是一个向量)，这个位置编码表体现了&lt;strong>词和词序的关系&lt;/strong>。
&lt;ul>
&lt;li>由于Transformer取消了RNN，也就不再逐个词串行处理，所以必须建立&lt;strong>词和词序的关系&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>STEP3&lt;/strong>.将STEP2的&lt;strong>位置表码表&lt;/strong>向量和&lt;strong>词向量&lt;/strong>相加，输入给&lt;strong>Encoder&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Outputs&lt;/strong>和&lt;strong>Decoder&lt;/strong>之间的流程和上述流程一样。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926092023205.png" alt="image-20230926092023205">&lt;/p>
&lt;p>那么位置编码表如何计算呢？论文3.5章节详细阐述如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>d&lt;/strong>：词向量的维度。&lt;/li>
&lt;li>&lt;strong>pos&lt;/strong>：单词在句子中的位置。&lt;/li>
&lt;li>&lt;strong>i&lt;/strong>：词向量的维度的奇数维。&lt;/li>
&lt;li>&lt;strong>PE&lt;/strong>：指定位置的单词，在词向量的某一个维度上的数值。&lt;/li>
&lt;li>通俗地理解，&lt;strong>d个PE值构成了指定单词在整个句子中的位置向量&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926093855305.png" alt="image-20230926093855305">&lt;/p>
&lt;p>我们不必纠结于论文中这两个公式的证明，笔者绘制一个例子，可视化地理解正弦位置编码表的作用：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>假设&lt;/strong>：输入序列为&amp;rdquo;&lt;strong>想去新疆&lt;/strong>&amp;ldquo;四个字，词向量的维度为4维，即&lt;strong>d=4&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP1&lt;/strong>：通过正弦位置编码公式，&lt;strong>想&lt;/strong>字的&lt;strong>位置0&lt;/strong>，求得位置0的&lt;strong>位置向量[0, 1, 0, 1]&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP2&lt;/strong>：通过正弦位置编码公式，&lt;strong>去&lt;/strong>字的&lt;strong>位置1&lt;/strong>，求得位置1的&lt;strong>位置向量[0.84, 0.54, 0.01, 1.0]&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP3&lt;/strong>：通过正弦位置编码公式，&lt;strong>新&lt;/strong>字的&lt;strong>位置2&lt;/strong>，求得位置2的&lt;strong>位置向量[0.91, -0.42, 0.02, 1.0]&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP4&lt;/strong>：通过正弦位置编码公式，&lt;strong>疆&lt;/strong>字的&lt;strong>位置3&lt;/strong>，求得位置3的&lt;strong>位置向量[0.14, -0.99, 0.03, 1.0]&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926111712233.png" alt="image-20230926111712233">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926110113612.png" alt="image-20230926110113612">&lt;/p>
&lt;h2 id="3局部2编码器堆栈">(3)局部2：编码器堆栈&lt;/h2>
&lt;p>我们再来细化&lt;strong>编码器&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>编码器本质上由&lt;strong>N个编码器&lt;/strong>串联而成的&lt;strong>编码器堆栈&lt;/strong>。&lt;/li>
&lt;li>论文中，&lt;strong>N=6&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926112341735.png" alt="image-20230926112341735">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>论文原文&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926113124754.png" alt="image-20230926113124754">&lt;/p>
&lt;h2 id="4局部3编码器">(4)局部3：编码器&lt;/h2>
&lt;p>我们再进一步细化&lt;strong>编码器Encoder&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>编码器Encoder&lt;/strong>由&lt;strong>多头注意力&lt;/strong>和&lt;strong>前向传播网络&lt;/strong>组成。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926114259743.png" alt="image-20230926114259743">&lt;/p>
&lt;p>&lt;strong>编码器堆栈&lt;/strong>的代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>①&lt;/strong>：这就是调用&lt;strong>正弦位置编码表&lt;/strong>，创建的&lt;strong>位置编码层&lt;/strong>，再将&lt;strong>词向量和位置编码向量相加&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>②&lt;/strong>：这就是将多个&lt;strong>编码器&lt;/strong>叠加成&lt;strong>编码器堆栈&lt;/strong>，每个&lt;strong>编码器的输入&lt;/strong>是&lt;strong>上个编码器的输出&lt;/strong>和&lt;strong>上个编码器输出的注意力权重&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>③&lt;/strong>：这就是表示&lt;strong>编码器堆栈&lt;/strong>输出的&lt;strong>编码器输出&lt;/strong>、&lt;strong>编码器输出的注意力权重&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926115605435.png" alt="image-20230926115605435">&lt;/p>
&lt;p>&lt;strong>编码器&lt;/strong>的代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>①&lt;/strong>：就是&lt;strong>多头注意力层&lt;/strong>，&lt;strong>第一个编码器&lt;/strong>的&lt;strong>多头注意力层&lt;/strong>的输入是&lt;strong>词嵌入+位置编码向量之和&lt;/strong>以及&lt;strong>自注意力掩码&lt;/strong>，&lt;strong>后续编码器&lt;/strong>的&lt;strong>多头注意力层&lt;/strong>的输入是&lt;strong>上一个编码器的输出&lt;/strong>和&lt;strong>自注意力掩码&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>②&lt;/strong>：就是&lt;strong>前向传播网络&lt;/strong>，它的输入是&lt;strong>多头注意力层的输出&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926122832935.png" alt="image-20230926122832935">&lt;/p>
&lt;p>这里又埋下了几个问题：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>多头注意力层&lt;/strong>如何实现？&lt;/li>
&lt;li>&lt;strong>前向传播网络&lt;/strong>如何实现？&lt;/li>
&lt;li>&lt;strong>自注意力位置掩码&lt;/strong>如何实现？&lt;/li>
&lt;/ul>
&lt;h2 id="5局部4多头注意力">(5)局部4：多头注意力&lt;/h2>
&lt;p>我们再来细化多头注意力：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>不赘述&lt;/strong>：关于&lt;strong>点积注意力&lt;/strong>、&lt;strong>缩放点积注意力&lt;/strong>、&lt;strong>编码器-解码器注意力&lt;/strong>、&lt;strong>QKV&lt;/strong>、&lt;strong>自注意力&lt;/strong>、&lt;strong>多头注意力&lt;/strong>，本文就不再赘述了。如果理解不太清晰，可以回看《【chatGPT】学习笔记13-Transformer之注意力机制，大语言模型的关键部件4》。&lt;/li>
&lt;li>&lt;strong>多头注意力&lt;/strong>的结构：&lt;strong>多头注意力的输入&lt;/strong>是&lt;strong>词向量与位置编码向量之和&lt;/strong>，每一个注意力头都是对&lt;strong>多头注意力的输入&lt;/strong>进行矩阵乘法得到&lt;strong>QKV&lt;/strong>，再输入给&lt;strong>缩放点积注意力组件&lt;/strong>，这个组件输出的是&lt;strong>注意力权重&lt;/strong>。最后，将每个注意力头输出的注意力权重求和，输入给一个线性层。&lt;/li>
&lt;li>&lt;strong>缩放点积注意力&lt;/strong>的结构：就是典型的缩放点积注意力的计算公式，即：Q、K求点积=&amp;gt;缩放=&amp;gt;注意力掩码=&amp;gt;Softmax=&amp;gt;和V点积。&lt;/li>
&lt;li>&lt;strong>细节&lt;/strong>：这里增加了Add &amp;amp; Norm，就是深度学习里面的残差连接、层归一化，为了解决梯度爆炸问题，这不是Transformer特有的新知识。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926162228532.png" alt="image-20230926162228532">&lt;/p>
&lt;p>论文原文：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>缩放点积注意力&lt;/strong>计算公式：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926161049010.png" alt="image-20230926161049010">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>多头注意力&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926161136259.png" alt="image-20230926161136259">&lt;/p>
&lt;p>&lt;strong>缩放点积注意力&lt;/strong>的代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926161300468.png" alt="image-20230926161300468">&lt;/p>
&lt;p>&lt;strong>多头注意力&lt;/strong>的代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926161409926.png" alt="image-20230926161409926">&lt;/p>
&lt;h2 id="6局部5前向传播网络">(6)局部5：前向传播网络&lt;/h2>
&lt;p>我们再来细化前向神经网络：&lt;/p>
&lt;ul>
&lt;li>前向神经网络的全称是&lt;strong>Position-wise Feed-Forward Network&lt;/strong>，即&lt;strong>基于位置的前馈神经网络&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>two linear transformations with a ReLU activation&lt;/strong>：首先使用第一个线性层做升维，接着使用ReLU激活函数，再使用第二个线性层做降维。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926163125569.png" alt="image-20230926163125569">&lt;/p>
&lt;p>这个基于位置的前馈神经网络到底有啥用呢？&lt;/p>
&lt;ul>
&lt;li>就是论文中，多头注意力结构中的最后一步&lt;strong>Linear&lt;/strong>！&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926163933555.png" alt="image-20230926163933555">&lt;/p>
&lt;p>论文原文：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926163424383.png" alt="image-20230926163424383">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926164434302.png" alt="image-20230926164434302">&lt;/p>
&lt;h2 id="7局部6填充位置掩码">(7)局部6：填充位置掩码&lt;/h2>
&lt;p>我们再来细化填充位置掩码：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>填充位置掩码&lt;/strong>用在&lt;strong>词嵌入&lt;/strong>之后，&lt;strong>编码器&lt;/strong>输入之前。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926170827083.png" alt="image-20230926170827083">&lt;/p>
&lt;ul>
&lt;li>填充位置掩码有什么作用呢？
&lt;ul>
&lt;li>&lt;strong>t1时刻&lt;/strong>：给编码器输入了一句话——&amp;ldquo;我想去新疆滑雪&amp;rdquo;。&lt;/li>
&lt;li>&lt;strong>t2时刻&lt;/strong>：给编码器输入第二句话——&amp;ldquo;想去就去啊&amp;rdquo;。为了和上一句话保持长度统一，我们就会在在第二句话末尾增加两个占位符。&lt;/li>
&lt;li>&lt;strong>t3时刻&lt;/strong>：生成填充位置掩码[1, 1, 1, 1, 1, 0, 0]。&lt;/li>
&lt;li>&lt;strong>t4时刻&lt;/strong>：编码器会将第二句话和填充位置掩码求与，这样编码器实施多头注意力的时候，就不会注意毫无意义的两个占位符。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926171245346.png" alt="image-20230926171245346">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926171345069.png" alt="image-20230926171345069">&lt;/p>
&lt;p>至此，我们就把Transformer架构中编码器部分细化完成了，我们继续细化解码器部分：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926170827083.png" alt="image-20230926170827083">&lt;/p>
&lt;h2 id="8局部7解码器堆栈">(8)局部7：解码器堆栈&lt;/h2>
&lt;p>解码器堆栈的思想到实现，和编码器堆栈完全一样，这里不再赘述，直接上图和代码：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926174658980.png" alt="image-20230926174658980">&lt;/p>
&lt;h2 id="9局部8解码器">(9)局部8：解码器&lt;/h2>
&lt;p>解码器的思想到实现，和编码器堆栈大致一样，这里不再赘述，直接上图和代码：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926174249742.png" alt="image-20230926174249742">&lt;/p>
&lt;p>&lt;strong>解码器堆栈&lt;/strong>代码如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926174857116.png" alt="image-20230926174857116">&lt;/p>
&lt;p>&lt;strong>解码器&lt;/strong>代码如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926174916494.png" alt="image-20230926174916494">&lt;/p>
&lt;h2 id="10局部9后续位置掩码">(10)局部9：后续位置掩码&lt;/h2>
&lt;p>在解码器中，还有最后一个遗留问题——后续位置掩码。&lt;/p>
&lt;p>后续位置掩码只是因为解码器实施多头注意力的时候，是不能注意到&lt;strong>未来&lt;/strong>的，也就是它还没有预测的后续词，所以要屏蔽掉。&lt;/p>
&lt;p>后续位置掩码和填充位置掩码的思想是一致的，不赘述。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926175344740.png" alt="image-20230926175344740">&lt;/p>
&lt;p>&lt;strong>后续位置掩码&lt;/strong>的代码实现：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926175131684.png" alt="image-20230926175131684">&lt;/p>
&lt;h2 id="11模型训练">(11)模型训练&lt;/h2>
&lt;p>至此，我们已经完整地实现了Transformer架构，我们开始对其进行训练：&lt;/p>
&lt;ul>
&lt;li>数据集如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926180145967.png" alt="image-20230926180145967">&lt;/p>
&lt;ul>
&lt;li>模型训练：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926180246638.png" alt="image-20230926180246638">&lt;/p>
&lt;h2 id="12模型测试">(12)模型测试&lt;/h2>
&lt;ul>
&lt;li>测试用例采用贪婪编码，比较简单，具体代码如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926180356687.png" alt="image-20230926180356687">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>笔者在今年2月份第一次阅读论文《Attention Is All You Need》，读了好几遍，不得要领，只觉得非常抽象。&lt;/p>
&lt;p>随着在网上阅读各类资料、逐步摸索复现论文中Transformer架构的源码，逐渐理解这篇论文中所说的——&lt;strong>Attention Is All You Need&lt;/strong>的含义。&lt;/p>
&lt;p>本以为理解了论文含义，提笔准备写出这篇文章时，又卡了壳——因为理解了，又很难表达出来Transformer的精妙原理！&lt;/p>
&lt;p>此时，笔者才真正领悟之前听过一位大神所说的：&lt;font color=red>”LLM涉及的每一篇经典论文，不仅值得&lt;strong>反复阅读&lt;/strong>，甚至应该&lt;strong>背诵下来&lt;/strong>。“&lt;/font>的含义。&lt;/p>
&lt;p>这篇文章写完，我们下一步就可以实现并训练我们平民版的ChatGPT了，且听下回分解了。&lt;/p></description></item></channel></rss>