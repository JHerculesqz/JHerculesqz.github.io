<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>【chatGPT】学习笔记46-LLM微调技术之P-Tuning V1 - 妙木山</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="猴王无敌"><meta name=description content="前面给大家分享了Soft Prompt技术分支下的Prefix-Tuning和Prompt Tuning，在这个技术分支下，还有一项需要重点了解"><meta name=keywords content="Hugo,theme,jane"><meta name=generator content="Hugo 0.74.2"><link rel=canonical href=https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8Bptuningv1/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.b3a8813c06e6d785beba22bf8264e174fa2cb3a396b22f9ba24e2c00c18aaf7f.css integrity="sha256-s6iBPAbm14W+uiK/gmThdPoss6OWsi+bok4sAMGKr38=" media=screen crossorigin=anonymous><meta property="og:title" content="【chatGPT】学习笔记46-LLM微调技术之P-Tuning V1"><meta property="og:description" content="前面给大家分享了Soft Prompt技术分支下的Prefix-Tuning和Prompt Tuning，在这个技术分支下，还有一项需要重点了解"><meta property="og:type" content="article"><meta property="og:url" content="https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8Bptuningv1/"><meta property="article:published_time" content="2024-05-01T10:00:59+08:00"><meta property="article:modified_time" content="2024-05-01T10:00:59+08:00"><meta itemprop=name content="【chatGPT】学习笔记46-LLM微调技术之P-Tuning V1"><meta itemprop=description content="前面给大家分享了Soft Prompt技术分支下的Prefix-Tuning和Prompt Tuning，在这个技术分支下，还有一项需要重点了解"><meta itemprop=datePublished content="2024-05-01T10:00:59+08:00"><meta itemprop=dateModified content="2024-05-01T10:00:59+08:00"><meta itemprop=wordCount content="3256"><meta itemprop=keywords content="AI拾遗-chat GPT,"><meta name=twitter:card content="summary"><meta name=twitter:title content="【chatGPT】学习笔记46-LLM微调技术之P-Tuning V1"><meta name=twitter:description content="前面给大家分享了Soft Prompt技术分支下的Prefix-Tuning和Prompt Tuning，在这个技术分支下，还有一项需要重点了解"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>妙木山</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/>首页</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/categories/>技术专栏</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/tags/>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/post/>全部文章</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/about/>关于</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>妙木山</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/>首页</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/categories/>技术专栏</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/post/>全部文章</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/about/>关于</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>【chatGPT】学习笔记46-LLM微调技术之P-Tuning V1</h1><div class=post-meta><time datetime=2024-05-01 class=post-time>2024-05-01</time><div class=post-category><a href=https://jherculesqz.github.io/categories/ai%E6%8B%BE%E9%81%97/>AI拾遗</a></div><span class=more-meta>约 3256 字</span>
<span class=more-meta>预计阅读 7 分钟</span>
<span id=busuanzi_container_page_pv>| 阅读 <span id=busuanzi_value_page_pv></span></span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#1abstract摘要>1.Abstract(摘要)</a></li><li><a href=#2introduction介绍>2.Introduction(介绍)</a></li><li><a href=#3design-decisions实验设计>3.Design Decisions(实验设计)</a><ul><li><a href=#1问题域>(1)问题域</a></li><li><a href=#2问题建模>(2)问题建模</a></li></ul></li><li><a href=#4experiments实验结果>4.Experiments(实验结果)</a><ul><li><a href=#1实验结果1knowledge-probing>(1)实验结果1：Knowledge Probing</a></li><li><a href=#2实验结果2fully-supervised-learning>(2)实验结果2：Fully-supervised Learning</a></li><li><a href=#3实验结果3few-shot-learning>(3)实验结果3：Few-Shot Learning</a></li></ul></li><li><a href=#5总结>5.总结</a></li></ul></nav></div></div><div class=post-content><p>前面给大家分享了<code>Soft Prompt</code>技术分支下的<code>Prefix-Tuning</code>和<code>Prompt Tuning</code>，在这个技术分支下，还有一项需要重点了解的微调技术——<code>P-Tuning</code>。</p><p><code>P-Tuning</code>是清华大学和MIT于2021年联合发布的一项微调技术，在NLU(自然语言理解)任务上有重大突破。</p><p>本文解读论文**《GPT Understands, Too》**，我们一起来学习一下<code>Prompt Tuning</code>技术的原理。</p><h1 id=1abstract摘要>1.Abstract(摘要)</h1><p>首先我们看一下论文摘要，快速理解论文的<strong>核心内容</strong>：</p><ul><li><p><strong>问题</strong>：<strong>Discrete Prompts</strong>(离散提示词)会导致大模型性能不稳定。</p><ul><li>比如：修改提示词中的一个单词，都可能导致大模型的性能大幅下降。</li><li>本质：根据自然语言形式的提示词进行预测，对于大模型本身<strong>从数学上是不可微的</strong>(这就是数学意义上的<strong>离散性</strong>)——不可微就意味着AI无法高效、稳定地<strong>提特征</strong>。</li></ul></li><li><p><strong>解决方案</strong>：论文提出的<code>P-Tuning</code>技术，也是一种使用<strong><code>Soft Prompt(软提示)</code></strong>进行迁移学习的方法。将离散提示词向量化为可训练的连续提示词(<strong>trainable continuous prompt embeddings</strong>)。</p></li><li><p><strong>实验效果</strong>：</p><ul><li><strong>P-Tuning</strong>通过连续提示词向量，降低了不同离散提示之间的差距，进而提升了模型的稳定性。</li><li><strong>P-Tuning</strong>在LAMA、SuperGLUE等NLU任务上，显著提高了模型性能。</li></ul></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV1/image-20240426094803830.png alt=image-20240426094803830></p><h1 id=2introduction介绍>2.Introduction(介绍)</h1><ul><li><strong>问题</strong>：离散提示会导致大模型的稳定性问题。<ul><li><strong>以手动离散提示为例</strong>：提示中改变一个单词可能会导致显著的性能下降，存在很大的不稳定性。</li><li><strong>一些优化尝试</strong>：<ul><li>调整语言模型本身，不稳定性问题有所缓解，但不同提示之间的性能差异仍然很大(特别是在少样本场景下)。</li><li><strong>自动提示法(automatic prompting)</strong>：试图为给定任务搜索更好的提示，但这些方法并没有改变离散提示的不稳定本质。</li></ul></li></ul></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV1/image-20240426114420388.png alt=image-20240426114420388></p><ul><li><p><strong>Prompt Tuning的核心思想</strong>：</p><ul><li><strong>prompt encoder</strong>：论文提到通过<strong>prompt encoder(提示词编码器)</strong>，将输入的离散提示Token，和连续提示Embedding连接起来后，输入给大语言模型。其中，<strong>prompt encoder</strong>可采用LSTM或MLP来实现。</li><li><strong>backpropagation to optimize&mldr;</strong>：可以通过反向传播，优化连续提示词，进而将离散提示转变为可微的连续提示。</li><li><strong>P-Tuning的本质</strong>：该技术的本质打破离散提示的限制——离散则不便于<strong>提特征</strong>，连续可微则可学习——因此P-Tuning抵消了离散提示中微小变化对稳定性。</li></ul></li><li><p><strong>实验效果</strong>：</p><ul><li>在LAMA基准测试中，使用P-Tuning，比手动离散提示(manual discrete prompts)提升了20多分，比搜索提示(searched prompts)提升了9分。</li><li>在SuperGLUE基准测试中，在全监督和少样本下都优于PET的最佳离散提示(the best discrete prompts)。</li><li>实验还证明，在更广泛的任务中，P-Tuning降低了不同离散提示之间的差异，进而提升了模型的稳定性。</li></ul></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV1/image-20240426113823515.png alt=image-20240426113823515></p><h1 id=3design-decisions实验设计>3.Design Decisions(实验设计)</h1><h2 id=1问题域>(1)问题域</h2><p>提示词是大家耳熟能详的激发LLM能力的技术手段，但是<strong>从数学上具有极大的局限性</strong>——就是它是<strong>数学意义上的离散</strong>。</p><p>论文作者举了这样的一个例子：</p><ul><li>表格第三行和表格第四行的两个提示词，只是少了一个单词<strong>In</strong>，AI猜出来X和Y填什么的准确度就下降了20分。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV1/image-20240501144315842.png alt=image-20240501144315842></p><p>在本论文发表前，业界还有一些自动化搜索离散提示的优化尝试：</p><ul><li><strong>mining the training corpus</strong>：挖掘训练语料库。</li><li><strong>gradient-based searching</strong>：基于梯度的搜索。</li><li><strong>using pretrained generative model</strong>：使用预训练的生成模型。</li></ul><p>这些优化方法的本质就是<strong>自动生成提示词</strong>，但是用自然语言表示的提示词依然还是<strong>数学意义上的离散</strong>。</p><h2 id=2问题建模>(2)问题建模</h2><p>论文对问题进行了数学建模：</p><ul><li><strong>M、V、h</strong>：M表示预训练模型， 词表大小V，隐藏层大小h。</li><li><strong>{(x<sub>i</sub>, y<sub>j</sub>)}<sub>i</sub></strong>：表示在NLU任务中的数据集。x<sub>0:n</sub>={x<sub>0</sub>, x<sub>1</sub>, &mldr;, x<sub>n</sub>}是一系列离散Token组成的输入，y∈Y表示标签。</li><li><strong>f<sub>M</sub>(x)=p(y|x)</strong>：表示预训练模型M的任务，就是预测分类的条件概率。</li><li><strong>[Di]</strong>：表示离散提示的Token，每一个离散提示都可以表示为T = {[D<sub>0:i</sub>, x, [D<sub>(i+1):j</sub>], y, [D<sub>(j+1):k</sub>]}。</li></ul><p>通俗一点说，上面这一通数学建模，就是描述了一个填字游戏：</p><ul><li>比如：The capital of <input checked disabled type=checkbox> is [y]。</li><li>如果x=Britain，则希望AI输出y=London。</li><li>如果x=中国，则希望AI输出y=北京。</li></ul><p>离散提示<strong>T = {[D<sub>0:i</sub>, x, [D<sub>(i+1):j</sub>], y, [D<sub>(j+1):k</sub>]}<strong>会被Embedding为</strong>{e(D<sub>0</sub>)&mldr;e(D<sub>i</sub>), e(x<sub>0</sub>), &mldr;, e(x<sub>n</sub>), &mldr;, e(D<sub>k</sub>)}</strong>，其中e ∈
R<sup>|V|×d</sup>。如下图：</p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV1/image-20240501151933103.png alt=image-20240501151933103></p><p><strong>P-Tuning的实现怎么表达呢</strong>？如下：</p><ul><li><strong>[P<sub>i</sub>]</strong>：表示第i个连续提示Embedding，注意论文的表述——<strong>连续的提示词嵌入(continuous prompt embedding)</strong>。</li><li><strong>T = {[P<sub>0:i</sub>, x, [P<sub>(i+1):j</sub>], y, [P<sub>(j+1):k</sub>]}</strong>：基于[P<sub>i</sub>]的含义，那么任意一个提示词都能表达为T = {[P<sub>0:i</sub>, x, [P<sub>(i+1):j</sub>], y, [P<sub>(j+1):k</sub>]}。</li><li><strong>f: [P<sub>i</sub>]->h<sub>i</sub></strong>：一个词嵌入函数，用来将T = {[P<sub>0:i</sub>, x, [P<sub>(i+1):j</sub>], y, [P<sub>(j+1):k</sub>]}转换为{h<sub>0</sub>, e(x), h<sub>i+1</sub>, &mldr;, h<sub>j</sub>, e(y), h<sub>j+1</sub>, &mldr;, h<sub>k</sub>}。</li><li><strong>{P<sub>i</sub>}<sup>k</sup><sub>i=1</sub></strong>：表示P-Tuning的目标——反向传播，优化损失值，在预训练模型之前学习到提示词的特征。</li></ul><p>不严谨地理解一下P-Tuning的玩法——就是加了个新的神经网络，不断地在学习如下提示词：</p><ul><li>如果有人说：<strong>吾饥矣</strong>，你就要说：我给你下面吃啊。</li><li>如果有人说：<strong>吾腹中空空</strong>，你就要说：我给你下面吃啊。</li><li>如果有人说：<strong>吾腹鸣如鼓</strong>，你就要说：我给你下面吃啊。</li></ul><p>它会发现<strong>吾饥矣、吾腹中空空、吾腹鸣如鼓</strong>的特征，都是在说<strong>肚子饿了</strong>，于是在调用大语言模型之前，它就把自然语言形态的离散提示词都转变为：</p><ul><li>如果有人说：<strong>我饿了</strong>，你就要说：xxx。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV1/image-20240501153355161.png alt=image-20240501153355161></p><p>最后，我们来完整地对比一下<strong>自动化搜索离散提示</strong>法和<strong>P-Tuning</strong>的差别：</p><ul><li><strong>自动搜索离散提示</strong>用的是<strong>Prompt Generator</strong>找特征。</li><li><strong>P-Tuning</strong>是用<strong>Prompt Encoder</strong>找特征。</li><li><strong>P-Tuning</strong>将数学意义上的<strong>离散提示词</strong>转换为了<strong>连续可微提示词</strong>，帮助AI更好地提特征。</li><li>其实两种思路本质都一样，都是很巧妙的想法。</li><li>论文还提到Prompt Encoder的实现采用了<strong>LSTM、MLPs、identity mapping function(恒等映射函数)</strong>。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV1/image-20240501153925852.png alt=image-20240501153925852></p><h1 id=4experiments实验结果>4.Experiments(实验结果)</h1><h2 id=1实验结果1knowledge-probing>(1)实验结果1：Knowledge Probing</h2><p>在知识探索(Knowledge Probing)型任务上，实验可以评估出AI获得现实世界知识量。</p><p>LAMA数据集创建了三元组形式的完型填空，来实施知识探索评估。</p><p>从实验结果上看，P-Tuning显著提高了知识探测的效果。</p><ul><li><strong>LAMA-34k数据集</strong>：从43.3%提高到50.6%</li><li><strong>LAMA-29k数据集</strong>：从45.2%提高到64.2%</li><li><strong>相较于离散提示搜索方法</strong>：P-Tuning优于离散提示搜索方法。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV1/image-20240501161239613.png alt=image-20240501161239613></p><h2 id=2实验结果2fully-supervised-learning>(2)实验结果2：Fully-supervised Learning</h2><p>实验采用了SuperGLUE基准测试，测试了7个自然语言理解任务(NLU)。包括：</p><ul><li>问答、MultiRC、文本蕴含、RTE、共指消解、因果推理、词义消歧。</li></ul><p>实验使用了四个版本的预训练模型：</p><ul><li>GPT2-Base</li><li>GPT2-medium</li><li>BERT-Base</li><li>BERT-Large</li></ul><p>实验证明<strong>P-Tuning可以提高 BERT和GPT上的全监督学习性能</strong>：</p><ul><li>在 BERT-Base上，P-Tuning在5/7任务上实现了最佳性能。</li><li>在 BERT-Large上，P-Tuning在4/7任务上超越了其他方法。</li><li>在 GPT2-Base和 GPT2-Medium上，P-Tuning 在所有任务上始终是最佳性能。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV1/image-20240501161948829.png alt=image-20240501161948829></p><h2 id=3实验结果3few-shot-learning>(3)实验结果3：Few-Shot Learning</h2><p>实验使用了少样本SuperGLUE基准测试，就是FewGLUE数据集。</p><p>实验证明了P-Tuning有一定的提升：</p><ul><li>ALBERT上，比PET平均高出1个点、比Prompt Tuning高出13个点。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV1/image-20240501162327022.png alt=image-20240501162327022></p><h1 id=5总结>5.总结</h1><p>从上述论文解读中，我们收获了如下技术观点：</p><ul><li><strong>离散提示的问题</strong>：数学上离散，不便于AI提特征。</li><li><strong>P-Tuning的核心思想</strong>：将离散提示词转换为连续可微提示词，微调的目标是用LSTM这类网络学习提示词特征。</li></ul><p>论文链接：https://arxiv.org/pdf/2103.10385</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>猴王无敌</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2024-05-01</span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><div class=post-reward><input type=checkbox name=reward id=reward hidden>
<label class=reward-button for=reward>赞赏支持</label><div class=qr-code><label class=qr-code-image for=reward><img class=image src=/weixin.png>
<span>微信打赏</span></label>
<label class=qr-code-image for=reward><img class=image src=/alipay.png>
<span>支付宝打赏</span></label></div></div><footer class=post-footer><div class=post-tags></div><nav class=post-nav><a class=next href=/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B045-llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8Bprompt-tuning/><span class="next-text nav-default">【chatGPT】学习笔记45-LLM微调技术之Prompt Tuning</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=mailto:JHercules_qz@qq.com rel="me noopener" class=iconfont title=email><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408 1361.641813S1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523L83.726336 1024H682.532949 753.579947 1348.948139L1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955C777.248 802.205449 742.347691 811.03081 718.063616 811.603883z"/></svg></a><a href=https://github.com/JHerculesqz rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=https://jherculesqz.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2021 -
2024
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>猴王无敌</span></span>
<span id=busuanzi_container>访客数/访问量：<span id=busuanzi_value_site_uv></span>/<span id=busuanzi_value_site_pv></span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script><script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script><script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script><script type=text/javascript src=/js/load-photoswipe.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>