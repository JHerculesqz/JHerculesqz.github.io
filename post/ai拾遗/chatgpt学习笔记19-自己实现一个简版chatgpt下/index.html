<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>【chatGPT】学习笔记19-自己实现一个简版ChatGPT(下) - 妙木山</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="猴王无敌"><meta name=description content="前两篇实现了简版GPT，并对其进行了SFT，我们接下来看ChatGPT整体训练流程的最后一个环节——对齐训练(Alignment Traini"><meta name=keywords content="Hugo,theme,jane"><meta name=generator content="Hugo 0.74.2"><link rel=canonical href=https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%8B/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.b3a8813c06e6d785beba22bf8264e174fa2cb3a396b22f9ba24e2c00c18aaf7f.css integrity="sha256-s6iBPAbm14W+uiK/gmThdPoss6OWsi+bok4sAMGKr38=" media=screen crossorigin=anonymous><meta property="og:title" content="【chatGPT】学习笔记19-自己实现一个简版ChatGPT(下)"><meta property="og:description" content="前两篇实现了简版GPT，并对其进行了SFT，我们接下来看ChatGPT整体训练流程的最后一个环节——对齐训练(Alignment Traini"><meta property="og:type" content="article"><meta property="og:url" content="https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%8B/"><meta property="article:published_time" content="2023-10-20T18:00:59+08:00"><meta property="article:modified_time" content="2023-10-20T18:00:59+08:00"><meta itemprop=name content="【chatGPT】学习笔记19-自己实现一个简版ChatGPT(下)"><meta itemprop=description content="前两篇实现了简版GPT，并对其进行了SFT，我们接下来看ChatGPT整体训练流程的最后一个环节——对齐训练(Alignment Traini"><meta itemprop=datePublished content="2023-10-20T18:00:59+08:00"><meta itemprop=dateModified content="2023-10-20T18:00:59+08:00"><meta itemprop=wordCount content="2160"><meta itemprop=keywords content="AI拾遗-chat GPT,"><meta name=twitter:card content="summary"><meta name=twitter:title content="【chatGPT】学习笔记19-自己实现一个简版ChatGPT(下)"><meta name=twitter:description content="前两篇实现了简版GPT，并对其进行了SFT，我们接下来看ChatGPT整体训练流程的最后一个环节——对齐训练(Alignment Traini"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>妙木山</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/>首页</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/categories/>技术专栏</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/tags/>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/post/>全部文章</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/about/>关于</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>妙木山</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/>首页</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/categories/>技术专栏</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/post/>全部文章</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/about/>关于</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>【chatGPT】学习笔记19-自己实现一个简版ChatGPT(下)</h1><div class=post-meta><time datetime=2023-10-20 class=post-time>2023-10-20</time><div class=post-category><a href=https://jherculesqz.github.io/categories/ai%E6%8B%BE%E9%81%97/>AI拾遗</a></div><span class=more-meta>约 2160 字</span>
<span class=more-meta>预计阅读 5 分钟</span>
<span id=busuanzi_container_page_pv>| 阅读 <span id=busuanzi_value_page_pv></span></span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#1方法3对齐训练alignment-training>1.方法3：对齐训练(Alignment Training)</a><ul><li><a href=#1与chatgpt整体训练流程图的对应关系>(1)与ChatGPT整体训练流程图的对应关系</a></li><li><a href=#2什么是对齐训练>(2)什么是对齐训练</a></li><li><a href=#3step2的reward-model模型训练伪码>(3)STEP2的Reward Model模型训练伪码</a></li><li><a href=#4step3的rlhf训练伪码>(4)STEP3的RLHF训练伪码</a></li></ul></li><li><a href=#2deepspeed>2.DeepSpeed</a></li><li><a href=#3实例-开展rlhf训练>3.实例-开展RLHF训练</a><ul><li><a href=#step0前置准备>STEP0.前置准备</a></li><li><a href=#step1sft>STEP1.SFT</a></li><li><a href=#step2rm>STEP2.RM</a></li><li><a href=#step3rlhf>STEP3.RLHF</a></li><li><a href=#step4模型测试>STEP4.模型测试</a></li></ul></li><li><a href=#4小结>4.小结</a></li></ul></nav></div></div><div class=post-content><p>前两篇实现了简版GPT，并对其进行了SFT，我们接下来看ChatGPT整体训练流程的最后一个环节——<strong>对齐训练(Alignment Training)</strong>。</p><h1 id=1方法3对齐训练alignment-training>1.方法3：对齐训练(Alignment Training)</h1><h2 id=1与chatgpt整体训练流程图的对应关系>(1)与ChatGPT整体训练流程图的对应关系</h2><ul><li>方法3对应于<strong>ChatGPT整体训练流程的STEP2、STEP3</strong>。</li><li>方法3的核心思想是利用了强化学习，最终将GPT3演进为了<strong>更通人性的ChatGPT</strong>。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020062050959.png alt=image-20231020062050959></p><ul><li>ChatGPT整体训练流程中的<strong>STEP2、STEP3</strong>，就是大名鼎鼎的<strong>RLHF</strong>——<strong>基于人类反馈的强化学习</strong>。<ul><li><strong>RL：Reinforcement Learning</strong></li><li><strong>HF：Human Feedback</strong></li></ul></li><li>ChatGPT整体训练流程中的<strong>STEP2</strong>，<strong>对应于</strong>强化学习模型的<strong>Interpreter模型</strong>。</li><li>ChatGPT整体训练流程中的<strong>STEP3</strong>，<strong>对应于</strong>强化学习模型的<strong>Action模型</strong>。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020085551189.png alt=image-20231020085551189></p><h2 id=2什么是对齐训练>(2)什么是对齐训练</h2><ul><li><p><strong>对齐训练</strong>：Alignment Training，它就是一种机器学习的模型训练方法。</p></li><li><p><strong>核心思想</strong>：训练出人类主观感受的模型，这个模型具备预测人类的决策的能力。</p><ul><li>这样，训练好的模型，就可以在未见过的场景下，按照类似人的行为模式做出选择。</li></ul></li><li><p><strong>对齐训练与强化学习的关系</strong>：OpenAI在对齐训练中，结合了强化学习。</p><ul><li>ChatGPT整体训练流程的STEP2就是对齐训练，学习出预测人类回答问题的偏好模型。</li><li>ChatGPT整体训练流程的STEP3就是强化学习，STEP2输出的这个模型，作为强化学习的Interpreter模型。STEP3不断迭代，最终学习到Action模型。<ul><li>通过SFT训练之后GPT3，本质就是一个能机械式地回答问题的机器人。</li><li>通过RLHF学习的Action模型，才是帮助SFT之后的GPT3，类似人类回答问题的关键机关。</li></ul></li></ul></li><li><p><strong>细节</strong>：ChatGPT整体训练流程图中，出现了PPO算法，PPO算法是近端策略梯度优化，增加一个限制Action模型在训练过程中梯度上升速度，本质就是避免Action模型产生一个离谱的Action。</p><ul><li>PPO算法展开说内容太多，本文不赘述，详见论文：https://arxiv.org/abs/1707.06347</li></ul></li></ul><h2 id=3step2的reward-model模型训练伪码>(3)STEP2的Reward Model模型训练伪码</h2><ul><li>我们再来看看STEP2的伪码，如下图：</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020093407332.png alt=image-20231020093407332></p><h2 id=4step3的rlhf训练伪码>(4)STEP3的RLHF训练伪码</h2><ul><li>我们再来看看STEP3的伪码，如下图：</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020095154134.png alt=image-20231020095154134></p><h1 id=2deepspeed>2.DeepSpeed</h1><p>RLHF，是ChatGPT最核心的技术机密，除了在《Introducing ChatGPT》(<a href=https://openai.com/blog/chatgpt>https://openai.com/blog/chatgpt</a>)中提到了，并未公开过源码。</p><p>在前文的伪码实现部分，虽然通过伪码描述了RLHF的核心逻辑，但距离商用还欠缺很多东西(如：分布式训练等)。</p><p>幸好微软开源了类似的框架，DeepSpeed，我们可以通过阅读它的源码、使用它，开展RLHF。</p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020100752488.png alt=image-20231020100752488></p><h1 id=3实例-开展rlhf训练>3.实例-开展RLHF训练</h1><h2 id=step0前置准备>STEP0.前置准备</h2><ul><li><strong>硬件</strong>：V100一块，32G显存</li><li><strong>基础软件</strong>：Ubuntun20.04，Minicoda3，Pytorch3.8，CUDA11.6，Python3.10</li><li><strong>预训练模型</strong>：选择Facebook的opt1.3B，即<strong>13亿参数</strong>的预训练模型。</li><li><strong>环境初始配置</strong>：创建虚拟环境，</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020102932305.png alt=image-20231020102932305></p><ul><li><strong>安装依赖</strong>：进入DeepSpeed-Chat目录，安装相关依赖</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020103116451.png alt=image-20231020103116451></p><ul><li><strong>环境测试</strong>：确认相关基础软件版本号。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020103548543.png alt=image-20231020103548543></p><h2 id=step1sft>STEP1.SFT</h2><ul><li>开展SFT训练时，由于服务器资源不足(省钱)，需要避免OOM异常，因此需要修改一下训练脚本。</li></ul><blockquote><p>路径：training/step1_supervised_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh</p></blockquote><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020104103388.png alt=image-20231020104103388></p><ul><li>设置待微调的预训练模型，以及输出路径。</li></ul><blockquote><p>路径：training/step1_supervised_finetuning/evaluation_scripts/run_prompt.sh</p></blockquote><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020110616405.png alt=image-20231020110616405></p><ul><li>执行训练脚本run_1.3b.sh，触发DeepSpeed开始SFT训练。</li></ul><iframe src="//player.bilibili.com/player.html?aid=959965022&bvid=BV1Hp4y1M7Ly&cid=1305868791&p=1" scrolling=no border=0 frameborder=no framespacing=0 allowfullscreen height=600px></iframe><h2 id=step2rm>STEP2.RM</h2><ul><li>开展RM训练时，由于服务器资源不足(省钱)，需要避免OOM异常，因此需要修改一下训练脚本。</li></ul><blockquote><p>路径：training_scripts/opt/single_gpu/run_350m.sh</p></blockquote><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020145149415.png alt=image-20231020145149415></p><ul><li>指定Reward Model的输出路径。</li></ul><blockquote><p>路径：evaluation_scripts/run_eval.sh</p></blockquote><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020145843742.png alt=image-20231020145843742></p><ul><li>执行训练脚本run_350m.sh，触发DeepSpeed开始RW训练。</li></ul><iframe src="//player.bilibili.com/player.html?aid=534943541&bvid=BV1gM411R7Z5&cid=1305868897&p=1" scrolling=no border=0 frameborder=no framespacing=0 allowfullscreen height=600px></iframe><h2 id=step3rlhf>STEP3.RLHF</h2><ul><li>开展RLHF训练时，由于服务器资源不足(省钱)，需要避免OOM异常，因此需要修改一下训练脚本。</li></ul><blockquote><p>training_scripts/opt/single_gpu/run_1.3b.sh</p></blockquote><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020155704428.png alt=image-20231020155704428></p><ul><li>执行训练脚本run_1.3b.sh，触发DeepSpeed开始RLHF训练。</li></ul><iframe src="//player.bilibili.com/player.html?aid=277474259&bvid=BV1Ww411F7xw&cid=1305868938&p=1" scrolling=no border=0 frameborder=no framespacing=0 allowfullscreen height=600px></iframe><h2 id=step4模型测试>STEP4.模型测试</h2><ul><li>执行测试脚本<code>python chat.py --path training/step3_rlhf_finetuning/output/actor</code>，不赘述。</li></ul><h1 id=4小结>4.小结</h1><p>本文是实现简版GPT的三篇中的最后一篇，也是最难理解的一部分内容：</p><ul><li>对齐训练是什么？</li><li>对齐训练和强化学习的关系是什么？</li><li>ChatGPT整体训练流程的STEP2、STEP3与强化学习的Interpreter和Action模型如何对应？</li><li>DeepSpeed的实际操作？</li></ul><p>本文也有没有展开探讨的内容，待本专栏后续继续展开：</p><ul><li>RLHF的策略梯度优化算法</li><li>PPO算法</li><li>……</li></ul><p>编写本专栏受益匪浅，也非常感恩因为编写本专栏认识的大神们，期待与各位小伙伴持续的讨论和思辨！</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>猴王无敌</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2023-10-20</span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><div class=post-reward><input type=checkbox name=reward id=reward hidden>
<label class=reward-button for=reward>赞赏支持</label><div class=qr-code><label class=qr-code-image for=reward><img class=image src=/weixin.png>
<span>微信打赏</span></label>
<label class=qr-code-image for=reward><img class=image src=/alipay.png>
<span>支付宝打赏</span></label></div></div><footer class=post-footer><div class=post-tags></div><nav class=post-nav><a class=prev href=/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAchatglm3/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">【chatGPT】学习笔记20-如何搭建ChatGLM3</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%AD/><span class="next-text nav-default">【chatGPT】学习笔记18-自己实现一个简版ChatGPT(中)</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=mailto:JHercules_qz@qq.com rel="me noopener" class=iconfont title=email><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408 1361.641813S1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523L83.726336 1024H682.532949 753.579947 1348.948139L1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955C777.248 802.205449 742.347691 811.03081 718.063616 811.603883z"/></svg></a><a href=https://github.com/JHerculesqz rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=https://jherculesqz.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2021 -
2023
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>猴王无敌</span></span>
<span id=busuanzi_container>访客数/访问量：<span id=busuanzi_value_site_uv></span>/<span id=busuanzi_value_site_pv></span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script><script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script><script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script><script type=text/javascript src=/js/load-photoswipe.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>