<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>【chatGPT】学习笔记47-LLM微调技术之P-Tuning V2 - 妙木山</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="猴王无敌"><meta name=description content="上篇专栏我们讲到，P-Tuning V1通过在预训练模型的输入层加入可训练的连续提示，有效提升了训练效果。但其在复杂NLU任务和小参数模型上表"><meta name=keywords content="Hugo,theme,jane"><meta name=generator content="Hugo 0.74.2"><link rel=canonical href=https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8Bptuningv2/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.b3a8813c06e6d785beba22bf8264e174fa2cb3a396b22f9ba24e2c00c18aaf7f.css integrity="sha256-s6iBPAbm14W+uiK/gmThdPoss6OWsi+bok4sAMGKr38=" media=screen crossorigin=anonymous><meta property="og:title" content="【chatGPT】学习笔记47-LLM微调技术之P-Tuning V2"><meta property="og:description" content="上篇专栏我们讲到，P-Tuning V1通过在预训练模型的输入层加入可训练的连续提示，有效提升了训练效果。但其在复杂NLU任务和小参数模型上表"><meta property="og:type" content="article"><meta property="og:url" content="https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8Bptuningv2/"><meta property="article:published_time" content="2024-05-11T10:00:59+08:00"><meta property="article:modified_time" content="2024-05-11T10:00:59+08:00"><meta itemprop=name content="【chatGPT】学习笔记47-LLM微调技术之P-Tuning V2"><meta itemprop=description content="上篇专栏我们讲到，P-Tuning V1通过在预训练模型的输入层加入可训练的连续提示，有效提升了训练效果。但其在复杂NLU任务和小参数模型上表"><meta itemprop=datePublished content="2024-05-11T10:00:59+08:00"><meta itemprop=dateModified content="2024-05-11T10:00:59+08:00"><meta itemprop=wordCount content="2675"><meta itemprop=keywords content="AI拾遗-chat GPT,"><meta name=twitter:card content="summary"><meta name=twitter:title content="【chatGPT】学习笔记47-LLM微调技术之P-Tuning V2"><meta name=twitter:description content="上篇专栏我们讲到，P-Tuning V1通过在预训练模型的输入层加入可训练的连续提示，有效提升了训练效果。但其在复杂NLU任务和小参数模型上表"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>妙木山</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/>首页</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/categories/>技术专栏</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/tags/>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/post/>全部文章</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/about/>关于</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>妙木山</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/>首页</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/categories/>技术专栏</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/post/>全部文章</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/about/>关于</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>【chatGPT】学习笔记47-LLM微调技术之P-Tuning V2</h1><div class=post-meta><time datetime=2024-05-11 class=post-time>2024-05-11</time><div class=post-category><a href=https://jherculesqz.github.io/categories/ai%E6%8B%BE%E9%81%97/>AI拾遗</a></div><span class=more-meta>约 2675 字</span>
<span class=more-meta>预计阅读 6 分钟</span>
<span id=busuanzi_container_page_pv>| 阅读 <span id=busuanzi_value_page_pv></span></span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#1abstract摘要>1.Abstract(摘要)</a></li><li><a href=#2introduction介绍>2.Introduction(介绍)</a></li><li><a href=#3design-decisions实验设计>3.Design Decisions(实验设计)</a><ul><li><a href=#1问题域>(1)问题域</a></li><li><a href=#2问题建模>(2)问题建模</a></li></ul></li><li><a href=#4experiments实验结果>4.Experiments(实验结果)</a><ul><li><a href=#1实验结果1across-scales>(1)实验结果1：Across Scales</a></li><li><a href=#2实验结果2across-tasks>(2)实验结果2：Across Tasks</a></li><li><a href=#3其它重要发现实现prompt-encoder的神经网络结构的选择技巧>(3)其它重要发现：实现Prompt Encoder的神经网络结构的选择技巧</a></li></ul></li><li><a href=#5总结>5.总结</a></li></ul></nav></div></div><div class=post-content><p>上篇专栏我们讲到，<code>P-Tuning V1</code>通过在预训练模型的输入层加入可训练的连续提示，有效提升了训练效果。但其在复杂NLU任务和小参数模型上表现并不理想。</p><p><code>P-Tuning V2</code>是对<code>P-Tuning V1</code>的改进，使其能在不同规模的模型和各种NLU任务中都能与全量微调相媲美。</p><p>本文解读论文**《P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks》**，探究<code>Prompt Tuning V2</code>技术的原理。</p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511112022603.png alt=image-20240511112022603></p><h1 id=1abstract摘要>1.Abstract(摘要)</h1><p>首先我们看一下论文摘要，快速理解论文的<strong>核心内容</strong>：</p><ul><li><strong>问题</strong>：<strong>P-Tuning v1</strong>的最大问题是不具备普适性(<strong>a lack of universality</strong>)。<ul><li><strong>不同规模模型的微调效果不稳定</strong>：Lack of universality across scales。模型规模超过10B时，<strong>P-Tuning v1</strong>和<strong>Fine Tuning</strong>水平相当。模型规模在0.1B到1B时，<strong>P-Tuning v1</strong>的效果远不如<strong>Fine Tuning</strong>。</li><li><strong>不同下游任务的微调效果不稳定</strong>：Lack of universality across tasks。实验证明，针对某些下游任务进行<strong>P-Tuning v1</strong>，效果远差于<strong>Fine Tuning</strong>。</li></ul></li><li><strong>解决方案</strong>：论文提出<strong>P-Tuning v2</strong>技术，采用<strong>Deep Prompt Tuning</strong>方法，同时针对NLU任务做了一定适配和优化。</li><li><strong>实验效果</strong>：实验证明<strong>P-Tuning v2</strong>，在不同规模的模型上、在不同下游任务上都可获得较高的稳定性。是一种对<strong>P-Tuning v1</strong>更好的替代方法。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511112132956.png alt=image-20240511112132956></p><h1 id=2introduction介绍>2.Introduction(介绍)</h1><ul><li><p><strong>问题</strong>：<strong>P-Tuning v1</strong>在不同规模的模型下、不同下游任务中，微调效果不稳定。</p><ul><li>如：当模型大小不大，特别是少于10B参数时，<strong>P-Tuning v1</strong>的表现不如<strong>Fine Tuning</strong>。</li><li><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511114454639.png alt=image-20240511114454639></li><li>如：抽取式问答(extractive question answering)，<strong>P-Tuning v1</strong>的表现不如<strong>Fine Tuning</strong>。</li><li><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511114429201.png alt=image-20240511114429201></li></ul></li><li><p><strong>P-Tuning v2的核心思想</strong>：</p><ul><li>P-Tuning v2采用<strong>Deep P-Tuning</strong>的优化方式，用于探索垂域知识。</li><li>Deep表现于在预训练模型的每一层注意力层增加了一个小模型，作用于每一层的输入。而P-Tuning v1仅在第一层增加了一个LSTM小模型。</li><li>这种方法的本质是：不同规模的模型对于<strong>P-Tuning v1</strong>在第一层增加的前缀向量的特征提取能力不同。越大的模型特征提取越强，后续各层都能感知注意到这个前缀向量的特征。反之，小模型特征提取能力弱，后续各层无法感知注意到前缀向量的特征。</li></ul></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511115216844.png alt=image-20240511115216844></p><ul><li><strong>实验效果</strong>：<ul><li>对300M到10B参数的模型上实验，<strong>P-Tuning v2</strong>具备很稳定的微调效果。</li><li>以抽取式问答和命名实体识别为代表的下游任务上，<strong>P-Tuning v2</strong>具备很稳定的微调效果。</li></ul></li></ul><h1 id=3design-decisions实验设计>3.Design Decisions(实验设计)</h1><h2 id=1问题域>(1)问题域</h2><p><strong>P-Tuning v1</strong>提出了将<strong>数学意义上的离散提示词转换为连续可微的提示词</strong>，但存在的问题还有2个：</p><ul><li>不同规模的模型微调效果不稳定。</li><li>不同下游任务的模型微调效果不稳定。</li></ul><p><strong>离散到连续</strong>是<strong>Soft Prompt</strong>技术分支的<strong>重要思想、重要里程碑</strong>，但<strong>P-Tuning v1</strong>已经做到连续可微了，还有什么改进空间呢？</p><h2 id=2问题建模>(2)问题建模</h2><p>为了寻找突破口，我们还是进行数学建模：</p><ul><li><strong>V、M、e</strong>：V表示模型M的词汇表，e表示模型M的词嵌入层。</li><li><strong>离散到连续的转换</strong>：假定离散提示词为序列**[h<sub>0</sub>, &mldr;, h<sub>i</sub>]**，经过**P-Tuning v1**的**Prompt Encoder**模块转换为向量序列**[e(x), e(h<sub>0</sub>), &mldr;, e(h<sub>i</sub>)]**。</li><li><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511144119291.png alt=image-20240511144119291></li></ul><p>通过问题建模，我们可以看到<strong>数学意义上</strong>的<strong>离散提示</strong>已经表示为<strong>连续提示</strong>。那么不同规模的模型、不同下游任务的微调效果不稳定，很可能源于<strong>P-Tuning v1</strong>在输入层添加的前缀向量没有起到有效作用，从逻辑上，我们可以有如下猜测：</p><ul><li><strong>模型规模对前缀向量的影响</strong>：不同规模的模型对前缀向量的特征提取能力是不同的，小模型特征提取不足，导致后续预训练模型的各层无法感知注意到前缀向量。</li><li><strong>下游任务类型对前缀向量的影响</strong>：从离散提示词看，不同下游任务的提示词是不同的。同理，不同下游任务的连续提示词应该也是不同的。</li></ul><p>因此：</p><ul><li>从数学上，<strong>P-Tuning v1</strong>的连续可微前缀向量没有太多改进空间。</li><li>从模型结构上，<ul><li><strong>可以在Transformer的各层添加前缀向量</strong>，以抵消小模型对前缀向量的特征提取不足的局限。</li><li><strong>可以改变前缀向量的长度</strong>，以实现不同下游任务有不同的前缀向量。</li></ul></li></ul><p>为了更好地阐述论文的改进思路，我们列出相关源码：</p><ul><li><p><strong>DebertaPrefixModelForQuestionAnswering</strong>类，是针对QA下游任务的。</p></li><li><p>支持通过超参数，<strong>设置不同下游任务的前缀向量长度</strong>。</p></li><li><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511150051142.png alt=image-20240511150051142></p></li><li><p><strong>RobertaPrefixForSequenceClassification</strong>类，是针对序列分类下游任务的。</p></li><li><p>支持通过超参数，<strong>设置不同下游任务的前缀向量长度</strong>。</p></li><li><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511151145088.png alt=image-20240511151145088></p></li><li><p>覆写Deberta的注意力层，支持在Deberta各注意力层都增加了前缀向量：</p></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511151537379.png alt=image-20240511151537379></p><p>最后，在train方法中，将上述对模型结构的改进串联起来：</p><ul><li>创建前缀向量编码器对象，根据本下游任务指定的提示长度，生成前缀向量。</li><li>前向传播时，将前缀向量传入本下游任务对应的各注意力层，实现不同层都能提取到前缀向量特征。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511151852070.png alt=image-20240511151852070></p><h1 id=4experiments实验结果>4.Experiments(实验结果)</h1><h2 id=1实验结果1across-scales>(1)实验结果1：Across Scales</h2><p>针对不同规模的模型，<strong>P-Tuning v2</strong>的微调效果比较稳定。</p><ul><li>在四种<strong>参数小于10B的模型</strong>上，<strong>P-Tuning v1</strong>微调效果远低于<strong>P-Tuning v2</strong>微调效果，<strong>P-Tuning v2</strong>微调效果与<strong>Fine Tuning</strong>相当。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511152631012.png alt=image-20240511152631012></p><h2 id=2实验结果2across-tasks>(2)实验结果2：Across Tasks</h2><ul><li>在<strong>CoNLL03、OntoNotes5.0、CoNLL04、SQuAD1.1dev、SQuAD2.0dev、CoNLL12、CoNLL05 WSJ、CoNLL05 Brown</strong>八种下游任务中，<strong>P-Tuning v1</strong>微调效果远低于<strong>P-Tuning v2</strong>微调效果，<strong>P-Tuning v2</strong>微调效果与<strong>Fine Tuning</strong>相当。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511153327159.png alt=image-20240511153327159></p><h2 id=3其它重要发现实现prompt-encoder的神经网络结构的选择技巧>(3)其它重要发现：实现Prompt Encoder的神经网络结构的选择技巧</h2><ul><li>在<strong>P-Tuning v1</strong>中，采用<strong>LSTM+MLP</strong>或<strong>MLP</strong>，其中MLP采用2层线性层、ReLU作为激活函数。</li><li>在<strong>P-Tuning v2</strong>中，通过超参数针对不同下游任务选择不同神经网络，其中MLP的一种实现可以采用2层线性层、tanh作为激活函数。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B047-LLM%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8BPTuningV2/image-20240511153852283.png alt=image-20240511153852283></p><h1 id=5总结>5.总结</h1><p>从上述论文解读中，我们收获了如下技术观点：</p><ul><li><strong>P-Tuning v1</strong>的局限性：不同的下游任务、不同规模的模型，微调结果不稳定。</li><li><strong>P-Tuning v2的核心思想</strong>：修改模型结构，在各层注意力层增加前缀处理器网络以抵消小模型对前缀向量特征提取不足的局限，支持不同下游任务选择不同前缀提示长度、选择不同前缀编码器神经网络结构。</li></ul><p>论文链接：https://arxiv.org/pdf/2110.07602</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>猴王无敌</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2024-05-11</span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><div class=post-reward><input type=checkbox name=reward id=reward hidden>
<label class=reward-button for=reward>赞赏支持</label><div class=qr-code><label class=qr-code-image for=reward><img class=image src=/weixin.png>
<span>微信打赏</span></label>
<label class=qr-code-image for=reward><img class=image src=/alipay.png>
<span>支付宝打赏</span></label></div></div><footer class=post-footer><div class=post-tags></div><nav class=post-nav><a class=next href=/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B046-llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E4%B9%8Bptuningv1/><span class="next-text nav-default">【chatGPT】学习笔记46-LLM微调技术之P-Tuning V1</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=mailto:JHercules_qz@qq.com rel="me noopener" class=iconfont title=email><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408 1361.641813S1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523L83.726336 1024H682.532949 753.579947 1348.948139L1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955C777.248 802.205449 742.347691 811.03081 718.063616 811.603883z"/></svg></a><a href=https://github.com/JHerculesqz rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=https://jherculesqz.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2021 -
2024
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>猴王无敌</span></span>
<span id=busuanzi_container>访客数/访问量：<span id=busuanzi_value_site_uv></span>/<span id=busuanzi_value_site_pv></span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script><script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script><script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script><script type=text/javascript src=/js/load-photoswipe.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>