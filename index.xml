<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>妙木山</title><link>https://jherculesqz.github.io/</link><description>Recent content on 妙木山</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 23 Nov 2023 14:00:59 +0800</lastBuildDate><atom:link href="https://jherculesqz.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>关于</title><link>https://jherculesqz.github.io/about/</link><pubDate>Thu, 05 Aug 2021 13:01:37 +0800</pubDate><guid>https://jherculesqz.github.io/about/</guid><description>&lt;h1 id="关于博客">关于博客&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>独立&lt;/strong>：一直在写技术博客，从微信公众号、头条号、SegmentFault、掘金、简书一路折腾过来，还是希望有一个自己独立的空间。&lt;/li>
&lt;li>&lt;strong>坚持&lt;/strong>：随着年龄增长，逐渐欲说还休，还是文字更有韵味，希望自己能坚持写下去。&lt;/li>
&lt;li>&lt;strong>浪漫&lt;/strong>：按照&lt;a href="https://archiveprogram.github.com">Archive Program&lt;/a>计划的愿景，我的博客会在&amp;rdquo; GitHub北极代码库&amp;quot;中保存千年。想想1000年以后，我的后代们能读到我这个中二祖先的文字，还是一件挺浪漫的事儿。&lt;/li>
&lt;li>&lt;strong>感谢&lt;/strong>：感谢GitHub Pages、Hugo、Jane提供的技术支持。&lt;/li>
&lt;li>&lt;strong>妙木山&lt;/strong>：妙木山是修炼仙术的地方，作为火影的死忠粉，&amp;ldquo;妙木山&amp;quot;无比适合这个博客的定位——修炼、探索。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/about/MiaoMu.png" alt="MiaoMu">&lt;/p>
&lt;h1 id="关于我">关于我&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>行业&lt;/strong>：软件行业16年，无法用语言表达对编程的喜爱——举个栗子吧：有段时间喜欢在酒吧里写代码，同去的小伙伴无聊地陌陌上约人，自我介绍就是&amp;quot;A+吧台，旁边有个写代码的沙雕&amp;rdquo;。&lt;/li>
&lt;li>&lt;strong>技术方向&lt;/strong>：近几年痴迷语言和编译器技术，还有点痴迷计算机图形学。
&lt;ul>
&lt;li>&lt;strong>编程语言&lt;/strong>：目前工作Java和JavaScript用的最多，但我最喜欢C#——PHP是最好的语言，行了吧！&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>哲学&lt;/strong>：不知何时，开始期待理解生命的意义。东一本西一本的书拿来乱翻，也没找到答案。不过，也不是全无收获——能模模糊糊地体会诗词的意境、能回味出毛选的奇妙、能敬畏金刚经的高深……继续求索吧……&lt;/li>
&lt;li>&lt;strong>兴趣&lt;/strong>：年轻的时候，喜欢轮滑、滑板、快乐肥仔水。现在，喜欢滑雪、乒乓球、茶(特指正山小种)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/about/Me.png" alt="Me">&lt;/p></description></item><item><title>【chatGPT】学习笔记29-LangChain解读1-快速入门</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-langchain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</link><pubDate>Thu, 23 Nov 2023 14:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-langchain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</guid><description>&lt;p>虽然利用提示词工程，我们已经能较好地使用LLM，但即使开发一个很简单的LLM应用，依然需要编写大量复杂代码(调用LLM只是最简单的一步)。&lt;/p>
&lt;p>&lt;strong>LangChain&lt;/strong>的目标就是让开发LLM应用变的简单，但LangChain更新极快，导致我们的学习成本较高。&lt;/p>
&lt;p>因此，我们准备做两件事，帮助大家提升学习LangChain的效率：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>翻译LangChain官方文档&lt;/strong>
&lt;ul>
&lt;li>翻译链接：https://jherculesqz.gitbook.io/langchain-guan-fang-wen-dang&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>解读LangChain官方文档&lt;/strong>
&lt;ul>
&lt;li>在本技术专栏中，将详细地逐一解读LangChain官方文档中的各个重要特性。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>本篇我们就来解读LangChain官方文档的《&lt;strong>Quickstart&lt;/strong>》章节(&lt;a href="https://python.langchain.com/docs/get_started/quickstart">https://python.langchain.com/docs/get_started/quickstart&lt;/a>)，帮助大家快速上手LangChain。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/5d7KfRriC6zji11ZFnwLotdqcHQ.svg" alt="LangChain">&lt;/p>
&lt;h1 id="1langchain概览">1.LangChain概览&lt;/h1>
&lt;h2 id="1什么是langchain">(1)什么是LangChain&lt;/h2>
&lt;p>&lt;strong>LangChain 是一个开源框架，支持由LLM驱动的应用程序的开发&lt;/strong>。它使应用程序能够：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>具有上下文感知能力&lt;/strong>：连接大语言模型和上下文的数据源 (如：提示词、few-shot、聊天历史记录等)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>推理&lt;/strong>：依靠语言模型进行推理 (如：根据给出的上下文回答问题，或者决定下一步动作）&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>LangChain 的价值点主要有两个:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>模块化组件&lt;/strong>：专注于组合和模块化，提供了基于LLM的各种组件。这些组件可以单独使用，也可以组合使用。&lt;/li>
&lt;li>&lt;strong>直接可用的链&lt;/strong>：将各种组件组合成可完成特定任务的&amp;quot;链&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;h2 id="2langchain整体架构">(2)LangChain整体架构&lt;/h2>
&lt;p>LangChain为以下模块提供标准的、可扩展的接口和外部集成，从简单到复杂排序如下:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Model I/O&lt;/strong>：与大语言模型的接口。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>检索 (Retrieval)&lt;/strong>：与应用程序特定数据的接口。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>链 (Chains)&lt;/strong>：构建调用序列。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>代理 (Agents)&lt;/strong>：让模型根据高级指令选择使用哪些工具。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Memory&lt;/strong>：在链运行期间保持应用程序状态。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Callbacks&lt;/strong>：记录并传送链的中间步骤。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="3如何构建llm应用程序">(3)如何构建LLM应用程序&lt;/h2>
&lt;p>LangChain提供了许多用来构建LLM应用程序的模块，其中最常用且最重要的模块是&lt;strong>LLMChain&lt;/strong>。&lt;/p>
&lt;p>&lt;strong>LLMChain&lt;/strong>包含三个主要组件:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>LLM&lt;/strong>：LLM是你要构建的应用程序的核心推理引擎。GPT、GLM等大模型LangChain都已适配支持。&lt;/li>
&lt;li>&lt;strong>提示模板&lt;/strong>：它为LLM提供指令，从而控制LLM的输出。所以大家要好好学习提示词工程。&lt;/li>
&lt;li>&lt;strong>输出解析器&lt;/strong>：把LLM的原始响应转化为程序更易处理的格式，方便后续使用。&lt;/li>
&lt;/ul>
&lt;p>接下来我们就基于LLMChain来体验LangChain的便捷吧。&lt;/p>
&lt;h1 id="2快速上手langchain">2.快速上手LangChain&lt;/h1>
&lt;p>下面，我们演示如何用LangChain来做文本总结：&lt;/p>
&lt;ul>
&lt;li>环境准备&lt;/li>
&lt;li>构造LLM&lt;/li>
&lt;li>构造提示词模板&lt;/li>
&lt;li>创建Chain，执行指定任务&lt;/li>
&lt;/ul>
&lt;h2 id="step1环境准备">STEP1.环境准备&lt;/h2>
&lt;ul>
&lt;li>安装LangChain。因为LangChain版本更新很快，安装时优先用&amp;rdquo;-U&amp;quot;升级模式安装。&lt;/li>
&lt;li>安装openai(需申请OpenAPI的Token)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123190055109.png" alt="image-20231123190055109">&lt;/p>
&lt;h2 id="step2构造llm">STEP2.构造LLM&lt;/h2>
&lt;ul>
&lt;li>使用langchain 中的 OpenAI 函数来初始化一个大语言模型&lt;code>llm&lt;/code>。
&lt;ul>
&lt;li>本例用的是&amp;quot;text-davinci-003&amp;rdquo;，当然你可以根据需求用gpt或其它模型。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123174527077.png" alt="image-20231123174527077">&lt;/p>
&lt;h2 id="step3构造提示词模板">STEP3.构造提示词模板&lt;/h2>
&lt;blockquote>
&lt;p>应用程序不会把用户的输入直接传给LLM，通常的做法是把用户输入传给提示词模板。&lt;/p>
&lt;p>提示词模板的好处是：&lt;/p>
&lt;ul>
&lt;li>格式化的提示词结构，包括指令、上下文、输入、输出要求等，为给LLM提供更详细的语境。&lt;/li>
&lt;li>支持设置变量，这可以让好用的提示词最大化被复用。&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;ul>
&lt;li>使用langchain的提示词模板函数初始化一个提示词模板&lt;code>prompt_template&lt;/code>
&lt;ul>
&lt;li>提示词指令是总结文本内容&lt;/li>
&lt;li>要处理的文本内容设成变量，本次任务是处理一段新闻，后面也可以随意处理其它文本内容&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123202743359.png" alt="image-20231123202743359">&lt;/p>
&lt;h2 id="step4创建chain">STEP4.创建Chain&lt;/h2>
&lt;p>现在，我们将以上组件组合成一个链，就可以执行任务了。&lt;/p>
&lt;ul>
&lt;li>使用LLMChain构建我们自己的链&lt;code>chain&lt;/code>，传入上面的两个组件&lt;code>llm&lt;/code>、&lt;code>prompt_template&lt;/code>。&lt;/li>
&lt;li>运行&lt;code>chain&lt;/code>，参数只需传入变量text(要处理的文本内容)，可以看到如下运行过程：
&lt;ul>
&lt;li>链开始，&lt;/li>
&lt;li>读取text变量，格式化提示词，传给LLM&lt;/li>
&lt;li>得到结果，链结束&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-LangChain%E8%A7%A3%E8%AF%BB1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20231123203230173.png" alt="image-20231123203230173">&lt;/p>
&lt;p>从上面的示例可以看到，只需一个命令就实现了提示词构建和LLM调用，我们利用Langchain很好的完成了任务。&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文解读了LangChain官方文档的《QuickStart》章节，并给出了基于LangChain构建LLM应用的实例代码。QuickStart章节关键要点如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>LangChain简介&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>LangChain 是一个开源框架，支持由LLM驱动的应用程序的开发。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LangChain 的主要价值点：提供了各种模块化组件和好用的链&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LLMChain是LangChain最常见且最重要的一个链，它包含3个主要组件：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>LLM&lt;/strong>：应用程序的核心推理引擎。&lt;/li>
&lt;li>&lt;strong>提示模板&lt;/strong>：它为LLM提供指令，从而控制LLM的输出。&lt;/li>
&lt;li>&lt;strong>输出解析器&lt;/strong>：把LLM的原始响应转化为程序更易处理的格式。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>实例演示&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>基于LangChain构建具备总结功能的LLM应用
&lt;ul>
&lt;li>环境准备&lt;/li>
&lt;li>构造LLM&lt;/li>
&lt;li>构造提示词模板&lt;/li>
&lt;li>创建Chain，执行指定任务&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记28-提示词解读4-实战案例之推理</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/</link><pubDate>Thu, 23 Nov 2023 13:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/</guid><description>&lt;p>在《【chatGPT】学习笔记27-提示词解读3-实战案例之摘要总结》中，我们演示了LLM的总结能力。&lt;/p>
&lt;p>接下来，我们继续跟着吴恩达老师的课程，解锁LLM另一个更强大的能力——推理(&lt;code>Inferring&lt;/code>)。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231122092928495.png" alt="image-20231122092928495">&lt;/p>
&lt;blockquote>
&lt;p>本文的“推理”是指利用LLM处理推理型的任务。&lt;/p>
&lt;/blockquote>
&lt;h1 id="1激发推理能力的提示词">1.激发推理能力的提示词&lt;/h1>
&lt;h2 id="1什么是llm的推理能力">(1)什么是LLM的推理能力&lt;/h2>
&lt;p>LLM的推理能力是指从已知信息中推导出新的结论的能力。&lt;/p>
&lt;p>例如在下面的例子中，LLM根据上下文理解用户意图，经过推理生成了新的信息，包括结论和相应的解释。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123133732549.png" alt="image-20231123133732549">&lt;/p>
&lt;h2 id="2如何激发llm的推理能力">(2)如何激发LLM的推理能力&lt;/h2>
&lt;p>我们可以这样构建提示词：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>使用清晰明确的指令词，让LLM理解做什么类型的推理任务，如判断xxx、预测xxx。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>提供足够的上下文信息，让LLM知道要处理的内容。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="2实战案例">2.实战案例&lt;/h1>
&lt;p>假设我是某智能问答系统的IT人员，要用LLM的推理能力帮忙做运营维护：&lt;/p>
&lt;ul>
&lt;li>判断用户对问答系统是否满意。&lt;/li>
&lt;li>用户问题千奇百怪，让智能客服能够应对各式花样提问。&lt;/li>
&lt;/ul>
&lt;h2 id="21满意度识别">2.1.满意度识别&lt;/h2>
&lt;p>一般问答系统都希望通过点赞👍/点踩👎按钮获取用户的反馈，但大部分用户都不会去点。&lt;/p>
&lt;p>利用LLM的推理能力，直接拿用户的对话信息来做满意度分析，可以大大提升运营效率。&lt;/p>
&lt;p>例如，让LLM判断用户回复的信息是什么感情色彩：&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123141130339.png" alt="image-20231123141130339">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123140406001.png" alt="image-20231123140406001">&lt;/p>
&lt;p>吴恩达老师&amp;quot;提示词工程课程&amp;quot;中说LLM擅长做情感判断，所以我又试了下让LLM列出评论中包含的情绪元素。看来LLM感情还是挺丰富的。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123141823738.png" alt="image-20231123141823738">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123141845933.png" alt="image-20231123141845933">&lt;/p>
&lt;h2 id="22应对花式提问">2.2.应对花式提问&lt;/h2>
&lt;p>传统智能问答系统是建立在知识库基础上的，通过关键词匹配最相关的答案，语义理解和推理能力非常有限。&lt;/p>
&lt;p>现实用户提问方式五花八门，如果某个问题不在知识库，系统将无法提供准确答案。&lt;/p>
&lt;p>基于LLM的推理能力，我们通过2个技巧快速提升智能问答系统的应对能力。&lt;/p>
&lt;h3 id="技巧1基于已知问题推导类似问题">技巧1：基于已知问题推导类似问题&lt;/h3>
&lt;p>基于知识库中的预置问题，利用LLM推导扩充不同的问法，丰富问题集，同时弥补传统问答系统语义理解的不足。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123152748076.png" alt="image-20231123152748076">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123152830392.png" alt="image-20231123152830392">&lt;/p>
&lt;h3 id="技巧2归纳推理">技巧2：归纳推理&lt;/h3>
&lt;p>上面的方法可能仍然不足以完全应对用户问题的多样性，那么可以继续用LLM来补漏。&lt;/p>
&lt;p>利用LLM的归纳推理能力，将用户问题和系统关键词检索出的相关问题做比较，从语义上判断是否相近。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153737082.png" alt="image-20231123153737082">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153803235.png" alt="image-20231123153803235">&lt;/p>
&lt;p>换个相关但不相近的问题&amp;ndash;都有关键词”会员“但语义不同，LLM仍然回答正确，看来LLM的推理能力还是可靠的。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153723987.png" alt="image-20231123153723987">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB4-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%8E%A8%E7%90%86/image-20231123153820768.png" alt="image-20231123153820768">&lt;/p>
&lt;ul>
&lt;li>综上，利用LLM推导和归纳推理这两个技巧，可以实现快速扩充知识库、增强检索能力。&lt;/li>
&lt;/ul>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文介绍了一个LLM另一个实用的提示词技巧，解锁大语言模型的推理能力，充分利用大模型的智慧。&lt;/p>
&lt;p>推理提示词的构建方法：&lt;/p>
&lt;ul>
&lt;li>使用清晰明确的指令词，让LLM理解做什么类型的推理任务，如判断xxx、预测xxx。&lt;/li>
&lt;li>提供足够的上下文信息，让LLM知道要处理的内容。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记27-提示词解读3-实战案例之摘要总结</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 14 Nov 2023 13:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/</guid><description>&lt;p>在《【chatGPT】学习笔记25-提示词解读2-通用技巧》中，我们看到了提示词的各种通用技巧，但无论哪种技巧，都是为了激发大语言模型的某种潜在能力。&lt;/p>
&lt;p>那么，大语言模型有哪些常见、实用的能力呢？作为生成式语言模型，大模型常见、实用的能力如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231113210314835.png" alt="image-20231113210314835">&lt;/p>
&lt;p>本篇先阐述如何通过提示词激发LLM的第一种能力——总结能力(&lt;code>summarizing&lt;/code>)。&lt;/p>
&lt;h1 id="1激发总结能力的提示词">1.激发总结能力的提示词&lt;/h1>
&lt;h2 id="1什么是llm的总结能力">(1)什么是LLM的总结能力&lt;/h2>
&lt;p>在如下场景中，特别需要&lt;strong>LLM的总结能力&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>会议纪要&lt;/strong>：秘书MM，如何快速输出一个时长4小时的会议纪要？&lt;/li>
&lt;li>&lt;strong>编写书评&lt;/strong>：编辑GG，如何快速阅读一本书，提取要点，编写一个书评呢？&lt;/li>
&lt;li>&lt;strong>编写新闻稿&lt;/strong>：记者MM，如何快速输出一个4小时的产品发布会的新闻稿？&lt;/li>
&lt;/ul>
&lt;p>再来理解一下，&lt;strong>LLM的总结能力&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>LLM具备捕捉文本中的重要细节和关联关系的能力，所以它可对文本进行&lt;strong>总结(summary)&lt;strong>和&lt;/strong>摘录(extract)&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>总结(summary)&lt;strong>和&lt;/strong>摘录(extract)&lt;strong>就是&lt;/strong>LLM的总结能力&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>总结(summary)&lt;/strong>：归纳总结一段文本的核心思想、主要内容。&lt;/li>
&lt;li>&lt;strong>摘录(extract)&lt;/strong>：快速提炼一段文本的关键要点，原文出处。&lt;/li>
&lt;/ul>
&lt;h2 id="2如何激发llm的总结能力">(2)如何激发LLM的总结能力&lt;/h2>
&lt;p>我们可以这样构建提示词：&lt;/p>
&lt;ul>
&lt;li>提示词中，出现明确的指令词，如：请&lt;strong>总结&lt;/strong>xxxx，请&lt;strong>摘录&lt;/strong>xxxx。&lt;/li>
&lt;li>明确输出的总结、摘录的约束，如：总结成几句话，多少个字。&lt;/li>
&lt;li>明确总结的侧重点、关注点，如：请总结&lt;strong>价格方面&lt;/strong>的内容。&lt;/li>
&lt;li>设定背景信息，如：你是一名新华社记者，这是一篇新闻稿。&lt;/li>
&lt;/ul>
&lt;h1 id="2实战案例">2.实战案例&lt;/h1>
&lt;p>我们以智界S7发布会新闻稿为例，演示通过提示词激发LLM总结能力：&lt;/p>
&lt;ul>
&lt;li>我是一名自媒体记者，我获取了华为智界S7发布会的演讲稿。&lt;/li>
&lt;li>我想快速输出一篇&amp;quot;智界S7发布会的新闻稿&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;h2 id="step1编写引言">STEP1.编写引言&lt;/h2>
&lt;p>首先，我需要为新闻稿写一个引言，简明扼要地介绍新闻的核心内容，如：何时、何地、发生何事。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115111855070.png" alt="image-20231115111855070">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115111905241.png" alt="image-20231115111905241">&lt;/p>
&lt;h2 id="step2编写主体段落">STEP2.编写主体段落&lt;/h2>
&lt;p>接下来，写新闻稿的主体段落。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112026820.png" alt="image-20231115112026820">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112057272.png" alt="image-20231115112057272">&lt;/p>
&lt;h2 id="step3编写记者观点">STEP3.编写记者观点&lt;/h2>
&lt;p>接下来，需要记者输出对该产品的观点，如：通过产品的功能参数、产品的价格，记者如何看待该产品的性价比。&lt;/p>
&lt;ul>
&lt;li>我对价格方面的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112357958.png" alt="image-20231115112357958">&lt;/p>
&lt;ul>
&lt;li>LLM对价格的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112405603.png" alt="image-20231115112405603">&lt;/p>
&lt;ul>
&lt;li>我对产品参数的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112515271.png" alt="image-20231115112515271">&lt;/p>
&lt;ul>
&lt;li>LLM对产品参数的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115112523094.png" alt="image-20231115112523094">&lt;/p>
&lt;ul>
&lt;li>综上，记者观点如下：
&lt;ul>
&lt;li>智界S7车长4971mm，轴距2950mm，车宽1963mm，首发搭载华为途灵智能底盘和HarmonyOS 4智能座舱，还有HUAWEI ADS 2.0高阶智能驾驶辅助系统等领先科技，将为轿车市场用户带来全场景智慧出行新体验。它的预售价仅25.8万起，&lt;strong>对于这样一辆高性能的新能源车，性价比极高&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="step4提炼发言人重要观点">STEP4.提炼发言人重要观点&lt;/h2>
&lt;p>然后，引用发言人余承东的几个重要观点，在新闻稿中突出发布会的重点信息。&lt;/p>
&lt;ul>
&lt;li>我的提示词如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115113113849.png" alt="image-20231115113113849">&lt;/p>
&lt;ul>
&lt;li>LLM的回答如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB3-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%91%98%E8%A6%81%E6%80%BB%E7%BB%93/image-20231115113122691.png" alt="image-20231115113122691">&lt;/p>
&lt;h2 id="step5汇总形成新闻稿">STEP5.汇总形成新闻稿&lt;/h2>
&lt;ul>
&lt;li>汇总上述信息，得到的新闻稿如下：&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>【标题】智界S7发布会再次引爆市场热点&lt;/p>
&lt;p>【引言】华为11月9日在深圳举行了智慧出行解决方案新战略发布会，同时推出华为智选车业务新生态。发布会上，华为智选车首款轿车智界S7正式开启预售，预售价格从25.8万元起，并将于11月28日正式发布。华为旨在通过全新平台和领先科技为用户带来全场景智慧出行新体验。&lt;/p>
&lt;p>【内容】&lt;/p>
&lt;p>华为于11月9日在深圳发布了智慧出行解决方案新战略，并推出华为智选车业务新生态，旗下拥有问界和智界系列车型。华为智选车首款轿车智界S7正式开启预售，预售价格为25.8万元起，并将于11月28日正式发布。华为常务董事余承东表示，问界系列车型的销量火爆，华为将全力提升产能以满足需求。&lt;/p>
&lt;p>华为智选车首款智慧轿车智界S7由华为与奇瑞强强联合打造，采用华为全栈智能汽车解决方案，拥有舒适大空间和出色性能体验。它搭载了华为途灵智能底盘和HarmonyOS 4智能座舱，以及HUAWEI ADS 2.0高阶智能驾驶辅助系统等先进技术。智界S7将为用户带来全新的智慧出行体验，11月28日将正式发布。&lt;/p>
&lt;p>华为表示要持续引领智能汽车的技术创新并推动智能化发展。华为与赛力斯联合打造的问界系列车型取得了优异的市场表现。余承东透露，问界新M7上市不到两月就获得了86000辆大定订单，其中70%以上的用户选择智驾版。问界M9订单突破25000台，火爆销售。华为将全力提升产能以满足订单需求。&lt;/p>
&lt;p>余承东表示：“价格方面我们内部反复讨论，多次测算，最后发现这款车四个版本定价我们都是亏钱的，只能期待后期这款车的放量出货来弥补亏损，目的也是让更多消费者体验华为的产品。”&lt;/p>
&lt;p>智界S7车长4971mm，轴距2950mm，车宽1963mm，首发搭载华为途灵智能底盘和HarmonyOS 4智能座舱，还有HUAWEI ADS 2.0高阶智能驾驶辅助系统等领先科技，将为轿车市场用户带来全场景智慧出行新体验。它的预售价仅25.8万起，&lt;strong>对于这样一辆高性能的新能源车，性价比极高&lt;/strong>。&lt;/p>
&lt;/blockquote>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文介绍了一个非常实用的提示词技巧，能够很好的激发大语言模型摘要总结的能力，让大模型成为我们的办公助手。&lt;/p>
&lt;p>摘要总结提示词构建方法：&lt;/p>
&lt;ul>
&lt;li>提示词中，出现明确的指令词，如：请&lt;strong>总结&lt;/strong>xxxx，请&lt;strong>摘录&lt;/strong>xxxx。&lt;/li>
&lt;li>明确输出的总结、摘录的约束，如：总结成几句话，多少个字。&lt;/li>
&lt;li>明确总结的侧重点、关注点，如：请总结&lt;strong>价格方面&lt;/strong>的内容。&lt;/li>
&lt;li>设定背景信息，如：你是一名新华社记者，这是一篇新闻稿。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记26-CNCC 2023参会纪要</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B026-cncc-2023%E5%8F%82%E4%BC%9A%E7%BA%AA%E8%A6%81/</link><pubDate>Fri, 10 Nov 2023 13:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B026-cncc-2023%E5%8F%82%E4%BC%9A%E7%BA%AA%E8%A6%81/</guid><description>&lt;p>本文记录笔者参加CNCC 2023 AI相关的议题，方便各位小伙伴快速了解学界在AI的理论研究和行业应用情况。&lt;/p>
&lt;h1 id="1cncc-2023概览">1.CNCC 2023概览&lt;/h1>
&lt;h2 id="1会议简介">(1)会议简介&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>本届大会以“&lt;strong>发展数字基础设施，支撑数字中国建设&lt;/strong>”为主题，探讨计算及信息科学技术领域的最新进展和宏观发展趋势，为数字中国建设提供支持。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>大会特邀了国际知名学者、两院院士、产学研各界代表在内的&lt;strong>700余位报告嘉宾&lt;/strong>，覆盖了&lt;strong>人工智能&lt;/strong>、安全、计算+、&lt;strong>软件工程&lt;/strong>、教育、网络、&lt;strong>芯片&lt;/strong>、&lt;strong>云计算&lt;/strong>等30余个领域，推动不同领域的交叉融合，为各界专业人士提供了广泛的专业内容。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>![image-20231109151407115](/AI拾遗/【chatGPT】学习笔记26-CNCC 2023参会纪要/image-20231109151407115.png)&lt;/p>
&lt;h2 id="2议题分布">(2)议题分布&lt;/h2>
&lt;p>CNCC 2023的众多议题中，LLM相关分会场73个。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>基础设施&lt;/strong>：18个分会场&lt;/li>
&lt;li>&lt;strong>LLM理论研究&amp;amp;工程化实践&lt;/strong>：15个分会场&lt;/li>
&lt;li>&lt;strong>LLM应用&lt;/strong>：38个分会场&lt;/li>
&lt;/ul>
&lt;p>![image-20231109195425387](/AI拾遗/【chatGPT】学习笔记26-CNCC 2023参会纪要/image-20231109195425387.png)&lt;/p>
&lt;h1 id="2方向1基础设施">2.方向1：基础设施&lt;/h1>
&lt;h2 id="21dpu相关">2.1.DPU相关&lt;/h2>
&lt;h3 id="议题1dpu标准化工作实践">议题1：DPU标准化工作实践&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>： 钟伟军，中国电子技术标准化研究院技术总监。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：DPU标准化工作，是DPU大规模落地应用中重要环节。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：DPU标准工作实践的成果和现状。如：《数据处理器(DPU)第1部分：参考框架》、《数据处理器(DPU)测试方法》等。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：DPU标准化工作的挑战及下一阶段的计划。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2面向ai时代的dpu云计算融合底座设计与实践">议题2：面向AI时代的DPU云计算融合底座设计与实践&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：曹辉，中科驭数产品运营部副总经理&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：越来越多的云计算基础设施组件正在计划融合或支持DPU方案，是下一代云计算架构演进的主流方向。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：在云原生领域，随着智算中心架构的发展，高吞吐、低时延是智算中心架构发展的挑战。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：中科驭数的解决方案是&lt;strong>IaaS on DPU&lt;/strong>，将IaaS平台下沉至DPU，提供高性能的容器、虚拟机、裸金属服务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3网络域场景dpu应用探索">议题3：网络域场景DPU应用探索&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：曹畅，中国联通研究院未来网络研究部总监&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：DPU具有高效、灵活的可编程网络数据处理加速能力，可支撑网络、存储、安全、管理等数据中心基础设施层可定制的业务加速能力。&lt;/li>
&lt;li>&lt;strong>枢纽&lt;/strong>：DPU衔接了算力和网络两大领域的重要枢纽，推动了计算和网络融合，助力传统算力基础设施向&lt;strong>算网一体的算力网络&lt;/strong>演进。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：在算力网络、5/6G、数据中心网络等网络域场景中，中国联通如果对DPU进行的探索及创新方案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4dpu--如何使能高性能ai网络">议题4：DPU , 如何使能高性能AI网络&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：王瑞雪，中国移动通信有限公司研究院基础网络技术研究所技术经理&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>NICC&lt;/strong>：New Intelligent Computing Center，以高性能GPU、AI加速卡为中心，以高速互联智算集群为目标，形成E级超大规模算力基础设施。&lt;/li>
&lt;li>&lt;strong>价值&lt;/strong>：强化互联技术、深化算力协同、定义新型存储、新增算力原生、升级绿色节能。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：AI大模型以GPU集群分布式训练为基础，集群节点间频繁参数同步带来大通信开销，因此网络是提升AI大模型训练效率的关键之一。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="22芯粒相关">2.2.芯粒相关&lt;/h2>
&lt;h3 id="议题1智能计算时代下的chiplet生态建设">议题1：智能计算时代下的Chiplet生态建设&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：谭展宏，北极雄芯信息科技有限公司CTO。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：海内外多家公司也陆续推出了基于Chiplet技术的产品。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：很多公司标榜着Chiplet这个关键词，但Chiplet的定义、使用方式和技术路线都有各自说法。&lt;/li>
&lt;li>&lt;strong>探索&lt;/strong>：本议题探讨Chiplet如何助力面向计算资源与智能计算，分享Chiplet的生态发展的思考。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2面向百芯万核的芯粒仿真初探">议题2：面向百芯万核的芯粒仿真初探&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：王小航，浙江大学教授。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：软件仿真器是探索集成芯片设计空间的重要工具&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：在大芯片和大模型的时代芯片规模提高，仿真性能无法支撑百芯万核规模的芯片仿真，仿真精度校准难，仿真配置多等。&lt;/li>
&lt;li>&lt;strong>方案&lt;/strong>：分析了上述问题的形成原因，通过并行仿真、精度调节、自动化设计空间探索等技术解决上述问题。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3芯粒测试关键技术研究">议题3：芯粒测试关键技术研究&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：蔡志匡，南京邮电大学教授。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：Chiplet是延续摩尔定律的关键技术，通过先进封装将芯粒集成在一个中介层上，解决芯片研制的规模大、成本高、周期长等问题。&lt;/li>
&lt;li>&lt;strong>关键点1&lt;/strong>：基本DFT技术、单芯粒测试技术、多芯粒测试技术。&lt;/li>
&lt;li>&lt;strong>关键点2&lt;/strong>：覆盖芯粒测试各个环节的芯粒系统级可测试设计方案(测试技术、测试EDA、测试装备)，实现高可靠性、全流程的系统级测试。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4从aigc到百模大战异构计算和chiplet-协同以致胜">议题4：从AIGC到百模大战，异构计算和Chiplet 协同以致胜&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：祝俊东，奇异摩尔产品及解决方案副总裁。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：随着LLM发展及百模大战，异构计算与Chiplet协同扮演关键角色。&lt;/li>
&lt;li>&lt;strong>趋势&lt;/strong>：百模大战引导出的关键挑战之一是&lt;strong>高性能芯片、更大规模的智算平台&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5面向25d集成的先进封装工艺与设计协同方案">议题5：面向2.5D集成的先进封装工艺与设计协同方案&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：樊嘉祺，华进半导体封装设计经理&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：摩尔定律趋缓，封装技术成为电子产品小型化、多功能化、降低功耗、提高带宽的重要手段。&lt;/li>
&lt;li>&lt;strong>趋势&lt;/strong>：芯片封装从传统的平面封装向系统集成、高速、高频、三维方向发展。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：芯片-封装协同设计、满足可靠性要求，材料和工艺方面，存在诸多挑战。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：华进半导体致力于系统封装设计、2.5D/3D 集成关键核心技术研发，提供设计仿真、晶圆制造、系统集成、模组测试等全方位解决方案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="23信息器件与智能计算相关">2.3.信息器件与智能计算相关&lt;/h2>
&lt;h3 id="议题1存算一体异构计算芯片">议题1：存算一体异构计算芯片&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：高滨，清华大学长聘副教授/博导，清华大学教务处副处长&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>背景&lt;/strong>：存算一体技术聚焦在单片三维集成的新型存储器技术。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：忆阻器相关的制造工艺和设计技术，包括28nm集成、EDA工具开发、IP单元电路设计、异构计算架构设计、编译器等。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：基于忆阻器的&lt;strong>超近存计算+存内计算&lt;/strong>的异构计算系统，在算力、灵活性、可扩展性、效率、精度等方面展现出巨大的优势，在多个场景已得到初步的应用验证。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2基于忆阻器的储池计算">议题2：基于忆阻器的储池计算&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：王中锐，香港大学电气与电子工程系助理教授&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：由于内存的物理上分离、处理单元以及晶体管工艺节点限制，传统数字硬件面临巨大挑战，忆阻器是高效和高集成度的深度学习解决方案。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：忆阻器的非理想特性使其难以在边缘侧AI实现原位学习。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：利用新颖的硬件-软件协同设计，利用忆阻器的高度并行和高效的存内计算，将忆阻器的随机性转化为优势。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：基于忆阻器的回声状态储池网络用于时空信号学习、利用随机忆阻器阵列进行图结构数据学习、图嵌入方法与忆阻器联想记忆相结合以满足少样本图学习的需求、基于忆阻器液态机的零样本学习用于多模态事件数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3新型神经元器件电路及其类脑系统应用">议题3：新型神经元器件、电路及其类脑系统应用&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：张续猛，复旦大学青年副研究员，2023年度CCF-之江实验室联合创新基金获得者，全国智能计算标准化工作组委员&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：忆阻器基神经元器件，具有丰富动力学、低功耗、以及高集成度等特点，被认为是构建紧凑神经元电路的理想单元之一。&lt;/li>
&lt;li>&lt;strong>技术&lt;/strong>：利用神经元不同放电模式实现高效计算方面的研究工作，神经元器件的本征温度响应和它在多模态感知方面的应用。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4模拟矩阵计算求解ax--b">议题4：模拟矩阵计算求解Ax = b&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：高滨，清华大学长聘副教授/博导，清华大学教务处副处长&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：求解矩阵方程&lt;strong>Ax = b&lt;/strong>是历史上计算机技术发展的重要驱动力，也构成了现代计算任务的核心。如：科学计算、机器学习、信号处理等。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：传统数字计算机通过执行串行算法(直接法/迭代法)求解该方程，具有高的计算复杂度。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：传统计算机采用冯·诺伊曼架构，求解速度与能效受存储器、处理器之间的通信瓶颈限制。&lt;/li>
&lt;li>&lt;strong>方案&lt;/strong>：模拟矩阵计算，基于存储器阵列架构与全局反馈实现，具有极高的计算并行度；设计存储器阵列的反馈连接方式，模拟矩阵计算电路能够以O(1)的时间求解矩阵求逆、广义逆(如最小二乘)，以及稀疏近似(如压缩感知还原、稀疏编码)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5基于rram硬件的高效小样本学习和图处理">议题5：基于RRAM硬件的高效小样本学习和图处理&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：李灿，香港大学电机与电子工程系的助理教授&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：RRAM，抗变存储器，一种新兴的非易失性模拟存储技术，在存算一体应用方面展示了巨大的潜力。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：使用RRAM进行哈希运算和相似度搜索。通过在交叉阵列中进行特殊编码以及在注意力机制中用于相似度搜索。结合这些操作能够使用基于记忆增强的神经网络(MANN)进行少样本学习，以及使用图注意力(Graph Attention Network)网络进行图数据处理。这可能相较于传统计算平台如CPU和GPU，能耗显著降低，准确度损失最小。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="25云计算相关">2.5.云计算相关&lt;/h2>
&lt;h3 id="议题1大模型与国产算力">议题1：大模型与国产算力&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：翟季冬，清华大学计算机系长聘教授。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：在新一代国产超级计算机上，从底层算子库、并行加速库、负载均衡和混合精度等多方面对大模型进行了性能优化，最终实现了百万亿级参数量的预训练模型训练加速，达到了 EFLOPS级别的训练性能。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="26国内厂商的基础设施情况">2.6.国内厂商的基础设施情况&lt;/h2>
&lt;h3 id="议题1构建泛化普惠的智能算力中科曙光">议题1：构建泛化普惠的智能算力(中科曙光)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：杜夏威，中科曙光智能计算产品事业部总经理。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：通用超算中心-&amp;gt;专用智算中心-&amp;gt;通用智能计算中心。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：成熟兼容的DTK，&lt;strong>兼容CUDA和ROCm&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：适配百度飞桨，上限飞桨官网。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2算力为基共筑数智未来华为昇腾">议题2：算力为基，共筑数智未来(华为昇腾)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：刘鑫，华为昇腾计算业务副总裁。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>介绍华为在AI领域通过昇腾计算构筑坚实算力底座，聚焦根技术创新，打造好用、易用、可信的人工智能平台，发展普惠算力，降低大模型开发门槛，加速大模型模型创新落地，与各产业界共同构筑AI生态未来。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3昇腾大模型基础设施解决方案华为昇腾">议题3：昇腾大模型基础设施解决方案(华为昇腾)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：周斌，华为昇腾计算业务研发总裁&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：大模型是复杂系统工程，每个环节都存在大量工程技术挑战。&lt;/li>
&lt;li>&lt;strong>关键技术&lt;/strong>：高密度计算、复杂通信、内存优化等，打造大模型超级流水线，全流程使能大模型创新落地。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4华为计算领域技术挑战难题解读华为昇腾">议题4：华为计算领域技术挑战难题解读(华为昇腾)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：石晓钟，华为计算产品线技术合作总监&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>难题1&lt;/strong>：计算系统的高可靠计算容错技术。&lt;/li>
&lt;li>&lt;strong>难题2&lt;/strong>：片上和系统相结合的内存纠错技术。&lt;/li>
&lt;li>&lt;strong>难题3&lt;/strong>：多言行算力下的高鲁棒性混合精度求解。&lt;/li>
&lt;li>&lt;strong>难题4&lt;/strong>：基于原生硬件的高性能算子/算法(Matmul、Self-Attention)。&lt;/li>
&lt;li>&lt;strong>难题5&lt;/strong>：基于原生硬件的高性能算子/算法(FFT、Conv2D)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5壁仞科技">议题5：壁仞科技&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：丁云帆，壁仞科技系统架构副总裁&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>服务于百度飞桨、文心一言。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：GPT的大规模分布式训练在模型的参数规模、算力规模和训练性能等维度都存在巨大的挑战，大模型的应用落地也存在成本高、延时大的难题。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：本报告介绍GPT大模型的分布式并行训练策略、如何基于国产大算力通用GPU打造大模型训练系统及低延时高性能的大模型推理引擎。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题6飞腾">议题6：飞腾&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：窦强，中国电子信息产业集团科技委副主任，飞腾信息技术有限公司首席科学家&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>归属&lt;/strong>：隶属于中国电子信息产业集团。&lt;/li>
&lt;li>&lt;strong>关键路径&lt;/strong>：体系结构优化、设计工艺协同优化DTCO、先进封装推动Chiplet、系统垂直优化。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="3方向2llm基础理论工程化实践">3.方向2：LLM基础理论&amp;amp;工程化实践&lt;/h1>
&lt;h2 id="31预训练微调">3.1.预训练&amp;amp;微调&lt;/h2>
&lt;h3 id="议题1大模型技术研究及应用">议题1：大模型技术研究及应用&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：宗成庆，中国科学院自动化研究所研究员、博士生导师&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>PS：宗老师这个议题讲的非常通透，NLP造诣很深厚。&lt;/li>
&lt;li>&lt;strong>对大模型改进1&lt;/strong>：丰富生成文本的信息。预训练模型过于关注提示词中给出的实体or事件，难以包含更丰富的实体和信息。&lt;/li>
&lt;li>&lt;strong>对大模型改进2&lt;/strong>：无梯度计算的大模型参数调试。即，仅微调模型参数的一小部分就可以达到不错的微调性能。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="32端云协同下分布式训练">3.2.端云协同下，分布式训练&lt;/h2>
&lt;h3 id="议题1端云协同下分布式模型训练">议题1：端云协同下分布式模型训练&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：吴飞，浙江大学求是特聘教授，博士生导师&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：在&lt;strong>泛在互联、端云协同、AI赋能&lt;/strong>背景下，形成端云协同机器学习计算范式，是人工智能成为&lt;strong>普惠化能力&lt;/strong>的关键问题之一。&lt;/li>
&lt;li>&lt;strong>技术点&lt;/strong>：将&lt;strong>云侧的泛化能力&lt;/strong>与&lt;strong>端侧的个性化能力&lt;/strong>结合起来，体现&lt;strong>须弥纳于芥子&lt;/strong>的哲学思想。云端or端侧学习能力提升、端云协同模型化、端云系统开放平台是研究重点。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="33神经符号计算">3.3.神经符号计算&lt;/h2>
&lt;h3 id="议题1神经符号双轮驱动的信息检索与知识获取">议题1：神经符号双轮驱动的信息检索与知识获取&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：程学旗，中国科学院计算技术研究所副所长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：反绎学习面临弱标注数据和弱逻辑规则情形时，可能导致性能下降、不稳定。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：反绎学习是融合机器学习与逻辑推理并使它们能够比较均衡地协同发挥作用的新范式，提升反绎学习鲁棒性是研究重点。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2细粒度多模态协同感知认知与生成">议题2：细粒度多模态协同感知、认知与生成&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：彭宇新，北京大学博雅特聘教授、国家杰青、国家万人。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：细粒度多模态协同感知、认知与生成对于刻画真实世界和人类生产生活方式具有重要意义。&lt;/li>
&lt;li>&lt;strong>研究目标&lt;/strong>：借鉴人脑的跨模态特性，通过挖掘并协同多源、互补、关联的细粒度和多模态信息，实现对真实世界概念、规则及其演化的深层感知、认知与综合归纳。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：细粒度图像分类、行人再识别、细粒度视频检索、细粒度跨媒体检索、跨媒体推理、细粒度视觉生成。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3从语言大模型到神经符号ai">议题3：从语言大模型到神经符号AI&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：杨博，吉林大学计算机学院教授/博导，计算机学院、软件学院院长。&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：神经符号AI期望将符号主义和链接注意融合起来，取长补短，建立具有高效、鲁棒、可解释的智能系统，是当前人工智能研究的一个热点。&lt;/li>
&lt;li>&lt;strong>本质&lt;/strong>：符号主义和链接主义是人工智能的两大方法论，分别模拟演绎推理和归纳学习两种认知过程。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4鲁棒反绎学习迈向安全利用弱标注与弱规则">议题4：鲁棒反绎学习：迈向安全利用弱标注与弱规则&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：李宇峰，南京大学人工智能学院教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>**关键：**提升反绎学习鲁棒性方面的近期研究进展。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="34知识图谱">3.4.知识图谱&lt;/h2>
&lt;h3 id="议题1大模型时代的知识图谱">议题1：大模型时代的知识图谱&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：白硕，CCF上海分部主席，CCF理事，恒生电子有限公司首席科学家。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人从逻辑学出发，阐述命题逻辑、描述逻辑、一阶逻辑、高阶逻辑等，深入剖析NLP领域的远距关联、隐形资产以及大语言模型的短板。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：从描述逻辑到知识图谱，事理图谱，阐述知识图谱的四大特点，进一步阐述了知识图谱融合大模型的应用场景分类和应用深度分类。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2大模型应用体会澜舟科技">议题2：大模型应用体会(澜舟科技)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：周明，澜舟科技创始人兼CEO。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>定位&lt;/strong>：在大语言模型时代，各公司应如何选择产品定位？澜舟科技介绍了自身在大模型时代的定位。&lt;/li>
&lt;li>&lt;strong>模型选择&lt;/strong>：报告人提出了&lt;strong>周明曲线&lt;/strong>，阐述了如何为客户选择合适的大模型规模，量体裁衣，打造专业赛道的垂域大模型。&lt;/li>
&lt;li>&lt;strong>趋势&lt;/strong>：&lt;strong>AI Agents&lt;/strong>是大模型落地的必然趋势，以解决复杂问题求解、实时信息获取和分析、领域专业知识补充、外部系统交互等问题。&lt;/li>
&lt;li>&lt;strong>案例&lt;/strong>：报告人分享了&lt;strong>垂域知识库搜索问答、企业用户智能搜索+AI问答、对话生成式BI分析、智能客服、会议内容智能分析&lt;/strong>领域的案例。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3类chatgpt语言大模型与知识图谱新进展">议题3：类ChatGPT语言大模型与知识图谱新进展&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：王鑫，天津大学智能与计算学部教授、博导，人工智能学院副院长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：以ChatGPT为代表的语言大模型是“联结主义”的最新成果，而知识图谱是“符号主义”的集大成者，如何充分发挥知识图谱的积累的能力，补齐大语言模型的短板，是重要的研究方向。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：探究类ChatGPT语言大模型与知识图谱相互作用而实现“神经+符号”结合的可能途径。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="35安全治理价值观对齐联邦学习">3.5.安全治理&amp;amp;价值观对齐&amp;amp;联邦学习&lt;/h2>
&lt;h3 id="议题1大语言模型之价值观对齐">议题1：大语言模型之价值观对齐&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：秦兵，哈尔滨工业大学计算学部教授，博士生导师。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：大模型智能时代革命到来，生成式人工智能存在的安全隐患等价值观伦理问题。&lt;/li>
&lt;li>&lt;strong>研究方向&lt;/strong>：探索大模型安全性内容生成方法，包括研究大模型辨别是非能力，以及人类普世价值观，社会文化价值观及立场对齐上的内容检测与生成方法，探索AI社会协作式的价值观对齐机制。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2面向异构计算环境的去中心化联邦学习框架">议题2：面向异构计算环境的去中心化联邦学习框架&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：吕建成，四川大学教授/博导、计算机学院(软件学院、智能科学与技术学院)院长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：联邦学习可以突破数据孤岛和隐私保护瓶颈，是助力人工智能落地的新兴技术。&lt;/li>
&lt;li>&lt;strong>挑战&lt;/strong>：联邦学习应用于实际场景时，面临异构的计算环境：设备计算性能异构、通信网络和训练数据异构。现有基于中心化参数服务器的主流优化范式存在计算和通信瓶颈，面临扩展性差、通信开销大、模型性能低等现实问题。&lt;/li>
&lt;li>&lt;strong>方案&lt;/strong>：以去中心基础架构、通信优化、个性化模型优化为代表的去中心化架构及其衍生算法 。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="36机器语音机器听觉">3.6.机器语音/机器听觉&lt;/h2>
&lt;h3 id="议题1听觉注意力的理论与算法">议题1：听觉注意力的理论与算法&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：李海洲，新加坡工程院院士，新加坡国立大学终身教授、德国不来梅大学卓越讲座教授&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>技术点&lt;/strong>：听觉注意力是面对复杂的声学场景，人的眼睛和耳朵紧密配合、由大脑协调而实现对目标声源的选择。报告人阐述了听觉注意力算法在语音增强、说话人提取、语言提取等应用课题中的实践。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2说话人声音模仿与鉴别技术">议题2：说话人声音模仿与鉴别技术&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：陶建华，CCF语音对话与听觉专委会副主任，清华大学自动化系教授，博导&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：迁移学习&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：高度拟人化和个性化的人物声音模仿技术，对通信、教育、金融、社交、娱乐等领域有重要作用。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：阐述了通过迁移学习、生成式网络模型，声音模仿技术的多项成果。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：系统性地介绍伪造声音鉴别技术，伪造溯源分析方法、面向复杂场景的声音生成与鉴别对抗博弈机制。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3speechgpt让大语言模型具有内生的语音对话能力">议题3：SpeechGPT：让大语言模型具有内生的语音对话能力&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：邱锡鹏，复旦大学计算机学院教授，博导&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>案例&lt;/strong>：介绍SpeechGPT的跨模态能力，SpeechGPT突破了传统语音到语音对话流水线方式 (ASR+LLM+TTS) 的束缚，实现了模态之间的知识传递，不需要额外的ASR和TTS系统也能和LLM直接进行语音对话。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="37全脑神经联接与类脑智能">3.7.全脑神经联接与类脑智能&lt;/h2>
&lt;h3 id="议题1破解脊椎动物全脑神经联接--脑与类脑研究的基石">议题1：破解脊椎动物全脑神经联接 – 脑与类脑研究的基石&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：杜久林，中国科学院脑科学与智能技术卓越创新中心副主任&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：大脑是在跨时空尺度上具有高度非线性作用的复杂动力学系统，心智的奥秘就蕴藏在这精巧的组织结构中。揭示大脑组织规律及其基础上产生的神经功能的机制，不仅是理解大脑奥秘的必由之路，也将为发展类脑智能构架与算法、突破冯•偌依曼构架提供新策略。&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：斑马鱼具有脊椎动物保守的神经系统结构，可以从全脑尺度上解读其大脑工作的基本原理。报告人讲述本研究团队运用自创的“既见森林(全脑)、又见树木(神经元)甚或树叶(突触)”的研究范式，实现了对脊椎动物全脑所有神经元形态结构与神经活动的在体观测与调控、以及动物行为的同时记录。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2文曲星基于开源芯片与敏捷开发的开源类脑芯片">议题2：文曲星：基于“开源芯片与敏捷开发”的开源类脑芯片&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：赵地，中科院计算所副研究员&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：在神经形态计算中，脉冲神经网络(Spiking Neural Network，SNN)是硬件实现的最佳选择。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：大多数加速器解决方案都基于CPU 加速器架构，这种结构因为复杂的控制流程而能源效率低下。报告人基于脉冲卷积神经网络的开源芯片构架：开发脉冲卷积单元，对现有的卷积神经网络单元进行特征提取和事件驱动设置，进一步提高单元工作工作的效率，并降低功耗的开销。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3全脑尺度的信息维持和行为策略调整">议题3：全脑尺度的信息维持和行为策略调整&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：穆宇，中国科学院脑科学与智能技术卓越创新中心研究员&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：空间上，大脑的每个部分都接收来自其他区域的输入并对其产生作用。时间上，每一刻的大脑都携带着前一刻的信息并影响着下一刻。对&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人阐述如何开发一种系统，支持在单个细胞的分辨率监测整个斑马鱼大脑，并实时处理所获得的神经元或行为信息以生成闭环干扰从感觉到运动的完整转导过程，在全脑尺度上进行剖析，助力理解复杂的脑功能并总结其完整的计算原理。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4类脑器件与系统">议题4：类脑器件与系统&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：缪峰，南京大学物理学院教授、博导、副院长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人阐述了二维材料与“原子乐高”电子学如何在发展未来的类脑智能技术中发挥重要作用，包括神经形态计算与类视网膜形态计算等。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="4方向3llm应用落地">4.方向3：LLM应用落地&lt;/h1>
&lt;h2 id="41软件工程">4.1.软件工程&lt;/h2>
&lt;h3 id="议题1大模型时代的软件研发华为">议题1：大模型时代的软件研发(华为)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：王千祥，华为云智能化软件研发首席专家&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>引导&lt;/strong>：从软件研发角度，大模型将带来哪些变化？报告人结合华为在基于LLM的代码生成等软件研发领域开展的系列探索，分享软件研发大模型的进展。&lt;/li>
&lt;li>&lt;strong>问题&lt;/strong>：开发者如何与大模型协同研发？程序如何与大模型协同运行？人类如何与大模型协同存在？&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2大模型催生ai原生研发新范式百度">议题2：大模型催生AI原生研发新范式(百度)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：臧志，百度工程效能部总监&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：探讨在大模型技术影响下，&lt;strong>产品思维-应用框架-研发过程&lt;/strong>将发生哪些变化。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：如何适配大模型时代的新要素构建新的研发生产力，以及新型的研发智能体如何在企业场景中落地应用。&lt;/li>
&lt;li>&lt;strong>核心要点&lt;/strong>：&lt;strong>SE 4 AI，AI 4 SE&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题3代码大模型赋能软件研发的探索与实践科大讯飞">议题3：代码大模型赋能软件研发的探索与实践(科大讯飞)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：薛增奎，科大讯飞效能平台首席技术专家&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：介绍科大讯飞的iFlyCode(基于自研代码大模型的智能编程助手产品)，以及在内外部应用的典型场景和成效。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题4基于代码大模型的代码智能体字节跳动">议题4：基于代码大模型的代码智能体(字节跳动)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：许晶晶，字节跳动研究员&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：讨论基于代码大模型的自主代理的构建和具体的应用场景。在智能体构建方面，如何结合代码规划、代码执行等能力？在应用场景方面，以数据分析场景为例，探讨智能体在其中的应用和实践。&lt;/li>
&lt;li>PS：这个小姐姐功力深厚。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题5大模型对软件开发模式的影响北大">议题5：大模型对软件开发模式的影响(北大)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：李戈，北京大学长聘教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：软件自动化理论认为AI辅助研发的瓶颈是模型大小。大语言模型为软件自动化打开了一扇窗。反之，模型不够大就是多少人工多少智能。&lt;/li>
&lt;li>**PS：**李老师很诙谐，净说大实话。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题6大模型时代软件测试技术方向与趋势同济大学">议题6：大模型时代软件测试技术方向与趋势(同济大学)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：朱少民，同济大学特聘教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：阐述了早期采用遗传算法、粒子群优化算法等生成测试数据，AI覆盖了测试建模、测试用例集优化、GUI白动化测试、测试结果分析等方面。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人着重讨论如何应用大模型为软件测试赋能、如何借助LLM相关技术更高效地完成测试工作，以及未来技术发展方向。阐述了大模型时代软件测试的新范式、大模型时代软件测试的技术方向。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="42智慧交通">4.2.智慧交通&lt;/h2>
&lt;h3 id="议题1视频物联网中云端协同智能计算">议题1：视频物联网中云端协同智能计算&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：马华东，北京邮电大学计算机学院教授&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>价值&lt;/strong>：视频物联是物联网的一种重要形态，也是支撑智慧城市、智能安防等应用的关键基础设施。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人以人、车、事件为典型目标，阐述了面向多任务多场景的深度神经网络智能视频算法体系&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：针对端设备资源受限、云端协同计算难、单一视觉模型能力弱等挑战，介绍了模型轻量化、云端模型互动、视觉大模型等相关技术&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="43智慧医疗">4.3.智慧医疗&lt;/h2>
&lt;h3 id="议题1exploring-different-modalities-for-healthcare-applications">议题1：Exploring Different Modalities for Healthcare Applications&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>报告人&lt;/strong>：邱锂力，微软亚洲研究院副院长&lt;/li>
&lt;li>&lt;strong>内容小结&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：报告人介绍如何利用无线传感和机器学习技术利用不同模式进行疾病诊断的探索，从语言、运动、呼吸、心跳、脑电波、医学图像等方面衡量一个人的健康状况。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="议题2生命科学基础模型">议题2：生命科学基础模型&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：宋乐，BioMap CTO和首席人工智能科学家&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>挑战&lt;/strong>：能否利用大量无监督数据来加速生命科学发现和药物设计？&lt;/li>
&lt;li>&lt;strong>成果&lt;/strong>：介绍xTrimo系列跨多尺度生物过程的大规模预训练模型，整合来自蛋白质序列、结构、蛋白质-蛋白质相互作用和单细胞转录组数据的大量数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="44智慧农业">4.4.智慧农业&lt;/h2>
&lt;h3 id="议题1智慧农业领域的大模型初探">议题1：智慧农业领域的大模型初探&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：刘劼，哈尔滨工业大学（深圳）国际人工智能研究院院长，IEEE Fellow&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键点&lt;/strong>：介绍大模型在遥感图像处理、作物数据生成等方面的尝试，并展望建立作物生长等大模型的前景。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="45aiot">4.5.AIoT&lt;/h2>
&lt;h3 id="议题1aiiot-human-centric-smart-sensing-design">议题1：AI+IoT: Human-Centric Smart Sensing Design&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>报告人&lt;/strong>：张黔，香港科技大学腾讯工程学教授、计算机科学与工程系讲座教授、IEEE Fellow、香港工程科学院院士&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内容小结&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>趋势&lt;/strong>：AI与IoT的融合，为以人为中心的应用创造了赋能的机会，也产生了相关的挑战。&lt;/li>
&lt;li>&lt;strong>关键点&lt;/strong>：如何处理数据的异构特性、不同终端用户数据的不完整性、以及终端设备资源受限造成的低质量数据等问题？感知模态的多样性为感知能力的突破带来的新机会点？&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记25-提示词解读2-通用技巧</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/</link><pubDate>Fri, 10 Nov 2023 12:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/</guid><description>&lt;p>上一篇，我们了解了提示词基本概念，本篇我们继续解读吴恩达老师的《ChatGPT Prompt Engineering for Developers》课程，看一下提示词常用技巧。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231108115607959.png" alt="image-20231108115607959">&lt;/p>
&lt;h1 id="1技巧构建合理的提示词结构">1.技巧：构建合理的提示词结构&lt;/h1>
&lt;p>完整的提示词包含以下四个要素：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>要素&lt;/th>
&lt;th>说明&lt;/th>
&lt;th>举例&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>指令词&lt;/strong>&lt;/td>
&lt;td>想要模型执行的特定任务或指令&lt;/td>
&lt;td>如：翻译、总结、生成&amp;hellip;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>背景(上下文)&lt;/strong>&lt;/td>
&lt;td>包含外部信息或额外的上下文信息，引导语言模型更好地响应&lt;/td>
&lt;td>如：“在人工智能领域”, “在医学领域”&amp;hellip;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>输入&lt;/strong>&lt;/td>
&lt;td>用户输入的内容或问题&lt;/td>
&lt;td>如：需要总结的文章&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>输出要求&lt;/strong>&lt;/td>
&lt;td>指定输出的类型或格式&lt;/td>
&lt;td>如：以JSON格式输出&amp;hellip;&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;font color=red>**注意：**提示词结构取决于您的任务类型，并非所有以上要素都是必须的。&lt;/font>&lt;/p>
&lt;h1 id="2技巧设定角色">2.技巧：设定角色&lt;/h1>
&lt;h2 id="1设定llm的角色">(1)设定LLM的角色&lt;/h2>
&lt;p>在提示词中设定LLM角色，&lt;strong>让模型进行角色扮演&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>直接提问&lt;/strong>，ChatGPT返回的答案较笼统，没有针对性。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110154844353.png" alt="image-20231110154844353">&lt;/p>
&lt;ul>
&lt;li>在提示词中&lt;strong>让LLM角色扮演&lt;/strong>，ChatGPT再次返回的答案就会出现医学领域的专有名词和专业指导。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110155206497.png" alt="image-20231110155206497">&lt;/p>
&lt;h2 id="2设定提问者的角色">(2)设定提问者的角色&lt;/h2>
&lt;p>除了让大语言模型进行角色扮演，还可以设定提问者的角色，为不同的提问对象生成定制化的答案。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>设定提问者的角色是一位百岁老人&lt;/strong>，ChatGPT的回答会考虑到老人的身体状况。(PS：百岁老人你都敢建议他去跑马拉松&amp;hellip;)&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110155639302.png" alt="image-20231110155639302">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>设定提问者的角色是缺乏运动的程序员&lt;/strong>，ChatGPT的回答会提醒程序员循序渐进。(PS：这个缺乏运动的程序员就是我&amp;hellip;)&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110155824839.png" alt="image-20231110155824839">&lt;/p>
&lt;h1 id="3技巧分隔符划分指令和内容">3.技巧：分隔符划分指令和内容&lt;/h1>
&lt;p>如果提示词包含2个要素：&lt;strong>指令词&lt;/strong>和&lt;strong>输入&lt;/strong>，那么我们如何让大语言模型知道哪些是&lt;strong>指令词&lt;/strong>，哪些是&lt;strong>输入&lt;/strong>？&lt;/p>
&lt;ul>
&lt;li>我们可以&lt;strong>使用分隔符&lt;/strong>(如```、&amp;quot;&amp;quot;&amp;quot;、&amp;lt;&amp;gt;等)区分&lt;strong>指令&lt;/strong>和待处理的&lt;strong>输入&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>看一个例子：&lt;/p>
&lt;ul>
&lt;li>我们不是想大语言模型给100岁老人参加马拉松的建议，而是希望将这段文字翻译为英文——我们可以通过&lt;code>&amp;quot;&amp;quot;&amp;quot;&lt;/code>，&lt;strong>区分出指令和输入&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110160402261.png" alt="">&lt;/p>
&lt;h1 id="4技巧指定文本判断条件">4.技巧：指定文本判断条件&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>在提示词中&lt;strong>指定文本判断条件&lt;/strong>，激发大语言模型对文字的分类能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>示例：在本示例中，激发了大语言模型对**&amp;ldquo;是否为指令&amp;rdquo;**的分类能力。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110161203289.png" alt="image-20231110161203289">&lt;/p>
&lt;h1 id="5技巧指定输出的格式">5.技巧：指定输出的格式&lt;/h1>
&lt;ul>
&lt;li>在提示词中&lt;strong>指定输出答案的格式&lt;/strong>，便于应用软件系统获得答案后的文本处理。&lt;/li>
&lt;li>示例：在本示例中，ChatGPT按照提示词中设定的JSON格式返回了答案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110163709627.png" alt="image-20231110163709627">&lt;/p>
&lt;h1 id="6-技巧few-shot">6. 技巧：Few-Shot&lt;/h1>
&lt;ul>
&lt;li>在提示词中，给出&lt;strong>一些示例的问答&lt;/strong>，可能&lt;strong>激发大语言模型的模仿能力&lt;/strong>。&lt;/li>
&lt;li>根据给出的示例问答的数量，可分为：
&lt;ul>
&lt;li>
&lt;p>&lt;strong>zero-shot&lt;/strong>：零样本提示。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>one-shot&lt;/strong>：单样本提示。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>few-shot&lt;/strong>：少样本提示。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>我们来看一个示例：&lt;/p>
&lt;ul>
&lt;li>直接问大语言模型问题，属于&lt;strong>zero-shot&lt;/strong>，大语言模型的答案风格比较自由。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110162842622.png" alt="image-20231110162842622">&lt;/p>
&lt;ul>
&lt;li>问大语言模型的同时，给出了老师、学生的一个问答对，属于&lt;strong>one-shot&lt;/strong>，大语言模型的答案风格就会&lt;strong>大致模仿&lt;/strong>一下示例问答对的风格。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110163038324.png" alt="image-20231110163038324">&lt;/p>
&lt;ul>
&lt;li>问大语言模型的同时，给出了老师、学生的多个问答对，属于&lt;strong>few-shot&lt;/strong>，大语言模型的答案风格就会&lt;strong>模仿&lt;/strong>示例问答对的风格及&lt;strong>老师的情绪&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110163115561.png" alt="image-20231110163115561">&lt;/p>
&lt;h1 id="7技巧cot">7.技巧：CoT&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>CoT&lt;/strong>：Chain of Thought，思维链。AI科学家在研究中发现，只需要在提示词最后增加一句话——&amp;ldquo;让我们一步一步思考&amp;rdquo;，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>我们看一下示例：我们的提问是大语言模型目前的短板能力(数学问题)，在没有任何提示的情况下，答案是错的。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110165008611.png" alt="image-20231110165008611">&lt;/p>
&lt;ul>
&lt;li>我们加上这句神奇的咒语——&lt;code>Let's think step by step.&lt;/code>，ChatGPT就可以回答正确了。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110165440078.png" alt="image-20231110165440078">&lt;/p>
&lt;h1 id="8技巧自洽self-consistency">8.技巧：自洽(SELF-CONSISTENCY)&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>Self-Consistency&lt;/strong>：自洽，即推理过程中，用多种推理路径得到结果，出现最大的答案大概率就是正确答案，从而体现了&lt;strong>自洽性&lt;/strong>。&lt;/li>
&lt;li>随着大语言模型能力日益增强，Self-Consistency已成为大语言模型的内部能力，需要多次实验才能观测到自洽的推理过程。&lt;/li>
&lt;li>我们来看一个例子：通过CoT，激发大语言模型推理思考，从它的回答中，可以看出大语言模型的推理过程产生了多种不同推理路径及答案，最终大语言模型自行选择了一个自洽的回答。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB2-%E9%80%9A%E7%94%A8%E6%8A%80%E5%B7%A7/image-20231110170209475.png" alt="image-20231110170209475">&lt;/p>
&lt;h1 id="9小结">9.小结&lt;/h1>
&lt;p>本文阐述了多种提示词常用技巧，实战中需要综合应用上述技巧，根据场景激发大语言模型的不同能力：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>技巧1：构建合理的提示词结构&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧2：设定角色&lt;/strong>，设定LLM角色、设定提问者角色。&lt;/li>
&lt;li>&lt;strong>技巧3：分隔符划分指令和内容&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧4：指定文本判断条件&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧5：指定输出格式&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧6：Few-Shot。&lt;/strong>&lt;/li>
&lt;li>&lt;strong>技巧7：CoT&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>技巧8：Self-Consistency&lt;/strong>。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记24-提示词解读1-提示词基本概念</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link><pubDate>Thu, 09 Nov 2023 15:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid><description>&lt;p>吴恩达老师的《ChatGPT Prompt Engineering for Developers》是一门学习提示词工程不错的课程，我们接下来用几篇文章来解读这门课程。&lt;/p>
&lt;h1 id="1什么是提示词工程">1.什么是提示词工程&lt;/h1>
&lt;p>首先看1个问题：&lt;/p>
&lt;ul>
&lt;li>向大语言模型输入&amp;quot;一二三四五&amp;rdquo;，它很可能回答&amp;quot;上山打老虎&amp;rdquo;。但，我们的意图是希望它把&amp;quot;一二三四五&amp;rdquo;&lt;strong>翻译成英文&lt;/strong>，怎么办？&lt;/li>
&lt;/ul>
&lt;p>我们的解决方法是：&lt;/p>
&lt;ul>
&lt;li>问大语言模型：&amp;ldquo;请将如下文字翻译为英文：一二三四五&amp;rdquo;，大语言模型就会回答&amp;quot;One Two Three Four Five&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;p>上述解决方法本质是什么呢？&lt;/p>
&lt;ul>
&lt;li>即在问题里明确表达&lt;strong>期望大语言模型如何处理&lt;/strong>一段文字。&lt;/li>
&lt;li>明确表达期望大语言模型做什么，就是一条指令，也就是&lt;strong>提示词&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>提示词理论的出现，源于两个假设：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>假设1&lt;/strong>：大语言模型已经掌握了很多世界知识，但由于知道的太多，一时想不起来。&lt;/li>
&lt;li>&lt;strong>假设2&lt;/strong>：自然语言存在二义性，需要更多的提示，才能准确地向大语言模型表达人类的真实意图。&lt;/li>
&lt;/ul>
&lt;p>因此，人类通过提示词，可以唤起大语言模型对已有知识的记忆，也可以让大语言模型更加准确地理解人类意图。&lt;/p>
&lt;p>开发提示词、优化提示词的过程，被称为&lt;strong>提示词工程&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>提示词工程包含了诸多工程方法，如：设计有效的提示策略、优化提示词表达等。&lt;/li>
&lt;/ul>
&lt;p>伴随着大语言模型的发展，提示词工程也形成了一套体系化的工程方法。它成为AI领域的热点技术之一，是AI工程师的必备技能。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231110144405400.png" alt="From《Pre-train, Prompt, and Predict: A Systematic Survey ofPrompting Methods in Natural Language Processing》">&lt;/p>
&lt;h1 id="2提示词基本原则">2.提示词基本原则&lt;/h1>
&lt;h2 id="1原则1简洁明确">(1)原则1：简洁明确&lt;/h2>
&lt;p>假想两个人类在说话，两人的表达能力有限，词不达意、含糊其辞、鸡同鸭讲&amp;hellip;，最终就导致两人之间的沟通极其困难。&lt;/p>
&lt;p>与大语言模型交互，和人类交流类似，也需要简洁明确的同问，向大语言模型清晰表达意图。&lt;/p>
&lt;p>我们来看一个例子：&lt;/p>
&lt;ul>
&lt;li>我们让ChatGPT写一首诗，它以立冬为题生成一首诗：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231110145755795.png" alt="image-20231110145755795">&lt;/p>
&lt;ul>
&lt;li>如果我们希望这首诗是五言绝句，则进一步这样提问，可以看到ChatGPT生成了一首以立冬为题的五言绝句。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231110145923990.png" alt="image-20231110145923990">&lt;/p>
&lt;p>上述示例，可以看出：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>写一首诗&lt;/strong>是一条&lt;strong>简洁的指令&lt;/strong>。&lt;/li>
&lt;li>相较于写一首诗，&lt;strong>写一首五言绝句&lt;/strong>是一条更加&lt;strong>简洁明确的指令&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;h2 id="2原则2迭代式提示词开发">(2)原则2：迭代式提示词开发&lt;/h2>
&lt;p>我们要知道两个事实：&lt;/p>
&lt;ul>
&lt;li>没有可以适应所有场景的完美提示词，需要我们针对不同场景，开发不同的提示词。&lt;/li>
&lt;li>即使在一个很小的场景下存在完美提示词，我们也无法一次性就找到它。&lt;/li>
&lt;/ul>
&lt;p>针对某个场景，寻找提示词的过程，就是&lt;strong>迭代式提示词开发&lt;/strong>。&lt;/p>
&lt;p>迭代式提示词开发的过程如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：针对特定场景，设计初始提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将初始提示词传递给大语言模型，获得返回结果(&lt;code>Experimental result&lt;/code>)。&lt;/li>
&lt;li>&lt;strong>Error Analysis阶段&lt;/strong>：分析返回结果，思考改进提示词的方法，重新进入&lt;strong>Idea阶段&lt;/strong>，直到找到特定场景下的完美提示词。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108102255487.png" alt="From 吴恩达提示词课程">&lt;/p>
&lt;p>我们再来看一个示例：我们需要一段用于营销的产品介绍。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：针对产品介绍场景，设计初始提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将初始提示词传递给大语言模型，获得返回结果。可以看到ChatGPT返回了一段不错的文案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108110737288.png" alt="image-20231108110737288">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Error Analysis阶段&lt;/strong>：从上一步获得的ChatGPT文案内容太长，我们思考改进提示词的方法是进一步明确字数要求。&lt;/li>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：根据上一阶段的改进思路，编写改进后的提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将改进后的提示词传递给大语言模型，获得返回结果。可以看到ChatGPT返回了一段简短的文案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108110819852.png" alt="image-20231108110819852">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Error Analysis阶段&lt;/strong>：从上一步获得的ChatGPT文案没有突出要点，我们思考改进提示词的方法是限定明确要突出的关键点。&lt;/li>
&lt;li>&lt;strong>Idea阶段&lt;/strong>：根据上一阶段的改进思路，编写改进后的提示词。&lt;/li>
&lt;li>&lt;strong>Implementation阶段&lt;/strong>：将改进后的提示词传递给大语言模型，获得返回结果。可以看到ChatGPT返回了一段简短、要点突出的文案。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%A7%A3%E8%AF%BB1-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image-20231108110848960.png" alt="image-20231108110848960">&lt;/p>
&lt;p>这就是&lt;strong>迭代式提示词开发&lt;/strong>的流程，核心要点是&lt;strong>多次迭代&lt;/strong>。&lt;/p>
&lt;h2 id="3原则3选择合适的提示词风格">(3)原则3：选择合适的提示词风格&lt;/h2>
&lt;p>提示词工程是一种&lt;code>Instruct-Tuning&lt;/code>技术，提示词的风格包含：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Prompt&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Instruction&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>初学者极易混淆这两种风格，我们来看一个例子：&lt;/p>
&lt;ul>
&lt;li>幼儿园老师希望引导小朋友唱歌，于是她说：在小小的花园里面挖呀挖呀挖&amp;hellip;，老师此时停顿下来并对小朋友投去了期待的目光，小朋友按耐不住激动的心情，接下句：种小小的种子开小小的花——这就是&lt;strong>Prompt(提示)&lt;/strong>。&lt;/li>
&lt;li>幼儿园老师希望小朋友背诵五言绝句，于是她说：请背诵《鹅鹅鹅》，小朋友在老师又一次期待的目光下，整齐划一地背诵出&amp;quot;鹅鹅鹅曲项向天歌&amp;hellip;&amp;quot;——这就是&lt;strong>Instruction(指令)&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>我们了解了提示词的两大风格后，就要针对不同场景、不同意图，选择不同的提示词风格。&lt;/p>
&lt;h1 id="4小结">4.小结&lt;/h1>
&lt;p>提示词工程是一项热门技术，本文对提示词工程基本概念进行了阐述：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>提示词工程是开发和优化提示词的过程&lt;/strong>，包括选择合适的提示词、设计有效的提示策略，以及优化提示词的表达方式等。&lt;/li>
&lt;li>提示词三个基本原则：
&lt;ul>
&lt;li>&lt;strong>简洁、明确&lt;/strong>&lt;/li>
&lt;li>&lt;strong>迭代式提示词开发&lt;/strong>&lt;/li>
&lt;li>&lt;strong>选择合适的提示词风格&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记23-让我们一起来翻译吴恩达LLM课程</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BEllm%E8%AF%BE%E7%A8%8B/</link><pubDate>Thu, 02 Nov 2023 15:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BEllm%E8%AF%BE%E7%A8%8B/</guid><description>&lt;p>哈喽小伙伴，我是小牛，初次见面，请多关照。&lt;/p>
&lt;p>最近跟着猴哥的学习笔记各种手撸GPT，理解了LLM原理。&lt;/p>
&lt;p>但我跟GPT的交情好像只停留在say hello的程度，说好的能替代“表哥”、“码农”、“ppt经理”的能力呢？&lt;/p>
&lt;p>然后chatGPT跟我说，有个叫吴恩达的大咖，有好几门神课，理论+实践，易学易懂，学会了就可以在职场上大放异彩。那还犹豫什么，卷！&lt;/p>
&lt;p>这些课程都是英文视频，为了方便学习，我们准备把它们翻译成中文。&lt;/p>
&lt;p>欢迎感兴趣的小伙伴们一起来翻译。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BELLM%E8%AF%BE%E7%A8%8B/image-20231102181630937.png" alt="image-20231102181630937">&lt;/p>
&lt;h1 id="1已翻译的课程">1.已翻译的课程&lt;/h1>
&lt;ul>
&lt;li>《提示词工程 by 吴恩达》：https://jherculesqz.gitbook.io/chatgpt-prompt-engineering-for-developers-1&lt;/li>
&lt;li>《LangChain by 吴恩达》：https://jherculesqz.gitbook.io/langchain-by-wu-en-da&lt;/li>
&lt;/ul>
&lt;h2 id="11提示词工程-by-吴恩达简介">1.1.《提示词工程 by 吴恩达》简介&lt;/h2>
&lt;p>GPT神器虽好，但要会用。本课程将介绍：&lt;/p>
&lt;ul>
&lt;li>如何构建清晰、明确的提示词，有哪些技巧&lt;/li>
&lt;li>如何通过提示词发掘大语言模型总结、推理、转换以及生成文本的能力&lt;/li>
&lt;li>动手做一个自己的聊天机器人&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BELLM%E8%AF%BE%E7%A8%8B/image-20231102181807030.png" alt="image-20231102181807030">&lt;/p>
&lt;h2 id="12langchain-by-吴恩达简介">1.2.《LangChain by 吴恩达》简介&lt;/h2>
&lt;p>LangChain是开发LLM应用的开发框架，是当红炸子鸡。本课程将介绍：&lt;/p>
&lt;ul>
&lt;li>什么是LangChain&lt;/li>
&lt;li>LangChain有哪些Chain&lt;/li>
&lt;li>如何用LangChain做聊天模型、QA问答系统&lt;/li>
&lt;li>如何用LangChain的agent功能使能大模型的推理能力&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E7%BF%BB%E8%AF%91%E5%90%B4%E6%81%A9%E8%BE%BELLM%E8%AF%BE%E7%A8%8B/image-20231102181929184.png" alt="image-20231102181929184">&lt;/p>
&lt;h1 id="2待翻译的课程">2.待翻译的课程&lt;/h1>
&lt;p>我们已经计划翻译的课程、论文有：&lt;/p>
&lt;ul>
&lt;li>《Finetuning Large Language Models》&lt;/li>
&lt;li>《Attention Is All You Need》&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>如果小伙伴们对其它LLM相关的文献、课程感兴趣，欢迎后台联系我们。&lt;/p>
&lt;blockquote>
&lt;p>免责声明：我们的翻译出于对技术的执着和个人兴趣，开源免费，仅供个人学习，不得商用。&lt;/p>
&lt;/blockquote></description></item><item><title>【chatGPT】学习笔记22-LangChain之Agent，对LLM的抽象5</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-langchain%E4%B9%8Bagent%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A15/</link><pubDate>Tue, 31 Oct 2023 15:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-langchain%E4%B9%8Bagent%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A15/</guid><description>&lt;p>业界目前的AI助手应用集中于两大功能：&lt;/p>
&lt;ul>
&lt;li>基于垂直领域知识的&lt;strong>智能问答&lt;/strong>&lt;/li>
&lt;li>基于垂直领域知识的&lt;strong>智能行动&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>在《【chatGPT】学习笔记21-LangChain之Retrieval，对LLM的抽象4》中，着重介绍了&lt;strong>智能问答&lt;/strong>依赖的技术点。&lt;/p>
&lt;p>本文重点介绍与&lt;strong>智能行动&lt;/strong>依赖的技术点。&lt;/p>
&lt;h1 id="1什么是react">1.什么是ReAct&lt;/h1>
&lt;h2 id="1基本概念">(1)基本概念&lt;/h2>
&lt;p>常见的LLM推理模式有两种：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Reason Only&lt;/strong>：比如CoT，利用提示词诱导LLM进行逻辑推理，进而回答偏数理逻辑类的问题。&lt;/li>
&lt;li>&lt;strong>Act Only&lt;/strong>：比如指令微调提到的，明确在问题中带有指令。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>ReAct&lt;/strong>提出了一种新的推理模式——&lt;strong>Reason + Act&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>LLM推理出&amp;rdquo;&lt;strong>把大象装进冰箱需要几步&lt;/strong>&amp;quot;，&lt;/li>
&lt;li>再针对待执行的每一步&lt;strong>选择合适的工具&lt;/strong>，&lt;/li>
&lt;li>在执行当前步骤后，通过环境的反馈，&lt;strong>决策下一步是什么&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-LangChain%E4%B9%8BAgent%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A15/image-20231031152602671.png" alt="image-20231031152602671">&lt;/p>
&lt;h2 id="2react优势">(2)ReAct优势&lt;/h2>
&lt;p>在论文《ReAct: Synergizing Reasoning and Acting in Language Models》中，阐述了ReAct的训练效果比&lt;code>Reson Only&lt;/code>和&lt;code>Act Only&lt;/code>都好：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-LangChain%E4%B9%8BAgent%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A15/image-20231031153243968.png" alt="image-20231031153243968">&lt;/p>
&lt;h2 id="3agents内部结构">(3)Agents内部结构&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>数据结构&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>AgentAction&lt;/code>：表示Agent应采取的行为。包含1个&lt;code>tool&lt;/code>属性和一个&lt;code>tool_input&lt;/code>属性，表示这个行为可采用的工具及工具输入。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>AgentFinish&lt;/code>：表示Agent完成后的返回结果。包含1个&lt;code>return_values&lt;/code>属性，字典类型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>intermediate_steps&lt;/code>：表示之前的Agent行为和返回结果。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Agent&lt;/strong>：智能体，可以分析出&amp;rdquo;&lt;strong>将大象放进冰箱里需要几步&lt;/strong>&amp;quot;，内部实现&lt;strong>依赖LLM的逻辑推理能力&lt;/strong>。它的输入包括：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>工具列表&lt;/strong>：&lt;code>List of available tools&lt;/code>，Agent可以用的工具集合。&lt;/li>
&lt;li>&lt;strong>用户输入&lt;/strong>：User input。&lt;/li>
&lt;li>&lt;strong>之前的Agent行为和返回结果&lt;/strong>：Any previously executed steps，就是&lt;code>intermediate_steps&lt;/code>对象。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tools&lt;/strong>：它是Agent某个行为可以使用的工具。每个工具需要有两个明确信息：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>工具的可用性&lt;/strong>：如&amp;quot;使用Google搜索&amp;quot;是一个工具，这个工具本身要真的可用、可靠。&lt;/li>
&lt;li>&lt;strong>工具的准确描述&lt;/strong>：对工具的作用有准确的描述，这段描述最终会变成提示词，帮助Agent知道要执行什么行为的时候，应该选择哪个工具更合适。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>AgentExecutor&lt;/strong>：Agent执行器。能够调用&lt;code>Agent&lt;/code>，不断获得下一步&lt;code>action(行为)&lt;/code>并执行。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>除了&lt;code>AgentExecutor&lt;/code>，LangChain还提供了实验性质的其它Agent执行器：&lt;/p>
&lt;ul>
&lt;li>Plan-and-execute Agent&lt;/li>
&lt;li>Baby AGI&lt;/li>
&lt;li>Auto GPT&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>AgentExecutor&lt;/code>核心代码如下：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="n">next_action&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">agent&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_action&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">while&lt;/span> &lt;span class="n">next_action&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="n">AgentFinish&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">observation&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">next_action&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">next_action&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">agent&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_action&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">next_action&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">observation&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">next_action&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="4langchain已经支持的agent和tool列表">(4)LangChain已经支持的Agent和Tool列表&lt;/h2>
&lt;ul>
&lt;li>LangChain已经提供了很多&lt;code>Agent&lt;/code>和&lt;code>Tools&lt;/code>，具体如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-LangChain%E4%B9%8BAgent%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A15/image-20231031151549996.png" alt="image-20231031151549996">&lt;/p>
&lt;h1 id="2代码示例">2.代码示例&lt;/h1>
&lt;p>&lt;code>Agent&lt;/code>是当前LLM App的一个热点方向，展开阐述会有很多的内容。本文仅通过1个经典问题代码示例，为各位小伙伴建立&lt;code>Agent&lt;/code>的宏观认识。后续本专栏再详细阐述&lt;code>Agent&lt;/code>开发的内容。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>问题&lt;/strong>：周杰伦的老婆是谁？她现在的年龄的0.43次方等于多少？&lt;/li>
&lt;li>&lt;strong>代码&lt;/strong>：
&lt;ul>
&lt;li>创建了&lt;code>tools&lt;/code>工具集对象&lt;/li>
&lt;li>初始化了&lt;code>agent&lt;/code>对象，&lt;code>agent&lt;/code>对象包含1个&lt;code>LLM&lt;/code>和1个&lt;code>tools&lt;/code>对象&lt;/li>
&lt;li>执行&lt;code>agent&lt;/code>对象的&lt;code>run&lt;/code>方法，由&lt;code>LLM&lt;/code>自行开展行动，直到获得最终答案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>运行结果分析&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>&lt;code>LLM&lt;/code>首先明确任务目标&lt;/strong>：背后应该是由一个复杂的提示词驱动的。&lt;/li>
&lt;li>&lt;strong>&lt;code>LLM&lt;/code>再分解出三个步骤&lt;/strong>：每个步骤的输出，都会作为下一个步骤的输入。&lt;/li>
&lt;li>&lt;strong>&lt;code>LLM&lt;/code>最后汇总结果&lt;/strong>：&lt;code>LLM&lt;/code>判断如果达成目标，则给出最终答案，并终止执行。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-LangChain%E4%B9%8BAgent%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A15/image-20231031154927730.png" alt="image-20231031154927730">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-LangChain%E4%B9%8BAgent%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A15/image-20231031160426352.png" alt="image-20231031160426352">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>本文关键要点如下：&lt;/p>
&lt;ul>
&lt;li>简述了&lt;code>Agent&lt;/code>理论基础&lt;code>ReAct&lt;/code>&lt;/li>
&lt;li>描述了论文&lt;code>ReAct: Synergizing Reasoning and Acting in Language Models&lt;/code>中的实验现象、&lt;code>ReAct&lt;/code>的优势。&lt;/li>
&lt;li>给出了一个有关&lt;strong>大语言模型不知道的有时效性的知识&lt;/strong>的问题，&lt;code>Agent&lt;/code>如何&lt;strong>利用大语言模型的推理能力&lt;/strong>解决此类问题的代码示例。&lt;/li>
&lt;/ul>
&lt;p>如果说上篇文章的&lt;code>Retrieval&lt;/code>帮助AI助手具备了&lt;strong>智能问答&lt;/strong>能力，这篇文章的&lt;code>Agent&lt;/code>则帮助AI助手实现了&lt;strong>智能行动&lt;/strong>。&lt;/p>
&lt;p>所以，&lt;code>Agent&lt;/code>这个方向是目前开发LLM应用的诸多厂商的关注热点，这里还有一些未及展开讨论的内容：&lt;/p>
&lt;ul>
&lt;li>如何自定义1个满足垂直领域的&lt;strong>自定义Agent&lt;/strong>？&lt;/li>
&lt;li>如何自定义1组满足垂直领域的&lt;strong>自定义Tool&lt;/strong>？&lt;/li>
&lt;/ul>
&lt;p>这些高级话题，留待本专栏后续分解，敬请期待。&lt;/p></description></item><item><title>【chatGPT】学习笔记21-LangChain之Retrieval，对LLM的抽象4</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-langchain%E4%B9%8Bretrieval%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A14/</link><pubDate>Mon, 30 Oct 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-langchain%E4%B9%8Bretrieval%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A14/</guid><description>&lt;p>本专栏通过解读了Transformer模型，实现简版GPT后，帮大家建立了对NLP原理、关键技术的理解。&lt;/p>
&lt;p>接下来，我们再关注一下应用层面的技术——如何开发LLM App。&lt;/p>
&lt;p>前面我们了解了LangChain的三大重要模块**&amp;ldquo;Model I/O、Memory、Chain&amp;rdquo;**，具体如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>LangChain的Model I/O&lt;/strong>：详见《【chatGPT】学习笔记10-LangChain之Model I/O，对LLM的抽象1》&lt;/li>
&lt;li>&lt;strong>LangChain的Memory&lt;/strong>：详见《【chatGPT】学习笔记14-LangChain之Memory，对LLM的抽象2》&lt;/li>
&lt;li>&lt;strong>LangChain的Chain&lt;/strong>：详见《【chatGPT】学习笔记15-LangChain之Chain，对LLM的抽象3》&lt;/li>
&lt;/ul>
&lt;p>本文继续展示LangChain的第四大模块&amp;rdquo;&lt;strong>Retrieval&lt;/strong>&amp;quot;。&lt;/p>
&lt;blockquote>
&lt;p>LangChain曾经把此模块称为Data Connection，其实更为贴切。&lt;/p>
&lt;/blockquote>
&lt;h1 id="1整体流程">1.整体流程&lt;/h1>
&lt;p>如果我们要开发一个基于LLM的AI问答系统，整体流程如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>文档加载&lt;/strong>：加载各类文档。&lt;/li>
&lt;li>&lt;strong>文档转换&lt;/strong>：将文档分割为一段段的文本。&lt;/li>
&lt;li>&lt;strong>文档向量化&lt;/strong>：将文本进行词嵌入，并存储于向量数据库。&lt;/li>
&lt;li>&lt;strong>文档检索&lt;/strong>：针对用户的问题进行向量检索。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231030140913593.png" alt="image-20231030140913593">&lt;/p>
&lt;p>我们接下来看看，LangChain如何支撑上述整体流程。&lt;/p>
&lt;h1 id="2文档加载器">2.文档加载器&lt;/h1>
&lt;h2 id="21基本概念">2.1.基本概念&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>LangChain提供的文档加载器(&lt;code>Document loaders&lt;/code>)，支持从不同数据源加载数据，最终输出为&lt;code>Document&lt;/code>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LangChain的厉害之处在于：它支持了100+的数据源，丰富程度基本覆盖了所有的数据源。具体支持的Loader如下：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231030143143187.png" alt="image-20231030143143187">&lt;/p>
&lt;p>接下来，我们通过阅读LangChain的源码，深入理解文档加载器。&lt;/p>
&lt;h2 id="22document">2.2.Document&lt;/h2>
&lt;h3 id="1源码解读">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;code>Document&lt;/code>类是文档加载器的输出。&lt;/li>
&lt;li>&lt;code>Document&lt;/code>类的代码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/schema/document.py&lt;/li>
&lt;li>&lt;code>Document&lt;/code>类的关键代码如下：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">Document&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Serializable&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Class for storing a piece of text and associated metadata.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">page_content&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;String text.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="err">文档内容&lt;/span>
&lt;span class="n">metadata&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">dict&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">default_factory&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">dict&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Arbitrary metadata about the page content (e.g., source, relationships to other
&lt;/span>&lt;span class="s2"> documents, etc.).
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="nb">type&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Literal&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;Document&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Document&amp;#34;&lt;/span>
&lt;span class="nd">@classmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">is_lc_serializable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">cls&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Return whether this class is serializable.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">True&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="23baseloader">2.3.BaseLoader&lt;/h2>
&lt;h3 id="1源码解读-1">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;code>BaseLoader&lt;/code>类是各种不同&lt;code>Loader&lt;/code>的基类。&lt;/li>
&lt;li>&lt;code>BaseLoader&lt;/code>类的代码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/document_loaders/base.py&lt;/li>
&lt;li>&lt;code>BaseLoader&lt;/code>类的关键代码如下：关键方法是&lt;code>load&lt;/code>、&lt;code>load_and_split&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">BaseLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ABC&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Interface for Document Loader.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Implementations should implement the lazy-loading method using generators
&lt;/span>&lt;span class="s2"> to avoid loading all Documents into memory at once.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> The `load` method will remain as is for backwards compatibility, but its
&lt;/span>&lt;span class="s2"> implementation should be just `list(self.lazy_load())`.
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="c1"># Sub-classes should implement this method&lt;/span>
&lt;span class="c1"># as return list(self.lazy_load()).&lt;/span>
&lt;span class="c1"># This method returns a List which is materialized in memory.&lt;/span>
&lt;span class="nd">@abstractmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load data into Document objects.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="err">加载数据并将其转换为文档对象&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load_and_split&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">text_splitter&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">TextSplitter&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load Documents and split into chunks. Chunks are returned as Documents.
&lt;/span>&lt;span class="s2"> 加载文档并分割成块
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Args:
&lt;/span>&lt;span class="s2"> text_splitter: TextSplitter instance to use for splitting documents.
&lt;/span>&lt;span class="s2"> Defaults to RecursiveCharacterTextSplitter.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Returns:
&lt;/span>&lt;span class="s2"> List of Documents.
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">text_splitter&lt;/span> &lt;span class="ow">is&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_text_splitter&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">TextSplitter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">RecursiveCharacterTextSplitter&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_text_splitter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">text_splitter&lt;/span>
&lt;span class="n">docs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">_text_splitter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split_documents&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">docs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Attention: This method will be upgraded into an abstractmethod once it&amp;#39;s&lt;/span>
&lt;span class="c1"># implemented in all the existing subclasses.&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">lazy_load&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Iterator&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;A lazy loader for Documents.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">NotImplementedError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;{self.__class__.__name__} does not implement lazy_load()&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="24textloader">2.4.TextLoader&lt;/h2>
&lt;h3 id="1源码解读-2">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;code>TextLoader&lt;/code>类是用于加载文本的Loader，继承于&lt;code>BaseLoader&lt;/code>。&lt;/li>
&lt;li>&lt;code>TextLoader&lt;/code>类的代码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/document_loaders/text.py&lt;/li>
&lt;li>&lt;code>TextLoader&lt;/code>类的关键代码如下：关键方法是实现了自己的&lt;code>load&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">TextLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BaseLoader&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load text file.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Args:
&lt;/span>&lt;span class="s2"> file_path: Path to the file to load.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> encoding: File encoding to use. If `None`, the file will be loaded
&lt;/span>&lt;span class="s2"> with the default system encoding.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> autodetect_encoding: Whether to try to autodetect the file encoding
&lt;/span>&lt;span class="s2"> if the specified encoding fails.
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">file_path&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">encoding&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">autodetect_encoding&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Initialize with file path.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">file_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">file_path&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encoding&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">encoding&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">autodetect_encoding&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">autodetect_encoding&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load from file path.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">file_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">encoding&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encoding&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">UnicodeDecodeError&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">autodetect_encoding&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">detected_encodings&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">detect_file_encodings&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">file_path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">encoding&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">detected_encodings&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">debug&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Trying encoding: {encoding.encoding}&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">file_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">encoding&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">encoding&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encoding&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">break&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">UnicodeDecodeError&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">continue&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">RuntimeError&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Error loading {self.file_path}&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="kn">from&lt;/span> &lt;span class="nn">e&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">Exception&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">RuntimeError&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Error loading {self.file_path}&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="kn">from&lt;/span> &lt;span class="nn">e&lt;/span>
&lt;span class="n">metadata&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;source&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">file_path&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">page_content&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metadata&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">metadata&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2代码示例">(2)代码示例&lt;/h3>
&lt;ul>
&lt;li>构造TextLoader，读取txt文件，返回docs对象。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031071416742.png" alt="image-20231031071416742">&lt;/p>
&lt;ul>
&lt;li>观测docs对象&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031071531911.png" alt="image-20231031071531911">&lt;/p>
&lt;h2 id="25arxivloader">2.5.ArxivLoader&lt;/h2>
&lt;h3 id="1源码解读-3">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;code>ArxivLoader&lt;/code>类是用于加载Arxiv的Loader，继承于&lt;code>BaseLoader&lt;/code>。&lt;/li>
&lt;li>&lt;code>ArxivLoader&lt;/code>类的代码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/document_loaders/arxiv.py&lt;/li>
&lt;li>&lt;code>ArxivLoader&lt;/code>类的关键代码如下：关键方法是实现了自己的&lt;code>load&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">ArxivLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BaseLoader&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load a query result from `Arxiv`.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> The loader converts the original PDF format into the text.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Args:
&lt;/span>&lt;span class="s2"> Supports all arguments of `ArxivAPIWrapper`.
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">query&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">doc_content_chars_max&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Any&lt;/span>
&lt;span class="p">):&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">query&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">query&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">client&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ArxivAPIWrapper&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">doc_content_chars_max&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">doc_content_chars_max&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">client&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">query&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2代码示例-1">(2)代码示例&lt;/h3>
&lt;ul>
&lt;li>读取指定版本号的论文，得到docs对象，docs对象包含了指定版本号的相关论文信息。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031071610543.png" alt="image-20231031071610543">&lt;/p>
&lt;h2 id="26unstructuredurlloader">2.6.UnstructuredURLLoader&lt;/h2>
&lt;h3 id="1源码解读-4">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;code>UnstructuredURLLoader&lt;/code>类是用于加载指定URL的Loader，继承于&lt;code>BaseLoader&lt;/code>。&lt;/li>
&lt;li>&lt;code>UnstructuredURLLoader&lt;/code>类的代码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/document_loaders/url.py&lt;/li>
&lt;li>&lt;code>UnstructuredURLLoader&lt;/code>类的关键代码如下：关键方法是实现了自己的&lt;code>load&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt"> 10
&lt;/span>&lt;span class="lnt"> 11
&lt;/span>&lt;span class="lnt"> 12
&lt;/span>&lt;span class="lnt"> 13
&lt;/span>&lt;span class="lnt"> 14
&lt;/span>&lt;span class="lnt"> 15
&lt;/span>&lt;span class="lnt"> 16
&lt;/span>&lt;span class="lnt"> 17
&lt;/span>&lt;span class="lnt"> 18
&lt;/span>&lt;span class="lnt"> 19
&lt;/span>&lt;span class="lnt"> 20
&lt;/span>&lt;span class="lnt"> 21
&lt;/span>&lt;span class="lnt"> 22
&lt;/span>&lt;span class="lnt"> 23
&lt;/span>&lt;span class="lnt"> 24
&lt;/span>&lt;span class="lnt"> 25
&lt;/span>&lt;span class="lnt"> 26
&lt;/span>&lt;span class="lnt"> 27
&lt;/span>&lt;span class="lnt"> 28
&lt;/span>&lt;span class="lnt"> 29
&lt;/span>&lt;span class="lnt"> 30
&lt;/span>&lt;span class="lnt"> 31
&lt;/span>&lt;span class="lnt"> 32
&lt;/span>&lt;span class="lnt"> 33
&lt;/span>&lt;span class="lnt"> 34
&lt;/span>&lt;span class="lnt"> 35
&lt;/span>&lt;span class="lnt"> 36
&lt;/span>&lt;span class="lnt"> 37
&lt;/span>&lt;span class="lnt"> 38
&lt;/span>&lt;span class="lnt"> 39
&lt;/span>&lt;span class="lnt"> 40
&lt;/span>&lt;span class="lnt"> 41
&lt;/span>&lt;span class="lnt"> 42
&lt;/span>&lt;span class="lnt"> 43
&lt;/span>&lt;span class="lnt"> 44
&lt;/span>&lt;span class="lnt"> 45
&lt;/span>&lt;span class="lnt"> 46
&lt;/span>&lt;span class="lnt"> 47
&lt;/span>&lt;span class="lnt"> 48
&lt;/span>&lt;span class="lnt"> 49
&lt;/span>&lt;span class="lnt"> 50
&lt;/span>&lt;span class="lnt"> 51
&lt;/span>&lt;span class="lnt"> 52
&lt;/span>&lt;span class="lnt"> 53
&lt;/span>&lt;span class="lnt"> 54
&lt;/span>&lt;span class="lnt"> 55
&lt;/span>&lt;span class="lnt"> 56
&lt;/span>&lt;span class="lnt"> 57
&lt;/span>&lt;span class="lnt"> 58
&lt;/span>&lt;span class="lnt"> 59
&lt;/span>&lt;span class="lnt"> 60
&lt;/span>&lt;span class="lnt"> 61
&lt;/span>&lt;span class="lnt"> 62
&lt;/span>&lt;span class="lnt"> 63
&lt;/span>&lt;span class="lnt"> 64
&lt;/span>&lt;span class="lnt"> 65
&lt;/span>&lt;span class="lnt"> 66
&lt;/span>&lt;span class="lnt"> 67
&lt;/span>&lt;span class="lnt"> 68
&lt;/span>&lt;span class="lnt"> 69
&lt;/span>&lt;span class="lnt"> 70
&lt;/span>&lt;span class="lnt"> 71
&lt;/span>&lt;span class="lnt"> 72
&lt;/span>&lt;span class="lnt"> 73
&lt;/span>&lt;span class="lnt"> 74
&lt;/span>&lt;span class="lnt"> 75
&lt;/span>&lt;span class="lnt"> 76
&lt;/span>&lt;span class="lnt"> 77
&lt;/span>&lt;span class="lnt"> 78
&lt;/span>&lt;span class="lnt"> 79
&lt;/span>&lt;span class="lnt"> 80
&lt;/span>&lt;span class="lnt"> 81
&lt;/span>&lt;span class="lnt"> 82
&lt;/span>&lt;span class="lnt"> 83
&lt;/span>&lt;span class="lnt"> 84
&lt;/span>&lt;span class="lnt"> 85
&lt;/span>&lt;span class="lnt"> 86
&lt;/span>&lt;span class="lnt"> 87
&lt;/span>&lt;span class="lnt"> 88
&lt;/span>&lt;span class="lnt"> 89
&lt;/span>&lt;span class="lnt"> 90
&lt;/span>&lt;span class="lnt"> 91
&lt;/span>&lt;span class="lnt"> 92
&lt;/span>&lt;span class="lnt"> 93
&lt;/span>&lt;span class="lnt"> 94
&lt;/span>&lt;span class="lnt"> 95
&lt;/span>&lt;span class="lnt"> 96
&lt;/span>&lt;span class="lnt"> 97
&lt;/span>&lt;span class="lnt"> 98
&lt;/span>&lt;span class="lnt"> 99
&lt;/span>&lt;span class="lnt">100
&lt;/span>&lt;span class="lnt">101
&lt;/span>&lt;span class="lnt">102
&lt;/span>&lt;span class="lnt">103
&lt;/span>&lt;span class="lnt">104
&lt;/span>&lt;span class="lnt">105
&lt;/span>&lt;span class="lnt">106
&lt;/span>&lt;span class="lnt">107
&lt;/span>&lt;span class="lnt">108
&lt;/span>&lt;span class="lnt">109
&lt;/span>&lt;span class="lnt">110
&lt;/span>&lt;span class="lnt">111
&lt;/span>&lt;span class="lnt">112
&lt;/span>&lt;span class="lnt">113
&lt;/span>&lt;span class="lnt">114
&lt;/span>&lt;span class="lnt">115
&lt;/span>&lt;span class="lnt">116
&lt;/span>&lt;span class="lnt">117
&lt;/span>&lt;span class="lnt">118
&lt;/span>&lt;span class="lnt">119
&lt;/span>&lt;span class="lnt">120
&lt;/span>&lt;span class="lnt">121
&lt;/span>&lt;span class="lnt">122
&lt;/span>&lt;span class="lnt">123
&lt;/span>&lt;span class="lnt">124
&lt;/span>&lt;span class="lnt">125
&lt;/span>&lt;span class="lnt">126
&lt;/span>&lt;span class="lnt">127
&lt;/span>&lt;span class="lnt">128
&lt;/span>&lt;span class="lnt">129
&lt;/span>&lt;span class="lnt">130
&lt;/span>&lt;span class="lnt">131
&lt;/span>&lt;span class="lnt">132
&lt;/span>&lt;span class="lnt">133
&lt;/span>&lt;span class="lnt">134
&lt;/span>&lt;span class="lnt">135
&lt;/span>&lt;span class="lnt">136
&lt;/span>&lt;span class="lnt">137
&lt;/span>&lt;span class="lnt">138
&lt;/span>&lt;span class="lnt">139
&lt;/span>&lt;span class="lnt">140
&lt;/span>&lt;span class="lnt">141
&lt;/span>&lt;span class="lnt">142
&lt;/span>&lt;span class="lnt">143
&lt;/span>&lt;span class="lnt">144
&lt;/span>&lt;span class="lnt">145
&lt;/span>&lt;span class="lnt">146
&lt;/span>&lt;span class="lnt">147
&lt;/span>&lt;span class="lnt">148
&lt;/span>&lt;span class="lnt">149
&lt;/span>&lt;span class="lnt">150
&lt;/span>&lt;span class="lnt">151
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">UnstructuredURLLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BaseLoader&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load files from remote URLs using `Unstructured`.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Use the unstructured partition function to detect the MIME type
&lt;/span>&lt;span class="s2"> and route the file to the appropriate partitioner.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> You can run the loader in one of two modes: &amp;#34;single&amp;#34; and &amp;#34;elements&amp;#34;.
&lt;/span>&lt;span class="s2"> If you use &amp;#34;single&amp;#34; mode, the document will be returned as a single
&lt;/span>&lt;span class="s2"> langchain Document object. If you use &amp;#34;elements&amp;#34; mode, the unstructured
&lt;/span>&lt;span class="s2"> library will split the document into elements such as Title and NarrativeText.
&lt;/span>&lt;span class="s2"> You can pass in additional unstructured kwargs after mode to apply
&lt;/span>&lt;span class="s2"> different unstructured settings.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Examples
&lt;/span>&lt;span class="s2"> --------
&lt;/span>&lt;span class="s2"> from langchain.document_loaders import UnstructuredURLLoader
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> loader = UnstructuredURLLoader(
&lt;/span>&lt;span class="s2"> ursl=[&amp;#34;&amp;lt;url-1&amp;gt;&amp;#34;, &amp;#34;&amp;lt;url-2&amp;gt;&amp;#34;], mode=&amp;#34;elements&amp;#34;, strategy=&amp;#34;fast&amp;#34;,
&lt;/span>&lt;span class="s2"> )
&lt;/span>&lt;span class="s2"> docs = loader.load()
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> References
&lt;/span>&lt;span class="s2"> ----------
&lt;/span>&lt;span class="s2"> https://unstructured-io.github.io/unstructured/bricks.html#partition
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">urls&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">],&lt;/span>
&lt;span class="n">continue_on_failure&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">mode&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;single&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">show_progress_bar&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="o">**&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Initialize with file path.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">unstructured&lt;/span> &lt;span class="c1"># noqa:F401&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">unstructured.__version__&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">__version__&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">__unstructured_version__&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">__unstructured_version__&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">ImportError&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">ImportError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s2">&amp;#34;unstructured package not found, please install it with &amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;`pip install unstructured`&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_validate_mode&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mode&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mode&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mode&lt;/span>
&lt;span class="n">headers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">unstructured_kwargs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pop&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;headers&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{})&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">headers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keys&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">warn_about_headers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_non_html_available&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="n">warn_about_headers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_headers_available_for_non_html&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">warn_about_headers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_headers_available_for_html&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">warn_about_headers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">warning&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s2">&amp;#34;You are using an old version of unstructured. &amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;The headers parameter is ignored&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">urls&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">urls&lt;/span>
&lt;span class="err">待加载网页&lt;/span> &lt;span class="n">URL&lt;/span> &lt;span class="err">列表&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">continue_on_failure&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">continue_on_failure&lt;/span>
&lt;span class="err">默认&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="err">，某个&lt;/span>&lt;span class="n">URL加载失败后&lt;/span>&lt;span class="err">，是否继续&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">headers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">headers&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">unstructured_kwargs&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show_progress_bar&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">show_progress_bar&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">_validate_mode&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">mode&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_valid_modes&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;single&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;elements&amp;#34;&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">mode&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">_valid_modes&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">ValueError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Got {mode} for `mode`, but should be one of `{_valid_modes}`&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">__is_headers_available_for_html&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;-&amp;#34;&lt;/span>&lt;span class="p">)[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">tuple&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">_unstructured_version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;.&amp;#34;&lt;/span>&lt;span class="p">)])&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">__is_headers_available_for_non_html&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;-&amp;#34;&lt;/span>&lt;span class="p">)[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">tuple&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">_unstructured_version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;.&amp;#34;&lt;/span>&lt;span class="p">)])&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">__is_non_html_available&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;-&amp;#34;&lt;/span>&lt;span class="p">)[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">tuple&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">_unstructured_version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;.&amp;#34;&lt;/span>&lt;span class="p">)])&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">unstructured_version&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Load file.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">unstructured.partition.auto&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">partition&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">unstructured.partition.html&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">partition_html&lt;/span>
&lt;span class="n">docs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show_progress_bar&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">tqdm&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">tqdm&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">ImportError&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">ImportError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s2">&amp;#34;Package tqdm must be installed if show_progress_bar=True. &amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;Please install with &amp;#39;pip install tqdm&amp;#39; or set &amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;show_progress_bar=False.&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="kn">from&lt;/span> &lt;span class="nn">e&lt;/span>
&lt;span class="n">urls&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tqdm&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">urls&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">urls&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">urls&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">url&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">urls&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_non_html_available&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_headers_available_for_non_html&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="n">elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">partition&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">url&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">headers&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">headers&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">partition&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__is_headers_available_for_html&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="n">elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">partition_html&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">url&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">headers&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">headers&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">partition_html&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unstructured_kwargs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">except&lt;/span> &lt;span class="ne">Exception&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">continue_on_failure&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">error&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Error fetching or processing {url}, exception: {e}&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">continue&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="n">e&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mode&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;single&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">el&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">el&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">elements&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">metadata&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;source&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">url&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="n">docs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">page_content&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metadata&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">metadata&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mode&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;elements&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">element&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">elements&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">metadata&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metadata&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">to_dict&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">metadata&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;category&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">category&lt;/span>
&lt;span class="n">docs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">page_content&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">metadata&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">metadata&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">docs&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2代码示例-2">(2)代码示例&lt;/h3>
&lt;ul>
&lt;li>读取指定URL网页，返回data对象&lt;/li>
&lt;li>data对象包含了网页中各类元素信息&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031071807666.png" alt="image-20231031071807666">&lt;/p>
&lt;h1 id="3文档转换器">3.文档转换器&lt;/h1>
&lt;h2 id="31基本概念">3.1.基本概念&lt;/h2>
&lt;ul>
&lt;li>LangChain提供的文档转器(&lt;code>Document transformers&lt;/code>)，支持用不同的分割方法，将&lt;code>Loader&lt;/code>获取的文档进行分割。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031072618565.png" alt="image-20231031072618565">&lt;/p>
&lt;p>这些文档转换器并不复杂，需要实操熟练掌握，本文不赘述，重点演示一下最常用的&lt;code>RecursiveCharacterTextSplitter&lt;/code>。&lt;/p>
&lt;h2 id="32recursivecharactertextsplitter">3.2.RecursiveCharacterTextSplitter&lt;/h2>
&lt;h3 id="1源码解读-5">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>作用：可输入字符列表作为切块分隔符，并根据第一个字符进行切块。如果切块太大，则使用下一个字符切块，以此类推。&lt;/li>
&lt;li>源码路径：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/text_splitter.py&lt;/li>
&lt;li>核心源码如下：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt"> 10
&lt;/span>&lt;span class="lnt"> 11
&lt;/span>&lt;span class="lnt"> 12
&lt;/span>&lt;span class="lnt"> 13
&lt;/span>&lt;span class="lnt"> 14
&lt;/span>&lt;span class="lnt"> 15
&lt;/span>&lt;span class="lnt"> 16
&lt;/span>&lt;span class="lnt"> 17
&lt;/span>&lt;span class="lnt"> 18
&lt;/span>&lt;span class="lnt"> 19
&lt;/span>&lt;span class="lnt"> 20
&lt;/span>&lt;span class="lnt"> 21
&lt;/span>&lt;span class="lnt"> 22
&lt;/span>&lt;span class="lnt"> 23
&lt;/span>&lt;span class="lnt"> 24
&lt;/span>&lt;span class="lnt"> 25
&lt;/span>&lt;span class="lnt"> 26
&lt;/span>&lt;span class="lnt"> 27
&lt;/span>&lt;span class="lnt"> 28
&lt;/span>&lt;span class="lnt"> 29
&lt;/span>&lt;span class="lnt"> 30
&lt;/span>&lt;span class="lnt"> 31
&lt;/span>&lt;span class="lnt"> 32
&lt;/span>&lt;span class="lnt"> 33
&lt;/span>&lt;span class="lnt"> 34
&lt;/span>&lt;span class="lnt"> 35
&lt;/span>&lt;span class="lnt"> 36
&lt;/span>&lt;span class="lnt"> 37
&lt;/span>&lt;span class="lnt"> 38
&lt;/span>&lt;span class="lnt"> 39
&lt;/span>&lt;span class="lnt"> 40
&lt;/span>&lt;span class="lnt"> 41
&lt;/span>&lt;span class="lnt"> 42
&lt;/span>&lt;span class="lnt"> 43
&lt;/span>&lt;span class="lnt"> 44
&lt;/span>&lt;span class="lnt"> 45
&lt;/span>&lt;span class="lnt"> 46
&lt;/span>&lt;span class="lnt"> 47
&lt;/span>&lt;span class="lnt"> 48
&lt;/span>&lt;span class="lnt"> 49
&lt;/span>&lt;span class="lnt"> 50
&lt;/span>&lt;span class="lnt"> 51
&lt;/span>&lt;span class="lnt"> 52
&lt;/span>&lt;span class="lnt"> 53
&lt;/span>&lt;span class="lnt"> 54
&lt;/span>&lt;span class="lnt"> 55
&lt;/span>&lt;span class="lnt"> 56
&lt;/span>&lt;span class="lnt"> 57
&lt;/span>&lt;span class="lnt"> 58
&lt;/span>&lt;span class="lnt"> 59
&lt;/span>&lt;span class="lnt"> 60
&lt;/span>&lt;span class="lnt"> 61
&lt;/span>&lt;span class="lnt"> 62
&lt;/span>&lt;span class="lnt"> 63
&lt;/span>&lt;span class="lnt"> 64
&lt;/span>&lt;span class="lnt"> 65
&lt;/span>&lt;span class="lnt"> 66
&lt;/span>&lt;span class="lnt"> 67
&lt;/span>&lt;span class="lnt"> 68
&lt;/span>&lt;span class="lnt"> 69
&lt;/span>&lt;span class="lnt"> 70
&lt;/span>&lt;span class="lnt"> 71
&lt;/span>&lt;span class="lnt"> 72
&lt;/span>&lt;span class="lnt"> 73
&lt;/span>&lt;span class="lnt"> 74
&lt;/span>&lt;span class="lnt"> 75
&lt;/span>&lt;span class="lnt"> 76
&lt;/span>&lt;span class="lnt"> 77
&lt;/span>&lt;span class="lnt"> 78
&lt;/span>&lt;span class="lnt"> 79
&lt;/span>&lt;span class="lnt"> 80
&lt;/span>&lt;span class="lnt"> 81
&lt;/span>&lt;span class="lnt"> 82
&lt;/span>&lt;span class="lnt"> 83
&lt;/span>&lt;span class="lnt"> 84
&lt;/span>&lt;span class="lnt"> 85
&lt;/span>&lt;span class="lnt"> 86
&lt;/span>&lt;span class="lnt"> 87
&lt;/span>&lt;span class="lnt"> 88
&lt;/span>&lt;span class="lnt"> 89
&lt;/span>&lt;span class="lnt"> 90
&lt;/span>&lt;span class="lnt"> 91
&lt;/span>&lt;span class="lnt"> 92
&lt;/span>&lt;span class="lnt"> 93
&lt;/span>&lt;span class="lnt"> 94
&lt;/span>&lt;span class="lnt"> 95
&lt;/span>&lt;span class="lnt"> 96
&lt;/span>&lt;span class="lnt"> 97
&lt;/span>&lt;span class="lnt"> 98
&lt;/span>&lt;span class="lnt"> 99
&lt;/span>&lt;span class="lnt">100
&lt;/span>&lt;span class="lnt">101
&lt;/span>&lt;span class="lnt">102
&lt;/span>&lt;span class="lnt">103
&lt;/span>&lt;span class="lnt">104
&lt;/span>&lt;span class="lnt">105
&lt;/span>&lt;span class="lnt">106
&lt;/span>&lt;span class="lnt">107
&lt;/span>&lt;span class="lnt">108
&lt;/span>&lt;span class="lnt">109
&lt;/span>&lt;span class="lnt">110
&lt;/span>&lt;span class="lnt">111
&lt;/span>&lt;span class="lnt">112
&lt;/span>&lt;span class="lnt">113
&lt;/span>&lt;span class="lnt">114
&lt;/span>&lt;span class="lnt">115
&lt;/span>&lt;span class="lnt">116
&lt;/span>&lt;span class="lnt">117
&lt;/span>&lt;span class="lnt">118
&lt;/span>&lt;span class="lnt">119
&lt;/span>&lt;span class="lnt">120
&lt;/span>&lt;span class="lnt">121
&lt;/span>&lt;span class="lnt">122
&lt;/span>&lt;span class="lnt">123
&lt;/span>&lt;span class="lnt">124
&lt;/span>&lt;span class="lnt">125
&lt;/span>&lt;span class="lnt">126
&lt;/span>&lt;span class="lnt">127
&lt;/span>&lt;span class="lnt">128
&lt;/span>&lt;span class="lnt">129
&lt;/span>&lt;span class="lnt">130
&lt;/span>&lt;span class="lnt">131
&lt;/span>&lt;span class="lnt">132
&lt;/span>&lt;span class="lnt">133
&lt;/span>&lt;span class="lnt">134
&lt;/span>&lt;span class="lnt">135
&lt;/span>&lt;span class="lnt">136
&lt;/span>&lt;span class="lnt">137
&lt;/span>&lt;span class="lnt">138
&lt;/span>&lt;span class="lnt">139
&lt;/span>&lt;span class="lnt">140
&lt;/span>&lt;span class="lnt">141
&lt;/span>&lt;span class="lnt">142
&lt;/span>&lt;span class="lnt">143
&lt;/span>&lt;span class="lnt">144
&lt;/span>&lt;span class="lnt">145
&lt;/span>&lt;span class="lnt">146
&lt;/span>&lt;span class="lnt">147
&lt;/span>&lt;span class="lnt">148
&lt;/span>&lt;span class="lnt">149
&lt;/span>&lt;span class="lnt">150
&lt;/span>&lt;span class="lnt">151
&lt;/span>&lt;span class="lnt">152
&lt;/span>&lt;span class="lnt">153
&lt;/span>&lt;span class="lnt">154
&lt;/span>&lt;span class="lnt">155
&lt;/span>&lt;span class="lnt">156
&lt;/span>&lt;span class="lnt">157
&lt;/span>&lt;span class="lnt">158
&lt;/span>&lt;span class="lnt">159
&lt;/span>&lt;span class="lnt">160
&lt;/span>&lt;span class="lnt">161
&lt;/span>&lt;span class="lnt">162
&lt;/span>&lt;span class="lnt">163
&lt;/span>&lt;span class="lnt">164
&lt;/span>&lt;span class="lnt">165
&lt;/span>&lt;span class="lnt">166
&lt;/span>&lt;span class="lnt">167
&lt;/span>&lt;span class="lnt">168
&lt;/span>&lt;span class="lnt">169
&lt;/span>&lt;span class="lnt">170
&lt;/span>&lt;span class="lnt">171
&lt;/span>&lt;span class="lnt">172
&lt;/span>&lt;span class="lnt">173
&lt;/span>&lt;span class="lnt">174
&lt;/span>&lt;span class="lnt">175
&lt;/span>&lt;span class="lnt">176
&lt;/span>&lt;span class="lnt">177
&lt;/span>&lt;span class="lnt">178
&lt;/span>&lt;span class="lnt">179
&lt;/span>&lt;span class="lnt">180
&lt;/span>&lt;span class="lnt">181
&lt;/span>&lt;span class="lnt">182
&lt;/span>&lt;span class="lnt">183
&lt;/span>&lt;span class="lnt">184
&lt;/span>&lt;span class="lnt">185
&lt;/span>&lt;span class="lnt">186
&lt;/span>&lt;span class="lnt">187
&lt;/span>&lt;span class="lnt">188
&lt;/span>&lt;span class="lnt">189
&lt;/span>&lt;span class="lnt">190
&lt;/span>&lt;span class="lnt">191
&lt;/span>&lt;span class="lnt">192
&lt;/span>&lt;span class="lnt">193
&lt;/span>&lt;span class="lnt">194
&lt;/span>&lt;span class="lnt">195
&lt;/span>&lt;span class="lnt">196
&lt;/span>&lt;span class="lnt">197
&lt;/span>&lt;span class="lnt">198
&lt;/span>&lt;span class="lnt">199
&lt;/span>&lt;span class="lnt">200
&lt;/span>&lt;span class="lnt">201
&lt;/span>&lt;span class="lnt">202
&lt;/span>&lt;span class="lnt">203
&lt;/span>&lt;span class="lnt">204
&lt;/span>&lt;span class="lnt">205
&lt;/span>&lt;span class="lnt">206
&lt;/span>&lt;span class="lnt">207
&lt;/span>&lt;span class="lnt">208
&lt;/span>&lt;span class="lnt">209
&lt;/span>&lt;span class="lnt">210
&lt;/span>&lt;span class="lnt">211
&lt;/span>&lt;span class="lnt">212
&lt;/span>&lt;span class="lnt">213
&lt;/span>&lt;span class="lnt">214
&lt;/span>&lt;span class="lnt">215
&lt;/span>&lt;span class="lnt">216
&lt;/span>&lt;span class="lnt">217
&lt;/span>&lt;span class="lnt">218
&lt;/span>&lt;span class="lnt">219
&lt;/span>&lt;span class="lnt">220
&lt;/span>&lt;span class="lnt">221
&lt;/span>&lt;span class="lnt">222
&lt;/span>&lt;span class="lnt">223
&lt;/span>&lt;span class="lnt">224
&lt;/span>&lt;span class="lnt">225
&lt;/span>&lt;span class="lnt">226
&lt;/span>&lt;span class="lnt">227
&lt;/span>&lt;span class="lnt">228
&lt;/span>&lt;span class="lnt">229
&lt;/span>&lt;span class="lnt">230
&lt;/span>&lt;span class="lnt">231
&lt;/span>&lt;span class="lnt">232
&lt;/span>&lt;span class="lnt">233
&lt;/span>&lt;span class="lnt">234
&lt;/span>&lt;span class="lnt">235
&lt;/span>&lt;span class="lnt">236
&lt;/span>&lt;span class="lnt">237
&lt;/span>&lt;span class="lnt">238
&lt;/span>&lt;span class="lnt">239
&lt;/span>&lt;span class="lnt">240
&lt;/span>&lt;span class="lnt">241
&lt;/span>&lt;span class="lnt">242
&lt;/span>&lt;span class="lnt">243
&lt;/span>&lt;span class="lnt">244
&lt;/span>&lt;span class="lnt">245
&lt;/span>&lt;span class="lnt">246
&lt;/span>&lt;span class="lnt">247
&lt;/span>&lt;span class="lnt">248
&lt;/span>&lt;span class="lnt">249
&lt;/span>&lt;span class="lnt">250
&lt;/span>&lt;span class="lnt">251
&lt;/span>&lt;span class="lnt">252
&lt;/span>&lt;span class="lnt">253
&lt;/span>&lt;span class="lnt">254
&lt;/span>&lt;span class="lnt">255
&lt;/span>&lt;span class="lnt">256
&lt;/span>&lt;span class="lnt">257
&lt;/span>&lt;span class="lnt">258
&lt;/span>&lt;span class="lnt">259
&lt;/span>&lt;span class="lnt">260
&lt;/span>&lt;span class="lnt">261
&lt;/span>&lt;span class="lnt">262
&lt;/span>&lt;span class="lnt">263
&lt;/span>&lt;span class="lnt">264
&lt;/span>&lt;span class="lnt">265
&lt;/span>&lt;span class="lnt">266
&lt;/span>&lt;span class="lnt">267
&lt;/span>&lt;span class="lnt">268
&lt;/span>&lt;span class="lnt">269
&lt;/span>&lt;span class="lnt">270
&lt;/span>&lt;span class="lnt">271
&lt;/span>&lt;span class="lnt">272
&lt;/span>&lt;span class="lnt">273
&lt;/span>&lt;span class="lnt">274
&lt;/span>&lt;span class="lnt">275
&lt;/span>&lt;span class="lnt">276
&lt;/span>&lt;span class="lnt">277
&lt;/span>&lt;span class="lnt">278
&lt;/span>&lt;span class="lnt">279
&lt;/span>&lt;span class="lnt">280
&lt;/span>&lt;span class="lnt">281
&lt;/span>&lt;span class="lnt">282
&lt;/span>&lt;span class="lnt">283
&lt;/span>&lt;span class="lnt">284
&lt;/span>&lt;span class="lnt">285
&lt;/span>&lt;span class="lnt">286
&lt;/span>&lt;span class="lnt">287
&lt;/span>&lt;span class="lnt">288
&lt;/span>&lt;span class="lnt">289
&lt;/span>&lt;span class="lnt">290
&lt;/span>&lt;span class="lnt">291
&lt;/span>&lt;span class="lnt">292
&lt;/span>&lt;span class="lnt">293
&lt;/span>&lt;span class="lnt">294
&lt;/span>&lt;span class="lnt">295
&lt;/span>&lt;span class="lnt">296
&lt;/span>&lt;span class="lnt">297
&lt;/span>&lt;span class="lnt">298
&lt;/span>&lt;span class="lnt">299
&lt;/span>&lt;span class="lnt">300
&lt;/span>&lt;span class="lnt">301
&lt;/span>&lt;span class="lnt">302
&lt;/span>&lt;span class="lnt">303
&lt;/span>&lt;span class="lnt">304
&lt;/span>&lt;span class="lnt">305
&lt;/span>&lt;span class="lnt">306
&lt;/span>&lt;span class="lnt">307
&lt;/span>&lt;span class="lnt">308
&lt;/span>&lt;span class="lnt">309
&lt;/span>&lt;span class="lnt">310
&lt;/span>&lt;span class="lnt">311
&lt;/span>&lt;span class="lnt">312
&lt;/span>&lt;span class="lnt">313
&lt;/span>&lt;span class="lnt">314
&lt;/span>&lt;span class="lnt">315
&lt;/span>&lt;span class="lnt">316
&lt;/span>&lt;span class="lnt">317
&lt;/span>&lt;span class="lnt">318
&lt;/span>&lt;span class="lnt">319
&lt;/span>&lt;span class="lnt">320
&lt;/span>&lt;span class="lnt">321
&lt;/span>&lt;span class="lnt">322
&lt;/span>&lt;span class="lnt">323
&lt;/span>&lt;span class="lnt">324
&lt;/span>&lt;span class="lnt">325
&lt;/span>&lt;span class="lnt">326
&lt;/span>&lt;span class="lnt">327
&lt;/span>&lt;span class="lnt">328
&lt;/span>&lt;span class="lnt">329
&lt;/span>&lt;span class="lnt">330
&lt;/span>&lt;span class="lnt">331
&lt;/span>&lt;span class="lnt">332
&lt;/span>&lt;span class="lnt">333
&lt;/span>&lt;span class="lnt">334
&lt;/span>&lt;span class="lnt">335
&lt;/span>&lt;span class="lnt">336
&lt;/span>&lt;span class="lnt">337
&lt;/span>&lt;span class="lnt">338
&lt;/span>&lt;span class="lnt">339
&lt;/span>&lt;span class="lnt">340
&lt;/span>&lt;span class="lnt">341
&lt;/span>&lt;span class="lnt">342
&lt;/span>&lt;span class="lnt">343
&lt;/span>&lt;span class="lnt">344
&lt;/span>&lt;span class="lnt">345
&lt;/span>&lt;span class="lnt">346
&lt;/span>&lt;span class="lnt">347
&lt;/span>&lt;span class="lnt">348
&lt;/span>&lt;span class="lnt">349
&lt;/span>&lt;span class="lnt">350
&lt;/span>&lt;span class="lnt">351
&lt;/span>&lt;span class="lnt">352
&lt;/span>&lt;span class="lnt">353
&lt;/span>&lt;span class="lnt">354
&lt;/span>&lt;span class="lnt">355
&lt;/span>&lt;span class="lnt">356
&lt;/span>&lt;span class="lnt">357
&lt;/span>&lt;span class="lnt">358
&lt;/span>&lt;span class="lnt">359
&lt;/span>&lt;span class="lnt">360
&lt;/span>&lt;span class="lnt">361
&lt;/span>&lt;span class="lnt">362
&lt;/span>&lt;span class="lnt">363
&lt;/span>&lt;span class="lnt">364
&lt;/span>&lt;span class="lnt">365
&lt;/span>&lt;span class="lnt">366
&lt;/span>&lt;span class="lnt">367
&lt;/span>&lt;span class="lnt">368
&lt;/span>&lt;span class="lnt">369
&lt;/span>&lt;span class="lnt">370
&lt;/span>&lt;span class="lnt">371
&lt;/span>&lt;span class="lnt">372
&lt;/span>&lt;span class="lnt">373
&lt;/span>&lt;span class="lnt">374
&lt;/span>&lt;span class="lnt">375
&lt;/span>&lt;span class="lnt">376
&lt;/span>&lt;span class="lnt">377
&lt;/span>&lt;span class="lnt">378
&lt;/span>&lt;span class="lnt">379
&lt;/span>&lt;span class="lnt">380
&lt;/span>&lt;span class="lnt">381
&lt;/span>&lt;span class="lnt">382
&lt;/span>&lt;span class="lnt">383
&lt;/span>&lt;span class="lnt">384
&lt;/span>&lt;span class="lnt">385
&lt;/span>&lt;span class="lnt">386
&lt;/span>&lt;span class="lnt">387
&lt;/span>&lt;span class="lnt">388
&lt;/span>&lt;span class="lnt">389
&lt;/span>&lt;span class="lnt">390
&lt;/span>&lt;span class="lnt">391
&lt;/span>&lt;span class="lnt">392
&lt;/span>&lt;span class="lnt">393
&lt;/span>&lt;span class="lnt">394
&lt;/span>&lt;span class="lnt">395
&lt;/span>&lt;span class="lnt">396
&lt;/span>&lt;span class="lnt">397
&lt;/span>&lt;span class="lnt">398
&lt;/span>&lt;span class="lnt">399
&lt;/span>&lt;span class="lnt">400
&lt;/span>&lt;span class="lnt">401
&lt;/span>&lt;span class="lnt">402
&lt;/span>&lt;span class="lnt">403
&lt;/span>&lt;span class="lnt">404
&lt;/span>&lt;span class="lnt">405
&lt;/span>&lt;span class="lnt">406
&lt;/span>&lt;span class="lnt">407
&lt;/span>&lt;span class="lnt">408
&lt;/span>&lt;span class="lnt">409
&lt;/span>&lt;span class="lnt">410
&lt;/span>&lt;span class="lnt">411
&lt;/span>&lt;span class="lnt">412
&lt;/span>&lt;span class="lnt">413
&lt;/span>&lt;span class="lnt">414
&lt;/span>&lt;span class="lnt">415
&lt;/span>&lt;span class="lnt">416
&lt;/span>&lt;span class="lnt">417
&lt;/span>&lt;span class="lnt">418
&lt;/span>&lt;span class="lnt">419
&lt;/span>&lt;span class="lnt">420
&lt;/span>&lt;span class="lnt">421
&lt;/span>&lt;span class="lnt">422
&lt;/span>&lt;span class="lnt">423
&lt;/span>&lt;span class="lnt">424
&lt;/span>&lt;span class="lnt">425
&lt;/span>&lt;span class="lnt">426
&lt;/span>&lt;span class="lnt">427
&lt;/span>&lt;span class="lnt">428
&lt;/span>&lt;span class="lnt">429
&lt;/span>&lt;span class="lnt">430
&lt;/span>&lt;span class="lnt">431
&lt;/span>&lt;span class="lnt">432
&lt;/span>&lt;span class="lnt">433
&lt;/span>&lt;span class="lnt">434
&lt;/span>&lt;span class="lnt">435
&lt;/span>&lt;span class="lnt">436
&lt;/span>&lt;span class="lnt">437
&lt;/span>&lt;span class="lnt">438
&lt;/span>&lt;span class="lnt">439
&lt;/span>&lt;span class="lnt">440
&lt;/span>&lt;span class="lnt">441
&lt;/span>&lt;span class="lnt">442
&lt;/span>&lt;span class="lnt">443
&lt;/span>&lt;span class="lnt">444
&lt;/span>&lt;span class="lnt">445
&lt;/span>&lt;span class="lnt">446
&lt;/span>&lt;span class="lnt">447
&lt;/span>&lt;span class="lnt">448
&lt;/span>&lt;span class="lnt">449
&lt;/span>&lt;span class="lnt">450
&lt;/span>&lt;span class="lnt">451
&lt;/span>&lt;span class="lnt">452
&lt;/span>&lt;span class="lnt">453
&lt;/span>&lt;span class="lnt">454
&lt;/span>&lt;span class="lnt">455
&lt;/span>&lt;span class="lnt">456
&lt;/span>&lt;span class="lnt">457
&lt;/span>&lt;span class="lnt">458
&lt;/span>&lt;span class="lnt">459
&lt;/span>&lt;span class="lnt">460
&lt;/span>&lt;span class="lnt">461
&lt;/span>&lt;span class="lnt">462
&lt;/span>&lt;span class="lnt">463
&lt;/span>&lt;span class="lnt">464
&lt;/span>&lt;span class="lnt">465
&lt;/span>&lt;span class="lnt">466
&lt;/span>&lt;span class="lnt">467
&lt;/span>&lt;span class="lnt">468
&lt;/span>&lt;span class="lnt">469
&lt;/span>&lt;span class="lnt">470
&lt;/span>&lt;span class="lnt">471
&lt;/span>&lt;span class="lnt">472
&lt;/span>&lt;span class="lnt">473
&lt;/span>&lt;span class="lnt">474
&lt;/span>&lt;span class="lnt">475
&lt;/span>&lt;span class="lnt">476
&lt;/span>&lt;span class="lnt">477
&lt;/span>&lt;span class="lnt">478
&lt;/span>&lt;span class="lnt">479
&lt;/span>&lt;span class="lnt">480
&lt;/span>&lt;span class="lnt">481
&lt;/span>&lt;span class="lnt">482
&lt;/span>&lt;span class="lnt">483
&lt;/span>&lt;span class="lnt">484
&lt;/span>&lt;span class="lnt">485
&lt;/span>&lt;span class="lnt">486
&lt;/span>&lt;span class="lnt">487
&lt;/span>&lt;span class="lnt">488
&lt;/span>&lt;span class="lnt">489
&lt;/span>&lt;span class="lnt">490
&lt;/span>&lt;span class="lnt">491
&lt;/span>&lt;span class="lnt">492
&lt;/span>&lt;span class="lnt">493
&lt;/span>&lt;span class="lnt">494
&lt;/span>&lt;span class="lnt">495
&lt;/span>&lt;span class="lnt">496
&lt;/span>&lt;span class="lnt">497
&lt;/span>&lt;span class="lnt">498
&lt;/span>&lt;span class="lnt">499
&lt;/span>&lt;span class="lnt">500
&lt;/span>&lt;span class="lnt">501
&lt;/span>&lt;span class="lnt">502
&lt;/span>&lt;span class="lnt">503
&lt;/span>&lt;span class="lnt">504
&lt;/span>&lt;span class="lnt">505
&lt;/span>&lt;span class="lnt">506
&lt;/span>&lt;span class="lnt">507
&lt;/span>&lt;span class="lnt">508
&lt;/span>&lt;span class="lnt">509
&lt;/span>&lt;span class="lnt">510
&lt;/span>&lt;span class="lnt">511
&lt;/span>&lt;span class="lnt">512
&lt;/span>&lt;span class="lnt">513
&lt;/span>&lt;span class="lnt">514
&lt;/span>&lt;span class="lnt">515
&lt;/span>&lt;span class="lnt">516
&lt;/span>&lt;span class="lnt">517
&lt;/span>&lt;span class="lnt">518
&lt;/span>&lt;span class="lnt">519
&lt;/span>&lt;span class="lnt">520
&lt;/span>&lt;span class="lnt">521
&lt;/span>&lt;span class="lnt">522
&lt;/span>&lt;span class="lnt">523
&lt;/span>&lt;span class="lnt">524
&lt;/span>&lt;span class="lnt">525
&lt;/span>&lt;span class="lnt">526
&lt;/span>&lt;span class="lnt">527
&lt;/span>&lt;span class="lnt">528
&lt;/span>&lt;span class="lnt">529
&lt;/span>&lt;span class="lnt">530
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">RecursiveCharacterTextSplitter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">TextSplitter&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Splitting text by recursively look at characters.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Recursively tries to split by different characters to find one
&lt;/span>&lt;span class="s2"> that works.
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">separators&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">keep_separator&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">is_separator_regex&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Create a new TextSplitter.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="nb">super&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">keep_separator&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">keep_separator&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_separators&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">separators&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_is_separator_regex&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">is_separator_regex&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">_split_text&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">separators&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Split incoming text and return chunks.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">final_chunks&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="c1"># Get appropriate separator to use&lt;/span>
&lt;span class="n">separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">separators&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">new_separators&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_s&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">separators&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">_separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">_s&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_is_separator_regex&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="n">re&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">escape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_s&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">_s&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">_s&lt;/span>
&lt;span class="k">break&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">re&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">search&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_separator&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">_s&lt;/span>
&lt;span class="n">new_separators&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">separators&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="p">:]&lt;/span>
&lt;span class="k">break&lt;/span>
&lt;span class="n">_separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">separator&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_is_separator_regex&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="n">re&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">escape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">separator&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">splits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">_split_text_with_regex&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_separator&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_keep_separator&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Now go merging things, recursively splitting longer texts.&lt;/span>
&lt;span class="n">_good_splits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="n">_separator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_keep_separator&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="n">separator&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">s&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">splits&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_length_function&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_chunk_size&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_good_splits&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">_good_splits&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">merged_text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_merge_splits&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_good_splits&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_separator&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">final_chunks&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extend&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">merged_text&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">_good_splits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">new_separators&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">final_chunks&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">other_info&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_split_text&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">new_separators&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">final_chunks&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extend&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">other_info&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">_good_splits&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">merged_text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_merge_splits&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_good_splits&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_separator&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">final_chunks&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extend&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">merged_text&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">final_chunks&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">split_text&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_split_text&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_separators&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nd">@classmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">from_language&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">cls&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">language&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Any&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">RecursiveCharacterTextSplitter&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">separators&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">cls&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_separators_for_language&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">language&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">cls&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">separators&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">separators&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">is_separator_regex&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nd">@staticmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">get_separators_for_language&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">language&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CPP&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">void &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">int &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">float &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">double &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GO&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">func &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">var &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">const &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">type &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">JAVA&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">public &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">protected &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">private &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">static &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">KOTLIN&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">public &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">protected &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">private &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">internal &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">companion &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">fun &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">val &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">var &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">when &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">else &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">JS&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">function &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">const &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">let &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">var &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">default &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TS&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">enum &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">interface &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">namespace &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">type &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">function &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">const &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">let &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">var &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">default &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PHP&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">function &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">foreach &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">do &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PROTO&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along message definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">message &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along service definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">service &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along enum definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">enum &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along option definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">option &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along import statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">import &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along syntax declarations&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">syntax &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PYTHON&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># First, try to split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">def &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\t&lt;/span>&lt;span class="s2">def &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Now split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RST&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along section titles&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">=+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">-+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\&lt;/span>&lt;span class="s2">*+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along directive markers&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">.. *&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RUBY&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">def &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">unless &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">do &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">begin &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">rescue &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RUST&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">fn &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">const &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">let &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">loop &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">match &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">const &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SCALA&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">object &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">def &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">val &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">var &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">match &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SWIFT&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along function definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">func &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">struct &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">enum &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">do &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MARKDOWN&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># First, try to split along Markdown headings (starting with level 2)&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">#{1,6} &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Note the alternative syntax for headings (below) is not handled here&lt;/span>
&lt;span class="c1"># Heading level 2&lt;/span>
&lt;span class="c1"># ---------------&lt;/span>
&lt;span class="c1"># End of code block&lt;/span>
&lt;span class="s2">&amp;#34;```&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Horizontal lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\&lt;/span>&lt;span class="s2">*&lt;/span>&lt;span class="se">\\&lt;/span>&lt;span class="s2">*&lt;/span>&lt;span class="se">\\&lt;/span>&lt;span class="s2">*+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">---+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">___+&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Note that this splitter doesn&amp;#39;t handle horizontal lines defined&lt;/span>
&lt;span class="c1"># by *three or more* of ***, ---, or ___, but this is not handled&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">LATEX&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># First, try to split along Latex sections&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">chapter{&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">section{&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">subsection{&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">subsubsection{&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Now split by environments&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{enumerate}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{itemize}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{description}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{list}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{quote}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{quotation}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{verse}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\\&lt;/span>&lt;span class="s2">begin{verbatim}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Now split by math environments&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\\\b&lt;/span>&lt;span class="s2">egin{align}&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;$$&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;$&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Now split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">HTML&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># First, try to split along HTML tags&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;body&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;div&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;p&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;br&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;li&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h1&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h2&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h3&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h4&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h5&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;h6&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;span&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;table&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;tr&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;td&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;th&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;ul&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;ol&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;header&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;footer&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;nav&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Head&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;head&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;style&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;script&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;meta&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;title&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CSHARP&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">interface &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">enum &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">implements &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">delegate &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">event &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along class definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">class &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">abstract &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">public &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">protected &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">private &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">static &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">return &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">continue &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">foreach &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">switch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">break &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">case &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">else &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by exceptions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">try &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">throw &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">finally &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">catch &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SOL&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along compiler information definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">pragma &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">using &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along contract definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">contract &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">interface &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">library &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along method definitions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">constructor &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">type &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">function &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">event &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">modifier &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">error &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">struct &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">enum &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along control flow statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">if &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">for &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">do while &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">assembly &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">elif&lt;/span> &lt;span class="n">language&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">Language&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">COBOL&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="c1"># Split along divisions&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">IDENTIFICATION DIVISION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">ENVIRONMENT DIVISION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">DATA DIVISION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">PROCEDURE DIVISION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along sections within DATA DIVISION&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">WORKING-STORAGE SECTION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">LINKAGE SECTION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">FILE SECTION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along sections within PROCEDURE DIVISION&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">INPUT-OUTPUT SECTION.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split along paragraphs and common statements&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">OPEN &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">CLOSE &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">READ &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">WRITE &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">IF &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">ELSE &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">MOVE &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">PERFORM &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">UNTIL &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">VARYING &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">ACCEPT &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">DISPLAY &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">STOP RUN.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="c1"># Split by the normal type of lines&lt;/span>
&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">ValueError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Language {language} is not supported! &amp;#34;&lt;/span>
&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;Please choose from {list(Language)}&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2代码示例-3">(2)代码示例&lt;/h3>
&lt;ul>
&lt;li>使用&lt;code>RecursiveCharacterTextSplitter&lt;/code>，定义好块的大小、切割重合度等参数，得到切分后的texts对象。&lt;/li>
&lt;li>texts对象就是将文档切分后的文本块集合。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231023063036651.png" alt="image-20231023063036651">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231023063047761.png" alt="image-20231023063047761">&lt;/p>
&lt;h1 id="4文档向量化">4.文档向量化&lt;/h1>
&lt;h2 id="41基本概念">4.1.基本概念&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>当我们获得了文本块以后，就需要将其向量化并持久化下来。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LangChain提供的词嵌入模型(&lt;code>Text Embedding Models&lt;/code>)，支持丰富的词嵌入模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>LangChain提供的向量存储器(&lt;code>Vector Stores&lt;/code>)，支持丰富的向量数据库。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这部分也是LangChain很强大的特性之一，几乎覆盖了世界上所有&lt;strong>主流的词嵌入模型&lt;/strong>和&lt;strong>主流的向量数据库&lt;/strong>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>词嵌入模型列表：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031082141950.png" alt="image-20231031082141950">&lt;/p>
&lt;ul>
&lt;li>向量数据库列表：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031073927426.png" alt="image-20231031073927426">&lt;/p>
&lt;h2 id="42代码示例">4.2.代码示例&lt;/h2>
&lt;ul>
&lt;li>以OpenAI的词嵌入模型为例，展示了如何使用LangChain的词嵌入模型。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231023065210069.png" alt="image-20231023065210069">&lt;/p>
&lt;h1 id="5检索器">5.检索器&lt;/h1>
&lt;h2 id="1基本概念">(1)基本概念&lt;/h2>
&lt;ul>
&lt;li>LangChain提供的检索器(&lt;code>Retrieves&lt;/code>)，支持丰富的检索能力。&lt;/li>
&lt;li>基础的，基于向量数据库的检索器如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031082838616.png" alt="image-20231031082838616">&lt;/p>
&lt;ul>
&lt;li>高级的(如：云原生)，基于云原生的检索器如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231031083352096.png" alt="image-20231031083352096">&lt;/p>
&lt;h2 id="2代码示例-4">(2)代码示例&lt;/h2>
&lt;ul>
&lt;li>如下代码演示了&lt;code>similarity_search&lt;/code>方法的使用：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-LangChain%E4%B9%8BRetrieval%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A14/image-20231023065351312.png" alt="image-20231023065351312">&lt;/p>
&lt;h1 id="6小结">6.小结&lt;/h1>
&lt;ul>
&lt;li>LangChain的&lt;code>Retrieval&lt;/code>特性的整体流程是：文档加载-&amp;gt;文档转换-&amp;gt;文档向量化-&amp;gt;数据检索&lt;/li>
&lt;li>文档加载器支持各类数据格式，各类数据源，实战时需熟悉各类文档加载器。&lt;/li>
&lt;li>文档转换器支持各类文本分割策略，实战时需熟悉各类文档分割策略。&lt;/li>
&lt;li>文档向量化时，有多种词嵌入模型，有多种向量数据库，实战时也需要熟练掌握。&lt;/li>
&lt;li>文档检索时，支持多种文档检索策略，实战时需熟练掌握。&lt;/li>
&lt;/ul>
&lt;p>下一篇，我们对LangChain最火的模块Agents进行探索，下篇见！&lt;/p></description></item><item><title>【chatGPT】学习笔记20-如何搭建ChatGLM3</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAchatglm3/</link><pubDate>Sun, 29 Oct 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAchatglm3/</guid><description>&lt;h1 id="1chatglm3更新了什么">1.ChatGLM3更新了什么&lt;/h1>
&lt;h2 id="1模型列表">(1)模型列表&lt;/h2>
&lt;p>智谱AI刚刚发布了ChatGLM3，其中&lt;strong>ChatGLM3-6B&lt;/strong>的能力提升如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>更强大的基础模型&lt;/strong>： 采用了更多样的训练数据、更充分的训练步数和更合理的训练策略。在语义、数学、推理、代码、知识等不同角度的数据集上表现更好。&lt;/li>
&lt;li>&lt;strong>更完整的功能支持&lt;/strong>：重新设计了Prompt模版格式，支持&lt;code>Function Call&lt;/code>、&lt;code>Code Interpreter&lt;/code>、&lt;code>Agent&lt;/code>。&lt;/li>
&lt;/ul>
&lt;p>除了ChatGLM3-6B，还发布了：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>ChatGLM3-6B-Base&lt;/strong>：它是ChatGLM3-6B的预训练模型，在10B以下的表现同比更好。&lt;/li>
&lt;li>&lt;strong>ChatGLM3-6B-32K&lt;/strong>：适用于长文本对话场景。&lt;/li>
&lt;/ul>
&lt;p>ChatGLM3发布的&lt;strong>模型列表&lt;/strong>如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Model&lt;/th>
&lt;th>Seq Length&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ChatGLM3-6B&lt;/td>
&lt;td>8k&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ChatGLM3-6B-Base&lt;/td>
&lt;td>8k&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ChatGLM3-6B-32K&lt;/td>
&lt;td>32k&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="2测评结果">(2)测评结果&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>典型数据集测试&lt;/strong>：在8个中英文典型数据集上，ChatGLM3-6B-Base的性能表现如下：
&lt;ul>
&lt;li>&lt;strong>测试方法&lt;/strong>：BBH 采用3-shot测试，GSM8K(需要推理)采用0-shot CoT测试、MATH(需要推理)采用0-shot CoT测试，MBPP 采用0-shot生成后运行测例计算 Pass@1 ，其它选择题类型数据集均采用0-shot测试。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Model&lt;/th>
&lt;th>GSM8K&lt;/th>
&lt;th>MATH&lt;/th>
&lt;th>BBH&lt;/th>
&lt;th>MMLU&lt;/th>
&lt;th>C-Eval&lt;/th>
&lt;th>CMMLU&lt;/th>
&lt;th>MBPP&lt;/th>
&lt;th>AGIEval&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ChatGLM2-6B-Base&lt;/td>
&lt;td>32.4&lt;/td>
&lt;td>6.5&lt;/td>
&lt;td>33.7&lt;/td>
&lt;td>47.9&lt;/td>
&lt;td>51.7&lt;/td>
&lt;td>50.0&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Best Baseline&lt;/td>
&lt;td>52.1&lt;/td>
&lt;td>13.1&lt;/td>
&lt;td>45.0&lt;/td>
&lt;td>60.1&lt;/td>
&lt;td>63.5&lt;/td>
&lt;td>62.2&lt;/td>
&lt;td>47.5&lt;/td>
&lt;td>45.8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ChatGLM3-6B-Base&lt;/td>
&lt;td>72.3&lt;/td>
&lt;td>25.7&lt;/td>
&lt;td>66.1&lt;/td>
&lt;td>61.4&lt;/td>
&lt;td>69.0&lt;/td>
&lt;td>67.5&lt;/td>
&lt;td>52.4&lt;/td>
&lt;td>53.7&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>&lt;strong>长文本测试&lt;/strong>：进行人工评估测试，ChatGLM3-6B-32K的性能表现如下。
&lt;ul>
&lt;li>&lt;strong>测试结论&lt;/strong>：与ChatGLM2相比，效果提升超50%(对论文阅读、文档摘要和财报分析等提升显著)。&lt;/li>
&lt;li>&lt;strong>测试方法&lt;/strong>：在LongBench评测集上进行。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Model&lt;/th>
&lt;th>平均&lt;/th>
&lt;th>Summary&lt;/th>
&lt;th>Single-Doc QA&lt;/th>
&lt;th>Multi-Doc QA&lt;/th>
&lt;th>Code&lt;/th>
&lt;th>Few-shot&lt;/th>
&lt;th>Synthetic&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ChatGLM2-6B-32K&lt;/td>
&lt;td>41.5&lt;/td>
&lt;td>24.8&lt;/td>
&lt;td>37.6&lt;/td>
&lt;td>34.7&lt;/td>
&lt;td>52.8&lt;/td>
&lt;td>51.3&lt;/td>
&lt;td>47.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ChatGLM3-6B-32K&lt;/td>
&lt;td>50.2&lt;/td>
&lt;td>26.6&lt;/td>
&lt;td>45.8&lt;/td>
&lt;td>46.1&lt;/td>
&lt;td>56.2&lt;/td>
&lt;td>61.2&lt;/td>
&lt;td>65&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="2准备硬件资源及基础软件">2.准备硬件资源及基础软件&lt;/h1>
&lt;p>笔者准备的硬件资源及基础软件如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>GPU&lt;/strong>：V100，32G显存，避免OOM问题。&lt;/li>
&lt;li>&lt;strong>CUDA&lt;/strong>：Cuda11.6&lt;/li>
&lt;li>&lt;strong>OS&lt;/strong>：Ubuntu22.04&lt;/li>
&lt;li>&lt;strong>Conda&lt;/strong>：Miniconda3&lt;/li>
&lt;li>&lt;strong>Python&lt;/strong>：Python3.10&lt;/li>
&lt;li>&lt;strong>Pytorch&lt;/strong>：Pytorch3.8&lt;/li>
&lt;/ul>
&lt;h1 id="3创建虚拟环境">3.创建虚拟环境&lt;/h1>
&lt;ul>
&lt;li>创建虚拟环境：&lt;code>conda create -p ./envs/HCZ_ChatGLM2 python=3.10&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030003623799.png" alt="image-20231030003623799">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>激活虚拟环境&lt;/strong>：&lt;code>conda activate ./envs/HCZ_ChatGLM3&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030003931661.png" alt="image-20231030003931661">&lt;/p>
&lt;h1 id="4上传模型及模型容器">4.上传模型及模型容器&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>chatglm3-6b下载地址&lt;/strong>：https://huggingface.co/THUDM/chatglm3-6b&lt;/li>
&lt;li>&lt;strong>chatglm3-6b容器下载地址&lt;/strong>：https://github.com/THUDM/ChatGLM3/archive/refs/heads/main.zip&lt;/li>
&lt;li>下载完成后，&lt;strong>上传到服务器&lt;/strong>，如下图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030071806371.png" alt="image-20231030071806371">&lt;/p>
&lt;h1 id="5安装依赖包">5.安装依赖包&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>进入容器目录&lt;/strong>：&lt;code>cd /opt/model/THUDM_chatglm3-6b-container&lt;/code>&lt;/li>
&lt;li>&lt;strong>安装依赖包&lt;/strong>：&lt;code>pip install -r requirements.txt&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030071933817.png" alt="image-20231030071933817">&lt;/p>
&lt;h1 id="6构建restful接口">6.构建Restful接口&lt;/h1>
&lt;ul>
&lt;li>借鉴ChatGLM2的&lt;code>api.py&lt;/code>，具体代码如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030074839307.png" alt="image-20231030074839307">&lt;/p>
&lt;h1 id="7运行chatglm3服务">7.运行ChatGLM3服务&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>进入容器目录&lt;/strong>：&lt;code>cd /opt/model/THUDM_chatglm3-6b-container&lt;/code>&lt;/li>
&lt;li>&lt;strong>运行服务&lt;/strong>：&lt;code>python api.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030075223648.png" alt="image-20231030075223648">&lt;/p>
&lt;h1 id="8测试">8.测试&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>向ChatGLM3提问&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030083402685.png" alt="image-20231030083402685">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>服务器端运行日志如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAChatGLM3/image-20231030083320605.png" alt="image-20231030083320605">&lt;/p>
&lt;h1 id="9小结">9.小结&lt;/h1>
&lt;ul>
&lt;li>本文阐述了ChatGLM3的官宣能力，并演示了如何搭建自己的ChatGLM3。&lt;/li>
&lt;li>ChatGLM3的新能力有待进一步集成到产品中进行验证。&lt;/li>
&lt;/ul></description></item><item><title>【chatGPT】学习笔记19-自己实现一个简版ChatGPT(下)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%8B/</link><pubDate>Fri, 20 Oct 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%8B/</guid><description>&lt;p>前两篇实现了简版GPT，并对其进行了SFT，我们接下来看ChatGPT整体训练流程的最后一个环节——&lt;strong>对齐训练(Alignment Training)&lt;/strong>。&lt;/p>
&lt;h1 id="1方法3对齐训练alignment-training">1.方法3：对齐训练(Alignment Training)&lt;/h1>
&lt;h2 id="1与chatgpt整体训练流程图的对应关系">(1)与ChatGPT整体训练流程图的对应关系&lt;/h2>
&lt;ul>
&lt;li>方法3对应于&lt;strong>ChatGPT整体训练流程的STEP2、STEP3&lt;/strong>。&lt;/li>
&lt;li>方法3的核心思想是利用了强化学习，最终将GPT3演进为了&lt;strong>更通人性的ChatGPT&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020062050959.png" alt="image-20231020062050959">&lt;/p>
&lt;ul>
&lt;li>ChatGPT整体训练流程中的&lt;strong>STEP2、STEP3&lt;/strong>，就是大名鼎鼎的&lt;strong>RLHF&lt;/strong>——&lt;strong>基于人类反馈的强化学习&lt;/strong>。
&lt;ul>
&lt;li>&lt;strong>RL：Reinforcement Learning&lt;/strong>&lt;/li>
&lt;li>&lt;strong>HF：Human Feedback&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>ChatGPT整体训练流程中的&lt;strong>STEP2&lt;/strong>，&lt;strong>对应于&lt;/strong>强化学习模型的&lt;strong>Interpreter模型&lt;/strong>。&lt;/li>
&lt;li>ChatGPT整体训练流程中的&lt;strong>STEP3&lt;/strong>，&lt;strong>对应于&lt;/strong>强化学习模型的&lt;strong>Action模型&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020085551189.png" alt="image-20231020085551189">&lt;/p>
&lt;h2 id="2什么是对齐训练">(2)什么是对齐训练&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>对齐训练&lt;/strong>：Alignment Training，它就是一种机器学习的模型训练方法。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>核心思想&lt;/strong>：训练出人类主观感受的模型，这个模型具备预测人类的决策的能力。&lt;/p>
&lt;ul>
&lt;li>这样，训练好的模型，就可以在未见过的场景下，按照类似人的行为模式做出选择。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>对齐训练与强化学习的关系&lt;/strong>：OpenAI在对齐训练中，结合了强化学习。&lt;/p>
&lt;ul>
&lt;li>ChatGPT整体训练流程的STEP2就是对齐训练，学习出预测人类回答问题的偏好模型。&lt;/li>
&lt;li>ChatGPT整体训练流程的STEP3就是强化学习，STEP2输出的这个模型，作为强化学习的Interpreter模型。STEP3不断迭代，最终学习到Action模型。
&lt;ul>
&lt;li>通过SFT训练之后GPT3，本质就是一个能机械式地回答问题的机器人。&lt;/li>
&lt;li>通过RLHF学习的Action模型，才是帮助SFT之后的GPT3，类似人类回答问题的关键机关。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>细节&lt;/strong>：ChatGPT整体训练流程图中，出现了PPO算法，PPO算法是近端策略梯度优化，增加一个限制Action模型在训练过程中梯度上升速度，本质就是避免Action模型产生一个离谱的Action。&lt;/p>
&lt;ul>
&lt;li>PPO算法展开说内容太多，本文不赘述，详见论文：https://arxiv.org/abs/1707.06347&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="3step2的reward-model模型训练伪码">(3)STEP2的Reward Model模型训练伪码&lt;/h2>
&lt;ul>
&lt;li>我们再来看看STEP2的伪码，如下图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020093407332.png" alt="image-20231020093407332">&lt;/p>
&lt;h2 id="4step3的rlhf训练伪码">(4)STEP3的RLHF训练伪码&lt;/h2>
&lt;ul>
&lt;li>我们再来看看STEP3的伪码，如下图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020095154134.png" alt="image-20231020095154134">&lt;/p>
&lt;h1 id="2deepspeed">2.DeepSpeed&lt;/h1>
&lt;p>RLHF，是ChatGPT最核心的技术机密，除了在《Introducing ChatGPT》(&lt;a href="https://openai.com/blog/chatgpt">https://openai.com/blog/chatgpt&lt;/a>)中提到了，并未公开过源码。&lt;/p>
&lt;p>在前文的伪码实现部分，虽然通过伪码描述了RLHF的核心逻辑，但距离商用还欠缺很多东西(如：分布式训练等)。&lt;/p>
&lt;p>幸好微软开源了类似的框架，DeepSpeed，我们可以通过阅读它的源码、使用它，开展RLHF。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020100752488.png" alt="image-20231020100752488">&lt;/p>
&lt;h1 id="3实例-开展rlhf训练">3.实例-开展RLHF训练&lt;/h1>
&lt;h2 id="step0前置准备">STEP0.前置准备&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>硬件&lt;/strong>：V100一块，32G显存&lt;/li>
&lt;li>&lt;strong>基础软件&lt;/strong>：Ubuntun20.04，Minicoda3，Pytorch3.8，CUDA11.6，Python3.10&lt;/li>
&lt;li>&lt;strong>预训练模型&lt;/strong>：选择Facebook的opt1.3B，即&lt;strong>13亿参数&lt;/strong>的预训练模型。&lt;/li>
&lt;li>&lt;strong>环境初始配置&lt;/strong>：创建虚拟环境，&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020102932305.png" alt="image-20231020102932305">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>安装依赖&lt;/strong>：进入DeepSpeed-Chat目录，安装相关依赖&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020103116451.png" alt="image-20231020103116451">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>环境测试&lt;/strong>：确认相关基础软件版本号。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020103548543.png" alt="image-20231020103548543">&lt;/p>
&lt;h2 id="step1sft">STEP1.SFT&lt;/h2>
&lt;ul>
&lt;li>开展SFT训练时，由于服务器资源不足(省钱)，需要避免OOM异常，因此需要修改一下训练脚本。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>路径：training/step1_supervised_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020104103388.png" alt="image-20231020104103388">&lt;/p>
&lt;ul>
&lt;li>设置待微调的预训练模型，以及输出路径。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>路径：training/step1_supervised_finetuning/evaluation_scripts/run_prompt.sh&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020110616405.png" alt="image-20231020110616405">&lt;/p>
&lt;ul>
&lt;li>执行训练脚本run_1.3b.sh，触发DeepSpeed开始SFT训练。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=959965022&amp;bvid=BV1Hp4y1M7Ly&amp;cid=1305868791&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;h2 id="step2rm">STEP2.RM&lt;/h2>
&lt;ul>
&lt;li>开展RM训练时，由于服务器资源不足(省钱)，需要避免OOM异常，因此需要修改一下训练脚本。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>路径：training_scripts/opt/single_gpu/run_350m.sh&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020145149415.png" alt="image-20231020145149415">&lt;/p>
&lt;ul>
&lt;li>指定Reward Model的输出路径。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>路径：evaluation_scripts/run_eval.sh&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020145843742.png" alt="image-20231020145843742">&lt;/p>
&lt;ul>
&lt;li>执行训练脚本run_350m.sh，触发DeepSpeed开始RW训练。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=534943541&amp;bvid=BV1gM411R7Z5&amp;cid=1305868897&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;h2 id="step3rlhf">STEP3.RLHF&lt;/h2>
&lt;ul>
&lt;li>开展RLHF训练时，由于服务器资源不足(省钱)，需要避免OOM异常，因此需要修改一下训练脚本。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>training_scripts/opt/single_gpu/run_1.3b.sh&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8B)/image-20231020155704428.png" alt="image-20231020155704428">&lt;/p>
&lt;ul>
&lt;li>执行训练脚本run_1.3b.sh，触发DeepSpeed开始RLHF训练。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=277474259&amp;bvid=BV1Ww411F7xw&amp;cid=1305868938&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;h2 id="step4模型测试">STEP4.模型测试&lt;/h2>
&lt;ul>
&lt;li>执行测试脚本&lt;code>python chat.py --path training/step3_rlhf_finetuning/output/actor&lt;/code>，不赘述。&lt;/li>
&lt;/ul>
&lt;h1 id="4小结">4.小结&lt;/h1>
&lt;p>本文是实现简版GPT的三篇中的最后一篇，也是最难理解的一部分内容：&lt;/p>
&lt;ul>
&lt;li>对齐训练是什么？&lt;/li>
&lt;li>对齐训练和强化学习的关系是什么？&lt;/li>
&lt;li>ChatGPT整体训练流程的STEP2、STEP3与强化学习的Interpreter和Action模型如何对应？&lt;/li>
&lt;li>DeepSpeed的实际操作？&lt;/li>
&lt;/ul>
&lt;p>本文也有没有展开探讨的内容，待本专栏后续继续展开：&lt;/p>
&lt;ul>
&lt;li>RLHF的策略梯度优化算法&lt;/li>
&lt;li>PPO算法&lt;/li>
&lt;li>……&lt;/li>
&lt;/ul>
&lt;p>编写本专栏受益匪浅，也非常感恩因为编写本专栏认识的大神们，期待与各位小伙伴持续的讨论和思辨！&lt;/p></description></item><item><title>【chatGPT】学习笔记18-自己实现一个简版ChatGPT(中)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%AD/</link><pubDate>Wed, 18 Oct 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%AD/</guid><description>&lt;p>根据上文我们实现的简版GPT，在足够数据、足够算力的前提下，理论上是可以训练出类GPT3的大语言模型的。&lt;/p>
&lt;p>但GPT3距离ChatGPT还有很远的距离，这一段距离涉及OpenAI未公开论文、源码的关键技术。&lt;/p>
&lt;p>我们接下来从OpenAPI已公开的信息来看看&lt;font color=red>&lt;strong>ChatGPT是如何炼成的&lt;/strong>&lt;/font>。&lt;/p>
&lt;h1 id="1chatgpt的历史版本">1.ChatGPT的历史版本&lt;/h1>
&lt;p>下图摘自Yule Wang的技术专栏，阐述了基于Transformer的大语言模型不同版本的脉络：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>BERT&lt;/strong>是编码器Only架构，&lt;strong>BART&lt;/strong>是编码器-解码器架构，它们延伸出去大语言模型下载后&lt;font color=red>&lt;strong>不能直接使用，需要垂域微调&lt;/strong>&lt;/font>。&lt;/li>
&lt;li>&lt;strong>T5&lt;/strong>是编码器-解码器架构，&lt;strong>GPT-2&lt;/strong>是解码器Only架构，它们下载后&lt;font color=red>&lt;strong>不做垂域微调，也能完成一些AI任务&lt;/strong>&lt;/font>。&lt;/li>
&lt;li>&lt;strong>GPT-3、GPT-4&lt;/strong>是解码器Only架构，它们下载后&lt;font color=red>&lt;strong>不做垂域微调，能完成大部分AI任务&lt;/strong>&lt;/font>。&lt;/li>
&lt;li>针对&lt;strong>GPT-3&lt;/strong>进行&lt;font color=red>&lt;strong>SFT(有监督微调)+RLHF(基于人类反馈的强化学习)&lt;strong>&lt;/font>，最终得到了&lt;/strong>ChatGPT&lt;/strong>，&lt;strong>GPT-3.5、InstructGPT&lt;/strong>算是过渡产品。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019083053465.png" alt="image-20231019083053465">&lt;/p>
&lt;h1 id="2chatgpt的整体训练流程">2.ChatGPT的整体训练流程&lt;/h1>
&lt;p>在《Introducing ChatGPT》(详见https://openai.com/blog/chatgpt)中，给出了从GPT3演进到ChatGPT的整体训练流程图：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/ChatGPT_Diagram.svg" alt="ChatGPT_Diagram">&lt;/p>
&lt;p>以前看这张图很模糊，通过前面复现Transformer架构、简版GPT的代码，才逐渐变得清晰。&lt;/p>
&lt;p>接下来，我们来逐一拆解。&lt;/p>
&lt;h1 id="3chatgpt的三大训练方法">3.ChatGPT的三大训练方法&lt;/h1>
&lt;p>下图比较形象地归纳了ChatGPT整体训练流程：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019094239673.png" alt="image-20231019094239673">&lt;/p>
&lt;h2 id="1方法1预训练pre-traning">(1)方法1：预训练(Pre-Traning)&lt;/h2>
&lt;ul>
&lt;li>构建好大语言模型的神经网络架构后，&lt;strong>通过大数据、大算力进行训练&lt;/strong>，得到预训练模型。如：GPT3就属于这类预训练模型。&lt;/li>
&lt;li>大语言模型的本质是生成内容，构建训练数据基本都是自动化的，所以&lt;strong>预训练的过程属于无监督学习&lt;/strong>。&lt;/li>
&lt;li>预训练模型非常庞大，&lt;strong>算是通才&lt;/strong>，具备&lt;strong>基本的自然语言处理能力、世界知识&lt;/strong>，甚至还有了&lt;strong>顿悟能力(涌现能力)&lt;/strong>。&lt;/li>
&lt;li>就好像下图红框内庞大的AI大脑(&lt;strong>画的有点恶心&lt;/strong>)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019150044511.png" alt="image-20231019150044511">&lt;/p>
&lt;h2 id="2方法2指令调优instruction-tuning">(2)方法2：指令调优(Instruction Tuning)&lt;/h2>
&lt;ul>
&lt;li>虽然花了巨大的时间成本和空间成本获得了预训练模型，但是它的水平，依然无法像一个真人，与人类对话。&lt;/li>
&lt;li>接下来还要进行微调——人工&lt;strong>准备少量的数据&lt;/strong>，对&lt;strong>预训练模型进行增量训练&lt;/strong>——因此也称为&lt;strong>有监督微调(SFT，Supervised Fine-tunning)&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>指令微调&lt;/strong>本质是站在巨人的肩膀上&lt;strong>对预训练模型进行增量训练&lt;/strong>。它可以针对世界知识进行增强，也可以针对某个垂直领域进行增强。&lt;/li>
&lt;li>指令微调后得到的大语言训练模型，将会接近于一个真人。&lt;/li>
&lt;li>就好像下图红框内的红色人脸(&lt;strong>画的也挺恶心&lt;/strong>)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019150129023.png" alt="image-20231019150129023">&lt;/p>
&lt;h2 id="3方法3对齐alignment">(3)方法3：对齐(Alignment)&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>在指令调优后，大语言模型虽然接近于真人，但生成的内容依然会很生硬。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>为什么呢？这就是人类的主观感受——人类对某些问题的答案，会有情绪、语气、风格等主观的特征。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>那么，又如何&lt;strong>让AI学会人类的主观感受&lt;/strong>呢？这&lt;strong>就是对齐Alignment&lt;/strong>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RLHF(基于人类反馈的强化学习)就是对齐的具体实现之一，利用这种强化学习手段，让大语言模型学会人类的主观感受，GPT3就演进成为了ChatGPT。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>就好像下图右侧红框内小黄球(&lt;strong>画的依然挺恶心&lt;/strong>)。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019151032099.png" alt="image-20231019151032099">&lt;/p>
&lt;p>接下来，我们逐一分析这三大方法。&lt;/p>
&lt;h1 id="4方法1预训练pre-training">4.方法1：预训练(Pre-Training)&lt;/h1>
&lt;h2 id="1与chatgpt整体训练流程图的对应关系">(1)与ChatGPT整体训练流程图的对应关系&lt;/h2>
&lt;p>我们对比两张图：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>预训练&lt;/strong>得到的大语言模型，就&lt;strong>是ChatGPT整体训练流程STEP1的输入&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019151849173.png" alt="image-20231019151849173">&lt;/p>
&lt;h2 id="2辩证看待预训练模型涌现能力神经网络">(2)辩证看待预训练模型、涌现能力、神经网络&lt;/h2>
&lt;p>前段时间，师父问了我3个终极问题，让我一时语塞：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>为什么ChatGPT大力能出奇迹，小力就不行？&lt;/strong>&lt;/li>
&lt;li>&lt;strong>为什么这样的神经网络模型就可以大力出奇迹，换个神经网络模型行不行？&lt;/strong>&lt;/li>
&lt;li>&lt;strong>如果无论什么神经网络模型只要能做到大力就能出奇迹，那么这些神经网络的本质是什么？&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>前面半年一直在复现Transformer论文的细节中，的确缺少了对宏观本质的思考，结合预训练这个章节的写作，正好梳理一下我的宏观思考：&lt;/p>
&lt;h3 id="思考1神经网络的本质是什么">思考1：神经网络的本质是什么？&lt;/h3>
&lt;ul>
&lt;li>观点1：客观世界中，&lt;strong>一切问题都能用函数表达&lt;/strong>。
&lt;ul>
&lt;li>只不过有的函数极其复杂，只有上帝才知道这个函数是什么。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>观点2：&lt;strong>神经网络的本质进行函数近似(Function Approximation)的工具&lt;/strong>。
&lt;ul>
&lt;li>&lt;strong>神经网络的输入&lt;/strong>：是大量的数据，数据中隐藏了某个问题背后的函数的数学规律。&lt;/li>
&lt;li>&lt;strong>神经网络的输出&lt;/strong>：找到无限逼近于某个问题背后的函数的近似函数。&lt;/li>
&lt;li>数学上，已经证明&lt;strong>神经网络能够近似出任意一个问题背后的函数&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>神经网络的结构&lt;/strong>，&lt;strong>决定了找到这个近似函数的成本&lt;/strong>(时间成本、空间成本……)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="思考2假设思考1正确如何解释神经网络的5种现象">思考2：假设思考1正确，如何解释神经网络的5种现象？&lt;/h3>
&lt;ul>
&lt;li>现象1：&lt;strong>过于简单的神经网络&lt;/strong>，需要很大力才能出奇迹。
&lt;ul>
&lt;li>任务是&amp;quot;让AI对红点和蓝点进行分类&amp;rdquo;，由于神经网络过于简单，所以迭代了2000多次才找出答案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=364782652&amp;bvid=BV1F94y1b7MW&amp;cid=1304339810&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>现象2：&lt;strong>过于简单的任务&lt;/strong>，不需要大力也能出奇迹。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=874844018&amp;bvid=BV1EN4y1C7v2&amp;cid=1304340008&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>现象3：恒定难度的任务，&lt;strong>加宽神经网络&lt;/strong>，大力能出奇迹。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=234774107&amp;bvid=BV1N8411r78C&amp;cid=1304339757&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>现象4：恒定难度的任务，&lt;strong>加深神经网络&lt;/strong>，大力能出奇迹。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=789763364&amp;bvid=BV1Ry4y1N7CU&amp;cid=1304340937&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;ul>
&lt;li>现象5：恒定难度的任务，&lt;strong>增强神经元&lt;/strong>，大力能出奇迹。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=277344904&amp;bvid=BV14w411w7Nx&amp;cid=1304343623&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;p>从上述5种现象，应该可以得到2个结论：&lt;/p>
&lt;ul>
&lt;li>在神经网络结构恒定的前提下，&lt;strong>待执行的任务难度&lt;/strong>，决定了&lt;strong>能否大力出奇迹、是否需要大力&lt;/strong>。&lt;/li>
&lt;li>在待执行的任务难度恒定的前提下，&lt;strong>神经网络结构&lt;/strong>，决定了&lt;strong>能否大力出奇迹、是否需要大力&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;h3 id="思考3辩证地看待预训练模型涌现能力transformer">思考3：辩证地看待预训练模型、涌现能力、Transformer&lt;/h3>
&lt;p>当GPT3.5出现&lt;strong>涌现能力(emergent capabilities)&lt;strong>后，它似乎被神话成了&lt;/strong>人类尚无办法解释的神迹&lt;/strong>。&lt;/p>
&lt;p>我们应该如此这般辩证地看待预训练模型、涌现、Transformer&lt;/p>
&lt;ul>
&lt;li>预训练模型不是ChatGPT首创，在深度学习时代就有了，有很多神经网络都是预训练好，节省后来人的训练成本。&lt;/li>
&lt;li>Transformer只是GPT3这种预训练模型遵循的神经网络结构，&lt;strong>Transformer这种神经网络结构本质是换了一种姿势寻找近似函数&lt;/strong>。&lt;/li>
&lt;li>如果问题P1、问题P2、……问题Pn背后的函数都极为相近，当神经网络结构找到了问题P1的近似函数，那么这个近似函数也能用来解决问题P2、……问题Pn——这就是经过训练，神经网络能自我学习到一些额外的能力的原因，即涌现能力。
&lt;ul>
&lt;li>进一步思考：深度学习时代有没有涌现呢？可能有，只是n这个值比较小，不太明显吧。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="5方法2指令调优instruction-tuning">5.方法2：指令调优(Instruction Tuning)&lt;/h1>
&lt;h2 id="1与chatgpt整体训练流程图的对应关系-1">(1)与ChatGPT整体训练流程图的对应关系&lt;/h2>
&lt;ul>
&lt;li>指令调优对应于ChatGPT整体训练流程的STEP1。&lt;/li>
&lt;li>&lt;strong>SFT&lt;/strong>：有监督微调，属于有监督学习。包括In-context Tuning(上下文调优)和Instruction Tuning(指令调优)。
&lt;ul>
&lt;li>&lt;strong>In-context Tuning&lt;/strong>：上下文调优，这种调优方式的本质是将多轮对话的聊天记录一起发送给大语言模型，有了上下文，大语言模型就能更好地回答问题。&lt;/li>
&lt;li>&lt;strong>Instruction Tuning&lt;/strong>：指令调优，这种调优方式的本质就是问题中带有明确的指令、明确的要求。Instruction Tuning是OpenAI在GPT-3.5-turbo模型中引入的一种新方法，是在传统的微调过程上的一种变体。&lt;/li>
&lt;li>对于上述两种调优方式，在提示词工程中都体现了它们的思想——&lt;strong>&amp;ldquo;上下文&amp;rdquo;、&amp;ldquo;指令&amp;rdquo;&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019170641604.png" alt="image-20231019170641604">&lt;/p>
&lt;h2 id="2训练sft模型的伪码">(2)训练SFT模型的伪码&lt;/h2>
&lt;p>前文讲了很多理论，还是需要撸一下代码比较便于理解。&lt;/p>
&lt;blockquote>
&lt;p>由于OpenAI对于SFT、RLHF并未公开源码，所以在这里只编写伪码，在后续实例中展示真实代码。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019181420212.png" alt="image-20231019181420212">&lt;/p>
&lt;h2 id="3sft实例">(3)SFT实例&lt;/h2>
&lt;p>针对简版GPT，只需要增加如下代码：&lt;/p>
&lt;ul>
&lt;li>首先，通过&lt;code>torch.load方法&lt;/code>加载上一篇已经预训练好的简版GPT模型，这个模型的训练数据仅包含了维基百科的基本数据。&lt;/li>
&lt;li>然后，将新增的医学知识数据集，对简版GPT模型进行增量训练。&lt;/li>
&lt;li>最后，通过&lt;code>torch.save方法&lt;/code>保存增量训练的简版GPT模型，此时，这个模型就包含了医学知识了。&lt;/li>
&lt;li>具体代码详见下图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%AD)/image-20231019182641050.png" alt="image-20231019182641050">&lt;/p>
&lt;h1 id="6小结">6.小结&lt;/h1>
&lt;p>讲到这里，内容已经比较饱和了，我们将在最后一篇阐述&lt;strong>方法3：对齐训练&lt;/strong>以及&lt;strong>RLHF的实例&lt;/strong>。&lt;/p>
&lt;p>我们接下来对本文进行一下小结：&lt;/p>
&lt;ul>
&lt;li>ChatGPT的历史版本：&lt;strong>GPT3、InstructGPT、ChatGPT&lt;/strong>。&lt;/li>
&lt;li>ChatGPT&lt;strong>整体训练流程&lt;/strong>，支撑了&lt;strong>GPT3到ChatGPT的演进&lt;/strong>。&lt;/li>
&lt;li>预训练模型是什么？如何&lt;strong>辩证地&lt;/strong>看待&lt;strong>预训练模型、涌现能力、神经网络的学习能力&lt;/strong>？&lt;/li>
&lt;li>SFT(有监督微调)的概念、原理，最后展示了&lt;strong>如何针对简版GPT进行SFT&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>我们下一步继续针对简版ChatGPT开展RLHF，且听下回分解。&lt;/p></description></item><item><title>【chatGPT】学习笔记17-自己实现一个简版ChatGPT(上)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%8A/</link><pubDate>Mon, 16 Oct 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88chatgpt%E4%B8%8A/</guid><description>&lt;p>接下来，我们用三篇文章阐述&lt;font color=red>**如何实现一个简版ChatGPT。**&lt;/font>&lt;/p>
&lt;h1 id="1回顾">1.回顾&lt;/h1>
&lt;p>想实现一个简版ChatGPT，依赖于如下前置知识：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>机器学习基本原理&lt;/strong>，可参考笔者这几篇文章：
&lt;ul>
&lt;li>《【chatGPT】学习笔记3-机器学习基本原理(上)》&lt;/li>
&lt;li>《【chatGPT】学习笔记4-机器学习基本原理(下)》&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>经典NLP相关技术&lt;/strong>，可参考笔者这几篇文章：
&lt;ul>
&lt;li>&lt;strong>N-Gram&lt;/strong>：《【chatGPT】学习笔记6-手撸一个上古GPT》&lt;/li>
&lt;li>&lt;strong>Embedding&lt;/strong>：《【chatGPT】学习笔记7-词的向量化，大语言模型的关键部件》&lt;/li>
&lt;li>&lt;strong>神经概率语言模型&lt;/strong>：《【chatGPT】学习笔记8-神经概率语言模型，大语言模型的关键部件2》&lt;/li>
&lt;li>&lt;strong>Seq2Seq&lt;/strong>：《【chatGPT】学习笔记9-Transformer之Seq2Seq，大语言模型的关键部件3》&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>现代NLP相关技术&lt;/strong>，可参考笔者这几篇文章：
&lt;ul>
&lt;li>&lt;strong>注意力机制&lt;/strong>：《【chatGPT】学习笔记13-Transformer之注意力机制，大语言模型的关键部件4》&lt;/li>
&lt;li>&lt;strong>Transformer&lt;/strong>：《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="2实现简版gpt">2.实现简版GPT&lt;/h1>
&lt;p>这是参考Transformer架构绘制的简版ChatGPT整体架构，我们将对它进行拆解：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017113929233.png" alt="image-20231017113929233">&lt;/p>
&lt;h2 id="1整体">(1)整体&lt;/h2>
&lt;p>将上图抽象化，我们可以看到：&lt;/p>
&lt;ul>
&lt;li>简版GPT遵循Transfomer架构，但是没有实现编码器&lt;/li>
&lt;li>Decoder的输出交给一个线性层，将解码器的输出转换为目标词汇表大小的概率分布——这属于常规操作，与Transformer核心思想关系不大。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017134713086.png" alt="image-20231017134713086">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>1&lt;/strong>：对应上图将&lt;strong>Outputs&lt;/strong>输入给&lt;strong>Decoder&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>2&lt;/strong>：对应上图将&lt;strong>Decoder的输出&lt;/strong>，传入给线性层。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017135734066.png" alt="image-20231017135734066">&lt;/p>
&lt;h2 id="2局部1正弦位置编码表">(2)局部1：正弦位置编码表&lt;/h2>
&lt;p>首先，我们来细化&lt;strong>Outputs&lt;/strong>和&lt;strong>Decoder&lt;/strong>之间的流程：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP1&lt;/strong>.对&lt;strong>Outputs&lt;/strong>实施词嵌入，得到词向量。&lt;/li>
&lt;li>&lt;strong>STEP2&lt;/strong>.在&lt;strong>词向量&lt;/strong>和&lt;strong>Decoder&lt;/strong>之间增加了&lt;strong>位置编码表&lt;/strong>(也是一个向量)，这个位置编码表体现了&lt;strong>词和词序的关系&lt;/strong>。
&lt;ul>
&lt;li>由于Transformer取消了RNN，也就不再逐个词串行处理，所以必须建立&lt;strong>词和词序的关系&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>STEP3&lt;/strong>.将STEP2的&lt;strong>位置表码表&lt;/strong>向量和&lt;strong>词向量&lt;/strong>相加，输入给&lt;strong>Decoder&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017140335543.png" alt="image-20231017140335543">&lt;/p>
&lt;p>正弦位置编码表的计算原理参见《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》的&amp;rdquo;(2)局部1：正弦位置编码表&amp;quot;章节，本文不再赘述。&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017140636308.png" alt="image-20231017140636308">&lt;/p>
&lt;h2 id="3局部2解码器堆栈">(3)局部2：解码器堆栈&lt;/h2>
&lt;p>我们再来细化&lt;strong>解码器&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>编码器本质上由&lt;strong>N个解码器&lt;/strong>串联而成的&lt;strong>解码器堆栈&lt;/strong>。&lt;/li>
&lt;li>我们的实现，也按照论文的设定层数，&lt;strong>N=6&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150909585.png" alt="image-20231017150909585">&lt;/p>
&lt;h2 id="4局部3解码器">(4)局部3：解码器&lt;/h2>
&lt;p>我们再进一步细化&lt;strong>解码器Decoder&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>解码器Decoder&lt;/strong>由&lt;strong>多头注意力&lt;/strong>和&lt;strong>前向传播网络&lt;/strong>组成。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150925061.png" alt="image-20231017150925061">&lt;/p>
&lt;p>&lt;strong>解码器堆栈&lt;/strong>的代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>①&lt;/strong>：这就是创建的&lt;strong>位置编码层&lt;/strong>，再将&lt;strong>词向量和位置编码向量相加&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>②&lt;/strong>：这就是将多个&lt;strong>解码器&lt;/strong>叠加成&lt;strong>解码器堆栈&lt;/strong>，每个&lt;strong>解码器的输入&lt;/strong>是&lt;strong>上个解码器的输出&lt;/strong>和&lt;strong>上个解码器输出的注意力权重&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>③&lt;/strong>：这就是表示&lt;strong>解码器堆栈&lt;/strong>输出的&lt;strong>解码器输出&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017142049236.png" alt="image-20231017142049236">&lt;/p>
&lt;p>&lt;strong>解码器&lt;/strong>的代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>①&lt;/strong>：就是&lt;strong>多头注意力层&lt;/strong>，&lt;strong>第一个解码器&lt;/strong>的&lt;strong>多头注意力层&lt;/strong>的输入是&lt;strong>词嵌入+位置编码向量之和&lt;/strong>以及&lt;strong>自注意力掩码&lt;/strong>，&lt;strong>后续解码器&lt;/strong>的&lt;strong>多头注意力层&lt;/strong>的输入是&lt;strong>上一个解码器的输出&lt;/strong>和&lt;strong>自注意力掩码&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>②&lt;/strong>：就是&lt;strong>前向传播网络&lt;/strong>，它的输入是&lt;strong>多头注意力层的输出&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017145220345.png" alt="image-20231017145220345">&lt;/p>
&lt;p>我们接下来看&lt;strong>多头注意力层、前向传播网络、自注意力位置掩码&lt;/strong>如何实现？&lt;/p>
&lt;h2 id="5局部4多头注意力">(5)局部4：多头注意力&lt;/h2>
&lt;p>多头注意力的原理参见《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》的&amp;rdquo;(5)局部4：多头注意力&amp;quot;章节，本文不再赘述。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150943298.png" alt="image-20231017150943298">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017145622219.png" alt="image-20231017145622219">&lt;/p>
&lt;h2 id="6局部5前向传播网络">(6)局部5：前向传播网络&lt;/h2>
&lt;p>多头注意力的原理参见《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》的&amp;rdquo;(6)局部5：前向传播网络&amp;quot;章节，本文不再赘述。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151000709.png" alt="image-20231017151000709">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150114991.png" alt="image-20231017150114991">&lt;/p>
&lt;h2 id="7局部6填充位置掩码">(7)局部6：填充位置掩码&lt;/h2>
&lt;p>多头注意力的原理参见《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》的&amp;rdquo;(7)局部6：填充位置掩码&amp;quot;章节，本文不再赘述。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151014381.png" alt="image-20231017151014381">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150413819.png" alt="image-20231017150413819">&lt;/p>
&lt;h2 id="8局部7后续位置掩码">(8)局部7：后续位置掩码&lt;/h2>
&lt;p>多头注意力的原理参见《【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5》的&amp;rdquo;(10)局部9：后续位置掩码&amp;quot;章节，本文不再赘述。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151026419.png" alt="image-20231017151026419">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017150515799.png" alt="image-20231017150515799">&lt;/p>
&lt;h2 id="9模型训练">(9)模型训练&lt;/h2>
&lt;p>至此，我们已经完整地实现了Transformer架构，我们开始对其进行训练：&lt;/p>
&lt;ul>
&lt;li>数据集如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151515137.png" alt="image-20231017151515137">&lt;/p>
&lt;ul>
&lt;li>模型训练：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151651529.png" alt="image-20231017151651529">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151717714.png" alt="image-20231017151717714">&lt;/p>
&lt;ul>
&lt;li>训练好后，会生成简版GPT的pth模型文件：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151835127.png" alt="image-20231017151835127">&lt;/p>
&lt;h2 id="10模型测试">(10)模型测试&lt;/h2>
&lt;ul>
&lt;li>测试用例采用贪婪编码和集束编码，比较简单，具体代码如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E7%89%88ChatGPT(%E4%B8%8A)/image-20231017151956136.png" alt="image-20231017151956136">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;ul>
&lt;li>本文基于Transformer架构，复现了简版ChatGPT，其关键在于只有解码器。&lt;/li>
&lt;li>理论上，如果有足够算力、足够训练数据，可以将此简版ChatGPT训练到GPT3的水平。&lt;/li>
&lt;li>那么，GPT3到ChatGPT还有一定的距离，我们知道ChatGPT公开的信息中，还对GPT3进行了&lt;strong>监督学习微调SFT&lt;/strong>、&lt;strong>基于人类反馈的强化学习RLHF&lt;/strong>等，得到了InstructGPT，进而得到了ChatGPT。&lt;/li>
&lt;/ul>
&lt;p>我们下一步继续针对简版ChatGPT开展SFT和RLHF，且听下回分解。&lt;/p></description></item><item><title>【chatGPT】学习笔记16-Transformer架构，大语言模型的关键部件5</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-transformer%E6%9E%B6%E6%9E%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/</link><pubDate>Tue, 26 Sep 2023 18:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-transformer%E6%9E%B6%E6%9E%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/</guid><description>&lt;p>在《AI拾遗》这个专栏中，我们建立了从&lt;strong>N-Gram&lt;/strong>到&lt;strong>词嵌入&lt;/strong>再到&lt;strong>神经概率语言模型&lt;/strong>，从&lt;strong>Seq2Seq&lt;/strong>到&lt;strong>注意力机制&lt;/strong>的知识脉络。&lt;/p>
&lt;p>这条脉络本质就是NLP发展的路线图，有了这些知识储备，我们终于可以来理解论文**《Attention Is All You Need》**中大名鼎鼎的**Transformer架构**了！&lt;/p>
&lt;h1 id="1问题">1.问题&lt;/h1>
&lt;p>在《【chatGPT】学习笔记13-Transformer之注意力机制，大语言模型的关键部件4》中，笔者为&lt;strong>编码器-解码器架构&lt;/strong>增加了&lt;strong>注意力机制&lt;/strong>，进而实现了&lt;strong>增强版的Seq2Seq模型&lt;/strong>，模型能力的确有所增强，但并不是彻底解决了&lt;strong>长距离依赖&lt;/strong>问题和&lt;strong>信息压缩&lt;/strong>问题。&lt;/p>
&lt;p>在《Attention Is All You Need》的第一章阐述了这个观点：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>howerver, remains&lt;/strong>(第二段最后一句)：历史上很多论文和技术都在增强&lt;strong>编码器-解码器架构&lt;/strong>，注意力机制也成为序列建模必备的技术，但&lt;strong>长距离依赖&lt;/strong>问题依然存在。&lt;/li>
&lt;li>&lt;strong>parallelization&lt;/strong>(第三段)：这里提到了并行化，这是前面没有提到的问题——RNN网络决定了Seq2Seq只能一个词一个词的处理。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926072417665.png" alt="image-20230926072417665">&lt;/p>
&lt;h1 id="2transformer逐步拆解">2.Transformer逐步拆解&lt;/h1>
&lt;p>这是论文中第三段绘制的Transformer整体架构，我们将对它进行拆解：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926074022967.png" alt="image-20230926074022967">&lt;/p>
&lt;h2 id="1整体transformer">(1)整体：Transformer&lt;/h2>
&lt;p>将上图抽象化，我们可以看到：&lt;/p>
&lt;ul>
&lt;li>Transformer依然可以遵循Encoder-Decoder架构&lt;/li>
&lt;li>Decoder的输出交给一个线性层，将解码器的输出转换为目标词汇表大小的概率分布——这属于常规操作，与Transformer核心思想关系不大。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926082223230.png" alt="image-20230926082223230">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>1&lt;/strong>：对应上图将&lt;strong>Inputs&lt;/strong>输入给&lt;strong>Encoder&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>2&lt;/strong>：对应上图将&lt;strong>Outputs+Encoder的输出&lt;/strong>，传入给&lt;strong>Decoder&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>3&lt;/strong>：对应上图将&lt;strong>Decoder的输出&lt;/strong>，传入给线性层。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926083838772.png" alt="image-20230926083838772">&lt;/p>
&lt;p>PS：这里的&lt;code>corpus&lt;/code>是一个封装了&lt;code>Inputs&lt;/code>和&lt;code>Outputs&lt;/code>的工具类，代码如下(比较简单，不赘述)：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926083336984.png" alt="image-20230926083336984">&lt;/p>
&lt;h2 id="2局部1正弦位置编码表">(2)局部1：正弦位置编码表&lt;/h2>
&lt;p>首先，我们来细化&lt;strong>Inputs&lt;/strong>和&lt;strong>Encoder&lt;/strong>之间的流程：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP1&lt;/strong>.对&lt;strong>Inputs&lt;/strong>实施词嵌入，得到词向量。&lt;/li>
&lt;li>&lt;strong>STEP2&lt;/strong>.在&lt;strong>词向量&lt;/strong>和&lt;strong>Encoder&lt;/strong>之间增加了&lt;strong>位置编码表&lt;/strong>(也是一个向量)，这个位置编码表体现了&lt;strong>词和词序的关系&lt;/strong>。
&lt;ul>
&lt;li>由于Transformer取消了RNN，也就不再逐个词串行处理，所以必须建立&lt;strong>词和词序的关系&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>STEP3&lt;/strong>.将STEP2的&lt;strong>位置表码表&lt;/strong>向量和&lt;strong>词向量&lt;/strong>相加，输入给&lt;strong>Encoder&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Outputs&lt;/strong>和&lt;strong>Decoder&lt;/strong>之间的流程和上述流程一样。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926092023205.png" alt="image-20230926092023205">&lt;/p>
&lt;p>那么位置编码表如何计算呢？论文3.5章节详细阐述如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>d&lt;/strong>：词向量的维度。&lt;/li>
&lt;li>&lt;strong>pos&lt;/strong>：单词在句子中的位置。&lt;/li>
&lt;li>&lt;strong>i&lt;/strong>：词向量的维度的奇数维。&lt;/li>
&lt;li>&lt;strong>PE&lt;/strong>：指定位置的单词，在词向量的某一个维度上的数值。&lt;/li>
&lt;li>通俗地理解，&lt;strong>d个PE值构成了指定单词在整个句子中的位置向量&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926093855305.png" alt="image-20230926093855305">&lt;/p>
&lt;p>我们不必纠结于论文中这两个公式的证明，笔者绘制一个例子，可视化地理解正弦位置编码表的作用：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>假设&lt;/strong>：输入序列为&amp;rdquo;&lt;strong>想去新疆&lt;/strong>&amp;ldquo;四个字，词向量的维度为4维，即&lt;strong>d=4&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP1&lt;/strong>：通过正弦位置编码公式，&lt;strong>想&lt;/strong>字的&lt;strong>位置0&lt;/strong>，求得位置0的&lt;strong>位置向量[0, 1, 0, 1]&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP2&lt;/strong>：通过正弦位置编码公式，&lt;strong>去&lt;/strong>字的&lt;strong>位置1&lt;/strong>，求得位置1的&lt;strong>位置向量[0.84, 0.54, 0.01, 1.0]&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP3&lt;/strong>：通过正弦位置编码公式，&lt;strong>新&lt;/strong>字的&lt;strong>位置2&lt;/strong>，求得位置2的&lt;strong>位置向量[0.91, -0.42, 0.02, 1.0]&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP4&lt;/strong>：通过正弦位置编码公式，&lt;strong>疆&lt;/strong>字的&lt;strong>位置3&lt;/strong>，求得位置3的&lt;strong>位置向量[0.14, -0.99, 0.03, 1.0]&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926111712233.png" alt="image-20230926111712233">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926110113612.png" alt="image-20230926110113612">&lt;/p>
&lt;h2 id="3局部2编码器堆栈">(3)局部2：编码器堆栈&lt;/h2>
&lt;p>我们再来细化&lt;strong>编码器&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>编码器本质上由&lt;strong>N个编码器&lt;/strong>串联而成的&lt;strong>编码器堆栈&lt;/strong>。&lt;/li>
&lt;li>论文中，&lt;strong>N=6&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926112341735.png" alt="image-20230926112341735">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>论文原文&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926113124754.png" alt="image-20230926113124754">&lt;/p>
&lt;h2 id="4局部3编码器">(4)局部3：编码器&lt;/h2>
&lt;p>我们再进一步细化&lt;strong>编码器Encoder&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>编码器Encoder&lt;/strong>由&lt;strong>多头注意力&lt;/strong>和&lt;strong>前向传播网络&lt;/strong>组成。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926114259743.png" alt="image-20230926114259743">&lt;/p>
&lt;p>&lt;strong>编码器堆栈&lt;/strong>的代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>①&lt;/strong>：这就是调用&lt;strong>正弦位置编码表&lt;/strong>，创建的&lt;strong>位置编码层&lt;/strong>，再将&lt;strong>词向量和位置编码向量相加&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>②&lt;/strong>：这就是将多个&lt;strong>编码器&lt;/strong>叠加成&lt;strong>编码器堆栈&lt;/strong>，每个&lt;strong>编码器的输入&lt;/strong>是&lt;strong>上个编码器的输出&lt;/strong>和&lt;strong>上个编码器输出的注意力权重&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>③&lt;/strong>：这就是表示&lt;strong>编码器堆栈&lt;/strong>输出的&lt;strong>编码器输出&lt;/strong>、&lt;strong>编码器输出的注意力权重&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926115605435.png" alt="image-20230926115605435">&lt;/p>
&lt;p>&lt;strong>编码器&lt;/strong>的代码实现如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>①&lt;/strong>：就是&lt;strong>多头注意力层&lt;/strong>，&lt;strong>第一个编码器&lt;/strong>的&lt;strong>多头注意力层&lt;/strong>的输入是&lt;strong>词嵌入+位置编码向量之和&lt;/strong>以及&lt;strong>自注意力掩码&lt;/strong>，&lt;strong>后续编码器&lt;/strong>的&lt;strong>多头注意力层&lt;/strong>的输入是&lt;strong>上一个编码器的输出&lt;/strong>和&lt;strong>自注意力掩码&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>②&lt;/strong>：就是&lt;strong>前向传播网络&lt;/strong>，它的输入是&lt;strong>多头注意力层的输出&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926122832935.png" alt="image-20230926122832935">&lt;/p>
&lt;p>这里又埋下了几个问题：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>多头注意力层&lt;/strong>如何实现？&lt;/li>
&lt;li>&lt;strong>前向传播网络&lt;/strong>如何实现？&lt;/li>
&lt;li>&lt;strong>自注意力位置掩码&lt;/strong>如何实现？&lt;/li>
&lt;/ul>
&lt;h2 id="5局部4多头注意力">(5)局部4：多头注意力&lt;/h2>
&lt;p>我们再来细化多头注意力：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>不赘述&lt;/strong>：关于&lt;strong>点积注意力&lt;/strong>、&lt;strong>缩放点积注意力&lt;/strong>、&lt;strong>编码器-解码器注意力&lt;/strong>、&lt;strong>QKV&lt;/strong>、&lt;strong>自注意力&lt;/strong>、&lt;strong>多头注意力&lt;/strong>，本文就不再赘述了。如果理解不太清晰，可以回看《【chatGPT】学习笔记13-Transformer之注意力机制，大语言模型的关键部件4》。&lt;/li>
&lt;li>&lt;strong>多头注意力&lt;/strong>的结构：&lt;strong>多头注意力的输入&lt;/strong>是&lt;strong>词向量与位置编码向量之和&lt;/strong>，每一个注意力头都是对&lt;strong>多头注意力的输入&lt;/strong>进行矩阵乘法得到&lt;strong>QKV&lt;/strong>，再输入给&lt;strong>缩放点积注意力组件&lt;/strong>，这个组件输出的是&lt;strong>注意力权重&lt;/strong>。最后，将每个注意力头输出的注意力权重求和，输入给一个线性层。&lt;/li>
&lt;li>&lt;strong>缩放点积注意力&lt;/strong>的结构：就是典型的缩放点积注意力的计算公式，即：Q、K求点积=&amp;gt;缩放=&amp;gt;注意力掩码=&amp;gt;Softmax=&amp;gt;和V点积。&lt;/li>
&lt;li>&lt;strong>细节&lt;/strong>：这里增加了Add &amp;amp; Norm，就是深度学习里面的残差连接、层归一化，为了解决梯度爆炸问题，这不是Transformer特有的新知识。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926162228532.png" alt="image-20230926162228532">&lt;/p>
&lt;p>论文原文：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>缩放点积注意力&lt;/strong>计算公式：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926161049010.png" alt="image-20230926161049010">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>多头注意力&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926161136259.png" alt="image-20230926161136259">&lt;/p>
&lt;p>&lt;strong>缩放点积注意力&lt;/strong>的代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926161300468.png" alt="image-20230926161300468">&lt;/p>
&lt;p>&lt;strong>多头注意力&lt;/strong>的代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926161409926.png" alt="image-20230926161409926">&lt;/p>
&lt;h2 id="6局部5前向传播网络">(6)局部5：前向传播网络&lt;/h2>
&lt;p>我们再来细化前向神经网络：&lt;/p>
&lt;ul>
&lt;li>前向神经网络的全称是&lt;strong>Position-wise Feed-Forward Network&lt;/strong>，即&lt;strong>基于位置的前馈神经网络&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>two linear transformations with a ReLU activation&lt;/strong>：首先使用第一个线性层做升维，接着使用ReLU激活函数，再使用第二个线性层做降维。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926163125569.png" alt="image-20230926163125569">&lt;/p>
&lt;p>这个基于位置的前馈神经网络到底有啥用呢？&lt;/p>
&lt;ul>
&lt;li>就是论文中，多头注意力结构中的最后一步&lt;strong>Linear&lt;/strong>！&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926163933555.png" alt="image-20230926163933555">&lt;/p>
&lt;p>论文原文：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926163424383.png" alt="image-20230926163424383">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926164434302.png" alt="image-20230926164434302">&lt;/p>
&lt;h2 id="7局部6填充位置掩码">(7)局部6：填充位置掩码&lt;/h2>
&lt;p>我们再来细化填充位置掩码：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>填充位置掩码&lt;/strong>用在&lt;strong>词嵌入&lt;/strong>之后，&lt;strong>编码器&lt;/strong>输入之前。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926170827083.png" alt="image-20230926170827083">&lt;/p>
&lt;ul>
&lt;li>填充位置掩码有什么作用呢？
&lt;ul>
&lt;li>&lt;strong>t1时刻&lt;/strong>：给编码器输入了一句话——&amp;ldquo;我想去新疆滑雪&amp;rdquo;。&lt;/li>
&lt;li>&lt;strong>t2时刻&lt;/strong>：给编码器输入第二句话——&amp;ldquo;想去就去啊&amp;rdquo;。为了和上一句话保持长度统一，我们就会在在第二句话末尾增加两个占位符。&lt;/li>
&lt;li>&lt;strong>t3时刻&lt;/strong>：生成填充位置掩码[1, 1, 1, 1, 1, 0, 0]。&lt;/li>
&lt;li>&lt;strong>t4时刻&lt;/strong>：编码器会将第二句话和填充位置掩码求与，这样编码器实施多头注意力的时候，就不会注意毫无意义的两个占位符。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926171245346.png" alt="image-20230926171245346">&lt;/p>
&lt;p>代码实现如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926171345069.png" alt="image-20230926171345069">&lt;/p>
&lt;p>至此，我们就把Transformer架构中编码器部分细化完成了，我们继续细化解码器部分：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926170827083.png" alt="image-20230926170827083">&lt;/p>
&lt;h2 id="8局部7解码器堆栈">(8)局部7：解码器堆栈&lt;/h2>
&lt;p>解码器堆栈的思想到实现，和编码器堆栈完全一样，这里不再赘述，直接上图和代码：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926174658980.png" alt="image-20230926174658980">&lt;/p>
&lt;h2 id="9局部8解码器">(9)局部8：解码器&lt;/h2>
&lt;p>解码器的思想到实现，和编码器堆栈大致一样，这里不再赘述，直接上图和代码：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926174249742.png" alt="image-20230926174249742">&lt;/p>
&lt;p>&lt;strong>解码器堆栈&lt;/strong>代码如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926174857116.png" alt="image-20230926174857116">&lt;/p>
&lt;p>&lt;strong>解码器&lt;/strong>代码如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926174916494.png" alt="image-20230926174916494">&lt;/p>
&lt;h2 id="10局部9后续位置掩码">(10)局部9：后续位置掩码&lt;/h2>
&lt;p>在解码器中，还有最后一个遗留问题——后续位置掩码。&lt;/p>
&lt;p>后续位置掩码只是因为解码器实施多头注意力的时候，是不能注意到&lt;strong>未来&lt;/strong>的，也就是它还没有预测的后续词，所以要屏蔽掉。&lt;/p>
&lt;p>后续位置掩码和填充位置掩码的思想是一致的，不赘述。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926175344740.png" alt="image-20230926175344740">&lt;/p>
&lt;p>&lt;strong>后续位置掩码&lt;/strong>的代码实现：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926175131684.png" alt="image-20230926175131684">&lt;/p>
&lt;h2 id="11模型训练">(11)模型训练&lt;/h2>
&lt;p>至此，我们已经完整地实现了Transformer架构，我们开始对其进行训练：&lt;/p>
&lt;ul>
&lt;li>数据集如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926180145967.png" alt="image-20230926180145967">&lt;/p>
&lt;ul>
&lt;li>模型训练：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926180246638.png" alt="image-20230926180246638">&lt;/p>
&lt;h2 id="12模型测试">(12)模型测试&lt;/h2>
&lt;ul>
&lt;li>测试用例采用贪婪编码，比较简单，具体代码如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Transformer%E6%9E%B6%E6%9E%84%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B65/image-20230926180356687.png" alt="image-20230926180356687">&lt;/p>
&lt;h1 id="3小结">3.小结&lt;/h1>
&lt;p>笔者在今年2月份第一次阅读论文《Attention Is All You Need》，读了好几遍，不得要领，只觉得非常抽象。&lt;/p>
&lt;p>随着在网上阅读各类资料、逐步摸索复现论文中Transformer架构的源码，逐渐理解这篇论文中所说的——&lt;strong>Attention Is All You Need&lt;/strong>的含义。&lt;/p>
&lt;p>本以为理解了论文含义，提笔准备写出这篇文章时，又卡了壳——因为理解了，又很难表达出来Transformer的精妙原理！&lt;/p>
&lt;p>此时，笔者才真正领悟之前听过一位大神所说的：&lt;font color=red>”LLM涉及的每一篇经典论文，不仅值得&lt;strong>反复阅读&lt;/strong>，甚至应该&lt;strong>背诵下来&lt;/strong>。“&lt;/font>的含义。&lt;/p>
&lt;p>这篇文章写完，我们下一步就可以实现并训练我们平民版的ChatGPT了，且听下回分解了。&lt;/p></description></item><item><title>【chatGPT】学习笔记15-LangChain之Chain，对LLM的抽象3</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-langchain%E4%B9%8Bchain%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A13/</link><pubDate>Wed, 20 Sep 2023 19:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-langchain%E4%B9%8Bchain%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A13/</guid><description>&lt;p>我们继续写点儿偏工程实践的内容——LangChain的核心模块3——Chain。&lt;/p>
&lt;h1 id="1核心模块3chain">1.核心模块3：Chain&lt;/h1>
&lt;p>在《【chatGPT】学习笔记11-LLM应用-垂直领域知识问答系统(基于ChatGLM2)》中，我们知道LangChain-ChatChat有如下工作流程：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921092837843.png" alt="image-20230921092837843">&lt;/p>
&lt;p>如何实现呢？其实，LangChain抽象了&lt;strong>Chain&lt;/strong>的概念。&lt;/p>
&lt;h2 id="11chain-class">1.1.Chain Class&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>类的继承关系&lt;/strong>：Chain &amp;ndash;&amp;gt; &lt;name>Chain # Examples: LLMChain, MapReduceChain, RouterChain&lt;/li>
&lt;li>代码路径/libs/langchain/langchain/chains/base.py，&lt;strong>详细源码如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">Chain&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Serializable&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Runnable&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">]],&lt;/span> &lt;span class="n">ABC&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Abstract base class for creating structured sequences of calls to components.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Chains should be used to encode a sequence of calls to components like
&lt;/span>&lt;span class="s2"> models, document retrievers, other chains, etc., and provide a simple interface
&lt;/span>&lt;span class="s2"> to this sequence.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> The Chain interface makes it easy to create apps that are:
&lt;/span>&lt;span class="s2"> - Stateful: add Memory to any Chain to give it state,
&lt;/span>&lt;span class="s2"> 有状态的：给Chain添加Memory，使其具有状态
&lt;/span>&lt;span class="s2"> - Observable: pass Callbacks to a Chain to execute additional functionality,
&lt;/span>&lt;span class="s2"> like logging, outside the main sequence of component calls,
&lt;/span>&lt;span class="s2"> 可观察的：向Chain传递Callback来执行额外的功能。
&lt;/span>&lt;span class="s2"> - Composable: the Chain API is flexible enough that it is easy to combine
&lt;/span>&lt;span class="s2"> Chains with other components, including other Chains.
&lt;/span>&lt;span class="s2"> 可组合的：Chain API足够灵活，可以轻松地将Chains与其他组件组合在一起，包括组合其他的Chain。
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> The main methods exposed by chains are:
&lt;/span>&lt;span class="s2"> - `__call__`: Chains are callable. The `__call__` method is the primary way to
&lt;/span>&lt;span class="s2"> execute a Chain. This takes inputs as a dictionary and returns a
&lt;/span>&lt;span class="s2"> dictionary output.
&lt;/span>&lt;span class="s2"> 执行Chain的主要方式，输入是一个字典，输出也是一个字典。
&lt;/span>&lt;span class="s2"> - `run`: A convenience method that takes inputs as args/kwargs and returns the
&lt;/span>&lt;span class="s2"> output as a string or object. This method can only be used for a subset of
&lt;/span>&lt;span class="s2"> chains and cannot return as rich of an output as `__call__`.
&lt;/span>&lt;span class="s2"> 输入是args/kwargs，输出是字符串or对象。仅用于部分链，没有__call__方法通用。
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="o">............&lt;/span>
&lt;span class="n">memory&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">BaseMemory&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Optional memory object. Defaults to None.
&lt;/span>&lt;span class="s2"> Memory is a class that gets called at the start
&lt;/span>&lt;span class="s2"> and at the end of every chain. At the start, memory loads variables and passes
&lt;/span>&lt;span class="s2"> them along in the chain. At the end, it saves any returned variables.
&lt;/span>&lt;span class="s2"> There are many different types of memory - please see memory docs
&lt;/span>&lt;span class="s2"> for the full catalog.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="err">每个链开始和结束时调用。存储&lt;/span>&lt;span class="n">Memory&lt;/span>&lt;span class="err">。&lt;/span>
&lt;span class="n">callbacks&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Callbacks&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">default&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">exclude&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Optional list of callback handlers (or callback manager). Defaults to None.
&lt;/span>&lt;span class="s2"> Callback handlers are called throughout the lifecycle of a call to a chain,
&lt;/span>&lt;span class="s2"> starting with on_chain_start, ending with on_chain_end or on_chain_error.
&lt;/span>&lt;span class="s2"> Each custom chain can optionally call additional callback methods, see Callback docs
&lt;/span>&lt;span class="s2"> for full details.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">callback_manager&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">BaseCallbackManager&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">default&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">exclude&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Deprecated, use `callbacks` instead.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">verbose&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">default_factory&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">_get_verbosity&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Whether or not run in verbose mode. In verbose mode, some intermediate logs
&lt;/span>&lt;span class="s2"> will be printed to the console. Defaults to `langchain.verbose` value.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="err">开启后，输出更纤细的日志。&lt;/span>
&lt;span class="o">............&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>我们看一个例子：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>LLMChain&lt;/strong>：创建了一个&lt;strong>步骤&lt;/strong>，该步骤可执行&lt;code>prompt&lt;/code>提示词。&lt;/li>
&lt;li>&lt;strong>run方法&lt;/strong>：调用LLMChain的&lt;code>run&lt;/code>方法，可以和LLM进行问答。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921094132633.png" alt="image-20230921094132633">&lt;/p>
&lt;h2 id="12顺序链">1.2.顺序链&lt;/h2>
&lt;h3 id="1源码解读">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>SequentialChain&lt;/strong>：继承于Chain，顺序链，允许将多个Chain链接起来，形成&lt;strong>Pipeline(流水线)&lt;/strong>。&lt;/li>
&lt;li>代码路径/libs/langchain/langchain/chains/sequential.py，&lt;strong>详细源码如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">SequentialChain&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Chain&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Chain where the outputs of one chain feed directly into next.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">chains&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Chain&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">input_variables&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">output_variables&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="c1">#: :meta private:&lt;/span>
&lt;span class="n">return_all&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>
&lt;span class="err">……………………&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>SimpleSequentialChain&lt;/strong>：继承于SequentialChain，一种简化版的顺序链，允许将多个Chain链接起来，形成&lt;strong>Pipeline(流水线)&lt;/strong>。&lt;/li>
&lt;li>代码路径/libs/langchain/langchain/chains/sequential.py，&lt;strong>详细源码如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">SimpleSequentialChain&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Chain&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Simple chain where the outputs of one step feed directly into next.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">chains&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Chain&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">strip_outputs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>
&lt;span class="n">input_key&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;input&amp;#34;&lt;/span> &lt;span class="c1">#: :meta private:&lt;/span>
&lt;span class="n">output_key&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;output&amp;#34;&lt;/span> &lt;span class="c1">#: :meta private:&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2simplesequentialchain的代码示例">(2)SimpleSequentialChain的代码示例&lt;/h3>
&lt;p>我们来看如下的代码，实现了LLM模仿医生对病情进行介绍，并给出治疗方案。&lt;/p>
&lt;ul>
&lt;li>通过&lt;strong>SimpleSequentialChain&lt;/strong>，连接了病情摘要Chain和病情评论Chain。&lt;/li>
&lt;li>病情摘要Chain的&lt;strong>输出&lt;/strong>，作为了病情评论Chain的&lt;strong>输入&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921095733390.png" alt="image-20230921095733390">&lt;/p>
&lt;h3 id="3sequentialchain的代码示例">(3)SequentialChain的代码示例&lt;/h3>
&lt;p>我们来看如下的代码，实现了LLM模仿医生对病情进行介绍，并给出治疗方案。&lt;/p>
&lt;p>不同的是，要支持多输入、多输出。&lt;/p>
&lt;ul>
&lt;li>通过&lt;strong>SequentialChain&lt;/strong>，连接了病情摘要Chain和病情评论Chain。&lt;/li>
&lt;li>病情摘要Chain的&lt;strong>输入有多个&lt;/strong>，病情摘要Chain的&lt;strong>输出&lt;/strong>作为了病情评论Chain的&lt;strong>输入&lt;/strong>，病情评论Chain的&lt;strong>输出有多个&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921100917222.png" alt="image-20230921100917222">&lt;/p>
&lt;h2 id="13决策链">1.3.决策链&lt;/h2>
&lt;h3 id="1源码解读-1">(1)源码解读&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>RouterChain&lt;/strong>：继承于Chain，决策链，允许将多个Chain链接起来，可以实现条件判断的&lt;strong>分支Pipeline(分支流水线)&lt;/strong>。&lt;/li>
&lt;li>代码路径/libs/langchain/langchain/chains/router/base.py，&lt;strong>详细源码如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">RouterChain&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Chain&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ABC&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Chain that outputs the name of a destination chain and the inputs to it.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">output_keys&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;destination&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;next_inputs&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">route&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">callbacks&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Callbacks&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Route&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;span class="s2"> Route inputs to a destination chain.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Args:
&lt;/span>&lt;span class="s2"> inputs: inputs to the chain
&lt;/span>&lt;span class="s2"> callbacks: callbacks to use for the chain
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Returns:
&lt;/span>&lt;span class="s2"> a Route object
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">callbacks&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">callbacks&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">Route&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;destination&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">result&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;next_inputs&amp;#34;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">async&lt;/span> &lt;span class="k">def&lt;/span> &lt;span class="nf">aroute&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">callbacks&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Callbacks&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>
&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Route&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">await&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">acall&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">callbacks&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">callbacks&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">Route&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;destination&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">result&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;next_inputs&amp;#34;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2routerchain的代码示例">(2)RouterChain的代码示例&lt;/h3>
&lt;p>我们来看如下的代码，实现了根据问题内容，选择程序员角色的AI或测试工程师AI出来回答问题。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>创建两个决策分支&lt;/strong>：能回答软件开发问题的程序员、能回答软件测试问题的程序员。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921102913545.png" alt="image-20230921102913545">&lt;/p>
&lt;ul>
&lt;li>创建根据问题内容进行决策的&lt;strong>RouterChain&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921102959963.png" alt="image-20230921102959963">&lt;/p>
&lt;p>这个决策链是如何实现的决策功能呢？进一步看一下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>destinations_str&lt;/strong>：描述了根据问题内容，期望选择哪个AI来回答问题。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921103109653.png" alt="image-20230921103109653">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>MULTI_PROMPT_ROUTER_TEMPLATE&lt;/strong>：LangChain提供了决策链的提示词模板。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921103154608.png" alt="image-20230921103154608">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>router_template&lt;/strong>：最终的决策链提示词为：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921103225927.png" alt="image-20230921103225927">&lt;/p>
&lt;ul>
&lt;li>将决策链和两个回答问题的链进行连接。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921103257969.png" alt="image-20230921103257969">&lt;/p>
&lt;ul>
&lt;li>测试一下关于软件开发的问题：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921103327682.png" alt="image-20230921103327682">&lt;/p>
&lt;ul>
&lt;li>测试一下关于软件测试的问题：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-LangChain%E4%B9%8BChain%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A13/image-20230921103359806.png" alt="image-20230921103359806">&lt;/p>
&lt;h1 id="2小结">2.小结&lt;/h1>
&lt;p>本文阐述了Chain模块的内部实现：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Chain类&lt;/strong>：抽象了&lt;strong>PipeLine流水线&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>顺序链&lt;/strong>：SequentialChain，实现了多输入多输出的串行执行的工作流。&lt;/li>
&lt;li>&lt;strong>决策链&lt;/strong>：RouterChain，实现了根据问题内容，选择工作流走向的能力。&lt;/li>
&lt;li>Chain类拥有很多子类，实现不同的业务流程，可以根据实战需要继续阅读源码和实践。&lt;/li>
&lt;/ul>
&lt;p>后续文章，我们继续解读LangChain的核心模块，感谢阅读。&lt;/p></description></item><item><title>【chatGPT】学习笔记14-LangChain之Memory，对LLM的抽象2</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-langchain%E4%B9%8Bmemory%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A12/</link><pubDate>Tue, 19 Sep 2023 19:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-langchain%E4%B9%8Bmemory%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A12/</guid><description>&lt;p>我们继续写点儿偏工程实践的内容——LangChain的核心模块2——Chain。&lt;/p>
&lt;h1 id="1核心模块2memory">1.核心模块2：Memory&lt;/h1>
&lt;p>实现一个问答系统，通常需要将历史上的问题和答案，作为本次问题的上下文。&lt;/p>
&lt;p>因此，LangChain提供了Memory模块，这个模块对记忆进行了抽象：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP1&lt;/strong>.当用户提出问题时，LangChain会去读&lt;strong>Memory&lt;/strong>，获得过去的消息&lt;strong>past_messages&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP2&lt;/strong>.LangChain构造提示词，格式为&amp;rdquo;&lt;strong>{past_messages}{question}&lt;/strong>&amp;quot;。&lt;/li>
&lt;li>&lt;strong>STEP3&lt;/strong>.LLM进行回答后，得到答案**{answer:&amp;hellip;}**。&lt;/li>
&lt;li>STEP4.LangChain将本次的答案**{answer:&amp;hellip;}**，**写入Memory**。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920062809577.png" alt="image-20230920062809577">&lt;/p>
&lt;p>LangChain提供了多种ChatMessageHistory、ChatMemory，我们接下来详细解读。&lt;/p>
&lt;h2 id="11chatmessagehistory">1.1.ChatMessageHistory&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>类的继承关系&lt;/strong>：BaseChatMessageHistory &amp;ndash;&amp;gt; &lt;name>ChatMessageHistory # Example: ZepChatMessageHistory&lt;/li>
&lt;li>&lt;strong>BaseChatMessageHistory&lt;/strong>：聊天消息历史记录的基类，定义了一系列方法，由子类实现&lt;/li>
&lt;li>代码路径/libs/langchain/langchain/schema/chat_history.py，&lt;strong>详细源码如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920064148308.png" alt="image-20230920064148308">&lt;/p>
&lt;h2 id="12basememory">1.2.BaseMemory&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>类的继承关系&lt;/strong>：BaseMemory &amp;ndash;&amp;gt; BaseChatMemory &amp;ndash;&amp;gt; &lt;name>Memory # Examples: ZepMemory, MotorheadMemory&lt;/li>
&lt;li>&lt;strong>BaseMemory&lt;/strong>：Memory基类，定义了一系列方法，由子类实现&lt;/li>
&lt;li>代码路径/libs/langchain/langchain/schema/memory.py，&lt;strong>详细源码如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">BaseMemory&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Serializable&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ABC&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Abstract base class for memory in Chains.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> Memory refers to state in Chains. Memory can be used to store information about
&lt;/span>&lt;span class="s2"> past executions of a Chain and inject that information into the inputs of
&lt;/span>&lt;span class="s2"> future executions of the Chain. For example, for conversational Chains Memory
&lt;/span>&lt;span class="s2"> can be used to store conversations and automatically add them to future model
&lt;/span>&lt;span class="s2"> prompts so that the model has the necessary context to respond coherently to
&lt;/span>&lt;span class="s2"> the latest input.
&lt;/span>&lt;span class="s2">这里的内存指的是Chains中的状态。内存可以用来存储Chain过去执行的信息，并将信息注入到Chain的未来执行的输入中。
&lt;/span>&lt;span class="s2">例如：对于会话型Chains，内存可以用来存储会话，并自动将它们添加到未来的模型提示词中，以便模型具有必要的上下文来连贯地响应最新的输入。
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> class Config:
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>&lt;span class="n">Configuration&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">this&lt;/span> &lt;span class="n">pydantic&lt;/span> &lt;span class="nb">object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;span class="s2"> 使用pydantic库，并在本类中定义抽象方法，待子类实现
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> arbitrary_types_allowed = True
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> @property
&lt;/span>&lt;span class="s2"> @abstractmethod
&lt;/span>&lt;span class="s2"> def memory_variables(self) -&amp;gt; List[str]:
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>&lt;span class="n">The&lt;/span> &lt;span class="n">string&lt;/span> &lt;span class="n">keys&lt;/span> &lt;span class="n">this&lt;/span> &lt;span class="n">memory&lt;/span> &lt;span class="k">class&lt;/span> &lt;span class="nc">will&lt;/span> &lt;span class="n">add&lt;/span> &lt;span class="n">to&lt;/span> &lt;span class="n">chain&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> @abstractmethod
&lt;/span>&lt;span class="s2"> def load_memory_variables(self, inputs: Dict[str, Any]) -&amp;gt; Dict[str, Any]:
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>&lt;span class="n">Return&lt;/span> &lt;span class="n">key&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">value&lt;/span> &lt;span class="n">pairs&lt;/span> &lt;span class="n">given&lt;/span> &lt;span class="n">the&lt;/span> &lt;span class="n">text&lt;/span> &lt;span class="nb">input&lt;/span> &lt;span class="n">to&lt;/span> &lt;span class="n">the&lt;/span> &lt;span class="n">chain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> @abstractmethod
&lt;/span>&lt;span class="s2"> def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -&amp;gt; None:
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>&lt;span class="n">Save&lt;/span> &lt;span class="n">the&lt;/span> &lt;span class="n">context&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="n">this&lt;/span> &lt;span class="n">chain&lt;/span> &lt;span class="n">run&lt;/span> &lt;span class="n">to&lt;/span> &lt;span class="n">memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> @abstractmethod
&lt;/span>&lt;span class="s2"> def clear(self) -&amp;gt; None:
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>&lt;span class="n">Clear&lt;/span> &lt;span class="n">memory&lt;/span> &lt;span class="n">contents&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="13basechatmemory">1.3.BaseChatMemory&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>BaseChatMemory&lt;/strong>：BaseMemoryd的子类，实现了一部分通用方法，剩余由子类扩展&lt;/li>
&lt;li>BaseChatMemory维护了ChatMessageHistory&lt;/li>
&lt;li>代码路径/libs/langchain/langchain/memory/chat_memory.py，&lt;strong>详细源码如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">BaseChatMemory&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BaseMemory&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ABC&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Abstract base class for chat memory.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">chat_memory&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">BaseChatMessageHistory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">default_factory&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">ChatMessageHistory&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">output_key&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>
&lt;span class="n">input_key&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Optional&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">None&lt;/span>
&lt;span class="n">return_messages&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">bool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">False&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">_get_input_output&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">prompt_input_key&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">outputs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">output_key&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">save_context&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">outputs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Save context from this conversation to buffer.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">input_str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">output_str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_get_input_output&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">outputs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">chat_memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add_user_message&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">input_str&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">chat_memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add_ai_message&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">output_str&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">clear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Clear memory contents.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">chat_memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">clear&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>接下来就可以看一下常用的几种Memory了。&lt;/p>
&lt;h2 id="14conversationbuffermemory">1.4.ConversationBufferMemory&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>ConversationBufferMemory&lt;/strong>：一种Memory的具体实现。提供了记录历史聊天记录的能力。&lt;/li>
&lt;li>代码路径/libs/langchain/langchain/memory/buffer.py，&lt;strong>详细源码如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">ConversationBufferMemory&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BaseChatMemory&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Buffer for storing conversation memory.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">human_prefix&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Human&amp;#34;&lt;/span>
&lt;span class="n">ai_prefix&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;AI&amp;#34;&lt;/span>
&lt;span class="n">memory_key&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;history&amp;#34;&lt;/span> &lt;span class="c1">#: :meta private:&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">buffer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;String buffer of memory.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">buffer_as_messages&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">return_messages&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">buffer_as_str&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">buffer_as_str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Exposes the buffer as a string in case return_messages is True.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">get_buffer_string&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">chat_memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">messages&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">human_prefix&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">human_prefix&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">ai_prefix&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ai_prefix&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">buffer_as_messages&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">BaseMessage&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Exposes the buffer as a list of messages in case return_messages is False.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">chat_memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">messages&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">memory_variables&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Will always return list of memory variables.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> :meta private:
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">memory_key&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load_memory_variables&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Return history buffer.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">memory_key&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">buffer&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>我们再来看一个例子：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920072953322.png" alt="image-20230920072953322">&lt;/p>
&lt;ul>
&lt;li>针对第一个问题，LangChain发送给LLM真实的问题如下：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920073630423.png" alt="image-20230920073630423">&lt;/p>
&lt;ul>
&lt;li>针对第二个问题，LangChain会把&lt;strong>第一次发给LLM的问题和答案&lt;/strong>+&lt;strong>第二次的问题&lt;/strong>发送给LLM：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920073804453.png" alt="image-20230920073804453">&lt;/p>
&lt;h2 id="15conversationbufferwindowmemory">1.5.ConversationBufferWindowMemory&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>ConversationBufferWindowMemory&lt;/strong>：一种Memory的具体实现。提供了带有滑动窗口的记录历史聊天记录的能力。&lt;/li>
&lt;li>代码路径/libs/langchain/langchain/memory/buffer_window.py，&lt;strong>详细源码如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">ConversationBufferWindowMemory&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BaseChatMemory&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Buffer for storing conversation memory inside a limited size window.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">human_prefix&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Human&amp;#34;&lt;/span>
&lt;span class="n">ai_prefix&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;AI&amp;#34;&lt;/span>
&lt;span class="n">memory_key&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;history&amp;#34;&lt;/span> &lt;span class="c1">#: :meta private:&lt;/span>
&lt;span class="n">k&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">5&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Number of messages to store in buffer.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">buffer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Union&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">BaseMessage&lt;/span>&lt;span class="p">]]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;String buffer of memory.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">buffer_as_messages&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">return_messages&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">buffer_as_str&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">buffer_as_str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Exposes the buffer as a string in case return_messages is True.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">messages&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">chat_memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">messages&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="p">:]&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">get_buffer_string&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">messages&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">human_prefix&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">human_prefix&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">ai_prefix&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ai_prefix&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">buffer_as_messages&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">BaseMessage&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Exposes the buffer as a list of messages in case return_messages is False.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">chat_memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">messages&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="p">:]&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">memory_variables&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Will always return list of memory variables.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> :meta private:
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">memory_key&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load_memory_variables&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Return history buffer.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">memory_key&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">buffer&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>我们看一个例子：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920074018406.png" alt="image-20230920074018406">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>第一次问答&lt;/strong>：LangChain真实发送的问题只有&amp;quot;你好&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920074115794.png" alt="image-20230920074115794">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>第二次问答&lt;/strong>：LangChain真实发送的问题是&lt;strong>第一次问题答案&lt;/strong>+&lt;strong>第二次问题&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920074225759.png" alt="image-20230920074225759">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>第三次问答&lt;/strong>：LangChain真实发送的问题是&lt;strong>第一次问题答案&lt;/strong>+&lt;strong>第二次问题答案&lt;/strong>+&lt;strong>第三次问题&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920074328411.png" alt="image-20230920074328411">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>第四次问答&lt;/strong>：LangChain真实发送的问题是&lt;strong>第二次问题答案&lt;/strong>+&lt;strong>第三次问题答案&lt;/strong>+&lt;strong>第四次问题&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920074412212.png" alt="image-20230920074412212">&lt;/p>
&lt;p>为什么会有近3次问答内容的限制呢？因为初始化ConversationBufferWindowMemory时，设置了&lt;code>k=2&lt;/code>。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920074524136.png" alt="image-20230920074524136">&lt;/p>
&lt;h2 id="16conversationsummarybuffermemory">1.6.ConversationSummaryBufferMemory&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>ConversationSummaryBufferMemory&lt;/strong>：一种Memory的具体实现。提供了记录历史聊天记录，并对历史聊天记录进行归纳总结的能力。&lt;/li>
&lt;li>代码路径/libs/langchain/langchain/memory/summary_buffer.py，&lt;strong>详细源码如下&lt;/strong>：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;span class="lnt">66
&lt;/span>&lt;span class="lnt">67
&lt;/span>&lt;span class="lnt">68
&lt;/span>&lt;span class="lnt">69
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">ConversationSummaryBufferMemory&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BaseChatMemory&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">SummarizerMixin&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Buffer with summarizer for storing conversation memory.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">max_token_limit&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2000&lt;/span>
&lt;span class="n">moving_summary_buffer&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">memory_key&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;history&amp;#34;&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">buffer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">BaseMessage&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">chat_memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">messages&lt;/span>
&lt;span class="nd">@property&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">memory_variables&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Will always return list of memory variables.
&lt;/span>&lt;span class="s2">
&lt;/span>&lt;span class="s2"> :meta private:
&lt;/span>&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">memory_key&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">load_memory_variables&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Return history buffer.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="nb">buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">buffer&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">moving_summary_buffer&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">first_messages&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">BaseMessage&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">summary_message_cls&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">moving_summary_buffer&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="nb">buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">first_messages&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">buffer&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">return_messages&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">final_buffer&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Any&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">buffer&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">final_buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">get_buffer_string&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="nb">buffer&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">human_prefix&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">human_prefix&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ai_prefix&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ai_prefix&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">memory_key&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">final_buffer&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="nd">@root_validator&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">validate_prompt_input_variables&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">cls&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Validate that prompt input variables are consistent.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">prompt_variables&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;prompt&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">input_variables&lt;/span>
&lt;span class="n">expected_keys&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;summary&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;new_lines&amp;#34;&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">expected_keys&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="nb">set&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">prompt_variables&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">raise&lt;/span> &lt;span class="ne">ValueError&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s2">&amp;#34;Got unexpected prompt input variables. The prompt expects &amp;#34;&lt;/span>
&lt;span class="n">f&lt;/span>&lt;span class="s2">&amp;#34;{prompt_variables}, but it should have {expected_keys}.&amp;#34;&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">values&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">save_context&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Any&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">outputs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Save context from this conversation to buffer.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="nb">super&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save_context&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">outputs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">prune&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">prune&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Prune buffer if it exceeds max token limit&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="nb">buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">chat_memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">messages&lt;/span>
&lt;span class="n">curr_buffer_length&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">llm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_num_tokens_from_messages&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">buffer&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">curr_buffer_length&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max_token_limit&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">pruned_memory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="k">while&lt;/span> &lt;span class="n">curr_buffer_length&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max_token_limit&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">pruned_memory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">buffer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pop&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="n">curr_buffer_length&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">llm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_num_tokens_from_messages&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">buffer&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">moving_summary_buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">predict_new_summary&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">pruned_memory&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">moving_summary_buffer&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">clear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Clear memory contents.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="nb">super&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">clear&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">moving_summary_buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>我们看一个例子：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-LangChain%E4%B9%8BMemory%EF%BC%8C%E5%AF%B9LLM%E7%9A%84%E6%8A%BD%E8%B1%A12/image-20230920074831714.png" alt="image-20230920074831714">&lt;/p>
&lt;ul>
&lt;li>从这段代码的输出，可以看到LangChain对历史问题和答案进行了概括总结：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="p">{&lt;/span>&lt;span class="err">&amp;#39;history&amp;#39;:&lt;/span> &lt;span class="err">[&lt;/span>
&lt;span class="err">SystemMessage(content=&amp;#39;\nThe&lt;/span> &lt;span class="err">human&lt;/span> &lt;span class="err">asks&lt;/span> &lt;span class="err">what&lt;/span> &lt;span class="err">the&lt;/span> &lt;span class="err">AI&lt;/span> &lt;span class="err">thinks&lt;/span> &lt;span class="err">of&lt;/span> &lt;span class="err">artificial&lt;/span> &lt;span class="err">intelligence.&lt;/span> &lt;span class="err">The&lt;/span> &lt;span class="err">AI&lt;/span> &lt;span class="err">thinks&lt;/span> &lt;span class="err">artificial&lt;/span> &lt;span class="err">intelligence&lt;/span> &lt;span class="err">is&lt;/span> &lt;span class="err">a&lt;/span> &lt;span class="err">force&lt;/span> &lt;span class="err">for&lt;/span> &lt;span class="err">good&lt;/span> &lt;span class="err">because&lt;/span> &lt;span class="err">it&lt;/span> &lt;span class="err">will&lt;/span> &lt;span class="err">help&lt;/span> &lt;span class="err">humans&lt;/span> &lt;span class="err">reach&lt;/span> &lt;span class="err">their&lt;/span> &lt;span class="err">full&lt;/span> &lt;span class="err">potential.&lt;/span> &lt;span class="err">The&lt;/span> &lt;span class="err">human&lt;/span> &lt;span class="err">then&lt;/span> &lt;span class="err">asks&lt;/span> &lt;span class="err">what&lt;/span> &lt;span class="err">LLM&lt;/span> &lt;span class="err">is,&lt;/span> &lt;span class="err">to&lt;/span> &lt;span class="err">which&lt;/span> &lt;span class="err">the&lt;/span> &lt;span class="err">AI&lt;/span> &lt;span class="err">responds&lt;/span> &lt;span class="err">that&lt;/span> &lt;span class="err">it&lt;/span> &lt;span class="err">stands&lt;/span> &lt;span class="err">for&lt;/span> &lt;span class="err">Large&lt;/span> &lt;span class="err">Language&lt;/span> &lt;span class="err">Model,&lt;/span> &lt;span class="err">and&lt;/span> &lt;span class="err">provides&lt;/span> &lt;span class="err">a&lt;/span> &lt;span class="err">list&lt;/span> &lt;span class="err">of&lt;/span> &lt;span class="err">LLM&lt;/span> &lt;span class="err">models,&lt;/span> &lt;span class="err">including&lt;/span> &lt;span class="err">GPT-3,&lt;/span> &lt;span class="err">GPT-J-6B,&lt;/span> &lt;span class="err">CLIP,&lt;/span> &lt;span class="err">BERT,&lt;/span> &lt;span class="err">and&lt;/span> &lt;span class="err">T5.&amp;#39;,&lt;/span>
&lt;span class="err">additional_kwargs={&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="err">)&lt;/span>
&lt;span class="err">]}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h1 id="2小结">2.小结&lt;/h1>
&lt;p>本文阐述了Memory模块的内部实现：&lt;/p>
&lt;ul>
&lt;li>ChatMessageHistory：提供记录历史聊天记录的对象&lt;/li>
&lt;li>BaseChatMemory：维护1个ChatMessageHistory对象，并对外提供CRUD历史聊天记录的接口&lt;/li>
&lt;li>ConversationBufferMemory：BaseChatMemory的1种子类，对外提供最终的CRUD历史聊天记录的接口&lt;/li>
&lt;li>ConversationBufferWindowMemory：在ConversationBufferMemory的基础上，提供了滑动窗口能力&lt;/li>
&lt;li>ConversationSummaryBufferMemory：在ConversationBufferMemory的基础上，提供了历史聊天记录的摘要能力&lt;/li>
&lt;/ul>
&lt;p>后续文章，我们继续解读LangChain的核心模块，感谢阅读。&lt;/p></description></item><item><title>【chatGPT】学习笔记13-Transformer之注意力机制，大语言模型的关键部件4</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/</link><pubDate>Mon, 18 Sep 2023 19:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/</guid><description>&lt;h1 id="1问题">1.问题&lt;/h1>
&lt;p>在《【chatGPT】学习笔记9-Transformer之Seq2Seq，大语言模型的关键部件3》中，我们实现了Seq2Seq，看到了编码器-解码器架构的诸多优势。&lt;/p>
&lt;p>但，Seq2Seq也有不完美的地方：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>长距离依赖问题&lt;/strong>：读了后面，忘了前面。&lt;/li>
&lt;li>&lt;strong>信息压缩问题&lt;/strong>：Seq2Seq的上下文向量是固定长度的，很难将无限的信息压缩到有限长度的向量中。&lt;/li>
&lt;/ul>
&lt;p>这个视频，体现了长距离依赖问题和信息压缩问题：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>长距离依赖问题&lt;/strong>：沈腾的几个问题，对于老大爷，都是听了后面忘了前面。&lt;/li>
&lt;li>&lt;strong>信息压缩问题&lt;/strong>：沈腾的每个问题，对于老大爷，字数都太多。&lt;/li>
&lt;/ul>
&lt;iframe src="//player.bilibili.com/player.html?aid=961160816&amp;bvid=BV1tH4y1S7Uu&amp;cid=1271780225&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px autoplay=0> &lt;/iframe>
&lt;p>&lt;font color=red>&lt;strong>长距离问题、信息压缩问题的本质，都是信息损失的问题&lt;/strong>。&lt;/font>&lt;/p>
&lt;h1 id="2注意力机制的核心思想">2.注意力机制的核心思想&lt;/h1>
&lt;p>理解了Seq2Seq的问题，我们会很自然地产生一种思路：如果将原始信息化繁为简，喂给LLM的是有效信息，而不是全量信息，是否可以解决长距离问题、信息压缩问题？&lt;/p>
&lt;p>我们再来看一段视频：&lt;/p>
&lt;ul>
&lt;li>从全量信息看，&amp;ldquo;关键问题&amp;quot;四个字高频出现。&lt;/li>
&lt;li>从有效信息看，这么长一段话也就是一句有效信息——&amp;ldquo;关键问题很重要&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;p>在人类世界，这些没用的废话叫艺术。在AI的世界，这些没用的废话叫干扰。&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919082648294.png" alt="image-20230919082648294">&lt;/p>
&lt;iframe src="//player.bilibili.com/player.html?aid=661221372&amp;bvid=BV1Vh4y1a7uD&amp;cid=1271806425&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px autoplay=0> &lt;/iframe>
&lt;p>从直觉上理解，人类接收信息时，会做两件事：&lt;/p>
&lt;ul>
&lt;li>关注&lt;strong>关键信息&lt;/strong>。&lt;/li>
&lt;li>关注&lt;strong>不同维度的关键信息&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>比如：《八佰》这张海报，你看到了什么？&lt;/p>
&lt;ul>
&lt;li>&lt;strong>四行仓库&lt;/strong>：它是海报的背景，为什么会吸引观众的注意？&lt;/li>
&lt;li>&lt;strong>残垣断壁&lt;/strong>：正常的第一眼感觉是这里应该经历过多轮惨烈战斗，为什么我们不会关注断壁、废楼、电线杆的破坏程度？为什么我们不会关注零落的士兵？&lt;/li>
&lt;li>&lt;strong>对比鲜明&lt;/strong>：四行仓库和残垣断壁对比鲜明，我们应该可以感受到导演想表达的一种情绪。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919083211415.png" alt="image-20230919083211415">&lt;/p>
&lt;p>上述这些，就是&lt;font color=red>&lt;strong>注意力&lt;/strong>&lt;/font>，而且是&lt;font color=red>&lt;strong>不同维度的注意力&lt;/strong>&lt;/font>：&lt;/p>
&lt;ul>
&lt;li>当有人问&amp;rdquo;《八佰》这部电影发生的地点在哪里？&amp;quot;，我们的注意力在&amp;rdquo;&lt;strong>四行仓库&lt;/strong>&amp;quot;。&lt;/li>
&lt;li>当游人问&amp;rdquo;《八佰》这部电影想表达什么主题？&amp;quot;，我们的注意力在&amp;quot;四行仓库与残垣断壁&amp;quot;的&lt;strong>对比鲜明&lt;/strong>——表现&amp;quot;八佰&amp;quot;勇士保卫上海最后一寸土地的英勇决绝。&lt;/li>
&lt;/ul>
&lt;p>论文《Attention Mechanisms in Computer Vision: A Survey》，更加形象化地展示了注意力在计算机视觉领域的实验效果：&lt;/p>
&lt;ul>
&lt;li>我们可以发现，加入了注意力机制的AI，会更加关注原始图像中的关键要素。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919084959023.png" alt="image-20230919084959023">&lt;/p>
&lt;h1 id="3注意力原理解读">3.注意力原理解读&lt;/h1>
&lt;p>接下来，我们尝试一下用代码实现一下直觉上理解的注意力机制。&lt;/p>
&lt;h2 id="31点积注意力">3.1.点积注意力&lt;/h2>
&lt;p>首先，回顾一下点积的定义，特别关注一下点积的代数表达：&lt;/p>
&lt;blockquote>
&lt;p>在数学中，&lt;strong>点积&lt;/strong>又称&lt;strong>数量积&lt;/strong>或&lt;strong>标量积&lt;/strong>，是一种接受两串等长的数字序列（通常是坐标向量）、返回单一数字的代数运算)。在欧几里得几何，两条笛卡尔坐标向量的点积常称为&lt;strong>内积&lt;/strong>。&lt;/p>
&lt;p>从代数角度看，先求两数字序列中每组对应元素的积，再求所有积之和，结果即为点积。&lt;/p>
&lt;p>从几何角度看，点积则是两向量的长度与它们夹角余弦的积。这两种定义在笛卡尔坐标系中等价。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919085940309.png" alt="image-20230919085940309">&lt;/p>
&lt;p>然后，我们再来看看&lt;strong>点积注意力&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>假设&lt;/strong>：向量X1表示帅哥，假设向量X2表示美女。&lt;/li>
&lt;li>&lt;strong>STEP1&lt;/strong>：计算X1和X2的点积&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919090930858.png" alt="image-20230919090930858">，这个叫&lt;strong>原始权重&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP2&lt;/strong>：对原始权重进行softmax&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919091338872.png" alt="image-20230919091338872">，得到&lt;strong>归一化注意力&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP3&lt;/strong>：计算归一化注意力与X2的加权和&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919092013095.png" alt="image-20230919092013095">，得到X1对X2的&lt;strong>最终注意力&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>结果&lt;/strong>：经过上述代数计算，最终注意力的信息主体肯定是X1，最终注意力还包含了X2的信息。因此可以这么理解：
&lt;ul>
&lt;li>向量X1表示：没有坠入爱河的帅哥。&lt;/li>
&lt;li>最终向量表示：心中有美女的，坠入爱河的帅哥。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>具体代码如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919092053498.png" alt="image-20230919092053498">&lt;/p>
&lt;p>运行结果：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919092401876.png" alt="image-20230919092401876">&lt;/p>
&lt;h2 id="32缩放点积注意力">3.2.缩放点积注意力&lt;/h2>
&lt;p>在&amp;quot;3.1.点积注意力&amp;quot;的STEP2中，对原始权重进行softmax，可能由于原始权重过大导致梯度过小甚至梯度消失。&lt;/p>
&lt;p>因此，缩放点积注意力的本质是对原始权重除以一个系数后，再进行softmax，具体如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>假设&lt;/strong>：向量X1表示帅哥，假设向量X2表示美女。&lt;/li>
&lt;li>&lt;strong>STEP1&lt;/strong>：计算X1和X2的点积&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919090930858.png" alt="image-20230919090930858">，这个叫&lt;strong>原始权重&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP2&lt;/strong>：对原始权重缩放&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919105751443.png" alt="image-20230919105751443">，得到&lt;strong>缩放权重&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP2&lt;/strong>：对&lt;strong>缩放权重&lt;/strong>进行softmax&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919105527069.png" alt="image-20230919105527069">，得到&lt;strong>归一化注意力&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>STEP3&lt;/strong>：计算归一化注意力与X2的加权和&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919105715585.png" alt="image-20230919105715585">，得到X1对X2的&lt;strong>最终注意力&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>结果&lt;/strong>：经过上述代数计算，最终注意力的信息主体肯定是X1，最终注意力还包含了X2的信息。因此可以这么理解：
&lt;ul>
&lt;li>向量X1表示：没有坠入爱河的帅哥。&lt;/li>
&lt;li>最终向量表示：心中有美女的，坠入爱河的帅哥。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>具体代码如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919105832012.png" alt="image-20230919105832012">&lt;/p>
&lt;p>运行结果：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919105847714.png" alt="image-20230919105847714">&lt;/p>
&lt;h2 id="33解码器-编码器注意力">3.3.解码器-编码器注意力&lt;/h2>
&lt;p>有了&lt;strong>缩放点积注意力&lt;/strong>，我们就可以尝试一下：&lt;strong>对编码器-解码器架构&lt;/strong>增加&lt;strong>注意力机制&lt;/strong>了。&lt;/p>
&lt;p>回顾一下《【chatGPT】学习笔记9-Transformer之Seq2Seq，大语言模型的关键部件3》，我们详细分析了各个时间点上编码器、解码器的处理流程。截取t5和t6时刻：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>t5时刻&lt;/strong>：第一个解码器的输入是&lt;strong>编码器输出的上下文向量&lt;/strong>+&lt;strong>TeachForcing的第一个单词&lt;/strong>Who，第一个解码器的输出是最终答案的首词Who+&lt;strong>隐藏状态&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>t6时刻&lt;/strong>：第二个解码器的输入是&lt;strong>第一个解码器的隐藏状态&lt;/strong>+&lt;strong>TeachForcing的第二个单词&lt;/strong>are+第一个解码器预测的最终答案的首词Who。&lt;/li>
&lt;/ul>
&lt;p>我们可以看出，每一个解码器的输入本质包含了三要素：&lt;/p>
&lt;ul>
&lt;li>&lt;font color=red>&lt;strong>问题是什么&lt;/strong>&lt;/font>：每个编码器输出的隐藏状态，但隐藏状态无法记忆太长的问题序列，所以&lt;strong>每个解码器只知道问题的只言片语&lt;/strong>。&lt;/li>
&lt;li>&lt;font color=red>&lt;strong>参考答案是什么&lt;/strong>&lt;/font>：TeachForcing会告诉每个解码器，参考答案是什么。&lt;/li>
&lt;li>&lt;font color=red>&lt;strong>上一个解码器的答案是什么&lt;/strong>&lt;/font>：每个解码器都能知道上一个解码器预测的答案的一部分是什么。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919110424183.png" alt="image-20230919110424183">&lt;/p>
&lt;p>思考一下：注意力机制，可以&lt;strong>如何优化编码器-解码器架构&lt;/strong>？&lt;/p>
&lt;p>显然，只有优化&amp;quot;问题是什么&amp;quot;这个要素——如果我们将第一个解码器增加注意力层，就可以让输出的隐藏状态注意编码器输出的上下文向量——这样每个解码器就&lt;font color=red>&lt;strong>能用有限长度的向量&lt;/strong>&lt;/font>了解&lt;font color=red>&lt;strong>原始问题中最关键的部分&lt;/strong>&lt;/font>。&lt;/p>
&lt;p>具体代码如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919161621858.png" alt="image-20230919161621858">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919161638084.png" alt="image-20230919161638084">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919161652216.png" alt="image-20230919161652216">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919161724555.png" alt="image-20230919161724555">&lt;/p>
&lt;p>运行结果如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919161901056.png" alt="image-20230919161901056">&lt;/p>
&lt;p>写到这里，我们要稍微小结一下(避免陷入术语、概念、数学公式的细节中)：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>神经网络架构&lt;/strong>：实现Seq2Seq的&lt;strong>编码器-解码器&lt;/strong>架构，是神经网络架构中的一种。&lt;/li>
&lt;li>&lt;strong>注意力机制&lt;/strong>：注意力机制是一种专项技术，也有很多种实现，无论是哪一种，都是在&lt;strong>解决神经网络架构的长距离问题、信息压缩问题&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>如果您对&lt;strong>编码器-解码器&lt;/strong>这种&lt;strong>神经网络架构&lt;/strong>的细节记不太清，可以回看这篇《【chatGPT】学习笔记9-Transformer之Seq2Seq，大语言模型的关键部件3》。&lt;/p>
&lt;p>如果您对&lt;strong>注意力机制&lt;/strong>这种专项技术的细节记不太清，可以回看本文的&lt;strong>点积注意力、缩放点积注意力、编码器-解码器注意力&lt;/strong>章节。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919174642861.png" alt="image-20230919174642861">&lt;/p>
&lt;p>当我们对上述概念有了基本认识后，我们也就可以理解，自1990年注意力机制提出后，有很多科学家在思考：&lt;/p>
&lt;ul>
&lt;li>&lt;font color=red>有没有一种&lt;strong>更好的神经网络架构&lt;/strong>，充分发挥这种&lt;strong>仿人类的注意力机制&lt;/strong>的独特优势&lt;/font>？&lt;/li>
&lt;/ul>
&lt;p>于是如雷贯耳的Transformer架构诞生了，于是如雷贯耳的论文《Attention Is All Your Need》诞生了。&lt;/p>
&lt;p>笔者不在本文展开描述Transformer的实现原理，但我们可以在本文接下来的部分解读一下QKV、自注意力、多头注意力等Transformer架构中与注意力机制强相关的技术点，为后续解读Transformer做知识铺垫。&lt;/p>
&lt;h2 id="34qkv">3.4.QKV&lt;/h2>
&lt;p>QKV注意力(query-key-value attention)是注意力机制中的一种变体。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919165526267.png" alt="image-20230919165526267">&lt;/p>
&lt;p>上图来自于维基百科，但维基百科对于QKV的介绍非常详细，但笔者试图给出这些过于理论化的QKV理论的通俗解释：&lt;/p>
&lt;ul>
&lt;li>注意力机制的本质是&lt;strong>让向量X1关注向量X2&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>Q&lt;/strong>uery，就是&lt;strong>向量X1&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>K&lt;/strong>ey、&lt;strong>V&lt;/strong>alue，就是&lt;strong>向量X2&lt;/strong>。Key和Value的区别，仅仅是数学公式的差异(注意力权重、注意力权重加权和)。&lt;/li>
&lt;li>&lt;strong>向量X1&lt;/strong>，也就是&lt;strong>Q&lt;/strong>uery，在编码器-解码器架构中，就是&lt;strong>解码器输出的隐藏状态&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>向量X2&lt;/strong>，也就是&lt;strong>K&lt;/strong>ey或者&lt;strong>V&lt;/strong>alue，在编码器-解码器架构中，就是&lt;strong>编码器输出的上下文向量&lt;/strong>。&lt;/li>
&lt;li>说白了，就是让&lt;strong>每个解码器的输出&lt;/strong>都关注&lt;strong>编码器输出的上下文向量&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>我们来看一下代码：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919171621721.png" alt="image-20230919171621721">&lt;/p>
&lt;h2 id="35自注意力">3.5.自注意力&lt;/h2>
&lt;p>自注意力的理论也非常抽象，笔者试图给出这些理论的通俗解释：&lt;/p>
&lt;ul>
&lt;li>注意力机制的本质是&lt;strong>让向量X1关注向量X2&lt;/strong>。自注意力的本质是&lt;strong>自己对自己&lt;/strong>的注意。&lt;/li>
&lt;li>&lt;strong>Q&lt;/strong>uery，就是&lt;strong>向量X1&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>K&lt;/strong>ey、&lt;strong>V&lt;/strong>alue，也是&lt;strong>向量X2&lt;/strong>。而向量X2的信息本质还是向量X1，只是线性变换的公式不同而已。&lt;/li>
&lt;/ul>
&lt;p>我们来看看实现自注意力的代码：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919172737253.png" alt="image-20230919172737253">&lt;/p>
&lt;h2 id="36多头注意力">3.6.多头注意力&lt;/h2>
&lt;ul>
&lt;li>理解了QKV注意力，那么多头注意力仅仅是从更多维度对信息进行点积、缩放、Softmax、加权和而已。&lt;/li>
&lt;/ul>
&lt;p>具体代码如下：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919173225726.png" alt="image-20230919173225726">&lt;/p>
&lt;h1 id="4总结">4.总结&lt;/h1>
&lt;ul>
&lt;li>本文通过介绍点积注意力、缩放点积注意力，进而解读了如何在编码器-解码器神经网络架构中，增加注意力机制。
&lt;ul>
&lt;li>本文的依据源于论文《An Attentive Survey of Attention Models》(&lt;a href="https://arxiv.org/abs/1904.02874">https://arxiv.org/abs/1904.02874&lt;/a>)&lt;/li>
&lt;li>本文试图通过通俗的比喻、实际的代码，解读论文中复杂、抽象的算法流程。如下图：&lt;/li>
&lt;li>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919174833717.png" alt="image-20230919174833717">&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>本文进一步解读了QKV注意力、自注意力、多头注意力，为后续解读Transformer神经网络架构(如下图)奠定基础知识。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Transformer%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E9%83%A8%E4%BB%B64/image-20230919174725878.png" alt="image-20230919174725878">&lt;/p>
&lt;p>解读GPT背后的论文及实现技术实属不易，&lt;/p>
&lt;p>从N-Gram到词嵌入，再到神经概率语言模型，再到Seq2Seq，直到本文的注意力机制，&lt;/p>
&lt;p>我们距离自行实现一个简化版大语言模型越来越近了，同时笔者也受益匪浅。&lt;/p>
&lt;p>欢迎各位小伙伴探讨交流，我们继续探索这个有趣的技术领域！&lt;/p></description></item><item><title>【chatGPT】学习笔记12-昇腾计算产业发展白皮书解读</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/</link><pubDate>Tue, 12 Sep 2023 19:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/</guid><description>&lt;p>本文来解读华为的《昇腾计算产业发展白皮书》，跟踪一下国内AI行业的宏观动态。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230912224057905.png" alt="image-20230912224057905">&lt;/p>
&lt;h2 id="1ai发展趋势和挑战">1.AI发展趋势和挑战&lt;/h2>
&lt;h3 id="11ai发展趋势">1.1.AI发展趋势&lt;/h3>
&lt;p>白皮书首先阐述了AI发展趋势：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>AI已成为推动社会发展的关键引擎&lt;/strong>：
&lt;ul>
&lt;li>AI在诸多特定领域超过人类能力。如：计算机视觉、语音识别、自然语言处理领域。&lt;/li>
&lt;li>AI将助力各产业实现智能化转型升级。根据弗若斯特沙利文数据，2019年中国AI市场规模为598.6亿元，2020~2024年复合增长率达34.8%。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>AI处于爆发式创新的前夜&lt;/strong>：
&lt;ul>
&lt;li>联接、AI、云、计算、行业应用等多种先进技术和机会将会互相催化、有机融合。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="12ai产业挑战">1.2.AI产业挑战&lt;/h3>
&lt;p>白皮书再阐述了AI产业的挑战：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>计算系统&lt;/strong>要满足AI场景的&lt;strong>复杂巨大、多样性的计算需求&lt;/strong>。
&lt;ul>
&lt;li>&lt;strong>算力增速快&lt;/strong>：2012~2018年，算力需求增加30万倍，远超摩尔定律。大语言模型时代，算力需求从TFLOPS级别，增至PFLOPS级别，甚至EFLOPS级别。&lt;/li>
&lt;li>&lt;strong>计算架构设计面临挑战&lt;/strong>：大规模算力需求，对计算系统的&lt;strong>计算性能、通信性能、可扩展性&lt;/strong>是巨大的挑战。&lt;/li>
&lt;li>&lt;strong>全方位面临挑战&lt;/strong>：基础软件、编程模型、编程语言、编译器、工具链、大规模运行时、调度系统、平台软件、通信组件、加速组件、加速引擎、AI框架、行业软件，都需要适配大规模算力需求。&lt;/li>
&lt;li>参考：https://openai.com/research/ai-and-compute&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/ai-and-compute-all.png" alt="ai-and-compute-all">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>从算法到产品化落地&lt;/strong>面临8大鸿沟：
&lt;ul>
&lt;li>&lt;strong>模型获取&lt;/strong>鸿沟：针对行业数据，选择、测试合适地模型，需要巨大的时间成本和算力成本。&lt;/li>
&lt;li>&lt;strong>数据准备&lt;/strong>鸿沟：构建能够真实反映实际业务数据分布的数据集，面临较大挑战。&lt;/li>
&lt;li>&lt;strong>模型训练&lt;/strong>鸿沟：超参数调优等模型训练环节，对大量传统行业开发者挡在AI门外。&lt;/li>
&lt;li>&lt;strong>准确度验证&lt;/strong>鸿沟：模型泛化能力的验证，是阻碍算法快速落地的因素之一。&lt;/li>
&lt;li>&lt;strong>应用开发&lt;/strong>鸿沟：AI需要接受包含行业知识的各种输入数据，对AI应用开发系统产生整合要求，开发效率是重要影响因素之一。&lt;/li>
&lt;li>&lt;strong>NPU性能&lt;/strong>鸿沟：AI算力真正转化为行业生产率，实际的运行性能将决定系统最终的性价比和业务执行能力。&lt;/li>
&lt;li>&lt;strong>业务流程监控&lt;/strong>鸿沟：确保AI系统在业务环境的持续准确运行，是行业应用的重中之重。&lt;strong>AI算法需要具备持续更新、增量学习的能力&lt;/strong>。&lt;/li>
&lt;li>&lt;strong>适配开发&lt;/strong>鸿沟：面对不同业务场景，需要以服务化和API形式封装AI算法，封装AI服务、部署AI服务于复杂的计算系统上，都将面临挑战。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230912232100695.png" alt="image-20230912232100695">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>可信AI&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>AI具有自我演化潜力&lt;/strong>：人类对于AI核心运行机制、AI隐式编程、学习能力，依然没有彻底研究清楚。&lt;/li>
&lt;li>&lt;strong>可信AI是大规模商用的基础&lt;/strong>：保护隐私、避免偏见、防止滥用、可靠边界、可解释、鲁棒性、防攻击等方面，都是AI能够真正大规模应用的挑战。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>人才需求&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>AI人才缺口巨大&lt;/strong>：中国AI人才缺口500万，供求比1:10。&lt;/li>
&lt;li>&lt;strong>与美国差距巨大&lt;/strong>：中国的AI人才数量仅为美国四分之一。&lt;/li>
&lt;li>&lt;strong>新一代AI发展规划&lt;/strong>：国务院《新一代AI发展规划》发布，明确指出建立AI高端人才队伍是AI发展重中之重。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="2昇腾计算产业">2.昇腾计算产业&lt;/h2>
&lt;h3 id="21昇腾计算产业体系和定位">2.1.昇腾计算产业体系和定位&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>昇腾计算产业覆盖全产业链，全生态链&lt;/strong>，包括：昇腾处理器、硬件、CANN(Compute Architecture for Neural Networks，异构计算架构)、AI计算框架、应用使能、开发工具链、运维工具、行业应用及服务。&lt;/li>
&lt;li>&lt;strong>昇腾计算硬件体系&lt;/strong>包括：
&lt;ul>
&lt;li>基于达芬奇内核的昇腾系列芯片，提供多样化AI算力。&lt;/li>
&lt;li>基于昇腾系列芯片的硬件产品，如嵌入式模组、板卡、小站、服务器、集群等。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>昇腾计算软件体系&lt;/strong>包括：
&lt;ul>
&lt;li>异构计算架构CANN，对标CUDA。&lt;/li>
&lt;li>AI计算框架MindSpore，对标Pytorch。&lt;/li>
&lt;li>工具链：运行时、加速库、编译器、调试调优工具、开发工具链MindStudio及运维工具。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>昇腾应用使能&lt;/strong>：基于MindX支撑的ModelArts、HiAI等。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230912234104109.png" alt="image-20230912234104109">&lt;/p>
&lt;h3 id="22昇腾计算产业价值">2.2.昇腾计算产业价值&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>硬件开放、软件开元、使能合作伙伴&lt;/strong>是华为构建昇腾生态的方式。&lt;/li>
&lt;li>华为&lt;strong>聚焦AI芯片、基础软件&lt;/strong>的创新与研发。&lt;/li>
&lt;li>&lt;strong>自有硬件+伙伴硬件&lt;/strong>，为客户提供多样化算力选择。&lt;/li>
&lt;li>昇腾通过模组、板卡、小站、服务器、集群等产品形态，&lt;strong>打造&amp;quot;端、边、云&amp;quot;的全场景AI基础设施解决方案&lt;/strong>。&lt;/li>
&lt;li>昇腾计算产业的三个愿景：
&lt;ul>
&lt;li>&lt;strong>用得起&lt;/strong>&lt;/li>
&lt;li>&lt;strong>用得好&lt;/strong>&lt;/li>
&lt;li>&lt;strong>用得放心&lt;/strong>：特指某国的芯片封锁吧。。。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="3昇腾计算技术体系">3.昇腾计算技术体系&lt;/h2>
&lt;h3 id="31昇腾计算架构">3.1.昇腾计算架构&lt;/h3>
&lt;p>下图展开了昇腾计算架构细节，从架构中可以看出：&lt;/p>
&lt;ul>
&lt;li>昇腾计算架构支持端边云全场景。&lt;/li>
&lt;li>超强算力：Atlas训练卡提供320 TFLOPS FP16高算力，Atlas集群提供1024P FLOPS算力。&lt;/li>
&lt;li>全站开放，模块间具备相互协同能力、各层之间支持独立演进。&lt;/li>
&lt;li>MindX将设备资源、算力资源抽象并管理，应用软件无需了解底层硬件的复杂配置和调度。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230912235737889.png" alt="image-20230912235737889">&lt;/p>
&lt;h3 id="32硬件体系">3.2.硬件体系&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>昇腾系列处理器&lt;/strong>：NPU针对矩阵运算进行专门优化设计，华为达芬奇架构面向AI计算设计的架构，独创16&lt;em>16&lt;/em>16的3D Cube设计。&lt;/li>
&lt;li>&lt;strong>模组和板卡&lt;/strong>：Atlas 200加速模块、Atlas 300推理卡、Atlas 900。&lt;/li>
&lt;li>&lt;strong>小站&lt;/strong>：基于昇腾系列处理器的边缘计算盒子。&lt;/li>
&lt;li>&lt;strong>服务器&lt;/strong>：Atlas 800、Atlas500。&lt;/li>
&lt;li>&lt;strong>集群&lt;/strong>：Atlas 900。&lt;/li>
&lt;/ul>
&lt;h3 id="33基础软件">3.3.基础软件&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>异构计算架构&lt;/strong>：
&lt;ul>
&lt;li>CANN支持10种设备形态、EMUI、Android、openEuler、UOS、Ubuntu、Debian、Suse等14种操作系统和AI计算框架。&lt;/li>
&lt;li>CANN是一个开发体系，包含了编程语言、编译器等编程模型。&lt;/li>
&lt;li>CANN包含4层：
&lt;ul>
&lt;li>Driver实现硬件和操作系统的适配。&lt;/li>
&lt;li>Runtime、DVPP、HCCL提供内存管理、算力分配、资源调度。其中，HCCL，Huawei Collective Communication Library，华为集合通信库，提供板间和框间通信能力。&lt;/li>
&lt;li>图引擎实现了大计算图拆分、图融合，最大化芯片算力利用率。&lt;/li>
&lt;li>AscendCL提供插件适配、开放图融合接口、支持自定义算子融合、提供Ascend IR中间表达接口、支持自定义模型、开放预置算子库。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>CANN提供两种算子开发方式，
&lt;ul>
&lt;li>一种是TBE-DSL(Tensor Boost Engine-Domain Specific Language)，实现数据切分和调度。&lt;/li>
&lt;li>一种是TBE-TIK(Tensor Iterator Kernel)，通过指令级编程，实现数据编排、计算表达。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230913000935774.png" alt="image-20230913000935774">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>开发工具链MindStudio，提供工程管理、编译、调试、运行、性能分析等全流程开发。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>AI计算框架MindSpore，提供动静态图转换、自动并行、端边云协同能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>应用使能的核心是MindX DL和MindX Edge，封装了底层硬件、算子的协同调度能力。&lt;/p>
&lt;ul>
&lt;li>MindX DL架构图：&lt;/li>
&lt;li>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230913001119293.png" alt="image-20230913001119293">&lt;/li>
&lt;li>MindX Edge架构图：&lt;/li>
&lt;li>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230913001132605.png" alt="image-20230913001132605">&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="4行业实践">4.行业实践&lt;/h2>
&lt;p>白皮书在本章节阐述了基于昇腾计算，构建的各行各业的解决方案：&lt;/p>
&lt;ul>
&lt;li>AI计算中心&lt;/li>
&lt;li>互联网&lt;/li>
&lt;li>制造&lt;/li>
&lt;li>机器人&lt;/li>
&lt;li>能源&lt;/li>
&lt;li>金融&lt;/li>
&lt;li>平安城市&lt;/li>
&lt;li>电信&lt;/li>
&lt;li>交通&lt;/li>
&lt;li>医疗&lt;/li>
&lt;/ul>
&lt;p>这里展开3个行业解决方案：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>计算中心&lt;/strong>解决方案：从解决方案看，昇腾计算覆盖了AI芯片、AI驱动，是AI最核心的基础设施，完全国产化，很牛。
&lt;ul>
&lt;li>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230913004001231.png" alt="image-20230913004001231">&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>工业&lt;/strong>解决方案：针对半导体晶圆质检，基于昇腾强大算力，实现工业领域的目标定位、测量、质检等能力。这一点真正突破了AI在工业领域落地的，很牛。
&lt;ul>
&lt;li>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230913004208756.png" alt="image-20230913004208756">&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>交通&lt;/strong>解决方案：
&lt;ul>
&lt;li>高速自由流收费稽核&lt;/li>
&lt;li>交通视频云&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="5产业生态">5.产业生态&lt;/h2>
&lt;p>在产业政策方面：&lt;/p>
&lt;ul>
&lt;li>昇腾与各地政府共建昇腾生态创新中心&lt;/li>
&lt;li>通过行业联盟聚拢厂家、ISV、用户，建立各行业标杆。&lt;/li>
&lt;/ul>
&lt;p>在开发者方面：&lt;/p>
&lt;ul>
&lt;li>90%的开发者聚焦于基于AI算法的应用软件开发。&lt;/li>
&lt;li>10%的开发者聚焦AI算法、AI驱动的开发。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230913004825461.png" alt="image-20230913004825461">&lt;/p>
&lt;p>在高校培养方面：&lt;/p>
&lt;ul>
&lt;li>昇腾与高校共建AI人才培养基地，与各高校推出昇腾计算体系课程与教材。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230913005027655.png" alt="image-20230913005027655">&lt;/p>
&lt;p>在合作伙伴方面：&lt;/p>
&lt;ul>
&lt;li>昇腾推出覆盖软件开发商、硬件开发商、云服务供应商、设备制造商等各类合作伙伴计划，华为为合作伙伴提供了资金+市场。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/image-20230913005123533.png" alt="image-20230913005123533">&lt;/p>
&lt;h2 id="6未来展望昇腾推动ai成为通用目的技术">6.未来展望：昇腾推动AI成为通用目的技术&lt;/h2>
&lt;p>引用白皮书中的一段话：&lt;strong>把数字世界带入每个人、每个家庭、每个组织，构建万物互联的智能世界&lt;/strong>。&lt;/p>
&lt;p>昇腾计算产业的愿景是作为中国的AI基石，AI的基础设施，成为通用目的技术。&lt;/p>
&lt;h2 id="7总结">7.总结&lt;/h2>
&lt;p>当我第一次看到昇腾的AI芯片层，CANN对标CUDA，无比惊讶、激动、自豪，这可是对标英伟达的大事，技术难度、商业难度都不可想象。&lt;/p>
&lt;p>昇腾计算已雏形初见，这可不是短期突击出来的。不得不说，华为在AI领域的持续投资令人钦佩！&lt;/p></description></item><item><title>【chatGPT】学习笔记11-LLM应用-垂直领域知识问答系统(基于ChatGLM2)</title><link>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-llm%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E5%9F%BA%E4%BA%8Echatglm2/</link><pubDate>Tue, 05 Sep 2023 19:00:59 +0800</pubDate><guid>https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-llm%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E5%9F%BA%E4%BA%8Echatglm2/</guid><description>&lt;p>今天我们再来写一篇关于大语言模型的实战应用——如何开发一个垂直领域的知识问答系统？&lt;/p>
&lt;h1 id="1原理">1.原理&lt;/h1>
&lt;h2 id="1基于传统技术的实现方案">(1)基于传统技术的实现方案&lt;/h2>
&lt;p>在没有大语言模型之前，有如下传统技术实现知识问答系统：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>关键词匹配&lt;/strong>：在系统内预设一些关键词，系统根据用户提出的问题进行关键词匹配，从中提取出匹配的答案。
&lt;ul>
&lt;li>&lt;strong>局限性&lt;/strong>：仅适用于简单、明确的问题，但复杂问题、多义词等，效果就不好。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>规则匹配&lt;/strong>：在系统内预设一些规则模板，系统根据用户提出的问题结构进行匹配，这些规则模板包括：语法规则、语义规则、业务领域规则。
&lt;ul>
&lt;li>&lt;strong>局限性&lt;/strong>：需要人类专家编写规则模板，对领域知识的抽象和表达能力有一定要求。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>统计方法&lt;/strong>：系统基于统计学模型构建，如：条件随机场(CRF，Conditional Random Field)，进行问题分类、命名实体识别等。
&lt;ul>
&lt;li>&lt;strong>局限性&lt;/strong>：强依赖数据，数据采集、数据清洗、数据标注，都要消耗人类巨大的工作量。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>知识图谱&lt;/strong>：系统基于领域相关的知识图谱或实体构建，可以通过图谱中的实体、关系和属性实现问题解析和答案生成。
&lt;ul>
&lt;li>&lt;strong>局限性&lt;/strong>：需要人类专家对业务领域的知识进行建模、抽象，好不容易构建好，知识刷新了。。。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="2基于大语言模型的实现方案">(2)基于大语言模型的实现方案&lt;/h2>
&lt;p>和老李师傅聊大语言模型，他说：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>大语言模型，是从&lt;strong>word&lt;/strong>到&lt;strong>world&lt;/strong>的过程——AI学习一堆word的关系，然后就具备了概括、抽象、推理的能力去描述世界。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>人类程序员，是从&lt;strong>world&lt;/strong>到&lt;strong>word&lt;/strong>的过程——人类学习这个世界，然后用代码描述世界(代码就是一堆word的组合)。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>最后，他老人家感叹道：&amp;ldquo;N年后，别人看我们，就像我们看伏尔加河上的纤夫。纤夫光着腚，我们光着头。&amp;rdquo;&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230905163751495.png" alt="image-20230905163751495">&lt;/p>
&lt;p>的确如此，相较于前述传统技术，基于大语言模型实现知识问答系统，有很多天然优势：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>学习效率高&lt;/strong>：大语言模型学习速度极快。后文实践章节中，有这么一个例子：我找公路军团的同学要了1000多份交通专业的文档和书籍，大语言模型&lt;strong>1分钟学习10个文档，2小时学完1000份&lt;/strong>，而&lt;strong>每小时只消耗了1.39元&lt;/strong>。这位交通领域的专家无比惊讶地告诉我——这1000多个文档，他也只详细看完了其中200个。&lt;/li>
&lt;li>&lt;strong>无需人工干预&lt;/strong>：传统技术需要大量的人工干预，特别强依赖人类专家那些&lt;strong>只可意会、不可言传&lt;/strong>的经验。而大语言模型可以自动学习和更新知识，无需人工干预。这意味着问答应用可以及时获取最新的知识，随着时间的推移变得更加智能和准确。&lt;/li>
&lt;li>&lt;strong>多轮对话&lt;/strong>：大语言模型还可以处理复杂的问题和多轮对话。它能够理解问题的语义和上下文，并根据用户的追问进行适当的回答。这使得问答应用更加交互式和人性化，提供更好的用户体验。&lt;/li>
&lt;li>……好处太多，省略千言万语……&lt;/li>
&lt;/ul>
&lt;h2 id="3大语言模型选型">(3)大语言模型选型&lt;/h2>
&lt;p>大语言模型的选型需要根据LLM App的应用场景，并且也不是只选1个，而是选择N个，形成大语言模型矩阵。&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906090930061.png" alt="image-20230906090930061">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>世界知识&lt;/strong>：从世界知识看，目前主流的LLM如下：
&lt;ul>
&lt;li>&lt;strong>GPT系&lt;/strong>：当红炸子鸡的它，提供的接口包括&lt;code>Model&lt;/code>、&lt;code>Completions&lt;/code>、&lt;code>Chat&lt;/code>、&lt;code>Edits&lt;/code>、&lt;code>Images&lt;/code>、&lt;code>Embeddings&lt;/code>、&lt;code>Audio&lt;/code>、&lt;code>Files&lt;/code>、&lt;code>Fine-tunes&lt;/code>、&lt;code>Others&lt;/code>等10大类，完整地覆盖了&lt;strong>训练&lt;/strong>、&lt;strong>推理&lt;/strong>场景。针对&lt;strong>微调场景&lt;/strong>，覆盖了词嵌入、微调，在&lt;strong>推理&lt;/strong>场景，覆盖了预测、聊天、修正、多模态。&lt;strong>知识文档不涉密且不差钱&lt;/strong>的公司，可直接使用。笔者为了测试GPT4的API，&lt;font color=green>&lt;strong>半小时就花光了40大洋&lt;/strong>&lt;/font>，求赞助！&lt;/li>
&lt;li>&lt;strong>LLama系&lt;/strong>：卷王Meta的开源大戏，LLama一出，瞬间抢走了chatGPT的焦点。随后各顶流大学就开始了基于LLama的训练微调，推出了以Vicuna、Alpaca为代表的一系列模型。LLama2发布后更是好评无数，没几天又推出了最会写代码的CodeLLama。。。大语言模型界的卷王实至名归！&lt;/li>
&lt;li>&lt;strong>Claude系&lt;/strong>：谷歌前员工的大神们拉旗单干的产品，也是GPT系的强劲对手。&lt;/li>
&lt;li>&lt;strong>GLM系&lt;/strong>：清华大学出品，公司化商业运作。chatGLM的中文能力非常不错，GLM-130B成为2022年亚洲唯一入选全球30个主流大模型全方位测评报告的候选对象。国货之光，本文的知识问答系统就是演示的它。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>模型系列&lt;/th>
&lt;th>版本&lt;/th>
&lt;th>厂商/机构&lt;/th>
&lt;th>开源or闭源&lt;/th>
&lt;th>调用形式&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>GPT系&lt;/td>
&lt;td>GPT3.5Turbo、GPT4&lt;/td>
&lt;td>OpenAI&lt;/td>
&lt;td>闭源&lt;/td>
&lt;td>远程调用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>LLama系&lt;/td>
&lt;td>LLama、LLama2、CodeLLama&lt;/td>
&lt;td>Meta&lt;/td>
&lt;td>开源&lt;/td>
&lt;td>本地调用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Claude系&lt;/td>
&lt;td>Claude-instant、Claude-2-100k&lt;/td>
&lt;td>Anthropic&lt;/td>
&lt;td>闭源&lt;/td>
&lt;td>远程调用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>GLM系&lt;/td>
&lt;td>chatGLM2、GLM-130B、VisualGLM-6B&lt;/td>
&lt;td>清华大学&lt;/td>
&lt;td>开源&lt;/td>
&lt;td>本地调用&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>&lt;strong>领域知识&lt;/strong>：以编程辅助领域为例，目前表现不错的LLM如下：&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>模型系列&lt;/th>
&lt;th>版本&lt;/th>
&lt;th>厂商/机构&lt;/th>
&lt;th>开源or闭源&lt;/th>
&lt;th>调用形式&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>BigCode系&lt;/td>
&lt;td>StarCoder、OctoPack、SantaCoder&lt;/td>
&lt;td>Hugging Face&lt;/td>
&lt;td>开源&lt;/td>
&lt;td>本地调用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>LLama系&lt;/td>
&lt;td>CodeLLama&lt;/td>
&lt;td>Meta&lt;/td>
&lt;td>开源&lt;/td>
&lt;td>本地调用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>GLM系&lt;/td>
&lt;td>CodeGeeX2&lt;/td>
&lt;td>清华大学&lt;/td>
&lt;td>开源&lt;/td>
&lt;td>本地调用&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>综上分析：&lt;/p>
&lt;ul>
&lt;li>对世界知识的表现体现的是大语言模型的&lt;strong>通才&lt;/strong>，对领域知识的表现体现的是大语言模型的&lt;strong>专才&lt;/strong>。&lt;/li>
&lt;li>在没有一个大语言模型即是通才又是专才的限制下，垂直领域知识问答系统需要的是&lt;strong>大语言模型矩阵&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;h2 id="4大语言模型之外的关键技术">(4)大语言模型之外的关键技术&lt;/h2>
&lt;p>是不是选择好了大语言模型，LLM APP就信手拈来呢？很不幸，不是！&lt;/p>
&lt;p>在最近的一次行业交流中，有两个议题值得思考：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>量变引起质变&lt;/strong>：百度智能云/技术委员会主席王耀，针对大语言模型的训练推理场景，阐述了通用云计算、分布式云、智能计算的计算范式的变化。其中，最心酸的一个故事是：以前硬件上某个万分之一的故障是可以接受的，现在不可以了，因为大语言模型训练的计算量级无比巨大！&lt;/li>
&lt;li>&lt;strong>淘金时代的卖铲人&lt;/strong>：LangChain CEO Harrision Chase分享的议题是《Why LangChain，What I Saw When Building AI Application with LLM》，在各大厂商逐鹿中原的时候，LangChain忽然火了，按照这个趋势，它应该会成为LLM APP的开发框架了。&lt;/li>
&lt;/ul>
&lt;p>因为，&lt;strong>训练&lt;/strong>大语言模型的计算量剧增，对原有的云计算有新的诉求。&lt;/p>
&lt;p>因为，&lt;strong>粘合&lt;/strong>大语言模型需要有很多工作，需要有LLM APP的开发框架。&lt;/p>
&lt;p>通过LangChain的特性介绍和架构，我们可以知道大语言模型之外，我们还需要做如下事情：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>文本处理&lt;/strong>：对各类型文档的加载，对文本的切分等。&lt;/li>
&lt;li>&lt;strong>向量存储&lt;/strong>：适配不同向量数据库，将文档内容向量化并存储。&lt;/li>
&lt;li>&lt;strong>提示词管理&lt;/strong>：创建提示词模板，最大化重用提示词。&lt;/li>
&lt;li>&lt;strong>模型适配&lt;/strong>：针对不同厂商，适配各类大语言模型的接口。&lt;/li>
&lt;li>&lt;strong>输出解析&lt;/strong>：对大语言模型输出的文本进行结构化解析。&lt;/li>
&lt;/ul>
&lt;p>具体可以看笔者这篇文章：《【chatGPT】学习笔记10-LangChain之ModelIO，对LLM的抽象1》&lt;/p>
&lt;h2 id="5架构示例langchain-chatchat">(5)架构示例：LangChain-ChatChat&lt;/h2>
&lt;p>垂直领域问答系统的开源项目已经有很多了，以LangChain-ChatChat为例，可以看到这类LLM APP的软件架构：&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906095324183.png" alt="image-20230906095324183">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>训练环节&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Unstructured Loader&lt;/strong>：负责将知识文档加载并解析。&lt;/li>
&lt;li>&lt;strong>Text Splitter&lt;/strong>：将文档按照标点符号，拆分断句。&lt;/li>
&lt;li>&lt;strong>Text Chunks&lt;/strong>：将断句分词分组，分词分组间存在一定的上下文关联。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906095608282.png" alt="image-20230906095608282">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Embedding&lt;/strong>：词嵌入，并将词向量存储于向量数据库中。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>应用环节&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Query Embedding&lt;/strong>：将用户提问转换了词向量。&lt;/li>
&lt;li>&lt;strong>Vector Similarity&lt;/strong>：在向量数据库中，用问题词向量，去搜索相关的知识文本向量。&lt;/li>
&lt;li>&lt;strong>Related Text Chunks&lt;/strong>：根据相关的知识文本向量，反查出对应的知识文本分词分组。这里有个细节，还会将文本分词分组的前后分词分组一并返回(因为这些文字可能有上下文关联关系)。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906100110319.png" alt="image-20230906100110319">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Prompt Template&lt;/strong>：提示词模板，这个模块是知识问答系统的关键！最简单的提示词模板就是：
&lt;ul>
&lt;li>&lt;strong>已知&lt;/strong>：[Related Text Chunks获得的知识文本分词分组]，&lt;strong>请问&lt;/strong>[用户的问题]如何答复？&lt;/li>
&lt;li>这，不就是开卷考试吗？&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906100510639.png" alt="image-20230906100510639">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>从上述架构可以看出来，曾经很复杂的知识问答系统，大部分核心难点，都被大语言模型搞定了。&lt;/p>
&lt;p>接下来，我们来动手实践一下，构建一个我们自己的知识问答系统。&lt;/p>
&lt;h1 id="2实践">2.实践&lt;/h1>
&lt;h2 id="21推理环境搭建">2.1.推理环境搭建&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>STEP1.基于MiniCoda，创建虚拟环境&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906101650577.png" alt="image-20230906101650577">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP2.激活虚拟环境，安装运行时环境&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906101852342.png" alt="image-20230906101852342">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP3.下载依赖。&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102057137.png" alt="image-20230906102057137">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP5.初始化向量数据库。&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102553686.png" alt="image-20230906102553686">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP6.配置model_config.py、server_config.py、llm_api.py。&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102733935.png" alt="image-20230906102733935">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102716203.png" alt="image-20230906102716203">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102703074.png" alt="image-20230906102703074">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102652268.png" alt="image-20230906102652268">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP7.启动应用&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906103336869.png" alt="image-20230906103336869">&lt;/p>
&lt;h2 id="22模型部署">2.2.模型部署&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>STEP1.下载大语言模型和词嵌入模型&lt;/strong>——chatGLM2-6B、m3e-base&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102213647.png" alt="image-20230906102213647">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102246753.png" alt="image-20230906102246753">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STEP2.部署大语言模型和词嵌入模型。&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906103747404.png" alt="image-20230906103747404">&lt;/p>
&lt;h2 id="23模型微调">2.3.模型微调&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>STEP1.通过WebUI，上传知识文档。&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906103254463.png" alt="image-20230906103254463">&lt;/p>
&lt;ul>
&lt;li>&lt;font color=red>&lt;strong>STEP2.编写提示词模板&lt;/strong>&lt;/font>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906104642146.png" alt="image-20230906104642146">&lt;/p>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906104709680.png" alt="image-20230906104709680">&lt;/p>
&lt;ul>
&lt;li>经过2小时的学习，LLM修炼完了1000多份智慧交通的资料，这学习效率杠杠滴！
&lt;ul>
&lt;li>PS：感谢公路军团的专家，提供珍藏多年的资料，改天请您吃饭！&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://jherculesqz.github.io/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906105032126.png" alt="image-20230906105032126">&lt;/p>
&lt;h2 id="24模型测试">2.4.模型测试&lt;/h2>
&lt;p>直接上视频，咨询了一下交通行业的这位专家，回答挺靠谱：&lt;/p>
&lt;iframe src="//player.bilibili.com/player.html?aid=830744059&amp;bvid=BV1C34y1N7QG&amp;cid=1258811184&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=600px> &lt;/iframe>
&lt;h1 id="3总结">3.总结&lt;/h1>
&lt;p>本文阐述了基于大语言模型的知识问答系统的实现原理及原型实践过程，原型距离可商用还有很多细节需打磨，但我们可以得到如下观点：&lt;/p>
&lt;ul>
&lt;li>从实现原理看：
&lt;ul>
&lt;li>&lt;strong>技术关键点1&lt;/strong>：要&lt;font color=red>&lt;strong>选择合适的多种大语言模型，形成大语言模型的矩阵&lt;/strong>&lt;/font>。&lt;/li>
&lt;li>&lt;strong>技术关键点2&lt;/strong>：除大语言模型选型，还需&lt;strong>借助LangChain处理好诸多环节&lt;/strong>(文档结构化、分段分词、词嵌入、上下文、向量搜索、提示词等)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>从实践看：
&lt;ul>
&lt;li>&lt;strong>数据&lt;/strong>：数据收集、数据清洗、词嵌入等，极为重要。&lt;/li>
&lt;li>&lt;strong>大语言模型&lt;/strong>：需跟踪各大厂商大语言模型的最新能力，快速替换到应用软件中，&lt;font color=red>&lt;strong>保持大语言模型的先进性&lt;/strong>&lt;/font>。&lt;/li>
&lt;li>&lt;strong>提示词&lt;/strong>：提示词模板的设计，决定了能否&lt;font color=red>&lt;strong>充分发挥大语言模型的潜力&lt;/strong>&lt;/font>。&lt;/li>
&lt;li>&lt;strong>工具链&lt;/strong>：熟练运用LangChain、向量数据库等工具，有助于设计并实现适应业务场景的问答业务流。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>今天就写到这里，后续专栏会继续展示基于大语言模型的LLM应用，欢迎共同探索(上述环境已做成镜像，需要的同学可后台联系作者)。&lt;/p></description></item></channel></rss>