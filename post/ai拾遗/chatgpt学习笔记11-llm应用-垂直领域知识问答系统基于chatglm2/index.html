<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>【chatGPT】学习笔记11-LLM应用-垂直领域知识问答系统(基于ChatGLM2) - 妙木山</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="猴王无敌"><meta name=description content="今天我们再来写一篇关于大语言模型的实战应用——如何开发一个垂直领域的知识问答系统？ 1.原理 (1)基于传统技术的实现方案 在没有大语言模型之前，"><meta name=keywords content="Hugo,theme,jane"><meta name=generator content="Hugo 0.74.2"><link rel=canonical href=https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-llm%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E5%9F%BA%E4%BA%8Echatglm2/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.b3a8813c06e6d785beba22bf8264e174fa2cb3a396b22f9ba24e2c00c18aaf7f.css integrity="sha256-s6iBPAbm14W+uiK/gmThdPoss6OWsi+bok4sAMGKr38=" media=screen crossorigin=anonymous><meta property="og:title" content="【chatGPT】学习笔记11-LLM应用-垂直领域知识问答系统(基于ChatGLM2)"><meta property="og:description" content="今天我们再来写一篇关于大语言模型的实战应用——如何开发一个垂直领域的知识问答系统？ 1.原理 (1)基于传统技术的实现方案 在没有大语言模型之前，"><meta property="og:type" content="article"><meta property="og:url" content="https://jherculesqz.github.io/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-llm%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E5%9F%BA%E4%BA%8Echatglm2/"><meta property="article:published_time" content="2023-09-05T19:00:59+08:00"><meta property="article:modified_time" content="2023-09-05T19:00:59+08:00"><meta itemprop=name content="【chatGPT】学习笔记11-LLM应用-垂直领域知识问答系统(基于ChatGLM2)"><meta itemprop=description content="今天我们再来写一篇关于大语言模型的实战应用——如何开发一个垂直领域的知识问答系统？ 1.原理 (1)基于传统技术的实现方案 在没有大语言模型之前，"><meta itemprop=datePublished content="2023-09-05T19:00:59+08:00"><meta itemprop=dateModified content="2023-09-05T19:00:59+08:00"><meta itemprop=wordCount content="3889"><meta itemprop=keywords content="AI拾遗-chat GPT,"><meta name=twitter:card content="summary"><meta name=twitter:title content="【chatGPT】学习笔记11-LLM应用-垂直领域知识问答系统(基于ChatGLM2)"><meta name=twitter:description content="今天我们再来写一篇关于大语言模型的实战应用——如何开发一个垂直领域的知识问答系统？ 1.原理 (1)基于传统技术的实现方案 在没有大语言模型之前，"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>妙木山</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/>首页</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/categories/>技术专栏</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/tags/>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/post/>全部文章</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://jherculesqz.github.io/about/>关于</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>妙木山</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/>首页</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/categories/>技术专栏</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/post/>全部文章</a></li><li class=menu-item><a class=menu-item-link href=https://jherculesqz.github.io/about/>关于</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>【chatGPT】学习笔记11-LLM应用-垂直领域知识问答系统(基于ChatGLM2)</h1><div class=post-meta><time datetime=2023-09-05 class=post-time>2023-09-05</time><div class=post-category><a href=https://jherculesqz.github.io/categories/ai%E6%8B%BE%E9%81%97/>AI拾遗</a></div><span class=more-meta>约 3889 字</span>
<span class=more-meta>预计阅读 8 分钟</span>
<span id=busuanzi_container_page_pv>| 阅读 <span id=busuanzi_value_page_pv></span></span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#1原理>1.原理</a><ul><li><a href=#1基于传统技术的实现方案>(1)基于传统技术的实现方案</a></li><li><a href=#2基于大语言模型的实现方案>(2)基于大语言模型的实现方案</a></li><li><a href=#3大语言模型选型>(3)大语言模型选型</a></li><li><a href=#4大语言模型之外的关键技术>(4)大语言模型之外的关键技术</a></li><li><a href=#5架构示例langchain-chatchat>(5)架构示例：LangChain-ChatChat</a></li></ul></li><li><a href=#2实践>2.实践</a><ul><li><a href=#21推理环境搭建>2.1.推理环境搭建</a></li><li><a href=#22模型部署>2.2.模型部署</a></li><li><a href=#23模型微调>2.3.模型微调</a></li><li><a href=#24模型测试>2.4.模型测试</a></li></ul></li><li><a href=#3总结>3.总结</a></li></ul></nav></div></div><div class=post-content><p>今天我们再来写一篇关于大语言模型的实战应用——如何开发一个垂直领域的知识问答系统？</p><h1 id=1原理>1.原理</h1><h2 id=1基于传统技术的实现方案>(1)基于传统技术的实现方案</h2><p>在没有大语言模型之前，有如下传统技术实现知识问答系统：</p><ul><li><strong>关键词匹配</strong>：在系统内预设一些关键词，系统根据用户提出的问题进行关键词匹配，从中提取出匹配的答案。<ul><li><strong>局限性</strong>：仅适用于简单、明确的问题，但复杂问题、多义词等，效果就不好。</li></ul></li><li><strong>规则匹配</strong>：在系统内预设一些规则模板，系统根据用户提出的问题结构进行匹配，这些规则模板包括：语法规则、语义规则、业务领域规则。<ul><li><strong>局限性</strong>：需要人类专家编写规则模板，对领域知识的抽象和表达能力有一定要求。</li></ul></li><li><strong>统计方法</strong>：系统基于统计学模型构建，如：条件随机场(CRF，Conditional Random Field)，进行问题分类、命名实体识别等。<ul><li><strong>局限性</strong>：强依赖数据，数据采集、数据清洗、数据标注，都要消耗人类巨大的工作量。</li></ul></li><li><strong>知识图谱</strong>：系统基于领域相关的知识图谱或实体构建，可以通过图谱中的实体、关系和属性实现问题解析和答案生成。<ul><li><strong>局限性</strong>：需要人类专家对业务领域的知识进行建模、抽象，好不容易构建好，知识刷新了。。。</li></ul></li></ul><h2 id=2基于大语言模型的实现方案>(2)基于大语言模型的实现方案</h2><p>和老李师傅聊大语言模型，他说：</p><ul><li><p>大语言模型，是从<strong>word</strong>到<strong>world</strong>的过程——AI学习一堆word的关系，然后就具备了概括、抽象、推理的能力去描述世界。</p></li><li><p>人类程序员，是从<strong>world</strong>到<strong>word</strong>的过程——人类学习这个世界，然后用代码描述世界(代码就是一堆word的组合)。</p></li></ul><p>最后，他老人家感叹道：&ldquo;N年后，别人看我们，就像我们看伏尔加河上的纤夫。纤夫光着腚，我们光着头。&rdquo;<img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230905163751495.png alt=image-20230905163751495></p><p>的确如此，相较于前述传统技术，基于大语言模型实现知识问答系统，有很多天然优势：</p><ul><li><strong>学习效率高</strong>：大语言模型学习速度极快。后文实践章节中，有这么一个例子：我找公路军团的同学要了1000多份交通专业的文档和书籍，大语言模型<strong>1分钟学习10个文档，2小时学完1000份</strong>，而<strong>每小时只消耗了1.39元</strong>。这位交通领域的专家无比惊讶地告诉我——这1000多个文档，他也只详细看完了其中200个。</li><li><strong>无需人工干预</strong>：传统技术需要大量的人工干预，特别强依赖人类专家那些<strong>只可意会、不可言传</strong>的经验。而大语言模型可以自动学习和更新知识，无需人工干预。这意味着问答应用可以及时获取最新的知识，随着时间的推移变得更加智能和准确。</li><li><strong>多轮对话</strong>：大语言模型还可以处理复杂的问题和多轮对话。它能够理解问题的语义和上下文，并根据用户的追问进行适当的回答。这使得问答应用更加交互式和人性化，提供更好的用户体验。</li><li>……好处太多，省略千言万语……</li></ul><h2 id=3大语言模型选型>(3)大语言模型选型</h2><p>大语言模型的选型需要根据LLM App的应用场景，并且也不是只选1个，而是选择N个，形成大语言模型矩阵。</p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906090930061.png alt=image-20230906090930061></p><ul><li><strong>世界知识</strong>：从世界知识看，目前主流的LLM如下：<ul><li><strong>GPT系</strong>：当红炸子鸡的它，提供的接口包括<code>Model</code>、<code>Completions</code>、<code>Chat</code>、<code>Edits</code>、<code>Images</code>、<code>Embeddings</code>、<code>Audio</code>、<code>Files</code>、<code>Fine-tunes</code>、<code>Others</code>等10大类，完整地覆盖了<strong>训练</strong>、<strong>推理</strong>场景。针对<strong>微调场景</strong>，覆盖了词嵌入、微调，在<strong>推理</strong>场景，覆盖了预测、聊天、修正、多模态。<strong>知识文档不涉密且不差钱</strong>的公司，可直接使用。笔者为了测试GPT4的API，<font color=green><strong>半小时就花光了40大洋</strong></font>，求赞助！</li><li><strong>LLama系</strong>：卷王Meta的开源大戏，LLama一出，瞬间抢走了chatGPT的焦点。随后各顶流大学就开始了基于LLama的训练微调，推出了以Vicuna、Alpaca为代表的一系列模型。LLama2发布后更是好评无数，没几天又推出了最会写代码的CodeLLama。。。大语言模型界的卷王实至名归！</li><li><strong>Claude系</strong>：谷歌前员工的大神们拉旗单干的产品，也是GPT系的强劲对手。</li><li><strong>GLM系</strong>：清华大学出品，公司化商业运作。chatGLM的中文能力非常不错，GLM-130B成为2022年亚洲唯一入选全球30个主流大模型全方位测评报告的候选对象。国货之光，本文的知识问答系统就是演示的它。</li></ul></li></ul><table><thead><tr><th>模型系列</th><th>版本</th><th>厂商/机构</th><th>开源or闭源</th><th>调用形式</th></tr></thead><tbody><tr><td>GPT系</td><td>GPT3.5Turbo、GPT4</td><td>OpenAI</td><td>闭源</td><td>远程调用</td></tr><tr><td>LLama系</td><td>LLama、LLama2、CodeLLama</td><td>Meta</td><td>开源</td><td>本地调用</td></tr><tr><td>Claude系</td><td>Claude-instant、Claude-2-100k</td><td>Anthropic</td><td>闭源</td><td>远程调用</td></tr><tr><td>GLM系</td><td>chatGLM2、GLM-130B、VisualGLM-6B</td><td>清华大学</td><td>开源</td><td>本地调用</td></tr></tbody></table><ul><li><strong>领域知识</strong>：以编程辅助领域为例，目前表现不错的LLM如下：</li></ul><table><thead><tr><th>模型系列</th><th>版本</th><th>厂商/机构</th><th>开源or闭源</th><th>调用形式</th></tr></thead><tbody><tr><td>BigCode系</td><td>StarCoder、OctoPack、SantaCoder</td><td>Hugging Face</td><td>开源</td><td>本地调用</td></tr><tr><td>LLama系</td><td>CodeLLama</td><td>Meta</td><td>开源</td><td>本地调用</td></tr><tr><td>GLM系</td><td>CodeGeeX2</td><td>清华大学</td><td>开源</td><td>本地调用</td></tr></tbody></table><p>综上分析：</p><ul><li>对世界知识的表现体现的是大语言模型的<strong>通才</strong>，对领域知识的表现体现的是大语言模型的<strong>专才</strong>。</li><li>在没有一个大语言模型即是通才又是专才的限制下，垂直领域知识问答系统需要的是<strong>大语言模型矩阵</strong>。</li></ul><h2 id=4大语言模型之外的关键技术>(4)大语言模型之外的关键技术</h2><p>是不是选择好了大语言模型，LLM APP就信手拈来呢？很不幸，不是！</p><p>在最近的一次行业交流中，有两个议题值得思考：</p><ul><li><strong>量变引起质变</strong>：百度智能云/技术委员会主席王耀，针对大语言模型的训练推理场景，阐述了通用云计算、分布式云、智能计算的计算范式的变化。其中，最心酸的一个故事是：以前硬件上某个万分之一的故障是可以接受的，现在不可以了，因为大语言模型训练的计算量级无比巨大！</li><li><strong>淘金时代的卖铲人</strong>：LangChain CEO Harrision Chase分享的议题是《Why LangChain，What I Saw When Building AI Application with LLM》，在各大厂商逐鹿中原的时候，LangChain忽然火了，按照这个趋势，它应该会成为LLM APP的开发框架了。</li></ul><p>因为，<strong>训练</strong>大语言模型的计算量剧增，对原有的云计算有新的诉求。</p><p>因为，<strong>粘合</strong>大语言模型需要有很多工作，需要有LLM APP的开发框架。</p><p>通过LangChain的特性介绍和架构，我们可以知道大语言模型之外，我们还需要做如下事情：</p><ul><li><strong>文本处理</strong>：对各类型文档的加载，对文本的切分等。</li><li><strong>向量存储</strong>：适配不同向量数据库，将文档内容向量化并存储。</li><li><strong>提示词管理</strong>：创建提示词模板，最大化重用提示词。</li><li><strong>模型适配</strong>：针对不同厂商，适配各类大语言模型的接口。</li><li><strong>输出解析</strong>：对大语言模型输出的文本进行结构化解析。</li></ul><p>具体可以看笔者这篇文章：《【chatGPT】学习笔记10-LangChain之ModelIO，对LLM的抽象1》</p><h2 id=5架构示例langchain-chatchat>(5)架构示例：LangChain-ChatChat</h2><p>垂直领域问答系统的开源项目已经有很多了，以LangChain-ChatChat为例，可以看到这类LLM APP的软件架构：</p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906095324183.png alt=image-20230906095324183></p><ul><li><p><strong>训练环节</strong>：</p><ul><li><strong>Unstructured Loader</strong>：负责将知识文档加载并解析。</li><li><strong>Text Splitter</strong>：将文档按照标点符号，拆分断句。</li><li><strong>Text Chunks</strong>：将断句分词分组，分词分组间存在一定的上下文关联。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906095608282.png alt=image-20230906095608282></p><ul><li><strong>Embedding</strong>：词嵌入，并将词向量存储于向量数据库中。</li></ul></li><li><p><strong>应用环节</strong>：</p><ul><li><strong>Query Embedding</strong>：将用户提问转换了词向量。</li><li><strong>Vector Similarity</strong>：在向量数据库中，用问题词向量，去搜索相关的知识文本向量。</li><li><strong>Related Text Chunks</strong>：根据相关的知识文本向量，反查出对应的知识文本分词分组。这里有个细节，还会将文本分词分组的前后分词分组一并返回(因为这些文字可能有上下文关联关系)。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906100110319.png alt=image-20230906100110319></p><ul><li><strong>Prompt Template</strong>：提示词模板，这个模块是知识问答系统的关键！最简单的提示词模板就是：<ul><li><strong>已知</strong>：[Related Text Chunks获得的知识文本分词分组]，<strong>请问</strong>[用户的问题]如何答复？</li><li>这，不就是开卷考试吗？</li></ul></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906100510639.png alt=image-20230906100510639></p></li></ul><p>从上述架构可以看出来，曾经很复杂的知识问答系统，大部分核心难点，都被大语言模型搞定了。</p><p>接下来，我们来动手实践一下，构建一个我们自己的知识问答系统。</p><h1 id=2实践>2.实践</h1><h2 id=21推理环境搭建>2.1.推理环境搭建</h2><ul><li><strong>STEP1.基于MiniCoda，创建虚拟环境</strong>。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906101650577.png alt=image-20230906101650577></p><ul><li><strong>STEP2.激活虚拟环境，安装运行时环境</strong>。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906101852342.png alt=image-20230906101852342></p><ul><li><strong>STEP3.下载依赖。</strong></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102057137.png alt=image-20230906102057137></p><ul><li><strong>STEP5.初始化向量数据库。</strong></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102553686.png alt=image-20230906102553686></p><ul><li><strong>STEP6.配置model_config.py、server_config.py、llm_api.py。</strong></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102733935.png alt=image-20230906102733935></p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102716203.png alt=image-20230906102716203></p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102703074.png alt=image-20230906102703074></p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102652268.png alt=image-20230906102652268></p><ul><li><strong>STEP7.启动应用</strong></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906103336869.png alt=image-20230906103336869></p><h2 id=22模型部署>2.2.模型部署</h2><ul><li><strong>STEP1.下载大语言模型和词嵌入模型</strong>——chatGLM2-6B、m3e-base</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102213647.png alt=image-20230906102213647></p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906102246753.png alt=image-20230906102246753></p><ul><li><strong>STEP2.部署大语言模型和词嵌入模型。</strong></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906103747404.png alt=image-20230906103747404></p><h2 id=23模型微调>2.3.模型微调</h2><ul><li><strong>STEP1.通过WebUI，上传知识文档。</strong></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906103254463.png alt=image-20230906103254463></p><ul><li><font color=red><strong>STEP2.编写提示词模板</strong></font>。</li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906104642146.png alt=image-20230906104642146></p><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906104709680.png alt=image-20230906104709680></p><ul><li>经过2小时的学习，LLM修炼完了1000多份智慧交通的资料，这学习效率杠杠滴！<ul><li>PS：感谢公路军团的专家，提供珍藏多年的资料，改天请您吃饭！</li></ul></li></ul><p><img src=/AI%E6%8B%BE%E9%81%97/%E3%80%90chatGPT%E3%80%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-LLM%E5%BA%94%E7%94%A8-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F(%E5%9F%BA%E4%BA%8EChatGLM2)/image-20230906105032126.png alt=image-20230906105032126></p><h2 id=24模型测试>2.4.模型测试</h2><p>直接上视频，咨询了一下交通行业的这位专家，回答挺靠谱：</p><iframe src="//player.bilibili.com/player.html?aid=830744059&bvid=BV1C34y1N7QG&cid=1258811184&p=1" scrolling=no border=0 frameborder=no framespacing=0 allowfullscreen height=600px></iframe><h1 id=3总结>3.总结</h1><p>本文阐述了基于大语言模型的知识问答系统的实现原理及原型实践过程，原型距离可商用还有很多细节需打磨，但我们可以得到如下观点：</p><ul><li>从实现原理看：<ul><li><strong>技术关键点1</strong>：要<font color=red><strong>选择合适的多种大语言模型，形成大语言模型的矩阵</strong></font>。</li><li><strong>技术关键点2</strong>：除大语言模型选型，还需<strong>借助LangChain处理好诸多环节</strong>(文档结构化、分段分词、词嵌入、上下文、向量搜索、提示词等)。</li></ul></li><li>从实践看：<ul><li><strong>数据</strong>：数据收集、数据清洗、词嵌入等，极为重要。</li><li><strong>大语言模型</strong>：需跟踪各大厂商大语言模型的最新能力，快速替换到应用软件中，<font color=red><strong>保持大语言模型的先进性</strong></font>。</li><li><strong>提示词</strong>：提示词模板的设计，决定了能否<font color=red><strong>充分发挥大语言模型的潜力</strong></font>。</li><li><strong>工具链</strong>：熟练运用LangChain、向量数据库等工具，有助于设计并实现适应业务场景的问答业务流。</li></ul></li></ul><p>今天就写到这里，后续专栏会继续展示基于大语言模型的LLM应用，欢迎共同探索(上述环境已做成镜像，需要的同学可后台联系作者)。</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>猴王无敌</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2023-09-05</span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><div class=post-reward><input type=checkbox name=reward id=reward hidden>
<label class=reward-button for=reward>赞赏支持</label><div class=qr-code><label class=qr-code-image for=reward><img class=image src=/weixin.png>
<span>微信打赏</span></label>
<label class=qr-code-image for=reward><img class=image src=/alipay.png>
<span>支付宝打赏</span></label></div></div><footer class=post-footer><div class=post-tags></div><nav class=post-nav><a class=prev href=/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">【chatGPT】学习笔记12-昇腾计算产业发展白皮书解读</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/ai%E6%8B%BE%E9%81%97/chatgpt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010-langchain%E4%B9%8Bmodelio%E5%AF%B9llm%E7%9A%84%E6%8A%BD%E8%B1%A11/><span class="next-text nav-default">【chatGPT】学习笔记10-LangChain之Model IO，对LLM的抽象1</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=mailto:JHercules_qz@qq.com rel="me noopener" class=iconfont title=email><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408 1361.641813S1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523L83.726336 1024H682.532949 753.579947 1348.948139L1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955C777.248 802.205449 742.347691 811.03081 718.063616 811.603883z"/></svg></a><a href=https://github.com/JHerculesqz rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=https://jherculesqz.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2021 -
2024
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>猴王无敌</span></span>
<span id=busuanzi_container>访客数/访问量：<span id=busuanzi_value_site_uv></span>/<span id=busuanzi_value_site_pv></span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script><script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script><script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script><script type=text/javascript src=/js/load-photoswipe.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>